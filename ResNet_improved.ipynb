{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YSW2/ResNet_sample/blob/master/ResNet_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag85N15pLKus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5422f4-009d-476f-9249-060c031b9911"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.get_device_name(0))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12JvW1tgLXTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94c56e3-a506-4360-b03b-dfed4a6f9b60"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number\n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "learning_rate = 0.1\n",
        "root_dir = '/content/app/'\n",
        "#default_directory = 'drive/app/torch/save_models'\n",
        "\n",
        "# Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
        "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "# automatically download\n",
        "train_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                 train=True,\n",
        "                                 transform=transform_train,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                train=False,\n",
        "                                transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
        "                                           num_workers=4)           # CPU loader number\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
        "                                          num_workers=4)            # CPU loader number\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels) #\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if downsample is not None:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False), #avgPooling?\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(in_channels=16, out_channels=32, stride=2, downsample=True),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(in_channels=32, out_channels=64, stride=2, downsample=True),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=8, stride=1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = ResNet()\n",
        "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1e-4,\n",
        "                                nesterov=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.device_count() > 0:\n",
        "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    print(\"USE ONLY CPU!\")\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    #change to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    torch.save(state, model_filename)\n",
        "    print(\"=> saving checkpoint\")\n",
        "\n",
        "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    if os.path.exists(model_filename):\n",
        "        print(\"=> loading checkpoint\")\n",
        "        state = torch.load(model_filename)\n",
        "        return state\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "#checkpoint = load_checkpoint(default_directory)\n",
        "#if not checkpoint:\n",
        "#    pass\n",
        "#else:\n",
        "#    start_epoch = checkpoint['epoch'] + 1\n",
        "#    model.load_state_dict(checkpoint['state_dict'])\n",
        "#    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "for epoch in range(start_epoch, 165):\n",
        "\n",
        "    if epoch < 80:\n",
        "        lr = learning_rate\n",
        "    elif epoch < 120:\n",
        "        lr = learning_rate * 0.1\n",
        "    else:\n",
        "        lr = learning_rate * 0.01\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    train(epoch)\n",
        "#    save_checkpoint(default_directory, {\n",
        "#        'epoch': epoch,\n",
        "#        'model': model,\n",
        "#        'state_dict': model.state_dict(),\n",
        "#        'optimizer': optimizer.state_dict(),\n",
        "#    })\n",
        "    test()\n",
        "\n",
        "now = time.gmtime(time.time() - start_time)\n",
        "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/app/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49223924.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/app/cifar-10-python.tar.gz to /content/app/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch: 43 | Batch_idx: 30 |  Loss: (0.2393) | Acc: (91.81%) (3643/3968)\n",
            "Epoch: 43 | Batch_idx: 40 |  Loss: (0.2349) | Acc: (91.84%) (4820/5248)\n",
            "Epoch: 43 | Batch_idx: 50 |  Loss: (0.2323) | Acc: (91.97%) (6004/6528)\n",
            "Epoch: 43 | Batch_idx: 60 |  Loss: (0.2238) | Acc: (92.28%) (7205/7808)\n",
            "Epoch: 43 | Batch_idx: 70 |  Loss: (0.2270) | Acc: (92.10%) (8370/9088)\n",
            "Epoch: 43 | Batch_idx: 80 |  Loss: (0.2261) | Acc: (92.04%) (9543/10368)\n",
            "Epoch: 43 | Batch_idx: 90 |  Loss: (0.2271) | Acc: (91.92%) (10707/11648)\n",
            "Epoch: 43 | Batch_idx: 100 |  Loss: (0.2267) | Acc: (91.95%) (11887/12928)\n",
            "Epoch: 43 | Batch_idx: 110 |  Loss: (0.2271) | Acc: (92.00%) (13072/14208)\n",
            "Epoch: 43 | Batch_idx: 120 |  Loss: (0.2281) | Acc: (92.02%) (14252/15488)\n",
            "Epoch: 43 | Batch_idx: 130 |  Loss: (0.2274) | Acc: (92.03%) (15431/16768)\n",
            "Epoch: 43 | Batch_idx: 140 |  Loss: (0.2263) | Acc: (92.03%) (16610/18048)\n",
            "Epoch: 43 | Batch_idx: 150 |  Loss: (0.2255) | Acc: (92.09%) (17800/19328)\n",
            "Epoch: 43 | Batch_idx: 160 |  Loss: (0.2267) | Acc: (92.05%) (18969/20608)\n",
            "Epoch: 43 | Batch_idx: 170 |  Loss: (0.2292) | Acc: (92.02%) (20141/21888)\n",
            "Epoch: 43 | Batch_idx: 180 |  Loss: (0.2291) | Acc: (92.02%) (21319/23168)\n",
            "Epoch: 43 | Batch_idx: 190 |  Loss: (0.2300) | Acc: (92.04%) (22501/24448)\n",
            "Epoch: 43 | Batch_idx: 200 |  Loss: (0.2298) | Acc: (92.08%) (23690/25728)\n",
            "Epoch: 43 | Batch_idx: 210 |  Loss: (0.2299) | Acc: (92.08%) (24869/27008)\n",
            "Epoch: 43 | Batch_idx: 220 |  Loss: (0.2298) | Acc: (92.07%) (26046/28288)\n",
            "Epoch: 43 | Batch_idx: 230 |  Loss: (0.2292) | Acc: (92.10%) (27231/29568)\n",
            "Epoch: 43 | Batch_idx: 240 |  Loss: (0.2283) | Acc: (92.13%) (28419/30848)\n",
            "Epoch: 43 | Batch_idx: 250 |  Loss: (0.2292) | Acc: (92.08%) (29584/32128)\n",
            "Epoch: 43 | Batch_idx: 260 |  Loss: (0.2289) | Acc: (92.09%) (30766/33408)\n",
            "Epoch: 43 | Batch_idx: 270 |  Loss: (0.2277) | Acc: (92.12%) (31953/34688)\n",
            "Epoch: 43 | Batch_idx: 280 |  Loss: (0.2269) | Acc: (92.11%) (33130/35968)\n",
            "Epoch: 43 | Batch_idx: 290 |  Loss: (0.2269) | Acc: (92.14%) (34320/37248)\n",
            "Epoch: 43 | Batch_idx: 300 |  Loss: (0.2269) | Acc: (92.15%) (35505/38528)\n",
            "Epoch: 43 | Batch_idx: 310 |  Loss: (0.2262) | Acc: (92.18%) (36695/39808)\n",
            "Epoch: 43 | Batch_idx: 320 |  Loss: (0.2262) | Acc: (92.20%) (37882/41088)\n",
            "Epoch: 43 | Batch_idx: 330 |  Loss: (0.2253) | Acc: (92.23%) (39077/42368)\n",
            "Epoch: 43 | Batch_idx: 340 |  Loss: (0.2252) | Acc: (92.24%) (40259/43648)\n",
            "Epoch: 43 | Batch_idx: 350 |  Loss: (0.2256) | Acc: (92.22%) (41433/44928)\n",
            "Epoch: 43 | Batch_idx: 360 |  Loss: (0.2254) | Acc: (92.23%) (42616/46208)\n",
            "Epoch: 43 | Batch_idx: 370 |  Loss: (0.2256) | Acc: (92.23%) (43798/47488)\n",
            "Epoch: 43 | Batch_idx: 380 |  Loss: (0.2266) | Acc: (92.18%) (44955/48768)\n",
            "Epoch: 43 | Batch_idx: 390 |  Loss: (0.2272) | Acc: (92.15%) (46074/50000)\n",
            "# TEST : Loss: (0.3997) | Acc: (87.44%) (8744/10000)\n",
            "Epoch: 44 | Batch_idx: 0 |  Loss: (0.3630) | Acc: (85.16%) (109/128)\n",
            "Epoch: 44 | Batch_idx: 10 |  Loss: (0.2349) | Acc: (91.26%) (1285/1408)\n",
            "Epoch: 44 | Batch_idx: 20 |  Loss: (0.2293) | Acc: (92.00%) (2473/2688)\n",
            "Epoch: 44 | Batch_idx: 30 |  Loss: (0.2204) | Acc: (92.26%) (3661/3968)\n",
            "Epoch: 44 | Batch_idx: 40 |  Loss: (0.2289) | Acc: (92.09%) (4833/5248)\n",
            "Epoch: 44 | Batch_idx: 50 |  Loss: (0.2220) | Acc: (92.39%) (6031/6528)\n",
            "Epoch: 44 | Batch_idx: 60 |  Loss: (0.2180) | Acc: (92.55%) (7226/7808)\n",
            "Epoch: 44 | Batch_idx: 70 |  Loss: (0.2179) | Acc: (92.52%) (8408/9088)\n",
            "Epoch: 44 | Batch_idx: 80 |  Loss: (0.2142) | Acc: (92.59%) (9600/10368)\n",
            "Epoch: 44 | Batch_idx: 90 |  Loss: (0.2117) | Acc: (92.65%) (10792/11648)\n",
            "Epoch: 44 | Batch_idx: 100 |  Loss: (0.2116) | Acc: (92.57%) (11968/12928)\n",
            "Epoch: 44 | Batch_idx: 110 |  Loss: (0.2113) | Acc: (92.60%) (13156/14208)\n",
            "Epoch: 44 | Batch_idx: 120 |  Loss: (0.2107) | Acc: (92.67%) (14353/15488)\n",
            "Epoch: 44 | Batch_idx: 130 |  Loss: (0.2115) | Acc: (92.65%) (15536/16768)\n",
            "Epoch: 44 | Batch_idx: 140 |  Loss: (0.2107) | Acc: (92.66%) (16724/18048)\n",
            "Epoch: 44 | Batch_idx: 150 |  Loss: (0.2114) | Acc: (92.64%) (17906/19328)\n",
            "Epoch: 44 | Batch_idx: 160 |  Loss: (0.2109) | Acc: (92.67%) (19097/20608)\n",
            "Epoch: 44 | Batch_idx: 170 |  Loss: (0.2120) | Acc: (92.69%) (20288/21888)\n",
            "Epoch: 44 | Batch_idx: 180 |  Loss: (0.2118) | Acc: (92.71%) (21479/23168)\n",
            "Epoch: 44 | Batch_idx: 190 |  Loss: (0.2107) | Acc: (92.74%) (22674/24448)\n",
            "Epoch: 44 | Batch_idx: 200 |  Loss: (0.2104) | Acc: (92.75%) (23864/25728)\n",
            "Epoch: 44 | Batch_idx: 210 |  Loss: (0.2115) | Acc: (92.71%) (25038/27008)\n",
            "Epoch: 44 | Batch_idx: 220 |  Loss: (0.2128) | Acc: (92.66%) (26211/28288)\n",
            "Epoch: 44 | Batch_idx: 230 |  Loss: (0.2124) | Acc: (92.66%) (27397/29568)\n",
            "Epoch: 44 | Batch_idx: 240 |  Loss: (0.2124) | Acc: (92.61%) (28568/30848)\n",
            "Epoch: 44 | Batch_idx: 250 |  Loss: (0.2151) | Acc: (92.53%) (29729/32128)\n",
            "Epoch: 44 | Batch_idx: 260 |  Loss: (0.2157) | Acc: (92.53%) (30911/33408)\n",
            "Epoch: 44 | Batch_idx: 270 |  Loss: (0.2181) | Acc: (92.45%) (32070/34688)\n",
            "Epoch: 44 | Batch_idx: 280 |  Loss: (0.2198) | Acc: (92.40%) (33234/35968)\n",
            "Epoch: 44 | Batch_idx: 290 |  Loss: (0.2207) | Acc: (92.38%) (34408/37248)\n",
            "Epoch: 44 | Batch_idx: 300 |  Loss: (0.2210) | Acc: (92.35%) (35580/38528)\n",
            "Epoch: 44 | Batch_idx: 310 |  Loss: (0.2211) | Acc: (92.32%) (36752/39808)\n",
            "Epoch: 44 | Batch_idx: 320 |  Loss: (0.2203) | Acc: (92.38%) (37957/41088)\n",
            "Epoch: 44 | Batch_idx: 330 |  Loss: (0.2207) | Acc: (92.38%) (39138/42368)\n",
            "Epoch: 44 | Batch_idx: 340 |  Loss: (0.2207) | Acc: (92.41%) (40333/43648)\n",
            "Epoch: 44 | Batch_idx: 350 |  Loss: (0.2206) | Acc: (92.41%) (41519/44928)\n",
            "Epoch: 44 | Batch_idx: 360 |  Loss: (0.2200) | Acc: (92.43%) (42710/46208)\n",
            "Epoch: 44 | Batch_idx: 370 |  Loss: (0.2197) | Acc: (92.42%) (43890/47488)\n",
            "Epoch: 44 | Batch_idx: 380 |  Loss: (0.2200) | Acc: (92.41%) (45068/48768)\n",
            "Epoch: 44 | Batch_idx: 390 |  Loss: (0.2208) | Acc: (92.39%) (46193/50000)\n",
            "# TEST : Loss: (0.4172) | Acc: (87.50%) (8750/10000)\n",
            "Epoch: 45 | Batch_idx: 0 |  Loss: (0.1971) | Acc: (92.97%) (119/128)\n",
            "Epoch: 45 | Batch_idx: 10 |  Loss: (0.2048) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 45 | Batch_idx: 20 |  Loss: (0.1920) | Acc: (93.15%) (2504/2688)\n",
            "Epoch: 45 | Batch_idx: 30 |  Loss: (0.1997) | Acc: (92.99%) (3690/3968)\n",
            "Epoch: 45 | Batch_idx: 40 |  Loss: (0.1917) | Acc: (93.39%) (4901/5248)\n",
            "Epoch: 45 | Batch_idx: 50 |  Loss: (0.1913) | Acc: (93.37%) (6095/6528)\n",
            "Epoch: 45 | Batch_idx: 60 |  Loss: (0.1881) | Acc: (93.51%) (7301/7808)\n",
            "Epoch: 45 | Batch_idx: 70 |  Loss: (0.1874) | Acc: (93.51%) (8498/9088)\n",
            "Epoch: 45 | Batch_idx: 80 |  Loss: (0.1893) | Acc: (93.41%) (9685/10368)\n",
            "Epoch: 45 | Batch_idx: 90 |  Loss: (0.1882) | Acc: (93.37%) (10876/11648)\n",
            "Epoch: 45 | Batch_idx: 100 |  Loss: (0.1914) | Acc: (93.23%) (12053/12928)\n",
            "Epoch: 45 | Batch_idx: 110 |  Loss: (0.1912) | Acc: (93.28%) (13253/14208)\n",
            "Epoch: 45 | Batch_idx: 120 |  Loss: (0.1949) | Acc: (93.10%) (14420/15488)\n",
            "Epoch: 45 | Batch_idx: 130 |  Loss: (0.1950) | Acc: (93.11%) (15612/16768)\n",
            "Epoch: 45 | Batch_idx: 140 |  Loss: (0.1978) | Acc: (93.03%) (16790/18048)\n",
            "Epoch: 45 | Batch_idx: 150 |  Loss: (0.2001) | Acc: (92.96%) (17967/19328)\n",
            "Epoch: 45 | Batch_idx: 160 |  Loss: (0.2005) | Acc: (92.92%) (19148/20608)\n",
            "Epoch: 45 | Batch_idx: 170 |  Loss: (0.2045) | Acc: (92.80%) (20312/21888)\n",
            "Epoch: 45 | Batch_idx: 180 |  Loss: (0.2068) | Acc: (92.71%) (21480/23168)\n",
            "Epoch: 45 | Batch_idx: 190 |  Loss: (0.2077) | Acc: (92.63%) (22647/24448)\n",
            "Epoch: 45 | Batch_idx: 200 |  Loss: (0.2081) | Acc: (92.65%) (23838/25728)\n",
            "Epoch: 45 | Batch_idx: 210 |  Loss: (0.2088) | Acc: (92.60%) (25010/27008)\n",
            "Epoch: 45 | Batch_idx: 220 |  Loss: (0.2089) | Acc: (92.60%) (26195/28288)\n",
            "Epoch: 45 | Batch_idx: 230 |  Loss: (0.2106) | Acc: (92.53%) (27359/29568)\n",
            "Epoch: 45 | Batch_idx: 240 |  Loss: (0.2107) | Acc: (92.52%) (28540/30848)\n",
            "Epoch: 45 | Batch_idx: 250 |  Loss: (0.2105) | Acc: (92.51%) (29722/32128)\n",
            "Epoch: 45 | Batch_idx: 260 |  Loss: (0.2117) | Acc: (92.48%) (30896/33408)\n",
            "Epoch: 45 | Batch_idx: 270 |  Loss: (0.2125) | Acc: (92.46%) (32074/34688)\n",
            "Epoch: 45 | Batch_idx: 280 |  Loss: (0.2127) | Acc: (92.50%) (33269/35968)\n",
            "Epoch: 45 | Batch_idx: 290 |  Loss: (0.2135) | Acc: (92.47%) (34444/37248)\n",
            "Epoch: 45 | Batch_idx: 300 |  Loss: (0.2153) | Acc: (92.41%) (35602/38528)\n",
            "Epoch: 45 | Batch_idx: 310 |  Loss: (0.2160) | Acc: (92.39%) (36779/39808)\n",
            "Epoch: 45 | Batch_idx: 320 |  Loss: (0.2173) | Acc: (92.36%) (37949/41088)\n",
            "Epoch: 45 | Batch_idx: 330 |  Loss: (0.2171) | Acc: (92.38%) (39139/42368)\n",
            "Epoch: 45 | Batch_idx: 340 |  Loss: (0.2171) | Acc: (92.37%) (40317/43648)\n",
            "Epoch: 45 | Batch_idx: 350 |  Loss: (0.2170) | Acc: (92.38%) (41506/44928)\n",
            "Epoch: 45 | Batch_idx: 360 |  Loss: (0.2165) | Acc: (92.40%) (42696/46208)\n",
            "Epoch: 45 | Batch_idx: 370 |  Loss: (0.2167) | Acc: (92.39%) (43876/47488)\n",
            "Epoch: 45 | Batch_idx: 380 |  Loss: (0.2171) | Acc: (92.37%) (45045/48768)\n",
            "Epoch: 45 | Batch_idx: 390 |  Loss: (0.2170) | Acc: (92.37%) (46184/50000)\n",
            "# TEST : Loss: (0.4212) | Acc: (87.13%) (8713/10000)\n",
            "Epoch: 46 | Batch_idx: 0 |  Loss: (0.1285) | Acc: (96.88%) (124/128)\n",
            "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2048) | Acc: (93.82%) (1321/1408)\n",
            "Epoch: 46 | Batch_idx: 20 |  Loss: (0.1905) | Acc: (94.35%) (2536/2688)\n",
            "Epoch: 46 | Batch_idx: 30 |  Loss: (0.1870) | Acc: (94.20%) (3738/3968)\n",
            "Epoch: 46 | Batch_idx: 40 |  Loss: (0.1919) | Acc: (93.88%) (4927/5248)\n",
            "Epoch: 46 | Batch_idx: 50 |  Loss: (0.1955) | Acc: (93.54%) (6106/6528)\n",
            "Epoch: 46 | Batch_idx: 60 |  Loss: (0.1964) | Acc: (93.35%) (7289/7808)\n",
            "Epoch: 46 | Batch_idx: 70 |  Loss: (0.1931) | Acc: (93.39%) (8487/9088)\n",
            "Epoch: 46 | Batch_idx: 80 |  Loss: (0.1909) | Acc: (93.51%) (9695/10368)\n",
            "Epoch: 46 | Batch_idx: 90 |  Loss: (0.1922) | Acc: (93.48%) (10888/11648)\n",
            "Epoch: 46 | Batch_idx: 100 |  Loss: (0.1954) | Acc: (93.41%) (12076/12928)\n",
            "Epoch: 46 | Batch_idx: 110 |  Loss: (0.1962) | Acc: (93.26%) (13250/14208)\n",
            "Epoch: 46 | Batch_idx: 120 |  Loss: (0.1983) | Acc: (93.17%) (14430/15488)\n",
            "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2013) | Acc: (93.09%) (15610/16768)\n",
            "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2040) | Acc: (92.97%) (16780/18048)\n",
            "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2063) | Acc: (92.91%) (17957/19328)\n",
            "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2067) | Acc: (92.89%) (19143/20608)\n",
            "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2081) | Acc: (92.82%) (20316/21888)\n",
            "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2084) | Acc: (92.82%) (21505/23168)\n",
            "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2091) | Acc: (92.81%) (22689/24448)\n",
            "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2106) | Acc: (92.74%) (23861/25728)\n",
            "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2128) | Acc: (92.68%) (25032/27008)\n",
            "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2126) | Acc: (92.70%) (26222/28288)\n",
            "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2117) | Acc: (92.72%) (27415/29568)\n",
            "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2119) | Acc: (92.67%) (28588/30848)\n",
            "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2120) | Acc: (92.65%) (29765/32128)\n",
            "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2119) | Acc: (92.65%) (30952/33408)\n",
            "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2118) | Acc: (92.67%) (32144/34688)\n",
            "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2122) | Acc: (92.66%) (33327/35968)\n",
            "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2122) | Acc: (92.66%) (34515/37248)\n",
            "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2129) | Acc: (92.63%) (35690/38528)\n",
            "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2132) | Acc: (92.61%) (36866/39808)\n",
            "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2130) | Acc: (92.61%) (38053/41088)\n",
            "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2134) | Acc: (92.61%) (39236/42368)\n",
            "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2139) | Acc: (92.58%) (40410/43648)\n",
            "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2147) | Acc: (92.55%) (41579/44928)\n",
            "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2154) | Acc: (92.51%) (42749/46208)\n",
            "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2162) | Acc: (92.49%) (43923/47488)\n",
            "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2170) | Acc: (92.46%) (45091/48768)\n",
            "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2175) | Acc: (92.46%) (46232/50000)\n",
            "# TEST : Loss: (0.4529) | Acc: (85.98%) (8598/10000)\n",
            "Epoch: 47 | Batch_idx: 0 |  Loss: (0.1511) | Acc: (96.09%) (123/128)\n",
            "Epoch: 47 | Batch_idx: 10 |  Loss: (0.1943) | Acc: (93.68%) (1319/1408)\n",
            "Epoch: 47 | Batch_idx: 20 |  Loss: (0.1802) | Acc: (93.90%) (2524/2688)\n",
            "Epoch: 47 | Batch_idx: 30 |  Loss: (0.1883) | Acc: (93.70%) (3718/3968)\n",
            "Epoch: 47 | Batch_idx: 40 |  Loss: (0.1942) | Acc: (93.33%) (4898/5248)\n",
            "Epoch: 47 | Batch_idx: 50 |  Loss: (0.1935) | Acc: (93.43%) (6099/6528)\n",
            "Epoch: 47 | Batch_idx: 60 |  Loss: (0.1941) | Acc: (93.34%) (7288/7808)\n",
            "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2016) | Acc: (92.98%) (8450/9088)\n",
            "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2020) | Acc: (92.93%) (9635/10368)\n",
            "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2027) | Acc: (92.95%) (10827/11648)\n",
            "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2068) | Acc: (92.78%) (11995/12928)\n",
            "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2058) | Acc: (92.79%) (13184/14208)\n",
            "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2060) | Acc: (92.81%) (14375/15488)\n",
            "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2064) | Acc: (92.78%) (15558/16768)\n",
            "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2073) | Acc: (92.80%) (16748/18048)\n",
            "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2084) | Acc: (92.72%) (17920/19328)\n",
            "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2101) | Acc: (92.67%) (19097/20608)\n",
            "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2091) | Acc: (92.72%) (20295/21888)\n",
            "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2105) | Acc: (92.66%) (21467/23168)\n",
            "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2107) | Acc: (92.66%) (22654/24448)\n",
            "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2102) | Acc: (92.63%) (23833/25728)\n",
            "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2105) | Acc: (92.67%) (25029/27008)\n",
            "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2100) | Acc: (92.68%) (26216/28288)\n",
            "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2108) | Acc: (92.64%) (27391/29568)\n",
            "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2117) | Acc: (92.62%) (28570/30848)\n",
            "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2127) | Acc: (92.56%) (29738/32128)\n",
            "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2124) | Acc: (92.57%) (30926/33408)\n",
            "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2126) | Acc: (92.58%) (32114/34688)\n",
            "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2129) | Acc: (92.57%) (33296/35968)\n",
            "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2126) | Acc: (92.56%) (34476/37248)\n",
            "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2130) | Acc: (92.55%) (35657/38528)\n",
            "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2141) | Acc: (92.52%) (36832/39808)\n",
            "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2143) | Acc: (92.53%) (38019/41088)\n",
            "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2143) | Acc: (92.50%) (39190/42368)\n",
            "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2147) | Acc: (92.48%) (40364/43648)\n",
            "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2143) | Acc: (92.47%) (41547/44928)\n",
            "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2142) | Acc: (92.48%) (42731/46208)\n",
            "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2141) | Acc: (92.49%) (43922/47488)\n",
            "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2145) | Acc: (92.48%) (45103/48768)\n",
            "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2152) | Acc: (92.47%) (46235/50000)\n",
            "# TEST : Loss: (0.3793) | Acc: (88.17%) (8817/10000)\n",
            "Epoch: 48 | Batch_idx: 0 |  Loss: (0.2023) | Acc: (92.97%) (119/128)\n",
            "Epoch: 48 | Batch_idx: 10 |  Loss: (0.1891) | Acc: (93.54%) (1317/1408)\n",
            "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2008) | Acc: (93.08%) (2502/2688)\n",
            "Epoch: 48 | Batch_idx: 30 |  Loss: (0.1974) | Acc: (93.04%) (3692/3968)\n",
            "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2026) | Acc: (92.84%) (4872/5248)\n",
            "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2004) | Acc: (92.98%) (6070/6528)\n",
            "Epoch: 48 | Batch_idx: 60 |  Loss: (0.1976) | Acc: (93.06%) (7266/7808)\n",
            "Epoch: 48 | Batch_idx: 70 |  Loss: (0.1964) | Acc: (93.13%) (8464/9088)\n",
            "Epoch: 48 | Batch_idx: 80 |  Loss: (0.1974) | Acc: (93.05%) (9647/10368)\n",
            "Epoch: 48 | Batch_idx: 90 |  Loss: (0.1984) | Acc: (92.94%) (10826/11648)\n",
            "Epoch: 48 | Batch_idx: 100 |  Loss: (0.1980) | Acc: (93.00%) (12023/12928)\n",
            "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2011) | Acc: (92.86%) (13194/14208)\n",
            "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2037) | Acc: (92.78%) (14369/15488)\n",
            "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2035) | Acc: (92.83%) (15565/16768)\n",
            "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2042) | Acc: (92.78%) (16745/18048)\n",
            "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2058) | Acc: (92.73%) (17923/19328)\n",
            "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2046) | Acc: (92.76%) (19117/20608)\n",
            "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2045) | Acc: (92.84%) (20320/21888)\n",
            "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2028) | Acc: (92.88%) (21518/23168)\n",
            "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2040) | Acc: (92.85%) (22700/24448)\n",
            "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2045) | Acc: (92.87%) (23894/25728)\n",
            "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2059) | Acc: (92.82%) (25068/27008)\n",
            "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2066) | Acc: (92.78%) (26247/28288)\n",
            "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2065) | Acc: (92.76%) (27426/29568)\n",
            "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2070) | Acc: (92.71%) (28600/30848)\n",
            "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2078) | Acc: (92.69%) (29778/32128)\n",
            "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2079) | Acc: (92.70%) (30968/33408)\n",
            "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2087) | Acc: (92.67%) (32145/34688)\n",
            "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2094) | Acc: (92.64%) (33320/35968)\n",
            "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2114) | Acc: (92.55%) (34472/37248)\n",
            "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2123) | Acc: (92.52%) (35647/38528)\n",
            "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2134) | Acc: (92.47%) (36811/39808)\n",
            "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2139) | Acc: (92.46%) (37992/41088)\n",
            "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2135) | Acc: (92.48%) (39181/42368)\n",
            "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2147) | Acc: (92.46%) (40355/43648)\n",
            "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2155) | Acc: (92.41%) (41520/44928)\n",
            "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2159) | Acc: (92.40%) (42696/46208)\n",
            "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2162) | Acc: (92.41%) (43883/47488)\n",
            "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2158) | Acc: (92.42%) (45073/48768)\n",
            "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2152) | Acc: (92.45%) (46225/50000)\n",
            "# TEST : Loss: (0.4181) | Acc: (86.91%) (8691/10000)\n",
            "Epoch: 49 | Batch_idx: 0 |  Loss: (0.1793) | Acc: (92.19%) (118/128)\n",
            "Epoch: 49 | Batch_idx: 10 |  Loss: (0.2060) | Acc: (92.90%) (1308/1408)\n",
            "Epoch: 49 | Batch_idx: 20 |  Loss: (0.2018) | Acc: (92.67%) (2491/2688)\n",
            "Epoch: 49 | Batch_idx: 30 |  Loss: (0.2073) | Acc: (92.52%) (3671/3968)\n",
            "Epoch: 49 | Batch_idx: 40 |  Loss: (0.2091) | Acc: (92.51%) (4855/5248)\n",
            "Epoch: 49 | Batch_idx: 50 |  Loss: (0.2063) | Acc: (92.63%) (6047/6528)\n",
            "Epoch: 49 | Batch_idx: 60 |  Loss: (0.2071) | Acc: (92.71%) (7239/7808)\n",
            "Epoch: 49 | Batch_idx: 70 |  Loss: (0.2067) | Acc: (92.72%) (8426/9088)\n",
            "Epoch: 49 | Batch_idx: 80 |  Loss: (0.2084) | Acc: (92.60%) (9601/10368)\n",
            "Epoch: 49 | Batch_idx: 90 |  Loss: (0.2097) | Acc: (92.55%) (10780/11648)\n",
            "Epoch: 49 | Batch_idx: 100 |  Loss: (0.2064) | Acc: (92.69%) (11983/12928)\n",
            "Epoch: 49 | Batch_idx: 110 |  Loss: (0.2064) | Acc: (92.63%) (13161/14208)\n",
            "Epoch: 49 | Batch_idx: 120 |  Loss: (0.2082) | Acc: (92.61%) (14343/15488)\n",
            "Epoch: 49 | Batch_idx: 130 |  Loss: (0.2062) | Acc: (92.71%) (15546/16768)\n",
            "Epoch: 49 | Batch_idx: 140 |  Loss: (0.2061) | Acc: (92.75%) (16740/18048)\n",
            "Epoch: 49 | Batch_idx: 150 |  Loss: (0.2050) | Acc: (92.79%) (17934/19328)\n",
            "Epoch: 49 | Batch_idx: 160 |  Loss: (0.2059) | Acc: (92.75%) (19113/20608)\n",
            "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2074) | Acc: (92.73%) (20297/21888)\n",
            "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2075) | Acc: (92.76%) (21490/23168)\n",
            "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2062) | Acc: (92.78%) (22684/24448)\n",
            "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2046) | Acc: (92.85%) (23889/25728)\n",
            "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2041) | Acc: (92.88%) (25085/27008)\n",
            "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2057) | Acc: (92.81%) (26254/28288)\n",
            "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2053) | Acc: (92.81%) (27443/29568)\n",
            "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2057) | Acc: (92.79%) (28625/30848)\n",
            "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2051) | Acc: (92.84%) (29827/32128)\n",
            "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2066) | Acc: (92.78%) (30996/33408)\n",
            "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2073) | Acc: (92.77%) (32180/34688)\n",
            "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2078) | Acc: (92.73%) (33353/35968)\n",
            "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2078) | Acc: (92.74%) (34543/37248)\n",
            "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2085) | Acc: (92.71%) (35721/38528)\n",
            "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2100) | Acc: (92.64%) (36880/39808)\n",
            "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2109) | Acc: (92.57%) (38037/41088)\n",
            "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2116) | Acc: (92.56%) (39214/42368)\n",
            "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2114) | Acc: (92.57%) (40406/43648)\n",
            "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2115) | Acc: (92.57%) (41592/44928)\n",
            "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2112) | Acc: (92.60%) (42787/46208)\n",
            "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2109) | Acc: (92.59%) (43971/47488)\n",
            "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2105) | Acc: (92.60%) (45161/48768)\n",
            "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2106) | Acc: (92.60%) (46302/50000)\n",
            "# TEST : Loss: (0.4133) | Acc: (87.03%) (8703/10000)\n",
            "Epoch: 50 | Batch_idx: 0 |  Loss: (0.1756) | Acc: (94.53%) (121/128)\n",
            "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2088) | Acc: (93.11%) (1311/1408)\n",
            "Epoch: 50 | Batch_idx: 20 |  Loss: (0.1957) | Acc: (93.53%) (2514/2688)\n",
            "Epoch: 50 | Batch_idx: 30 |  Loss: (0.1908) | Acc: (93.60%) (3714/3968)\n",
            "Epoch: 50 | Batch_idx: 40 |  Loss: (0.1879) | Acc: (93.77%) (4921/5248)\n",
            "Epoch: 50 | Batch_idx: 50 |  Loss: (0.1880) | Acc: (93.81%) (6124/6528)\n",
            "Epoch: 50 | Batch_idx: 60 |  Loss: (0.1814) | Acc: (93.95%) (7336/7808)\n",
            "Epoch: 50 | Batch_idx: 70 |  Loss: (0.1824) | Acc: (93.90%) (8534/9088)\n",
            "Epoch: 50 | Batch_idx: 80 |  Loss: (0.1828) | Acc: (93.84%) (9729/10368)\n",
            "Epoch: 50 | Batch_idx: 90 |  Loss: (0.1854) | Acc: (93.72%) (10916/11648)\n",
            "Epoch: 50 | Batch_idx: 100 |  Loss: (0.1861) | Acc: (93.70%) (12114/12928)\n",
            "Epoch: 50 | Batch_idx: 110 |  Loss: (0.1883) | Acc: (93.65%) (13306/14208)\n",
            "Epoch: 50 | Batch_idx: 120 |  Loss: (0.1930) | Acc: (93.42%) (14469/15488)\n",
            "Epoch: 50 | Batch_idx: 130 |  Loss: (0.1951) | Acc: (93.35%) (15653/16768)\n",
            "Epoch: 50 | Batch_idx: 140 |  Loss: (0.1962) | Acc: (93.28%) (16835/18048)\n",
            "Epoch: 50 | Batch_idx: 150 |  Loss: (0.1990) | Acc: (93.19%) (18011/19328)\n",
            "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2003) | Acc: (93.17%) (19200/20608)\n",
            "Epoch: 50 | Batch_idx: 170 |  Loss: (0.1995) | Acc: (93.17%) (20393/21888)\n",
            "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2003) | Acc: (93.15%) (21580/23168)\n",
            "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2009) | Acc: (93.14%) (22770/24448)\n",
            "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2036) | Acc: (93.04%) (23938/25728)\n",
            "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2031) | Acc: (93.05%) (25130/27008)\n",
            "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2043) | Acc: (92.99%) (26304/28288)\n",
            "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2053) | Acc: (92.96%) (27485/29568)\n",
            "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2068) | Acc: (92.88%) (28652/30848)\n",
            "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2074) | Acc: (92.85%) (29832/32128)\n",
            "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2084) | Acc: (92.83%) (31013/33408)\n",
            "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2090) | Acc: (92.81%) (32194/34688)\n",
            "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2086) | Acc: (92.81%) (33381/35968)\n",
            "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2102) | Acc: (92.76%) (34553/37248)\n",
            "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2101) | Acc: (92.75%) (35735/38528)\n",
            "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2108) | Acc: (92.73%) (36912/39808)\n",
            "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2121) | Acc: (92.69%) (38083/41088)\n",
            "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2115) | Acc: (92.71%) (39280/42368)\n",
            "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2112) | Acc: (92.71%) (40465/43648)\n",
            "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2105) | Acc: (92.72%) (41658/44928)\n",
            "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2101) | Acc: (92.72%) (42844/46208)\n",
            "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2099) | Acc: (92.72%) (44032/47488)\n",
            "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2099) | Acc: (92.71%) (45213/48768)\n",
            "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2097) | Acc: (92.72%) (46359/50000)\n",
            "# TEST : Loss: (0.4228) | Acc: (87.67%) (8767/10000)\n",
            "Epoch: 51 | Batch_idx: 0 |  Loss: (0.1527) | Acc: (96.09%) (123/128)\n",
            "Epoch: 51 | Batch_idx: 10 |  Loss: (0.1554) | Acc: (94.60%) (1332/1408)\n",
            "Epoch: 51 | Batch_idx: 20 |  Loss: (0.1669) | Acc: (94.38%) (2537/2688)\n",
            "Epoch: 51 | Batch_idx: 30 |  Loss: (0.1798) | Acc: (93.60%) (3714/3968)\n",
            "Epoch: 51 | Batch_idx: 40 |  Loss: (0.1788) | Acc: (93.60%) (4912/5248)\n",
            "Epoch: 51 | Batch_idx: 50 |  Loss: (0.1849) | Acc: (93.34%) (6093/6528)\n",
            "Epoch: 51 | Batch_idx: 60 |  Loss: (0.1845) | Acc: (93.39%) (7292/7808)\n",
            "Epoch: 51 | Batch_idx: 70 |  Loss: (0.1862) | Acc: (93.47%) (8495/9088)\n",
            "Epoch: 51 | Batch_idx: 80 |  Loss: (0.1894) | Acc: (93.37%) (9681/10368)\n",
            "Epoch: 51 | Batch_idx: 90 |  Loss: (0.1903) | Acc: (93.36%) (10875/11648)\n",
            "Epoch: 51 | Batch_idx: 100 |  Loss: (0.1876) | Acc: (93.41%) (12076/12928)\n",
            "Epoch: 51 | Batch_idx: 110 |  Loss: (0.1870) | Acc: (93.44%) (13276/14208)\n",
            "Epoch: 51 | Batch_idx: 120 |  Loss: (0.1879) | Acc: (93.36%) (14460/15488)\n",
            "Epoch: 51 | Batch_idx: 130 |  Loss: (0.1910) | Acc: (93.32%) (15648/16768)\n",
            "Epoch: 51 | Batch_idx: 140 |  Loss: (0.1932) | Acc: (93.22%) (16825/18048)\n",
            "Epoch: 51 | Batch_idx: 150 |  Loss: (0.1954) | Acc: (93.13%) (18000/19328)\n",
            "Epoch: 51 | Batch_idx: 160 |  Loss: (0.1961) | Acc: (93.09%) (19185/20608)\n",
            "Epoch: 51 | Batch_idx: 170 |  Loss: (0.1950) | Acc: (93.13%) (20384/21888)\n",
            "Epoch: 51 | Batch_idx: 180 |  Loss: (0.1968) | Acc: (93.05%) (21558/23168)\n",
            "Epoch: 51 | Batch_idx: 190 |  Loss: (0.1977) | Acc: (93.01%) (22740/24448)\n",
            "Epoch: 51 | Batch_idx: 200 |  Loss: (0.1984) | Acc: (92.97%) (23919/25728)\n",
            "Epoch: 51 | Batch_idx: 210 |  Loss: (0.1996) | Acc: (92.93%) (25099/27008)\n",
            "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2009) | Acc: (92.88%) (26273/28288)\n",
            "Epoch: 51 | Batch_idx: 230 |  Loss: (0.1998) | Acc: (92.91%) (27472/29568)\n",
            "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2013) | Acc: (92.88%) (28652/30848)\n",
            "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2015) | Acc: (92.85%) (29830/32128)\n",
            "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2023) | Acc: (92.83%) (31013/33408)\n",
            "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2028) | Acc: (92.80%) (32192/34688)\n",
            "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2037) | Acc: (92.75%) (33362/35968)\n",
            "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2049) | Acc: (92.71%) (34533/37248)\n",
            "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2054) | Acc: (92.68%) (35707/38528)\n",
            "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2061) | Acc: (92.64%) (36879/39808)\n",
            "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2070) | Acc: (92.63%) (38060/41088)\n",
            "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2075) | Acc: (92.62%) (39241/42368)\n",
            "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2079) | Acc: (92.61%) (40423/43648)\n",
            "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2087) | Acc: (92.61%) (41607/44928)\n",
            "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2084) | Acc: (92.61%) (42794/46208)\n",
            "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2090) | Acc: (92.60%) (43972/47488)\n",
            "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2093) | Acc: (92.60%) (45158/48768)\n",
            "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2100) | Acc: (92.59%) (46296/50000)\n",
            "# TEST : Loss: (0.4436) | Acc: (86.89%) (8689/10000)\n",
            "Epoch: 52 | Batch_idx: 0 |  Loss: (0.3075) | Acc: (89.06%) (114/128)\n",
            "Epoch: 52 | Batch_idx: 10 |  Loss: (0.1837) | Acc: (93.54%) (1317/1408)\n",
            "Epoch: 52 | Batch_idx: 20 |  Loss: (0.1954) | Acc: (92.82%) (2495/2688)\n",
            "Epoch: 52 | Batch_idx: 30 |  Loss: (0.1959) | Acc: (92.99%) (3690/3968)\n",
            "Epoch: 52 | Batch_idx: 40 |  Loss: (0.1936) | Acc: (93.03%) (4882/5248)\n",
            "Epoch: 52 | Batch_idx: 50 |  Loss: (0.1902) | Acc: (93.26%) (6088/6528)\n",
            "Epoch: 52 | Batch_idx: 60 |  Loss: (0.1910) | Acc: (93.21%) (7278/7808)\n",
            "Epoch: 52 | Batch_idx: 70 |  Loss: (0.1934) | Acc: (93.23%) (8473/9088)\n",
            "Epoch: 52 | Batch_idx: 80 |  Loss: (0.1925) | Acc: (93.33%) (9676/10368)\n",
            "Epoch: 52 | Batch_idx: 90 |  Loss: (0.1927) | Acc: (93.27%) (10864/11648)\n",
            "Epoch: 52 | Batch_idx: 100 |  Loss: (0.1968) | Acc: (93.20%) (12049/12928)\n",
            "Epoch: 52 | Batch_idx: 110 |  Loss: (0.1954) | Acc: (93.28%) (13253/14208)\n",
            "Epoch: 52 | Batch_idx: 120 |  Loss: (0.1966) | Acc: (93.19%) (14433/15488)\n",
            "Epoch: 52 | Batch_idx: 130 |  Loss: (0.1973) | Acc: (93.12%) (15614/16768)\n",
            "Epoch: 52 | Batch_idx: 140 |  Loss: (0.1967) | Acc: (93.13%) (16809/18048)\n",
            "Epoch: 52 | Batch_idx: 150 |  Loss: (0.1967) | Acc: (93.14%) (18002/19328)\n",
            "Epoch: 52 | Batch_idx: 160 |  Loss: (0.1978) | Acc: (93.14%) (19194/20608)\n",
            "Epoch: 52 | Batch_idx: 170 |  Loss: (0.1975) | Acc: (93.11%) (20381/21888)\n",
            "Epoch: 52 | Batch_idx: 180 |  Loss: (0.1985) | Acc: (93.03%) (21553/23168)\n",
            "Epoch: 52 | Batch_idx: 190 |  Loss: (0.1974) | Acc: (93.04%) (22746/24448)\n",
            "Epoch: 52 | Batch_idx: 200 |  Loss: (0.1976) | Acc: (93.04%) (23937/25728)\n",
            "Epoch: 52 | Batch_idx: 210 |  Loss: (0.1981) | Acc: (93.02%) (25123/27008)\n",
            "Epoch: 52 | Batch_idx: 220 |  Loss: (0.1983) | Acc: (93.00%) (26307/28288)\n",
            "Epoch: 52 | Batch_idx: 230 |  Loss: (0.1987) | Acc: (92.98%) (27491/29568)\n",
            "Epoch: 52 | Batch_idx: 240 |  Loss: (0.1991) | Acc: (92.96%) (28676/30848)\n",
            "Epoch: 52 | Batch_idx: 250 |  Loss: (0.1998) | Acc: (92.95%) (29863/32128)\n",
            "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2014) | Acc: (92.92%) (31042/33408)\n",
            "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2008) | Acc: (92.95%) (32241/34688)\n",
            "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2005) | Acc: (92.95%) (33433/35968)\n",
            "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2008) | Acc: (92.94%) (34618/37248)\n",
            "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2019) | Acc: (92.89%) (35790/38528)\n",
            "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2030) | Acc: (92.87%) (36968/39808)\n",
            "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2042) | Acc: (92.83%) (38144/41088)\n",
            "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2040) | Acc: (92.86%) (39342/42368)\n",
            "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2042) | Acc: (92.87%) (40538/43648)\n",
            "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2038) | Acc: (92.87%) (41723/44928)\n",
            "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2044) | Acc: (92.82%) (42892/46208)\n",
            "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2046) | Acc: (92.82%) (44077/47488)\n",
            "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2040) | Acc: (92.82%) (45266/48768)\n",
            "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2036) | Acc: (92.81%) (46406/50000)\n",
            "# TEST : Loss: (0.4305) | Acc: (86.89%) (8689/10000)\n",
            "Epoch: 53 | Batch_idx: 0 |  Loss: (0.1396) | Acc: (95.31%) (122/128)\n",
            "Epoch: 53 | Batch_idx: 10 |  Loss: (0.1989) | Acc: (92.97%) (1309/1408)\n",
            "Epoch: 53 | Batch_idx: 20 |  Loss: (0.1929) | Acc: (93.08%) (2502/2688)\n",
            "Epoch: 53 | Batch_idx: 30 |  Loss: (0.1866) | Acc: (93.27%) (3701/3968)\n",
            "Epoch: 53 | Batch_idx: 40 |  Loss: (0.1817) | Acc: (93.46%) (4905/5248)\n",
            "Epoch: 53 | Batch_idx: 50 |  Loss: (0.1788) | Acc: (93.63%) (6112/6528)\n",
            "Epoch: 53 | Batch_idx: 60 |  Loss: (0.1809) | Acc: (93.52%) (7302/7808)\n",
            "Epoch: 53 | Batch_idx: 70 |  Loss: (0.1853) | Acc: (93.34%) (8483/9088)\n",
            "Epoch: 53 | Batch_idx: 80 |  Loss: (0.1918) | Acc: (93.11%) (9654/10368)\n",
            "Epoch: 53 | Batch_idx: 90 |  Loss: (0.1900) | Acc: (93.17%) (10852/11648)\n",
            "Epoch: 53 | Batch_idx: 100 |  Loss: (0.1923) | Acc: (93.15%) (12043/12928)\n",
            "Epoch: 53 | Batch_idx: 110 |  Loss: (0.1933) | Acc: (93.13%) (13232/14208)\n",
            "Epoch: 53 | Batch_idx: 120 |  Loss: (0.1917) | Acc: (93.24%) (14441/15488)\n",
            "Epoch: 53 | Batch_idx: 130 |  Loss: (0.1924) | Acc: (93.21%) (15630/16768)\n",
            "Epoch: 53 | Batch_idx: 140 |  Loss: (0.1963) | Acc: (93.06%) (16796/18048)\n",
            "Epoch: 53 | Batch_idx: 150 |  Loss: (0.1969) | Acc: (93.04%) (17983/19328)\n",
            "Epoch: 53 | Batch_idx: 160 |  Loss: (0.1961) | Acc: (93.07%) (19179/20608)\n",
            "Epoch: 53 | Batch_idx: 170 |  Loss: (0.1976) | Acc: (93.03%) (20362/21888)\n",
            "Epoch: 53 | Batch_idx: 180 |  Loss: (0.1952) | Acc: (93.10%) (21569/23168)\n",
            "Epoch: 53 | Batch_idx: 190 |  Loss: (0.1954) | Acc: (93.10%) (22760/24448)\n",
            "Epoch: 53 | Batch_idx: 200 |  Loss: (0.1953) | Acc: (93.07%) (23944/25728)\n",
            "Epoch: 53 | Batch_idx: 210 |  Loss: (0.1964) | Acc: (93.02%) (25123/27008)\n",
            "Epoch: 53 | Batch_idx: 220 |  Loss: (0.1976) | Acc: (93.00%) (26307/28288)\n",
            "Epoch: 53 | Batch_idx: 230 |  Loss: (0.1986) | Acc: (92.99%) (27495/29568)\n",
            "Epoch: 53 | Batch_idx: 240 |  Loss: (0.1995) | Acc: (92.96%) (28677/30848)\n",
            "Epoch: 53 | Batch_idx: 250 |  Loss: (0.1994) | Acc: (92.96%) (29865/32128)\n",
            "Epoch: 53 | Batch_idx: 260 |  Loss: (0.1996) | Acc: (92.95%) (31053/33408)\n",
            "Epoch: 53 | Batch_idx: 270 |  Loss: (0.2003) | Acc: (92.93%) (32236/34688)\n",
            "Epoch: 53 | Batch_idx: 280 |  Loss: (0.2016) | Acc: (92.90%) (33414/35968)\n",
            "Epoch: 53 | Batch_idx: 290 |  Loss: (0.2025) | Acc: (92.87%) (34591/37248)\n",
            "Epoch: 53 | Batch_idx: 300 |  Loss: (0.2020) | Acc: (92.90%) (35793/38528)\n",
            "Epoch: 53 | Batch_idx: 310 |  Loss: (0.2020) | Acc: (92.91%) (36984/39808)\n",
            "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2018) | Acc: (92.93%) (38182/41088)\n",
            "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2017) | Acc: (92.95%) (39382/42368)\n",
            "Epoch: 53 | Batch_idx: 340 |  Loss: (0.2022) | Acc: (92.93%) (40563/43648)\n",
            "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2022) | Acc: (92.94%) (41756/44928)\n",
            "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2032) | Acc: (92.89%) (42924/46208)\n",
            "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2034) | Acc: (92.88%) (44106/47488)\n",
            "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2049) | Acc: (92.83%) (45269/48768)\n",
            "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2051) | Acc: (92.82%) (46410/50000)\n",
            "# TEST : Loss: (0.5686) | Acc: (83.15%) (8315/10000)\n",
            "Epoch: 54 | Batch_idx: 0 |  Loss: (0.2268) | Acc: (90.62%) (116/128)\n",
            "Epoch: 54 | Batch_idx: 10 |  Loss: (0.1685) | Acc: (93.82%) (1321/1408)\n",
            "Epoch: 54 | Batch_idx: 20 |  Loss: (0.1667) | Acc: (94.01%) (2527/2688)\n",
            "Epoch: 54 | Batch_idx: 30 |  Loss: (0.1618) | Acc: (94.38%) (3745/3968)\n",
            "Epoch: 54 | Batch_idx: 40 |  Loss: (0.1649) | Acc: (94.19%) (4943/5248)\n",
            "Epoch: 54 | Batch_idx: 50 |  Loss: (0.1684) | Acc: (94.26%) (6153/6528)\n",
            "Epoch: 54 | Batch_idx: 60 |  Loss: (0.1690) | Acc: (94.20%) (7355/7808)\n",
            "Epoch: 54 | Batch_idx: 70 |  Loss: (0.1721) | Acc: (93.96%) (8539/9088)\n",
            "Epoch: 54 | Batch_idx: 80 |  Loss: (0.1719) | Acc: (93.99%) (9745/10368)\n",
            "Epoch: 54 | Batch_idx: 90 |  Loss: (0.1747) | Acc: (93.89%) (10936/11648)\n",
            "Epoch: 54 | Batch_idx: 100 |  Loss: (0.1786) | Acc: (93.72%) (12116/12928)\n",
            "Epoch: 54 | Batch_idx: 110 |  Loss: (0.1803) | Acc: (93.69%) (13312/14208)\n",
            "Epoch: 54 | Batch_idx: 120 |  Loss: (0.1783) | Acc: (93.76%) (14522/15488)\n",
            "Epoch: 54 | Batch_idx: 130 |  Loss: (0.1826) | Acc: (93.66%) (15705/16768)\n",
            "Epoch: 54 | Batch_idx: 140 |  Loss: (0.1832) | Acc: (93.69%) (16910/18048)\n",
            "Epoch: 54 | Batch_idx: 150 |  Loss: (0.1846) | Acc: (93.67%) (18105/19328)\n",
            "Epoch: 54 | Batch_idx: 160 |  Loss: (0.1858) | Acc: (93.59%) (19288/20608)\n",
            "Epoch: 54 | Batch_idx: 170 |  Loss: (0.1874) | Acc: (93.51%) (20468/21888)\n",
            "Epoch: 54 | Batch_idx: 180 |  Loss: (0.1881) | Acc: (93.54%) (21672/23168)\n",
            "Epoch: 54 | Batch_idx: 190 |  Loss: (0.1897) | Acc: (93.50%) (22859/24448)\n",
            "Epoch: 54 | Batch_idx: 200 |  Loss: (0.1916) | Acc: (93.45%) (24043/25728)\n",
            "Epoch: 54 | Batch_idx: 210 |  Loss: (0.1916) | Acc: (93.47%) (25245/27008)\n",
            "Epoch: 54 | Batch_idx: 220 |  Loss: (0.1916) | Acc: (93.45%) (26436/28288)\n",
            "Epoch: 54 | Batch_idx: 230 |  Loss: (0.1911) | Acc: (93.43%) (27626/29568)\n",
            "Epoch: 54 | Batch_idx: 240 |  Loss: (0.1914) | Acc: (93.40%) (28813/30848)\n",
            "Epoch: 54 | Batch_idx: 250 |  Loss: (0.1924) | Acc: (93.34%) (29987/32128)\n",
            "Epoch: 54 | Batch_idx: 260 |  Loss: (0.1939) | Acc: (93.28%) (31164/33408)\n",
            "Epoch: 54 | Batch_idx: 270 |  Loss: (0.1950) | Acc: (93.23%) (32340/34688)\n",
            "Epoch: 54 | Batch_idx: 280 |  Loss: (0.1954) | Acc: (93.20%) (33523/35968)\n",
            "Epoch: 54 | Batch_idx: 290 |  Loss: (0.1961) | Acc: (93.16%) (34701/37248)\n",
            "Epoch: 54 | Batch_idx: 300 |  Loss: (0.1966) | Acc: (93.14%) (35885/38528)\n",
            "Epoch: 54 | Batch_idx: 310 |  Loss: (0.1970) | Acc: (93.13%) (37075/39808)\n",
            "Epoch: 54 | Batch_idx: 320 |  Loss: (0.1982) | Acc: (93.09%) (38250/41088)\n",
            "Epoch: 54 | Batch_idx: 330 |  Loss: (0.1975) | Acc: (93.11%) (39447/42368)\n",
            "Epoch: 54 | Batch_idx: 340 |  Loss: (0.1974) | Acc: (93.11%) (40640/43648)\n",
            "Epoch: 54 | Batch_idx: 350 |  Loss: (0.1987) | Acc: (93.07%) (41813/44928)\n",
            "Epoch: 54 | Batch_idx: 360 |  Loss: (0.1981) | Acc: (93.09%) (43014/46208)\n",
            "Epoch: 54 | Batch_idx: 370 |  Loss: (0.1987) | Acc: (93.08%) (44201/47488)\n",
            "Epoch: 54 | Batch_idx: 380 |  Loss: (0.1985) | Acc: (93.08%) (45394/48768)\n",
            "Epoch: 54 | Batch_idx: 390 |  Loss: (0.1986) | Acc: (93.08%) (46541/50000)\n",
            "# TEST : Loss: (0.3970) | Acc: (88.05%) (8805/10000)\n",
            "Epoch: 55 | Batch_idx: 0 |  Loss: (0.2689) | Acc: (90.62%) (116/128)\n",
            "Epoch: 55 | Batch_idx: 10 |  Loss: (0.2031) | Acc: (93.11%) (1311/1408)\n",
            "Epoch: 55 | Batch_idx: 20 |  Loss: (0.1905) | Acc: (93.19%) (2505/2688)\n",
            "Epoch: 55 | Batch_idx: 30 |  Loss: (0.1817) | Acc: (93.60%) (3714/3968)\n",
            "Epoch: 55 | Batch_idx: 40 |  Loss: (0.1785) | Acc: (93.73%) (4919/5248)\n",
            "Epoch: 55 | Batch_idx: 50 |  Loss: (0.1730) | Acc: (94.04%) (6139/6528)\n",
            "Epoch: 55 | Batch_idx: 60 |  Loss: (0.1745) | Acc: (93.98%) (7338/7808)\n",
            "Epoch: 55 | Batch_idx: 70 |  Loss: (0.1761) | Acc: (93.94%) (8537/9088)\n",
            "Epoch: 55 | Batch_idx: 80 |  Loss: (0.1736) | Acc: (93.99%) (9745/10368)\n",
            "Epoch: 55 | Batch_idx: 90 |  Loss: (0.1772) | Acc: (93.83%) (10929/11648)\n",
            "Epoch: 55 | Batch_idx: 100 |  Loss: (0.1790) | Acc: (93.79%) (12125/12928)\n",
            "Epoch: 55 | Batch_idx: 110 |  Loss: (0.1771) | Acc: (93.80%) (13327/14208)\n",
            "Epoch: 55 | Batch_idx: 120 |  Loss: (0.1741) | Acc: (93.88%) (14540/15488)\n",
            "Epoch: 55 | Batch_idx: 130 |  Loss: (0.1739) | Acc: (93.86%) (15739/16768)\n",
            "Epoch: 55 | Batch_idx: 140 |  Loss: (0.1763) | Acc: (93.79%) (16927/18048)\n",
            "Epoch: 55 | Batch_idx: 150 |  Loss: (0.1779) | Acc: (93.72%) (18114/19328)\n",
            "Epoch: 55 | Batch_idx: 160 |  Loss: (0.1806) | Acc: (93.58%) (19285/20608)\n",
            "Epoch: 55 | Batch_idx: 170 |  Loss: (0.1819) | Acc: (93.57%) (20480/21888)\n",
            "Epoch: 55 | Batch_idx: 180 |  Loss: (0.1843) | Acc: (93.50%) (21661/23168)\n",
            "Epoch: 55 | Batch_idx: 190 |  Loss: (0.1849) | Acc: (93.50%) (22859/24448)\n",
            "Epoch: 55 | Batch_idx: 200 |  Loss: (0.1849) | Acc: (93.51%) (24058/25728)\n",
            "Epoch: 55 | Batch_idx: 210 |  Loss: (0.1842) | Acc: (93.53%) (25260/27008)\n",
            "Epoch: 55 | Batch_idx: 220 |  Loss: (0.1846) | Acc: (93.52%) (26456/28288)\n",
            "Epoch: 55 | Batch_idx: 230 |  Loss: (0.1850) | Acc: (93.54%) (27658/29568)\n",
            "Epoch: 55 | Batch_idx: 240 |  Loss: (0.1867) | Acc: (93.49%) (28839/30848)\n",
            "Epoch: 55 | Batch_idx: 250 |  Loss: (0.1868) | Acc: (93.49%) (30035/32128)\n",
            "Epoch: 55 | Batch_idx: 260 |  Loss: (0.1875) | Acc: (93.46%) (31223/33408)\n",
            "Epoch: 55 | Batch_idx: 270 |  Loss: (0.1885) | Acc: (93.44%) (32413/34688)\n",
            "Epoch: 55 | Batch_idx: 280 |  Loss: (0.1896) | Acc: (93.43%) (33606/35968)\n",
            "Epoch: 55 | Batch_idx: 290 |  Loss: (0.1900) | Acc: (93.43%) (34800/37248)\n",
            "Epoch: 55 | Batch_idx: 300 |  Loss: (0.1907) | Acc: (93.38%) (35978/38528)\n",
            "Epoch: 55 | Batch_idx: 310 |  Loss: (0.1909) | Acc: (93.38%) (37171/39808)\n",
            "Epoch: 55 | Batch_idx: 320 |  Loss: (0.1919) | Acc: (93.33%) (38347/41088)\n",
            "Epoch: 55 | Batch_idx: 330 |  Loss: (0.1933) | Acc: (93.29%) (39526/42368)\n",
            "Epoch: 55 | Batch_idx: 340 |  Loss: (0.1943) | Acc: (93.26%) (40705/43648)\n",
            "Epoch: 55 | Batch_idx: 350 |  Loss: (0.1952) | Acc: (93.24%) (41889/44928)\n",
            "Epoch: 55 | Batch_idx: 360 |  Loss: (0.1956) | Acc: (93.21%) (43071/46208)\n",
            "Epoch: 55 | Batch_idx: 370 |  Loss: (0.1965) | Acc: (93.17%) (44244/47488)\n",
            "Epoch: 55 | Batch_idx: 380 |  Loss: (0.1971) | Acc: (93.16%) (45432/48768)\n",
            "Epoch: 55 | Batch_idx: 390 |  Loss: (0.1971) | Acc: (93.17%) (46585/50000)\n",
            "# TEST : Loss: (0.3719) | Acc: (88.24%) (8824/10000)\n",
            "Epoch: 56 | Batch_idx: 0 |  Loss: (0.1030) | Acc: (98.44%) (126/128)\n",
            "Epoch: 56 | Batch_idx: 10 |  Loss: (0.1549) | Acc: (94.74%) (1334/1408)\n",
            "Epoch: 56 | Batch_idx: 20 |  Loss: (0.1755) | Acc: (94.01%) (2527/2688)\n",
            "Epoch: 56 | Batch_idx: 30 |  Loss: (0.1742) | Acc: (94.00%) (3730/3968)\n",
            "Epoch: 56 | Batch_idx: 40 |  Loss: (0.1866) | Acc: (93.62%) (4913/5248)\n",
            "Epoch: 56 | Batch_idx: 50 |  Loss: (0.1842) | Acc: (93.63%) (6112/6528)\n",
            "Epoch: 56 | Batch_idx: 60 |  Loss: (0.1856) | Acc: (93.56%) (7305/7808)\n",
            "Epoch: 56 | Batch_idx: 70 |  Loss: (0.1864) | Acc: (93.46%) (8494/9088)\n",
            "Epoch: 56 | Batch_idx: 80 |  Loss: (0.1827) | Acc: (93.71%) (9716/10368)\n",
            "Epoch: 56 | Batch_idx: 90 |  Loss: (0.1848) | Acc: (93.67%) (10911/11648)\n",
            "Epoch: 56 | Batch_idx: 100 |  Loss: (0.1863) | Acc: (93.55%) (12094/12928)\n",
            "Epoch: 56 | Batch_idx: 110 |  Loss: (0.1868) | Acc: (93.57%) (13295/14208)\n",
            "Epoch: 56 | Batch_idx: 120 |  Loss: (0.1860) | Acc: (93.54%) (14487/15488)\n",
            "Epoch: 56 | Batch_idx: 130 |  Loss: (0.1847) | Acc: (93.54%) (15684/16768)\n",
            "Epoch: 56 | Batch_idx: 140 |  Loss: (0.1873) | Acc: (93.41%) (16859/18048)\n",
            "Epoch: 56 | Batch_idx: 150 |  Loss: (0.1893) | Acc: (93.40%) (18053/19328)\n",
            "Epoch: 56 | Batch_idx: 160 |  Loss: (0.1896) | Acc: (93.37%) (19241/20608)\n",
            "Epoch: 56 | Batch_idx: 170 |  Loss: (0.1893) | Acc: (93.41%) (20445/21888)\n",
            "Epoch: 56 | Batch_idx: 180 |  Loss: (0.1903) | Acc: (93.40%) (21638/23168)\n",
            "Epoch: 56 | Batch_idx: 190 |  Loss: (0.1911) | Acc: (93.37%) (22827/24448)\n",
            "Epoch: 56 | Batch_idx: 200 |  Loss: (0.1925) | Acc: (93.31%) (24007/25728)\n",
            "Epoch: 56 | Batch_idx: 210 |  Loss: (0.1924) | Acc: (93.29%) (25195/27008)\n",
            "Epoch: 56 | Batch_idx: 220 |  Loss: (0.1904) | Acc: (93.37%) (26412/28288)\n",
            "Epoch: 56 | Batch_idx: 230 |  Loss: (0.1913) | Acc: (93.29%) (27585/29568)\n",
            "Epoch: 56 | Batch_idx: 240 |  Loss: (0.1912) | Acc: (93.29%) (28778/30848)\n",
            "Epoch: 56 | Batch_idx: 250 |  Loss: (0.1912) | Acc: (93.32%) (29982/32128)\n",
            "Epoch: 56 | Batch_idx: 260 |  Loss: (0.1923) | Acc: (93.30%) (31171/33408)\n",
            "Epoch: 56 | Batch_idx: 270 |  Loss: (0.1926) | Acc: (93.28%) (32357/34688)\n",
            "Epoch: 56 | Batch_idx: 280 |  Loss: (0.1929) | Acc: (93.24%) (33536/35968)\n",
            "Epoch: 56 | Batch_idx: 290 |  Loss: (0.1923) | Acc: (93.24%) (34730/37248)\n",
            "Epoch: 56 | Batch_idx: 300 |  Loss: (0.1919) | Acc: (93.24%) (35925/38528)\n",
            "Epoch: 56 | Batch_idx: 310 |  Loss: (0.1915) | Acc: (93.27%) (37130/39808)\n",
            "Epoch: 56 | Batch_idx: 320 |  Loss: (0.1943) | Acc: (93.17%) (38283/41088)\n",
            "Epoch: 56 | Batch_idx: 330 |  Loss: (0.1954) | Acc: (93.14%) (39463/42368)\n",
            "Epoch: 56 | Batch_idx: 340 |  Loss: (0.1959) | Acc: (93.14%) (40654/43648)\n",
            "Epoch: 56 | Batch_idx: 350 |  Loss: (0.1966) | Acc: (93.11%) (41833/44928)\n",
            "Epoch: 56 | Batch_idx: 360 |  Loss: (0.1963) | Acc: (93.14%) (43038/46208)\n",
            "Epoch: 56 | Batch_idx: 370 |  Loss: (0.1965) | Acc: (93.15%) (44234/47488)\n",
            "Epoch: 56 | Batch_idx: 380 |  Loss: (0.1974) | Acc: (93.10%) (45405/48768)\n",
            "Epoch: 56 | Batch_idx: 390 |  Loss: (0.1978) | Acc: (93.12%) (46559/50000)\n",
            "# TEST : Loss: (0.4204) | Acc: (87.16%) (8716/10000)\n",
            "Epoch: 57 | Batch_idx: 0 |  Loss: (0.1410) | Acc: (96.09%) (123/128)\n",
            "Epoch: 57 | Batch_idx: 10 |  Loss: (0.1917) | Acc: (93.32%) (1314/1408)\n",
            "Epoch: 57 | Batch_idx: 20 |  Loss: (0.1943) | Acc: (92.97%) (2499/2688)\n",
            "Epoch: 57 | Batch_idx: 30 |  Loss: (0.1712) | Acc: (93.72%) (3719/3968)\n",
            "Epoch: 57 | Batch_idx: 40 |  Loss: (0.1704) | Acc: (93.98%) (4932/5248)\n",
            "Epoch: 57 | Batch_idx: 50 |  Loss: (0.1706) | Acc: (94.01%) (6137/6528)\n",
            "Epoch: 57 | Batch_idx: 60 |  Loss: (0.1709) | Acc: (94.04%) (7343/7808)\n",
            "Epoch: 57 | Batch_idx: 70 |  Loss: (0.1757) | Acc: (93.94%) (8537/9088)\n",
            "Epoch: 57 | Batch_idx: 80 |  Loss: (0.1762) | Acc: (93.87%) (9732/10368)\n",
            "Epoch: 57 | Batch_idx: 90 |  Loss: (0.1807) | Acc: (93.74%) (10919/11648)\n",
            "Epoch: 57 | Batch_idx: 100 |  Loss: (0.1800) | Acc: (93.77%) (12123/12928)\n",
            "Epoch: 57 | Batch_idx: 110 |  Loss: (0.1815) | Acc: (93.74%) (13319/14208)\n",
            "Epoch: 57 | Batch_idx: 120 |  Loss: (0.1818) | Acc: (93.72%) (14515/15488)\n",
            "Epoch: 57 | Batch_idx: 130 |  Loss: (0.1796) | Acc: (93.83%) (15733/16768)\n",
            "Epoch: 57 | Batch_idx: 140 |  Loss: (0.1787) | Acc: (93.80%) (16929/18048)\n",
            "Epoch: 57 | Batch_idx: 150 |  Loss: (0.1797) | Acc: (93.76%) (18121/19328)\n",
            "Epoch: 57 | Batch_idx: 160 |  Loss: (0.1791) | Acc: (93.80%) (19330/20608)\n",
            "Epoch: 57 | Batch_idx: 170 |  Loss: (0.1794) | Acc: (93.76%) (20522/21888)\n",
            "Epoch: 57 | Batch_idx: 180 |  Loss: (0.1811) | Acc: (93.71%) (21710/23168)\n",
            "Epoch: 57 | Batch_idx: 190 |  Loss: (0.1808) | Acc: (93.72%) (22913/24448)\n",
            "Epoch: 57 | Batch_idx: 200 |  Loss: (0.1819) | Acc: (93.63%) (24090/25728)\n",
            "Epoch: 57 | Batch_idx: 210 |  Loss: (0.1805) | Acc: (93.66%) (25296/27008)\n",
            "Epoch: 57 | Batch_idx: 220 |  Loss: (0.1819) | Acc: (93.64%) (26489/28288)\n",
            "Epoch: 57 | Batch_idx: 230 |  Loss: (0.1822) | Acc: (93.63%) (27685/29568)\n",
            "Epoch: 57 | Batch_idx: 240 |  Loss: (0.1822) | Acc: (93.63%) (28884/30848)\n",
            "Epoch: 57 | Batch_idx: 250 |  Loss: (0.1837) | Acc: (93.59%) (30069/32128)\n",
            "Epoch: 57 | Batch_idx: 260 |  Loss: (0.1838) | Acc: (93.60%) (31271/33408)\n",
            "Epoch: 57 | Batch_idx: 270 |  Loss: (0.1828) | Acc: (93.64%) (32481/34688)\n",
            "Epoch: 57 | Batch_idx: 280 |  Loss: (0.1832) | Acc: (93.62%) (33672/35968)\n",
            "Epoch: 57 | Batch_idx: 290 |  Loss: (0.1833) | Acc: (93.63%) (34875/37248)\n",
            "Epoch: 57 | Batch_idx: 300 |  Loss: (0.1838) | Acc: (93.62%) (36068/38528)\n",
            "Epoch: 57 | Batch_idx: 310 |  Loss: (0.1844) | Acc: (93.58%) (37253/39808)\n",
            "Epoch: 57 | Batch_idx: 320 |  Loss: (0.1846) | Acc: (93.57%) (38447/41088)\n",
            "Epoch: 57 | Batch_idx: 330 |  Loss: (0.1862) | Acc: (93.52%) (39624/42368)\n",
            "Epoch: 57 | Batch_idx: 340 |  Loss: (0.1861) | Acc: (93.53%) (40825/43648)\n",
            "Epoch: 57 | Batch_idx: 350 |  Loss: (0.1868) | Acc: (93.51%) (42010/44928)\n",
            "Epoch: 57 | Batch_idx: 360 |  Loss: (0.1878) | Acc: (93.48%) (43195/46208)\n",
            "Epoch: 57 | Batch_idx: 370 |  Loss: (0.1881) | Acc: (93.47%) (44387/47488)\n",
            "Epoch: 57 | Batch_idx: 380 |  Loss: (0.1888) | Acc: (93.43%) (45563/48768)\n",
            "Epoch: 57 | Batch_idx: 390 |  Loss: (0.1886) | Acc: (93.41%) (46706/50000)\n",
            "# TEST : Loss: (0.4242) | Acc: (87.29%) (8729/10000)\n",
            "Epoch: 58 | Batch_idx: 0 |  Loss: (0.1442) | Acc: (94.53%) (121/128)\n",
            "Epoch: 58 | Batch_idx: 10 |  Loss: (0.2111) | Acc: (92.54%) (1303/1408)\n",
            "Epoch: 58 | Batch_idx: 20 |  Loss: (0.2004) | Acc: (93.23%) (2506/2688)\n",
            "Epoch: 58 | Batch_idx: 30 |  Loss: (0.1981) | Acc: (93.32%) (3703/3968)\n",
            "Epoch: 58 | Batch_idx: 40 |  Loss: (0.1954) | Acc: (93.35%) (4899/5248)\n",
            "Epoch: 58 | Batch_idx: 50 |  Loss: (0.1918) | Acc: (93.44%) (6100/6528)\n",
            "Epoch: 58 | Batch_idx: 60 |  Loss: (0.1948) | Acc: (93.21%) (7278/7808)\n",
            "Epoch: 58 | Batch_idx: 70 |  Loss: (0.1939) | Acc: (93.21%) (8471/9088)\n",
            "Epoch: 58 | Batch_idx: 80 |  Loss: (0.1930) | Acc: (93.25%) (9668/10368)\n",
            "Epoch: 58 | Batch_idx: 90 |  Loss: (0.1931) | Acc: (93.22%) (10858/11648)\n",
            "Epoch: 58 | Batch_idx: 100 |  Loss: (0.1939) | Acc: (93.14%) (12041/12928)\n",
            "Epoch: 58 | Batch_idx: 110 |  Loss: (0.1932) | Acc: (93.13%) (13232/14208)\n",
            "Epoch: 58 | Batch_idx: 120 |  Loss: (0.1914) | Acc: (93.24%) (14441/15488)\n",
            "Epoch: 58 | Batch_idx: 130 |  Loss: (0.1919) | Acc: (93.21%) (15630/16768)\n",
            "Epoch: 58 | Batch_idx: 140 |  Loss: (0.1917) | Acc: (93.20%) (16820/18048)\n",
            "Epoch: 58 | Batch_idx: 150 |  Loss: (0.1916) | Acc: (93.18%) (18009/19328)\n",
            "Epoch: 58 | Batch_idx: 160 |  Loss: (0.1920) | Acc: (93.16%) (19198/20608)\n",
            "Epoch: 58 | Batch_idx: 170 |  Loss: (0.1918) | Acc: (93.19%) (20397/21888)\n",
            "Epoch: 58 | Batch_idx: 180 |  Loss: (0.1908) | Acc: (93.25%) (21604/23168)\n",
            "Epoch: 58 | Batch_idx: 190 |  Loss: (0.1900) | Acc: (93.29%) (22807/24448)\n",
            "Epoch: 58 | Batch_idx: 200 |  Loss: (0.1906) | Acc: (93.26%) (23995/25728)\n",
            "Epoch: 58 | Batch_idx: 210 |  Loss: (0.1907) | Acc: (93.28%) (25192/27008)\n",
            "Epoch: 58 | Batch_idx: 220 |  Loss: (0.1914) | Acc: (93.26%) (26381/28288)\n",
            "Epoch: 58 | Batch_idx: 230 |  Loss: (0.1914) | Acc: (93.25%) (27573/29568)\n",
            "Epoch: 58 | Batch_idx: 240 |  Loss: (0.1912) | Acc: (93.24%) (28764/30848)\n",
            "Epoch: 58 | Batch_idx: 250 |  Loss: (0.1916) | Acc: (93.25%) (29960/32128)\n",
            "Epoch: 58 | Batch_idx: 260 |  Loss: (0.1929) | Acc: (93.20%) (31136/33408)\n",
            "Epoch: 58 | Batch_idx: 270 |  Loss: (0.1933) | Acc: (93.17%) (32318/34688)\n",
            "Epoch: 58 | Batch_idx: 280 |  Loss: (0.1958) | Acc: (93.05%) (33470/35968)\n",
            "Epoch: 58 | Batch_idx: 290 |  Loss: (0.1966) | Acc: (93.04%) (34655/37248)\n",
            "Epoch: 58 | Batch_idx: 300 |  Loss: (0.1957) | Acc: (93.09%) (35864/38528)\n",
            "Epoch: 58 | Batch_idx: 310 |  Loss: (0.1953) | Acc: (93.10%) (37062/39808)\n",
            "Epoch: 58 | Batch_idx: 320 |  Loss: (0.1953) | Acc: (93.11%) (38255/41088)\n",
            "Epoch: 58 | Batch_idx: 330 |  Loss: (0.1958) | Acc: (93.12%) (39452/42368)\n",
            "Epoch: 58 | Batch_idx: 340 |  Loss: (0.1965) | Acc: (93.12%) (40644/43648)\n",
            "Epoch: 58 | Batch_idx: 350 |  Loss: (0.1971) | Acc: (93.12%) (41837/44928)\n",
            "Epoch: 58 | Batch_idx: 360 |  Loss: (0.1980) | Acc: (93.10%) (43021/46208)\n",
            "Epoch: 58 | Batch_idx: 370 |  Loss: (0.1991) | Acc: (93.08%) (44200/47488)\n",
            "Epoch: 58 | Batch_idx: 380 |  Loss: (0.1990) | Acc: (93.05%) (45381/48768)\n",
            "Epoch: 58 | Batch_idx: 390 |  Loss: (0.1991) | Acc: (93.04%) (46519/50000)\n",
            "# TEST : Loss: (0.4034) | Acc: (87.75%) (8775/10000)\n",
            "Epoch: 59 | Batch_idx: 0 |  Loss: (0.1650) | Acc: (94.53%) (121/128)\n",
            "Epoch: 59 | Batch_idx: 10 |  Loss: (0.1807) | Acc: (94.11%) (1325/1408)\n",
            "Epoch: 59 | Batch_idx: 20 |  Loss: (0.1910) | Acc: (93.68%) (2518/2688)\n",
            "Epoch: 59 | Batch_idx: 30 |  Loss: (0.1834) | Acc: (93.88%) (3725/3968)\n",
            "Epoch: 59 | Batch_idx: 40 |  Loss: (0.1838) | Acc: (93.58%) (4911/5248)\n",
            "Epoch: 59 | Batch_idx: 50 |  Loss: (0.1793) | Acc: (93.70%) (6117/6528)\n",
            "Epoch: 59 | Batch_idx: 60 |  Loss: (0.1800) | Acc: (93.61%) (7309/7808)\n",
            "Epoch: 59 | Batch_idx: 70 |  Loss: (0.1773) | Acc: (93.77%) (8522/9088)\n",
            "Epoch: 59 | Batch_idx: 80 |  Loss: (0.1772) | Acc: (93.73%) (9718/10368)\n",
            "Epoch: 59 | Batch_idx: 90 |  Loss: (0.1791) | Acc: (93.64%) (10907/11648)\n",
            "Epoch: 59 | Batch_idx: 100 |  Loss: (0.1822) | Acc: (93.60%) (12101/12928)\n",
            "Epoch: 59 | Batch_idx: 110 |  Loss: (0.1825) | Acc: (93.60%) (13298/14208)\n",
            "Epoch: 59 | Batch_idx: 120 |  Loss: (0.1856) | Acc: (93.45%) (14474/15488)\n",
            "Epoch: 59 | Batch_idx: 130 |  Loss: (0.1857) | Acc: (93.45%) (15670/16768)\n",
            "Epoch: 59 | Batch_idx: 140 |  Loss: (0.1850) | Acc: (93.47%) (16870/18048)\n",
            "Epoch: 59 | Batch_idx: 150 |  Loss: (0.1855) | Acc: (93.43%) (18059/19328)\n",
            "Epoch: 59 | Batch_idx: 160 |  Loss: (0.1841) | Acc: (93.48%) (19264/20608)\n",
            "Epoch: 59 | Batch_idx: 170 |  Loss: (0.1830) | Acc: (93.51%) (20468/21888)\n",
            "Epoch: 59 | Batch_idx: 180 |  Loss: (0.1829) | Acc: (93.52%) (21667/23168)\n",
            "Epoch: 59 | Batch_idx: 190 |  Loss: (0.1833) | Acc: (93.50%) (22860/24448)\n",
            "Epoch: 59 | Batch_idx: 200 |  Loss: (0.1830) | Acc: (93.52%) (24062/25728)\n",
            "Epoch: 59 | Batch_idx: 210 |  Loss: (0.1838) | Acc: (93.52%) (25257/27008)\n",
            "Epoch: 59 | Batch_idx: 220 |  Loss: (0.1844) | Acc: (93.51%) (26452/28288)\n",
            "Epoch: 59 | Batch_idx: 230 |  Loss: (0.1852) | Acc: (93.50%) (27645/29568)\n",
            "Epoch: 59 | Batch_idx: 240 |  Loss: (0.1855) | Acc: (93.48%) (28838/30848)\n",
            "Epoch: 59 | Batch_idx: 250 |  Loss: (0.1851) | Acc: (93.50%) (30041/32128)\n",
            "Epoch: 59 | Batch_idx: 260 |  Loss: (0.1844) | Acc: (93.53%) (31247/33408)\n",
            "Epoch: 59 | Batch_idx: 270 |  Loss: (0.1833) | Acc: (93.56%) (32455/34688)\n",
            "Epoch: 59 | Batch_idx: 280 |  Loss: (0.1844) | Acc: (93.55%) (33647/35968)\n",
            "Epoch: 59 | Batch_idx: 290 |  Loss: (0.1852) | Acc: (93.50%) (34827/37248)\n",
            "Epoch: 59 | Batch_idx: 300 |  Loss: (0.1862) | Acc: (93.47%) (36013/38528)\n",
            "Epoch: 59 | Batch_idx: 310 |  Loss: (0.1874) | Acc: (93.43%) (37192/39808)\n",
            "Epoch: 59 | Batch_idx: 320 |  Loss: (0.1873) | Acc: (93.43%) (38388/41088)\n",
            "Epoch: 59 | Batch_idx: 330 |  Loss: (0.1878) | Acc: (93.42%) (39582/42368)\n",
            "Epoch: 59 | Batch_idx: 340 |  Loss: (0.1886) | Acc: (93.40%) (40768/43648)\n",
            "Epoch: 59 | Batch_idx: 350 |  Loss: (0.1883) | Acc: (93.42%) (41973/44928)\n",
            "Epoch: 59 | Batch_idx: 360 |  Loss: (0.1887) | Acc: (93.41%) (43165/46208)\n",
            "Epoch: 59 | Batch_idx: 370 |  Loss: (0.1890) | Acc: (93.39%) (44350/47488)\n",
            "Epoch: 59 | Batch_idx: 380 |  Loss: (0.1893) | Acc: (93.39%) (45542/48768)\n",
            "Epoch: 59 | Batch_idx: 390 |  Loss: (0.1892) | Acc: (93.40%) (46702/50000)\n",
            "# TEST : Loss: (0.3959) | Acc: (88.33%) (8833/10000)\n",
            "Epoch: 60 | Batch_idx: 0 |  Loss: (0.1310) | Acc: (93.75%) (120/128)\n",
            "Epoch: 60 | Batch_idx: 10 |  Loss: (0.1503) | Acc: (94.96%) (1337/1408)\n",
            "Epoch: 60 | Batch_idx: 20 |  Loss: (0.1603) | Acc: (94.46%) (2539/2688)\n",
            "Epoch: 60 | Batch_idx: 30 |  Loss: (0.1658) | Acc: (94.23%) (3739/3968)\n",
            "Epoch: 60 | Batch_idx: 40 |  Loss: (0.1708) | Acc: (93.98%) (4932/5248)\n",
            "Epoch: 60 | Batch_idx: 50 |  Loss: (0.1735) | Acc: (94.07%) (6141/6528)\n",
            "Epoch: 60 | Batch_idx: 60 |  Loss: (0.1752) | Acc: (93.89%) (7331/7808)\n",
            "Epoch: 60 | Batch_idx: 70 |  Loss: (0.1746) | Acc: (93.89%) (8533/9088)\n",
            "Epoch: 60 | Batch_idx: 80 |  Loss: (0.1791) | Acc: (93.69%) (9714/10368)\n",
            "Epoch: 60 | Batch_idx: 90 |  Loss: (0.1776) | Acc: (93.78%) (10923/11648)\n",
            "Epoch: 60 | Batch_idx: 100 |  Loss: (0.1776) | Acc: (93.75%) (12120/12928)\n",
            "Epoch: 60 | Batch_idx: 110 |  Loss: (0.1768) | Acc: (93.81%) (13328/14208)\n",
            "Epoch: 60 | Batch_idx: 120 |  Loss: (0.1793) | Acc: (93.70%) (14512/15488)\n",
            "Epoch: 60 | Batch_idx: 130 |  Loss: (0.1796) | Acc: (93.76%) (15721/16768)\n",
            "Epoch: 60 | Batch_idx: 140 |  Loss: (0.1825) | Acc: (93.66%) (16904/18048)\n",
            "Epoch: 60 | Batch_idx: 150 |  Loss: (0.1830) | Acc: (93.60%) (18091/19328)\n",
            "Epoch: 60 | Batch_idx: 160 |  Loss: (0.1843) | Acc: (93.59%) (19287/20608)\n",
            "Epoch: 60 | Batch_idx: 170 |  Loss: (0.1841) | Acc: (93.62%) (20491/21888)\n",
            "Epoch: 60 | Batch_idx: 180 |  Loss: (0.1841) | Acc: (93.63%) (21693/23168)\n",
            "Epoch: 60 | Batch_idx: 190 |  Loss: (0.1852) | Acc: (93.55%) (22870/24448)\n",
            "Epoch: 60 | Batch_idx: 200 |  Loss: (0.1868) | Acc: (93.51%) (24058/25728)\n",
            "Epoch: 60 | Batch_idx: 210 |  Loss: (0.1871) | Acc: (93.49%) (25251/27008)\n",
            "Epoch: 60 | Batch_idx: 220 |  Loss: (0.1886) | Acc: (93.42%) (26428/28288)\n",
            "Epoch: 60 | Batch_idx: 230 |  Loss: (0.1889) | Acc: (93.43%) (27626/29568)\n",
            "Epoch: 60 | Batch_idx: 240 |  Loss: (0.1893) | Acc: (93.42%) (28819/30848)\n",
            "Epoch: 60 | Batch_idx: 250 |  Loss: (0.1889) | Acc: (93.40%) (30009/32128)\n",
            "Epoch: 60 | Batch_idx: 260 |  Loss: (0.1890) | Acc: (93.40%) (31203/33408)\n",
            "Epoch: 60 | Batch_idx: 270 |  Loss: (0.1904) | Acc: (93.34%) (32379/34688)\n",
            "Epoch: 60 | Batch_idx: 280 |  Loss: (0.1906) | Acc: (93.34%) (33572/35968)\n",
            "Epoch: 60 | Batch_idx: 290 |  Loss: (0.1911) | Acc: (93.31%) (34757/37248)\n",
            "Epoch: 60 | Batch_idx: 300 |  Loss: (0.1911) | Acc: (93.32%) (35954/38528)\n",
            "Epoch: 60 | Batch_idx: 310 |  Loss: (0.1914) | Acc: (93.30%) (37139/39808)\n",
            "Epoch: 60 | Batch_idx: 320 |  Loss: (0.1925) | Acc: (93.24%) (38311/41088)\n",
            "Epoch: 60 | Batch_idx: 330 |  Loss: (0.1934) | Acc: (93.20%) (39488/42368)\n",
            "Epoch: 60 | Batch_idx: 340 |  Loss: (0.1944) | Acc: (93.17%) (40669/43648)\n",
            "Epoch: 60 | Batch_idx: 350 |  Loss: (0.1949) | Acc: (93.17%) (41860/44928)\n",
            "Epoch: 60 | Batch_idx: 360 |  Loss: (0.1947) | Acc: (93.18%) (43056/46208)\n",
            "Epoch: 60 | Batch_idx: 370 |  Loss: (0.1954) | Acc: (93.14%) (44232/47488)\n",
            "Epoch: 60 | Batch_idx: 380 |  Loss: (0.1958) | Acc: (93.12%) (45414/48768)\n",
            "Epoch: 60 | Batch_idx: 390 |  Loss: (0.1967) | Acc: (93.09%) (46546/50000)\n",
            "# TEST : Loss: (0.4018) | Acc: (87.50%) (8750/10000)\n",
            "Epoch: 61 | Batch_idx: 0 |  Loss: (0.1964) | Acc: (92.19%) (118/128)\n",
            "Epoch: 61 | Batch_idx: 10 |  Loss: (0.1630) | Acc: (94.39%) (1329/1408)\n",
            "Epoch: 61 | Batch_idx: 20 |  Loss: (0.1789) | Acc: (93.71%) (2519/2688)\n",
            "Epoch: 61 | Batch_idx: 30 |  Loss: (0.1730) | Acc: (94.10%) (3734/3968)\n",
            "Epoch: 61 | Batch_idx: 40 |  Loss: (0.1706) | Acc: (94.17%) (4942/5248)\n",
            "Epoch: 61 | Batch_idx: 50 |  Loss: (0.1740) | Acc: (93.92%) (6131/6528)\n",
            "Epoch: 61 | Batch_idx: 60 |  Loss: (0.1713) | Acc: (93.97%) (7337/7808)\n",
            "Epoch: 61 | Batch_idx: 70 |  Loss: (0.1685) | Acc: (94.05%) (8547/9088)\n",
            "Epoch: 61 | Batch_idx: 80 |  Loss: (0.1751) | Acc: (93.92%) (9738/10368)\n",
            "Epoch: 61 | Batch_idx: 90 |  Loss: (0.1791) | Acc: (93.77%) (10922/11648)\n",
            "Epoch: 61 | Batch_idx: 100 |  Loss: (0.1783) | Acc: (93.74%) (12119/12928)\n",
            "Epoch: 61 | Batch_idx: 110 |  Loss: (0.1804) | Acc: (93.68%) (13310/14208)\n",
            "Epoch: 61 | Batch_idx: 120 |  Loss: (0.1822) | Acc: (93.65%) (14505/15488)\n",
            "Epoch: 61 | Batch_idx: 130 |  Loss: (0.1830) | Acc: (93.60%) (15695/16768)\n",
            "Epoch: 61 | Batch_idx: 140 |  Loss: (0.1831) | Acc: (93.58%) (16889/18048)\n",
            "Epoch: 61 | Batch_idx: 150 |  Loss: (0.1852) | Acc: (93.51%) (18073/19328)\n",
            "Epoch: 61 | Batch_idx: 160 |  Loss: (0.1868) | Acc: (93.45%) (19259/20608)\n",
            "Epoch: 61 | Batch_idx: 170 |  Loss: (0.1865) | Acc: (93.50%) (20465/21888)\n",
            "Epoch: 61 | Batch_idx: 180 |  Loss: (0.1861) | Acc: (93.53%) (21668/23168)\n",
            "Epoch: 61 | Batch_idx: 190 |  Loss: (0.1865) | Acc: (93.51%) (22862/24448)\n",
            "Epoch: 61 | Batch_idx: 200 |  Loss: (0.1882) | Acc: (93.47%) (24049/25728)\n",
            "Epoch: 61 | Batch_idx: 210 |  Loss: (0.1891) | Acc: (93.41%) (25228/27008)\n",
            "Epoch: 61 | Batch_idx: 220 |  Loss: (0.1892) | Acc: (93.39%) (26417/28288)\n",
            "Epoch: 61 | Batch_idx: 230 |  Loss: (0.1900) | Acc: (93.32%) (27594/29568)\n",
            "Epoch: 61 | Batch_idx: 240 |  Loss: (0.1901) | Acc: (93.34%) (28794/30848)\n",
            "Epoch: 61 | Batch_idx: 250 |  Loss: (0.1901) | Acc: (93.33%) (29985/32128)\n",
            "Epoch: 61 | Batch_idx: 260 |  Loss: (0.1902) | Acc: (93.31%) (31174/33408)\n",
            "Epoch: 61 | Batch_idx: 270 |  Loss: (0.1912) | Acc: (93.29%) (32361/34688)\n",
            "Epoch: 61 | Batch_idx: 280 |  Loss: (0.1912) | Acc: (93.29%) (33556/35968)\n",
            "Epoch: 61 | Batch_idx: 290 |  Loss: (0.1912) | Acc: (93.29%) (34747/37248)\n",
            "Epoch: 61 | Batch_idx: 300 |  Loss: (0.1910) | Acc: (93.29%) (35941/38528)\n",
            "Epoch: 61 | Batch_idx: 310 |  Loss: (0.1905) | Acc: (93.31%) (37146/39808)\n",
            "Epoch: 61 | Batch_idx: 320 |  Loss: (0.1913) | Acc: (93.28%) (38327/41088)\n",
            "Epoch: 61 | Batch_idx: 330 |  Loss: (0.1921) | Acc: (93.26%) (39511/42368)\n",
            "Epoch: 61 | Batch_idx: 340 |  Loss: (0.1916) | Acc: (93.28%) (40714/43648)\n",
            "Epoch: 61 | Batch_idx: 350 |  Loss: (0.1914) | Acc: (93.28%) (41910/44928)\n",
            "Epoch: 61 | Batch_idx: 360 |  Loss: (0.1918) | Acc: (93.30%) (43110/46208)\n",
            "Epoch: 61 | Batch_idx: 370 |  Loss: (0.1916) | Acc: (93.30%) (44307/47488)\n",
            "Epoch: 61 | Batch_idx: 380 |  Loss: (0.1918) | Acc: (93.31%) (45507/48768)\n",
            "Epoch: 61 | Batch_idx: 390 |  Loss: (0.1929) | Acc: (93.27%) (46637/50000)\n",
            "# TEST : Loss: (0.4561) | Acc: (86.52%) (8652/10000)\n",
            "Epoch: 62 | Batch_idx: 0 |  Loss: (0.1213) | Acc: (95.31%) (122/128)\n",
            "Epoch: 62 | Batch_idx: 10 |  Loss: (0.2011) | Acc: (93.47%) (1316/1408)\n",
            "Epoch: 62 | Batch_idx: 20 |  Loss: (0.1858) | Acc: (93.56%) (2515/2688)\n",
            "Epoch: 62 | Batch_idx: 30 |  Loss: (0.1784) | Acc: (93.75%) (3720/3968)\n",
            "Epoch: 62 | Batch_idx: 40 |  Loss: (0.1690) | Acc: (94.11%) (4939/5248)\n",
            "Epoch: 62 | Batch_idx: 50 |  Loss: (0.1742) | Acc: (93.90%) (6130/6528)\n",
            "Epoch: 62 | Batch_idx: 60 |  Loss: (0.1692) | Acc: (94.08%) (7346/7808)\n",
            "Epoch: 62 | Batch_idx: 70 |  Loss: (0.1699) | Acc: (94.00%) (8543/9088)\n",
            "Epoch: 62 | Batch_idx: 80 |  Loss: (0.1741) | Acc: (93.82%) (9727/10368)\n",
            "Epoch: 62 | Batch_idx: 90 |  Loss: (0.1755) | Acc: (93.79%) (10925/11648)\n",
            "Epoch: 62 | Batch_idx: 100 |  Loss: (0.1771) | Acc: (93.72%) (12116/12928)\n",
            "Epoch: 62 | Batch_idx: 110 |  Loss: (0.1775) | Acc: (93.71%) (13314/14208)\n",
            "Epoch: 62 | Batch_idx: 120 |  Loss: (0.1767) | Acc: (93.72%) (14515/15488)\n",
            "Epoch: 62 | Batch_idx: 130 |  Loss: (0.1802) | Acc: (93.65%) (15703/16768)\n",
            "Epoch: 62 | Batch_idx: 140 |  Loss: (0.1798) | Acc: (93.65%) (16902/18048)\n",
            "Epoch: 62 | Batch_idx: 150 |  Loss: (0.1796) | Acc: (93.65%) (18100/19328)\n",
            "Epoch: 62 | Batch_idx: 160 |  Loss: (0.1809) | Acc: (93.61%) (19291/20608)\n",
            "Epoch: 62 | Batch_idx: 170 |  Loss: (0.1828) | Acc: (93.54%) (20473/21888)\n",
            "Epoch: 62 | Batch_idx: 180 |  Loss: (0.1838) | Acc: (93.50%) (21663/23168)\n",
            "Epoch: 62 | Batch_idx: 190 |  Loss: (0.1835) | Acc: (93.53%) (22865/24448)\n",
            "Epoch: 62 | Batch_idx: 200 |  Loss: (0.1855) | Acc: (93.46%) (24045/25728)\n",
            "Epoch: 62 | Batch_idx: 210 |  Loss: (0.1874) | Acc: (93.39%) (25222/27008)\n",
            "Epoch: 62 | Batch_idx: 220 |  Loss: (0.1884) | Acc: (93.34%) (26404/28288)\n",
            "Epoch: 62 | Batch_idx: 230 |  Loss: (0.1901) | Acc: (93.28%) (27582/29568)\n",
            "Epoch: 62 | Batch_idx: 240 |  Loss: (0.1900) | Acc: (93.28%) (28776/30848)\n",
            "Epoch: 62 | Batch_idx: 250 |  Loss: (0.1896) | Acc: (93.30%) (29977/32128)\n",
            "Epoch: 62 | Batch_idx: 260 |  Loss: (0.1894) | Acc: (93.30%) (31169/33408)\n",
            "Epoch: 62 | Batch_idx: 270 |  Loss: (0.1894) | Acc: (93.32%) (32372/34688)\n",
            "Epoch: 62 | Batch_idx: 280 |  Loss: (0.1878) | Acc: (93.39%) (33589/35968)\n",
            "Epoch: 62 | Batch_idx: 290 |  Loss: (0.1868) | Acc: (93.44%) (34805/37248)\n",
            "Epoch: 62 | Batch_idx: 300 |  Loss: (0.1873) | Acc: (93.43%) (35997/38528)\n",
            "Epoch: 62 | Batch_idx: 310 |  Loss: (0.1880) | Acc: (93.40%) (37181/39808)\n",
            "Epoch: 62 | Batch_idx: 320 |  Loss: (0.1873) | Acc: (93.42%) (38384/41088)\n",
            "Epoch: 62 | Batch_idx: 330 |  Loss: (0.1875) | Acc: (93.41%) (39577/42368)\n",
            "Epoch: 62 | Batch_idx: 340 |  Loss: (0.1881) | Acc: (93.38%) (40760/43648)\n",
            "Epoch: 62 | Batch_idx: 350 |  Loss: (0.1886) | Acc: (93.38%) (41954/44928)\n",
            "Epoch: 62 | Batch_idx: 360 |  Loss: (0.1882) | Acc: (93.40%) (43158/46208)\n",
            "Epoch: 62 | Batch_idx: 370 |  Loss: (0.1878) | Acc: (93.42%) (44361/47488)\n",
            "Epoch: 62 | Batch_idx: 380 |  Loss: (0.1883) | Acc: (93.39%) (45542/48768)\n",
            "Epoch: 62 | Batch_idx: 390 |  Loss: (0.1889) | Acc: (93.35%) (46674/50000)\n",
            "# TEST : Loss: (0.4296) | Acc: (87.39%) (8739/10000)\n",
            "Epoch: 63 | Batch_idx: 0 |  Loss: (0.2216) | Acc: (93.75%) (120/128)\n",
            "Epoch: 63 | Batch_idx: 10 |  Loss: (0.1951) | Acc: (93.18%) (1312/1408)\n",
            "Epoch: 63 | Batch_idx: 20 |  Loss: (0.1726) | Acc: (93.75%) (2520/2688)\n",
            "Epoch: 63 | Batch_idx: 30 |  Loss: (0.1855) | Acc: (93.62%) (3715/3968)\n",
            "Epoch: 63 | Batch_idx: 40 |  Loss: (0.1785) | Acc: (93.65%) (4915/5248)\n",
            "Epoch: 63 | Batch_idx: 50 |  Loss: (0.1787) | Acc: (93.66%) (6114/6528)\n",
            "Epoch: 63 | Batch_idx: 60 |  Loss: (0.1755) | Acc: (93.78%) (7322/7808)\n",
            "Epoch: 63 | Batch_idx: 70 |  Loss: (0.1794) | Acc: (93.68%) (8514/9088)\n",
            "Epoch: 63 | Batch_idx: 80 |  Loss: (0.1819) | Acc: (93.53%) (9697/10368)\n",
            "Epoch: 63 | Batch_idx: 90 |  Loss: (0.1808) | Acc: (93.53%) (10894/11648)\n",
            "Epoch: 63 | Batch_idx: 100 |  Loss: (0.1826) | Acc: (93.49%) (12086/12928)\n",
            "Epoch: 63 | Batch_idx: 110 |  Loss: (0.1814) | Acc: (93.52%) (13288/14208)\n",
            "Epoch: 63 | Batch_idx: 120 |  Loss: (0.1804) | Acc: (93.60%) (14496/15488)\n",
            "Epoch: 63 | Batch_idx: 130 |  Loss: (0.1800) | Acc: (93.62%) (15698/16768)\n",
            "Epoch: 63 | Batch_idx: 140 |  Loss: (0.1813) | Acc: (93.58%) (16889/18048)\n",
            "Epoch: 63 | Batch_idx: 150 |  Loss: (0.1803) | Acc: (93.63%) (18097/19328)\n",
            "Epoch: 63 | Batch_idx: 160 |  Loss: (0.1808) | Acc: (93.62%) (19294/20608)\n",
            "Epoch: 63 | Batch_idx: 170 |  Loss: (0.1803) | Acc: (93.65%) (20499/21888)\n",
            "Epoch: 63 | Batch_idx: 180 |  Loss: (0.1815) | Acc: (93.59%) (21684/23168)\n",
            "Epoch: 63 | Batch_idx: 190 |  Loss: (0.1822) | Acc: (93.57%) (22876/24448)\n",
            "Epoch: 63 | Batch_idx: 200 |  Loss: (0.1828) | Acc: (93.58%) (24075/25728)\n",
            "Epoch: 63 | Batch_idx: 210 |  Loss: (0.1840) | Acc: (93.53%) (25260/27008)\n",
            "Epoch: 63 | Batch_idx: 220 |  Loss: (0.1845) | Acc: (93.50%) (26449/28288)\n",
            "Epoch: 63 | Batch_idx: 230 |  Loss: (0.1843) | Acc: (93.48%) (27641/29568)\n",
            "Epoch: 63 | Batch_idx: 240 |  Loss: (0.1844) | Acc: (93.50%) (28843/30848)\n",
            "Epoch: 63 | Batch_idx: 250 |  Loss: (0.1846) | Acc: (93.47%) (30031/32128)\n",
            "Epoch: 63 | Batch_idx: 260 |  Loss: (0.1844) | Acc: (93.47%) (31226/33408)\n",
            "Epoch: 63 | Batch_idx: 270 |  Loss: (0.1852) | Acc: (93.44%) (32413/34688)\n",
            "Epoch: 63 | Batch_idx: 280 |  Loss: (0.1851) | Acc: (93.46%) (33617/35968)\n",
            "Epoch: 63 | Batch_idx: 290 |  Loss: (0.1853) | Acc: (93.45%) (34810/37248)\n",
            "Epoch: 63 | Batch_idx: 300 |  Loss: (0.1860) | Acc: (93.44%) (36002/38528)\n",
            "Epoch: 63 | Batch_idx: 310 |  Loss: (0.1854) | Acc: (93.45%) (37202/39808)\n",
            "Epoch: 63 | Batch_idx: 320 |  Loss: (0.1850) | Acc: (93.47%) (38404/41088)\n",
            "Epoch: 63 | Batch_idx: 330 |  Loss: (0.1848) | Acc: (93.45%) (39595/42368)\n",
            "Epoch: 63 | Batch_idx: 340 |  Loss: (0.1861) | Acc: (93.41%) (40773/43648)\n",
            "Epoch: 63 | Batch_idx: 350 |  Loss: (0.1865) | Acc: (93.41%) (41967/44928)\n",
            "Epoch: 63 | Batch_idx: 360 |  Loss: (0.1871) | Acc: (93.40%) (43157/46208)\n",
            "Epoch: 63 | Batch_idx: 370 |  Loss: (0.1873) | Acc: (93.38%) (44344/47488)\n",
            "Epoch: 63 | Batch_idx: 380 |  Loss: (0.1881) | Acc: (93.35%) (45524/48768)\n",
            "Epoch: 63 | Batch_idx: 390 |  Loss: (0.1883) | Acc: (93.34%) (46669/50000)\n",
            "# TEST : Loss: (0.4206) | Acc: (87.26%) (8726/10000)\n",
            "Epoch: 64 | Batch_idx: 0 |  Loss: (0.1400) | Acc: (96.09%) (123/128)\n",
            "Epoch: 64 | Batch_idx: 10 |  Loss: (0.1861) | Acc: (93.32%) (1314/1408)\n",
            "Epoch: 64 | Batch_idx: 20 |  Loss: (0.1812) | Acc: (93.49%) (2513/2688)\n",
            "Epoch: 64 | Batch_idx: 30 |  Loss: (0.1701) | Acc: (94.05%) (3732/3968)\n",
            "Epoch: 64 | Batch_idx: 40 |  Loss: (0.1687) | Acc: (94.23%) (4945/5248)\n",
            "Epoch: 64 | Batch_idx: 50 |  Loss: (0.1635) | Acc: (94.41%) (6163/6528)\n",
            "Epoch: 64 | Batch_idx: 60 |  Loss: (0.1631) | Acc: (94.36%) (7368/7808)\n",
            "Epoch: 64 | Batch_idx: 70 |  Loss: (0.1597) | Acc: (94.40%) (8579/9088)\n",
            "Epoch: 64 | Batch_idx: 80 |  Loss: (0.1648) | Acc: (94.22%) (9769/10368)\n",
            "Epoch: 64 | Batch_idx: 90 |  Loss: (0.1657) | Acc: (94.16%) (10968/11648)\n",
            "Epoch: 64 | Batch_idx: 100 |  Loss: (0.1707) | Acc: (94.02%) (12155/12928)\n",
            "Epoch: 64 | Batch_idx: 110 |  Loss: (0.1732) | Acc: (93.90%) (13341/14208)\n",
            "Epoch: 64 | Batch_idx: 120 |  Loss: (0.1724) | Acc: (93.94%) (14549/15488)\n",
            "Epoch: 64 | Batch_idx: 130 |  Loss: (0.1750) | Acc: (93.84%) (15735/16768)\n",
            "Epoch: 64 | Batch_idx: 140 |  Loss: (0.1763) | Acc: (93.81%) (16931/18048)\n",
            "Epoch: 64 | Batch_idx: 150 |  Loss: (0.1766) | Acc: (93.83%) (18136/19328)\n",
            "Epoch: 64 | Batch_idx: 160 |  Loss: (0.1778) | Acc: (93.77%) (19324/20608)\n",
            "Epoch: 64 | Batch_idx: 170 |  Loss: (0.1810) | Acc: (93.64%) (20497/21888)\n",
            "Epoch: 64 | Batch_idx: 180 |  Loss: (0.1802) | Acc: (93.69%) (21707/23168)\n",
            "Epoch: 64 | Batch_idx: 190 |  Loss: (0.1806) | Acc: (93.66%) (22897/24448)\n",
            "Epoch: 64 | Batch_idx: 200 |  Loss: (0.1827) | Acc: (93.55%) (24069/25728)\n",
            "Epoch: 64 | Batch_idx: 210 |  Loss: (0.1849) | Acc: (93.50%) (25252/27008)\n",
            "Epoch: 64 | Batch_idx: 220 |  Loss: (0.1847) | Acc: (93.53%) (26459/28288)\n",
            "Epoch: 64 | Batch_idx: 230 |  Loss: (0.1853) | Acc: (93.51%) (27649/29568)\n",
            "Epoch: 64 | Batch_idx: 240 |  Loss: (0.1866) | Acc: (93.47%) (28834/30848)\n",
            "Epoch: 64 | Batch_idx: 250 |  Loss: (0.1884) | Acc: (93.42%) (30013/32128)\n",
            "Epoch: 64 | Batch_idx: 260 |  Loss: (0.1891) | Acc: (93.38%) (31197/33408)\n",
            "Epoch: 64 | Batch_idx: 270 |  Loss: (0.1891) | Acc: (93.38%) (32392/34688)\n",
            "Epoch: 64 | Batch_idx: 280 |  Loss: (0.1890) | Acc: (93.38%) (33587/35968)\n",
            "Epoch: 64 | Batch_idx: 290 |  Loss: (0.1895) | Acc: (93.37%) (34778/37248)\n",
            "Epoch: 64 | Batch_idx: 300 |  Loss: (0.1890) | Acc: (93.42%) (35991/38528)\n",
            "Epoch: 64 | Batch_idx: 310 |  Loss: (0.1891) | Acc: (93.41%) (37185/39808)\n",
            "Epoch: 64 | Batch_idx: 320 |  Loss: (0.1889) | Acc: (93.43%) (38387/41088)\n",
            "Epoch: 64 | Batch_idx: 330 |  Loss: (0.1884) | Acc: (93.44%) (39588/42368)\n",
            "Epoch: 64 | Batch_idx: 340 |  Loss: (0.1886) | Acc: (93.45%) (40788/43648)\n",
            "Epoch: 64 | Batch_idx: 350 |  Loss: (0.1882) | Acc: (93.48%) (41998/44928)\n",
            "Epoch: 64 | Batch_idx: 360 |  Loss: (0.1881) | Acc: (93.48%) (43195/46208)\n",
            "Epoch: 64 | Batch_idx: 370 |  Loss: (0.1885) | Acc: (93.47%) (44389/47488)\n",
            "Epoch: 64 | Batch_idx: 380 |  Loss: (0.1888) | Acc: (93.45%) (45576/48768)\n",
            "Epoch: 64 | Batch_idx: 390 |  Loss: (0.1887) | Acc: (93.46%) (46728/50000)\n",
            "# TEST : Loss: (0.4315) | Acc: (87.49%) (8749/10000)\n",
            "Epoch: 65 | Batch_idx: 0 |  Loss: (0.1907) | Acc: (91.41%) (117/128)\n",
            "Epoch: 65 | Batch_idx: 10 |  Loss: (0.1563) | Acc: (94.39%) (1329/1408)\n",
            "Epoch: 65 | Batch_idx: 20 |  Loss: (0.1674) | Acc: (93.60%) (2516/2688)\n",
            "Epoch: 65 | Batch_idx: 30 |  Loss: (0.1662) | Acc: (93.78%) (3721/3968)\n",
            "Epoch: 65 | Batch_idx: 40 |  Loss: (0.1699) | Acc: (93.77%) (4921/5248)\n",
            "Epoch: 65 | Batch_idx: 50 |  Loss: (0.1763) | Acc: (93.58%) (6109/6528)\n",
            "Epoch: 65 | Batch_idx: 60 |  Loss: (0.1768) | Acc: (93.71%) (7317/7808)\n",
            "Epoch: 65 | Batch_idx: 70 |  Loss: (0.1785) | Acc: (93.60%) (8506/9088)\n",
            "Epoch: 65 | Batch_idx: 80 |  Loss: (0.1798) | Acc: (93.61%) (9705/10368)\n",
            "Epoch: 65 | Batch_idx: 90 |  Loss: (0.1836) | Acc: (93.39%) (10878/11648)\n",
            "Epoch: 65 | Batch_idx: 100 |  Loss: (0.1880) | Acc: (93.15%) (12042/12928)\n",
            "Epoch: 65 | Batch_idx: 110 |  Loss: (0.1916) | Acc: (93.03%) (13217/14208)\n",
            "Epoch: 65 | Batch_idx: 120 |  Loss: (0.1944) | Acc: (92.92%) (14391/15488)\n",
            "Epoch: 65 | Batch_idx: 130 |  Loss: (0.1945) | Acc: (92.96%) (15587/16768)\n",
            "Epoch: 65 | Batch_idx: 140 |  Loss: (0.1935) | Acc: (93.00%) (16785/18048)\n",
            "Epoch: 65 | Batch_idx: 150 |  Loss: (0.1906) | Acc: (93.10%) (17995/19328)\n",
            "Epoch: 65 | Batch_idx: 160 |  Loss: (0.1916) | Acc: (93.09%) (19185/20608)\n",
            "Epoch: 65 | Batch_idx: 170 |  Loss: (0.1925) | Acc: (93.05%) (20366/21888)\n",
            "Epoch: 65 | Batch_idx: 180 |  Loss: (0.1924) | Acc: (93.04%) (21555/23168)\n",
            "Epoch: 65 | Batch_idx: 190 |  Loss: (0.1926) | Acc: (93.04%) (22746/24448)\n",
            "Epoch: 65 | Batch_idx: 200 |  Loss: (0.1918) | Acc: (93.08%) (23948/25728)\n",
            "Epoch: 65 | Batch_idx: 210 |  Loss: (0.1913) | Acc: (93.11%) (25148/27008)\n",
            "Epoch: 65 | Batch_idx: 220 |  Loss: (0.1911) | Acc: (93.11%) (26338/28288)\n",
            "Epoch: 65 | Batch_idx: 230 |  Loss: (0.1909) | Acc: (93.13%) (27536/29568)\n",
            "Epoch: 65 | Batch_idx: 240 |  Loss: (0.1912) | Acc: (93.11%) (28723/30848)\n",
            "Epoch: 65 | Batch_idx: 250 |  Loss: (0.1917) | Acc: (93.12%) (29917/32128)\n",
            "Epoch: 65 | Batch_idx: 260 |  Loss: (0.1930) | Acc: (93.06%) (31089/33408)\n",
            "Epoch: 65 | Batch_idx: 270 |  Loss: (0.1925) | Acc: (93.08%) (32287/34688)\n",
            "Epoch: 65 | Batch_idx: 280 |  Loss: (0.1927) | Acc: (93.09%) (33483/35968)\n",
            "Epoch: 65 | Batch_idx: 290 |  Loss: (0.1920) | Acc: (93.11%) (34683/37248)\n",
            "Epoch: 65 | Batch_idx: 300 |  Loss: (0.1914) | Acc: (93.13%) (35882/38528)\n",
            "Epoch: 65 | Batch_idx: 310 |  Loss: (0.1923) | Acc: (93.10%) (37063/39808)\n",
            "Epoch: 65 | Batch_idx: 320 |  Loss: (0.1918) | Acc: (93.11%) (38259/41088)\n",
            "Epoch: 65 | Batch_idx: 330 |  Loss: (0.1920) | Acc: (93.12%) (39452/42368)\n",
            "Epoch: 65 | Batch_idx: 340 |  Loss: (0.1914) | Acc: (93.15%) (40658/43648)\n",
            "Epoch: 65 | Batch_idx: 350 |  Loss: (0.1914) | Acc: (93.14%) (41848/44928)\n",
            "Epoch: 65 | Batch_idx: 360 |  Loss: (0.1915) | Acc: (93.16%) (43046/46208)\n",
            "Epoch: 65 | Batch_idx: 370 |  Loss: (0.1916) | Acc: (93.18%) (44249/47488)\n",
            "Epoch: 65 | Batch_idx: 380 |  Loss: (0.1917) | Acc: (93.18%) (45441/48768)\n",
            "Epoch: 65 | Batch_idx: 390 |  Loss: (0.1912) | Acc: (93.20%) (46599/50000)\n",
            "# TEST : Loss: (0.4163) | Acc: (87.44%) (8744/10000)\n",
            "Epoch: 66 | Batch_idx: 0 |  Loss: (0.1279) | Acc: (94.53%) (121/128)\n",
            "Epoch: 66 | Batch_idx: 10 |  Loss: (0.1703) | Acc: (94.11%) (1325/1408)\n",
            "Epoch: 66 | Batch_idx: 20 |  Loss: (0.1627) | Acc: (94.42%) (2538/2688)\n",
            "Epoch: 66 | Batch_idx: 30 |  Loss: (0.1714) | Acc: (94.00%) (3730/3968)\n",
            "Epoch: 66 | Batch_idx: 40 |  Loss: (0.1711) | Acc: (93.92%) (4929/5248)\n",
            "Epoch: 66 | Batch_idx: 50 |  Loss: (0.1723) | Acc: (93.86%) (6127/6528)\n",
            "Epoch: 66 | Batch_idx: 60 |  Loss: (0.1744) | Acc: (93.66%) (7313/7808)\n",
            "Epoch: 66 | Batch_idx: 70 |  Loss: (0.1739) | Acc: (93.60%) (8506/9088)\n",
            "Epoch: 66 | Batch_idx: 80 |  Loss: (0.1747) | Acc: (93.61%) (9705/10368)\n",
            "Epoch: 66 | Batch_idx: 90 |  Loss: (0.1786) | Acc: (93.52%) (10893/11648)\n",
            "Epoch: 66 | Batch_idx: 100 |  Loss: (0.1766) | Acc: (93.60%) (12100/12928)\n",
            "Epoch: 66 | Batch_idx: 110 |  Loss: (0.1762) | Acc: (93.64%) (13304/14208)\n",
            "Epoch: 66 | Batch_idx: 120 |  Loss: (0.1733) | Acc: (93.72%) (14515/15488)\n",
            "Epoch: 66 | Batch_idx: 130 |  Loss: (0.1714) | Acc: (93.80%) (15728/16768)\n",
            "Epoch: 66 | Batch_idx: 140 |  Loss: (0.1727) | Acc: (93.76%) (16921/18048)\n",
            "Epoch: 66 | Batch_idx: 150 |  Loss: (0.1723) | Acc: (93.76%) (18122/19328)\n",
            "Epoch: 66 | Batch_idx: 160 |  Loss: (0.1725) | Acc: (93.73%) (19316/20608)\n",
            "Epoch: 66 | Batch_idx: 170 |  Loss: (0.1740) | Acc: (93.71%) (20512/21888)\n",
            "Epoch: 66 | Batch_idx: 180 |  Loss: (0.1738) | Acc: (93.72%) (21713/23168)\n",
            "Epoch: 66 | Batch_idx: 190 |  Loss: (0.1764) | Acc: (93.62%) (22889/24448)\n",
            "Epoch: 66 | Batch_idx: 200 |  Loss: (0.1776) | Acc: (93.58%) (24077/25728)\n",
            "Epoch: 66 | Batch_idx: 210 |  Loss: (0.1784) | Acc: (93.58%) (25275/27008)\n",
            "Epoch: 66 | Batch_idx: 220 |  Loss: (0.1790) | Acc: (93.55%) (26463/28288)\n",
            "Epoch: 66 | Batch_idx: 230 |  Loss: (0.1796) | Acc: (93.53%) (27656/29568)\n",
            "Epoch: 66 | Batch_idx: 240 |  Loss: (0.1797) | Acc: (93.54%) (28855/30848)\n",
            "Epoch: 66 | Batch_idx: 250 |  Loss: (0.1809) | Acc: (93.53%) (30048/32128)\n",
            "Epoch: 66 | Batch_idx: 260 |  Loss: (0.1837) | Acc: (93.44%) (31216/33408)\n",
            "Epoch: 66 | Batch_idx: 270 |  Loss: (0.1857) | Acc: (93.35%) (32380/34688)\n",
            "Epoch: 66 | Batch_idx: 280 |  Loss: (0.1860) | Acc: (93.32%) (33565/35968)\n",
            "Epoch: 66 | Batch_idx: 290 |  Loss: (0.1865) | Acc: (93.29%) (34748/37248)\n",
            "Epoch: 66 | Batch_idx: 300 |  Loss: (0.1878) | Acc: (93.26%) (35933/38528)\n",
            "Epoch: 66 | Batch_idx: 310 |  Loss: (0.1875) | Acc: (93.27%) (37130/39808)\n",
            "Epoch: 66 | Batch_idx: 320 |  Loss: (0.1877) | Acc: (93.28%) (38325/41088)\n",
            "Epoch: 66 | Batch_idx: 330 |  Loss: (0.1900) | Acc: (93.23%) (39498/42368)\n",
            "Epoch: 66 | Batch_idx: 340 |  Loss: (0.1905) | Acc: (93.21%) (40683/43648)\n",
            "Epoch: 66 | Batch_idx: 350 |  Loss: (0.1907) | Acc: (93.19%) (41869/44928)\n",
            "Epoch: 66 | Batch_idx: 360 |  Loss: (0.1904) | Acc: (93.22%) (43077/46208)\n",
            "Epoch: 66 | Batch_idx: 370 |  Loss: (0.1901) | Acc: (93.23%) (44272/47488)\n",
            "Epoch: 66 | Batch_idx: 380 |  Loss: (0.1901) | Acc: (93.23%) (45466/48768)\n",
            "Epoch: 66 | Batch_idx: 390 |  Loss: (0.1898) | Acc: (93.25%) (46623/50000)\n",
            "# TEST : Loss: (0.3642) | Acc: (88.91%) (8891/10000)\n",
            "Epoch: 67 | Batch_idx: 0 |  Loss: (0.1238) | Acc: (96.88%) (124/128)\n",
            "Epoch: 67 | Batch_idx: 10 |  Loss: (0.1427) | Acc: (96.02%) (1352/1408)\n",
            "Epoch: 67 | Batch_idx: 20 |  Loss: (0.1439) | Acc: (95.50%) (2567/2688)\n",
            "Epoch: 67 | Batch_idx: 30 |  Loss: (0.1443) | Acc: (95.41%) (3786/3968)\n",
            "Epoch: 67 | Batch_idx: 40 |  Loss: (0.1506) | Acc: (95.08%) (4990/5248)\n",
            "Epoch: 67 | Batch_idx: 50 |  Loss: (0.1591) | Acc: (94.62%) (6177/6528)\n",
            "Epoch: 67 | Batch_idx: 60 |  Loss: (0.1605) | Acc: (94.53%) (7381/7808)\n",
            "Epoch: 67 | Batch_idx: 70 |  Loss: (0.1652) | Acc: (94.29%) (8569/9088)\n",
            "Epoch: 67 | Batch_idx: 80 |  Loss: (0.1711) | Acc: (94.00%) (9746/10368)\n",
            "Epoch: 67 | Batch_idx: 90 |  Loss: (0.1729) | Acc: (93.95%) (10943/11648)\n",
            "Epoch: 67 | Batch_idx: 100 |  Loss: (0.1761) | Acc: (93.82%) (12129/12928)\n",
            "Epoch: 67 | Batch_idx: 110 |  Loss: (0.1770) | Acc: (93.83%) (13331/14208)\n",
            "Epoch: 67 | Batch_idx: 120 |  Loss: (0.1819) | Acc: (93.66%) (14506/15488)\n",
            "Epoch: 67 | Batch_idx: 130 |  Loss: (0.1814) | Acc: (93.70%) (15711/16768)\n",
            "Epoch: 67 | Batch_idx: 140 |  Loss: (0.1836) | Acc: (93.59%) (16892/18048)\n",
            "Epoch: 67 | Batch_idx: 150 |  Loss: (0.1844) | Acc: (93.58%) (18088/19328)\n",
            "Epoch: 67 | Batch_idx: 160 |  Loss: (0.1863) | Acc: (93.54%) (19276/20608)\n",
            "Epoch: 67 | Batch_idx: 170 |  Loss: (0.1853) | Acc: (93.56%) (20479/21888)\n",
            "Epoch: 67 | Batch_idx: 180 |  Loss: (0.1854) | Acc: (93.55%) (21673/23168)\n",
            "Epoch: 67 | Batch_idx: 190 |  Loss: (0.1858) | Acc: (93.52%) (22864/24448)\n",
            "Epoch: 67 | Batch_idx: 200 |  Loss: (0.1847) | Acc: (93.56%) (24072/25728)\n",
            "Epoch: 67 | Batch_idx: 210 |  Loss: (0.1849) | Acc: (93.58%) (25273/27008)\n",
            "Epoch: 67 | Batch_idx: 220 |  Loss: (0.1863) | Acc: (93.52%) (26456/28288)\n",
            "Epoch: 67 | Batch_idx: 230 |  Loss: (0.1869) | Acc: (93.50%) (27645/29568)\n",
            "Epoch: 67 | Batch_idx: 240 |  Loss: (0.1866) | Acc: (93.51%) (28846/30848)\n",
            "Epoch: 67 | Batch_idx: 250 |  Loss: (0.1869) | Acc: (93.49%) (30035/32128)\n",
            "Epoch: 67 | Batch_idx: 260 |  Loss: (0.1867) | Acc: (93.46%) (31224/33408)\n",
            "Epoch: 67 | Batch_idx: 270 |  Loss: (0.1869) | Acc: (93.45%) (32415/34688)\n",
            "Epoch: 67 | Batch_idx: 280 |  Loss: (0.1871) | Acc: (93.44%) (33610/35968)\n",
            "Epoch: 67 | Batch_idx: 290 |  Loss: (0.1883) | Acc: (93.44%) (34804/37248)\n",
            "Epoch: 67 | Batch_idx: 300 |  Loss: (0.1889) | Acc: (93.41%) (35989/38528)\n",
            "Epoch: 67 | Batch_idx: 310 |  Loss: (0.1896) | Acc: (93.40%) (37179/39808)\n",
            "Epoch: 67 | Batch_idx: 320 |  Loss: (0.1902) | Acc: (93.38%) (38368/41088)\n",
            "Epoch: 67 | Batch_idx: 330 |  Loss: (0.1903) | Acc: (93.36%) (39555/42368)\n",
            "Epoch: 67 | Batch_idx: 340 |  Loss: (0.1898) | Acc: (93.36%) (40751/43648)\n",
            "Epoch: 67 | Batch_idx: 350 |  Loss: (0.1903) | Acc: (93.34%) (41938/44928)\n",
            "Epoch: 67 | Batch_idx: 360 |  Loss: (0.1900) | Acc: (93.37%) (43143/46208)\n",
            "Epoch: 67 | Batch_idx: 370 |  Loss: (0.1898) | Acc: (93.38%) (44343/47488)\n",
            "Epoch: 67 | Batch_idx: 380 |  Loss: (0.1901) | Acc: (93.38%) (45539/48768)\n",
            "Epoch: 67 | Batch_idx: 390 |  Loss: (0.1905) | Acc: (93.35%) (46674/50000)\n",
            "# TEST : Loss: (0.3942) | Acc: (87.68%) (8768/10000)\n",
            "Epoch: 68 | Batch_idx: 0 |  Loss: (0.2194) | Acc: (91.41%) (117/128)\n",
            "Epoch: 68 | Batch_idx: 10 |  Loss: (0.1849) | Acc: (93.04%) (1310/1408)\n",
            "Epoch: 68 | Batch_idx: 20 |  Loss: (0.1900) | Acc: (93.23%) (2506/2688)\n",
            "Epoch: 68 | Batch_idx: 30 |  Loss: (0.1951) | Acc: (93.32%) (3703/3968)\n",
            "Epoch: 68 | Batch_idx: 40 |  Loss: (0.1934) | Acc: (93.25%) (4894/5248)\n",
            "Epoch: 68 | Batch_idx: 50 |  Loss: (0.1881) | Acc: (93.31%) (6091/6528)\n",
            "Epoch: 68 | Batch_idx: 60 |  Loss: (0.1838) | Acc: (93.49%) (7300/7808)\n",
            "Epoch: 68 | Batch_idx: 70 |  Loss: (0.1798) | Acc: (93.63%) (8509/9088)\n",
            "Epoch: 68 | Batch_idx: 80 |  Loss: (0.1770) | Acc: (93.78%) (9723/10368)\n",
            "Epoch: 68 | Batch_idx: 90 |  Loss: (0.1768) | Acc: (93.79%) (10925/11648)\n",
            "Epoch: 68 | Batch_idx: 100 |  Loss: (0.1779) | Acc: (93.70%) (12114/12928)\n",
            "Epoch: 68 | Batch_idx: 110 |  Loss: (0.1801) | Acc: (93.58%) (13296/14208)\n",
            "Epoch: 68 | Batch_idx: 120 |  Loss: (0.1802) | Acc: (93.55%) (14489/15488)\n",
            "Epoch: 68 | Batch_idx: 130 |  Loss: (0.1798) | Acc: (93.59%) (15693/16768)\n",
            "Epoch: 68 | Batch_idx: 140 |  Loss: (0.1780) | Acc: (93.62%) (16897/18048)\n",
            "Epoch: 68 | Batch_idx: 150 |  Loss: (0.1779) | Acc: (93.61%) (18092/19328)\n",
            "Epoch: 68 | Batch_idx: 160 |  Loss: (0.1781) | Acc: (93.58%) (19284/20608)\n",
            "Epoch: 68 | Batch_idx: 170 |  Loss: (0.1779) | Acc: (93.59%) (20484/21888)\n",
            "Epoch: 68 | Batch_idx: 180 |  Loss: (0.1787) | Acc: (93.56%) (21676/23168)\n",
            "Epoch: 68 | Batch_idx: 190 |  Loss: (0.1786) | Acc: (93.55%) (22871/24448)\n",
            "Epoch: 68 | Batch_idx: 200 |  Loss: (0.1805) | Acc: (93.48%) (24051/25728)\n",
            "Epoch: 68 | Batch_idx: 210 |  Loss: (0.1807) | Acc: (93.48%) (25247/27008)\n",
            "Epoch: 68 | Batch_idx: 220 |  Loss: (0.1804) | Acc: (93.50%) (26448/28288)\n",
            "Epoch: 68 | Batch_idx: 230 |  Loss: (0.1817) | Acc: (93.43%) (27625/29568)\n",
            "Epoch: 68 | Batch_idx: 240 |  Loss: (0.1809) | Acc: (93.47%) (28833/30848)\n",
            "Epoch: 68 | Batch_idx: 250 |  Loss: (0.1808) | Acc: (93.49%) (30038/32128)\n",
            "Epoch: 68 | Batch_idx: 260 |  Loss: (0.1812) | Acc: (93.48%) (31229/33408)\n",
            "Epoch: 68 | Batch_idx: 270 |  Loss: (0.1817) | Acc: (93.48%) (32426/34688)\n",
            "Epoch: 68 | Batch_idx: 280 |  Loss: (0.1816) | Acc: (93.51%) (33632/35968)\n",
            "Epoch: 68 | Batch_idx: 290 |  Loss: (0.1819) | Acc: (93.50%) (34826/37248)\n",
            "Epoch: 68 | Batch_idx: 300 |  Loss: (0.1823) | Acc: (93.48%) (36015/38528)\n",
            "Epoch: 68 | Batch_idx: 310 |  Loss: (0.1823) | Acc: (93.49%) (37215/39808)\n",
            "Epoch: 68 | Batch_idx: 320 |  Loss: (0.1831) | Acc: (93.46%) (38400/41088)\n",
            "Epoch: 68 | Batch_idx: 330 |  Loss: (0.1837) | Acc: (93.43%) (39586/42368)\n",
            "Epoch: 68 | Batch_idx: 340 |  Loss: (0.1837) | Acc: (93.44%) (40783/43648)\n",
            "Epoch: 68 | Batch_idx: 350 |  Loss: (0.1835) | Acc: (93.46%) (41988/44928)\n",
            "Epoch: 68 | Batch_idx: 360 |  Loss: (0.1834) | Acc: (93.46%) (43184/46208)\n",
            "Epoch: 68 | Batch_idx: 370 |  Loss: (0.1829) | Acc: (93.48%) (44393/47488)\n",
            "Epoch: 68 | Batch_idx: 380 |  Loss: (0.1831) | Acc: (93.49%) (45593/48768)\n",
            "Epoch: 68 | Batch_idx: 390 |  Loss: (0.1841) | Acc: (93.47%) (46736/50000)\n",
            "# TEST : Loss: (0.4397) | Acc: (86.71%) (8671/10000)\n",
            "Epoch: 69 | Batch_idx: 0 |  Loss: (0.1506) | Acc: (93.75%) (120/128)\n",
            "Epoch: 69 | Batch_idx: 10 |  Loss: (0.1754) | Acc: (93.61%) (1318/1408)\n",
            "Epoch: 69 | Batch_idx: 20 |  Loss: (0.1827) | Acc: (93.30%) (2508/2688)\n",
            "Epoch: 69 | Batch_idx: 30 |  Loss: (0.1863) | Acc: (93.47%) (3709/3968)\n",
            "Epoch: 69 | Batch_idx: 40 |  Loss: (0.1853) | Acc: (93.39%) (4901/5248)\n",
            "Epoch: 69 | Batch_idx: 50 |  Loss: (0.1811) | Acc: (93.52%) (6105/6528)\n",
            "Epoch: 69 | Batch_idx: 60 |  Loss: (0.1815) | Acc: (93.57%) (7306/7808)\n",
            "Epoch: 69 | Batch_idx: 70 |  Loss: (0.1803) | Acc: (93.62%) (8508/9088)\n",
            "Epoch: 69 | Batch_idx: 80 |  Loss: (0.1793) | Acc: (93.68%) (9713/10368)\n",
            "Epoch: 69 | Batch_idx: 90 |  Loss: (0.1758) | Acc: (93.75%) (10920/11648)\n",
            "Epoch: 69 | Batch_idx: 100 |  Loss: (0.1739) | Acc: (93.76%) (12121/12928)\n",
            "Epoch: 69 | Batch_idx: 110 |  Loss: (0.1737) | Acc: (93.68%) (13310/14208)\n",
            "Epoch: 69 | Batch_idx: 120 |  Loss: (0.1757) | Acc: (93.62%) (14500/15488)\n",
            "Epoch: 69 | Batch_idx: 130 |  Loss: (0.1753) | Acc: (93.66%) (15705/16768)\n",
            "Epoch: 69 | Batch_idx: 140 |  Loss: (0.1772) | Acc: (93.62%) (16896/18048)\n",
            "Epoch: 69 | Batch_idx: 150 |  Loss: (0.1775) | Acc: (93.60%) (18091/19328)\n",
            "Epoch: 69 | Batch_idx: 160 |  Loss: (0.1782) | Acc: (93.55%) (19278/20608)\n",
            "Epoch: 69 | Batch_idx: 170 |  Loss: (0.1811) | Acc: (93.47%) (20459/21888)\n",
            "Epoch: 69 | Batch_idx: 180 |  Loss: (0.1823) | Acc: (93.44%) (21649/23168)\n",
            "Epoch: 69 | Batch_idx: 190 |  Loss: (0.1829) | Acc: (93.43%) (22841/24448)\n",
            "Epoch: 69 | Batch_idx: 200 |  Loss: (0.1841) | Acc: (93.38%) (24026/25728)\n",
            "Epoch: 69 | Batch_idx: 210 |  Loss: (0.1843) | Acc: (93.36%) (25215/27008)\n",
            "Epoch: 69 | Batch_idx: 220 |  Loss: (0.1838) | Acc: (93.39%) (26418/28288)\n",
            "Epoch: 69 | Batch_idx: 230 |  Loss: (0.1833) | Acc: (93.38%) (27611/29568)\n",
            "Epoch: 69 | Batch_idx: 240 |  Loss: (0.1828) | Acc: (93.42%) (28819/30848)\n",
            "Epoch: 69 | Batch_idx: 250 |  Loss: (0.1829) | Acc: (93.42%) (30014/32128)\n",
            "Epoch: 69 | Batch_idx: 260 |  Loss: (0.1835) | Acc: (93.40%) (31202/33408)\n",
            "Epoch: 69 | Batch_idx: 270 |  Loss: (0.1831) | Acc: (93.44%) (32411/34688)\n",
            "Epoch: 69 | Batch_idx: 280 |  Loss: (0.1825) | Acc: (93.46%) (33614/35968)\n",
            "Epoch: 69 | Batch_idx: 290 |  Loss: (0.1829) | Acc: (93.43%) (34799/37248)\n",
            "Epoch: 69 | Batch_idx: 300 |  Loss: (0.1827) | Acc: (93.45%) (36006/38528)\n",
            "Epoch: 69 | Batch_idx: 310 |  Loss: (0.1824) | Acc: (93.46%) (37206/39808)\n",
            "Epoch: 69 | Batch_idx: 320 |  Loss: (0.1834) | Acc: (93.43%) (38387/41088)\n",
            "Epoch: 69 | Batch_idx: 330 |  Loss: (0.1844) | Acc: (93.38%) (39564/42368)\n",
            "Epoch: 69 | Batch_idx: 340 |  Loss: (0.1843) | Acc: (93.39%) (40763/43648)\n",
            "Epoch: 69 | Batch_idx: 350 |  Loss: (0.1838) | Acc: (93.42%) (41973/44928)\n",
            "Epoch: 69 | Batch_idx: 360 |  Loss: (0.1840) | Acc: (93.42%) (43168/46208)\n",
            "Epoch: 69 | Batch_idx: 370 |  Loss: (0.1848) | Acc: (93.38%) (44342/47488)\n",
            "Epoch: 69 | Batch_idx: 380 |  Loss: (0.1852) | Acc: (93.37%) (45535/48768)\n",
            "Epoch: 69 | Batch_idx: 390 |  Loss: (0.1854) | Acc: (93.36%) (46682/50000)\n",
            "# TEST : Loss: (0.4146) | Acc: (87.49%) (8749/10000)\n",
            "Epoch: 70 | Batch_idx: 0 |  Loss: (0.1509) | Acc: (95.31%) (122/128)\n",
            "Epoch: 70 | Batch_idx: 10 |  Loss: (0.1762) | Acc: (93.32%) (1314/1408)\n",
            "Epoch: 70 | Batch_idx: 20 |  Loss: (0.1847) | Acc: (93.34%) (2509/2688)\n",
            "Epoch: 70 | Batch_idx: 30 |  Loss: (0.1855) | Acc: (93.40%) (3706/3968)\n",
            "Epoch: 70 | Batch_idx: 40 |  Loss: (0.1787) | Acc: (93.73%) (4919/5248)\n",
            "Epoch: 70 | Batch_idx: 50 |  Loss: (0.1749) | Acc: (93.80%) (6123/6528)\n",
            "Epoch: 70 | Batch_idx: 60 |  Loss: (0.1737) | Acc: (93.78%) (7322/7808)\n",
            "Epoch: 70 | Batch_idx: 70 |  Loss: (0.1753) | Acc: (93.68%) (8514/9088)\n",
            "Epoch: 70 | Batch_idx: 80 |  Loss: (0.1750) | Acc: (93.70%) (9715/10368)\n",
            "Epoch: 70 | Batch_idx: 90 |  Loss: (0.1746) | Acc: (93.67%) (10911/11648)\n",
            "Epoch: 70 | Batch_idx: 100 |  Loss: (0.1734) | Acc: (93.77%) (12122/12928)\n",
            "Epoch: 70 | Batch_idx: 110 |  Loss: (0.1728) | Acc: (93.81%) (13329/14208)\n",
            "Epoch: 70 | Batch_idx: 120 |  Loss: (0.1724) | Acc: (93.89%) (14542/15488)\n",
            "Epoch: 70 | Batch_idx: 130 |  Loss: (0.1747) | Acc: (93.79%) (15727/16768)\n",
            "Epoch: 70 | Batch_idx: 140 |  Loss: (0.1761) | Acc: (93.73%) (16917/18048)\n",
            "Epoch: 70 | Batch_idx: 150 |  Loss: (0.1748) | Acc: (93.83%) (18135/19328)\n",
            "Epoch: 70 | Batch_idx: 160 |  Loss: (0.1750) | Acc: (93.82%) (19335/20608)\n",
            "Epoch: 70 | Batch_idx: 170 |  Loss: (0.1746) | Acc: (93.88%) (20549/21888)\n",
            "Epoch: 70 | Batch_idx: 180 |  Loss: (0.1749) | Acc: (93.84%) (21740/23168)\n",
            "Epoch: 70 | Batch_idx: 190 |  Loss: (0.1736) | Acc: (93.89%) (22954/24448)\n",
            "Epoch: 70 | Batch_idx: 200 |  Loss: (0.1753) | Acc: (93.89%) (24156/25728)\n",
            "Epoch: 70 | Batch_idx: 210 |  Loss: (0.1752) | Acc: (93.86%) (25351/27008)\n",
            "Epoch: 70 | Batch_idx: 220 |  Loss: (0.1750) | Acc: (93.88%) (26557/28288)\n",
            "Epoch: 70 | Batch_idx: 230 |  Loss: (0.1748) | Acc: (93.90%) (27763/29568)\n",
            "Epoch: 70 | Batch_idx: 240 |  Loss: (0.1754) | Acc: (93.86%) (28954/30848)\n",
            "Epoch: 70 | Batch_idx: 250 |  Loss: (0.1763) | Acc: (93.83%) (30145/32128)\n",
            "Epoch: 70 | Batch_idx: 260 |  Loss: (0.1770) | Acc: (93.84%) (31351/33408)\n",
            "Epoch: 70 | Batch_idx: 270 |  Loss: (0.1773) | Acc: (93.84%) (32552/34688)\n",
            "Epoch: 70 | Batch_idx: 280 |  Loss: (0.1770) | Acc: (93.85%) (33755/35968)\n",
            "Epoch: 70 | Batch_idx: 290 |  Loss: (0.1783) | Acc: (93.80%) (34937/37248)\n",
            "Epoch: 70 | Batch_idx: 300 |  Loss: (0.1786) | Acc: (93.79%) (36134/38528)\n",
            "Epoch: 70 | Batch_idx: 310 |  Loss: (0.1787) | Acc: (93.78%) (37330/39808)\n",
            "Epoch: 70 | Batch_idx: 320 |  Loss: (0.1779) | Acc: (93.81%) (38543/41088)\n",
            "Epoch: 70 | Batch_idx: 330 |  Loss: (0.1777) | Acc: (93.83%) (39753/42368)\n",
            "Epoch: 70 | Batch_idx: 340 |  Loss: (0.1778) | Acc: (93.81%) (40947/43648)\n",
            "Epoch: 70 | Batch_idx: 350 |  Loss: (0.1787) | Acc: (93.78%) (42135/44928)\n",
            "Epoch: 70 | Batch_idx: 360 |  Loss: (0.1784) | Acc: (93.80%) (43343/46208)\n",
            "Epoch: 70 | Batch_idx: 370 |  Loss: (0.1789) | Acc: (93.78%) (44536/47488)\n",
            "Epoch: 70 | Batch_idx: 380 |  Loss: (0.1788) | Acc: (93.77%) (45731/48768)\n",
            "Epoch: 70 | Batch_idx: 390 |  Loss: (0.1797) | Acc: (93.74%) (46872/50000)\n",
            "# TEST : Loss: (0.3949) | Acc: (88.09%) (8809/10000)\n",
            "Epoch: 71 | Batch_idx: 0 |  Loss: (0.1797) | Acc: (93.75%) (120/128)\n",
            "Epoch: 71 | Batch_idx: 10 |  Loss: (0.1798) | Acc: (93.54%) (1317/1408)\n",
            "Epoch: 71 | Batch_idx: 20 |  Loss: (0.1816) | Acc: (94.08%) (2529/2688)\n",
            "Epoch: 71 | Batch_idx: 30 |  Loss: (0.1745) | Acc: (94.15%) (3736/3968)\n",
            "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1760) | Acc: (93.90%) (4928/5248)\n",
            "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1778) | Acc: (93.64%) (6113/6528)\n",
            "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1724) | Acc: (93.88%) (7330/7808)\n",
            "Epoch: 71 | Batch_idx: 70 |  Loss: (0.1717) | Acc: (94.00%) (8543/9088)\n",
            "Epoch: 71 | Batch_idx: 80 |  Loss: (0.1723) | Acc: (94.00%) (9746/10368)\n",
            "Epoch: 71 | Batch_idx: 90 |  Loss: (0.1748) | Acc: (93.91%) (10939/11648)\n",
            "Epoch: 71 | Batch_idx: 100 |  Loss: (0.1752) | Acc: (93.87%) (12136/12928)\n",
            "Epoch: 71 | Batch_idx: 110 |  Loss: (0.1750) | Acc: (93.88%) (13338/14208)\n",
            "Epoch: 71 | Batch_idx: 120 |  Loss: (0.1742) | Acc: (93.93%) (14548/15488)\n",
            "Epoch: 71 | Batch_idx: 130 |  Loss: (0.1774) | Acc: (93.79%) (15726/16768)\n",
            "Epoch: 71 | Batch_idx: 140 |  Loss: (0.1772) | Acc: (93.78%) (16926/18048)\n",
            "Epoch: 71 | Batch_idx: 150 |  Loss: (0.1794) | Acc: (93.71%) (18113/19328)\n",
            "Epoch: 71 | Batch_idx: 160 |  Loss: (0.1806) | Acc: (93.67%) (19304/20608)\n",
            "Epoch: 71 | Batch_idx: 170 |  Loss: (0.1817) | Acc: (93.62%) (20492/21888)\n",
            "Epoch: 71 | Batch_idx: 180 |  Loss: (0.1816) | Acc: (93.62%) (21690/23168)\n",
            "Epoch: 71 | Batch_idx: 190 |  Loss: (0.1819) | Acc: (93.60%) (22883/24448)\n",
            "Epoch: 71 | Batch_idx: 200 |  Loss: (0.1824) | Acc: (93.63%) (24088/25728)\n",
            "Epoch: 71 | Batch_idx: 210 |  Loss: (0.1818) | Acc: (93.62%) (25285/27008)\n",
            "Epoch: 71 | Batch_idx: 220 |  Loss: (0.1810) | Acc: (93.64%) (26490/28288)\n",
            "Epoch: 71 | Batch_idx: 230 |  Loss: (0.1786) | Acc: (93.74%) (27718/29568)\n",
            "Epoch: 71 | Batch_idx: 240 |  Loss: (0.1795) | Acc: (93.71%) (28909/30848)\n",
            "Epoch: 71 | Batch_idx: 250 |  Loss: (0.1791) | Acc: (93.73%) (30113/32128)\n",
            "Epoch: 71 | Batch_idx: 260 |  Loss: (0.1787) | Acc: (93.75%) (31320/33408)\n",
            "Epoch: 71 | Batch_idx: 270 |  Loss: (0.1788) | Acc: (93.75%) (32520/34688)\n",
            "Epoch: 71 | Batch_idx: 280 |  Loss: (0.1777) | Acc: (93.78%) (33729/35968)\n",
            "Epoch: 71 | Batch_idx: 290 |  Loss: (0.1768) | Acc: (93.80%) (34939/37248)\n",
            "Epoch: 71 | Batch_idx: 300 |  Loss: (0.1774) | Acc: (93.79%) (36134/38528)\n",
            "Epoch: 71 | Batch_idx: 310 |  Loss: (0.1782) | Acc: (93.72%) (37309/39808)\n",
            "Epoch: 71 | Batch_idx: 320 |  Loss: (0.1796) | Acc: (93.69%) (38494/41088)\n",
            "Epoch: 71 | Batch_idx: 330 |  Loss: (0.1799) | Acc: (93.66%) (39683/42368)\n",
            "Epoch: 71 | Batch_idx: 340 |  Loss: (0.1815) | Acc: (93.61%) (40861/43648)\n",
            "Epoch: 71 | Batch_idx: 350 |  Loss: (0.1814) | Acc: (93.63%) (42064/44928)\n",
            "Epoch: 71 | Batch_idx: 360 |  Loss: (0.1819) | Acc: (93.60%) (43252/46208)\n",
            "Epoch: 71 | Batch_idx: 370 |  Loss: (0.1830) | Acc: (93.56%) (44431/47488)\n",
            "Epoch: 71 | Batch_idx: 380 |  Loss: (0.1836) | Acc: (93.54%) (45617/48768)\n",
            "Epoch: 71 | Batch_idx: 390 |  Loss: (0.1834) | Acc: (93.55%) (46776/50000)\n",
            "# TEST : Loss: (0.6985) | Acc: (81.36%) (8136/10000)\n",
            "Epoch: 72 | Batch_idx: 0 |  Loss: (0.2168) | Acc: (92.97%) (119/128)\n",
            "Epoch: 72 | Batch_idx: 10 |  Loss: (0.1795) | Acc: (93.82%) (1321/1408)\n",
            "Epoch: 72 | Batch_idx: 20 |  Loss: (0.1752) | Acc: (93.68%) (2518/2688)\n",
            "Epoch: 72 | Batch_idx: 30 |  Loss: (0.1705) | Acc: (93.88%) (3725/3968)\n",
            "Epoch: 72 | Batch_idx: 40 |  Loss: (0.1670) | Acc: (94.11%) (4939/5248)\n",
            "Epoch: 72 | Batch_idx: 50 |  Loss: (0.1672) | Acc: (94.04%) (6139/6528)\n",
            "Epoch: 72 | Batch_idx: 60 |  Loss: (0.1727) | Acc: (93.98%) (7338/7808)\n",
            "Epoch: 72 | Batch_idx: 70 |  Loss: (0.1721) | Acc: (94.05%) (8547/9088)\n",
            "Epoch: 72 | Batch_idx: 80 |  Loss: (0.1702) | Acc: (94.12%) (9758/10368)\n",
            "Epoch: 72 | Batch_idx: 90 |  Loss: (0.1715) | Acc: (93.96%) (10945/11648)\n",
            "Epoch: 72 | Batch_idx: 100 |  Loss: (0.1751) | Acc: (93.83%) (12130/12928)\n",
            "Epoch: 72 | Batch_idx: 110 |  Loss: (0.1747) | Acc: (93.88%) (13339/14208)\n",
            "Epoch: 72 | Batch_idx: 120 |  Loss: (0.1759) | Acc: (93.82%) (14531/15488)\n",
            "Epoch: 72 | Batch_idx: 130 |  Loss: (0.1758) | Acc: (93.79%) (15727/16768)\n",
            "Epoch: 72 | Batch_idx: 140 |  Loss: (0.1757) | Acc: (93.81%) (16931/18048)\n",
            "Epoch: 72 | Batch_idx: 150 |  Loss: (0.1767) | Acc: (93.74%) (18118/19328)\n",
            "Epoch: 72 | Batch_idx: 160 |  Loss: (0.1754) | Acc: (93.80%) (19331/20608)\n",
            "Epoch: 72 | Batch_idx: 170 |  Loss: (0.1750) | Acc: (93.82%) (20535/21888)\n",
            "Epoch: 72 | Batch_idx: 180 |  Loss: (0.1762) | Acc: (93.82%) (21736/23168)\n",
            "Epoch: 72 | Batch_idx: 190 |  Loss: (0.1750) | Acc: (93.86%) (22947/24448)\n",
            "Epoch: 72 | Batch_idx: 200 |  Loss: (0.1756) | Acc: (93.84%) (24143/25728)\n",
            "Epoch: 72 | Batch_idx: 210 |  Loss: (0.1771) | Acc: (93.79%) (25332/27008)\n",
            "Epoch: 72 | Batch_idx: 220 |  Loss: (0.1775) | Acc: (93.77%) (26526/28288)\n",
            "Epoch: 72 | Batch_idx: 230 |  Loss: (0.1794) | Acc: (93.70%) (27704/29568)\n",
            "Epoch: 72 | Batch_idx: 240 |  Loss: (0.1799) | Acc: (93.67%) (28896/30848)\n",
            "Epoch: 72 | Batch_idx: 250 |  Loss: (0.1796) | Acc: (93.68%) (30098/32128)\n",
            "Epoch: 72 | Batch_idx: 260 |  Loss: (0.1795) | Acc: (93.70%) (31303/33408)\n",
            "Epoch: 72 | Batch_idx: 270 |  Loss: (0.1798) | Acc: (93.71%) (32506/34688)\n",
            "Epoch: 72 | Batch_idx: 280 |  Loss: (0.1795) | Acc: (93.72%) (33711/35968)\n",
            "Epoch: 72 | Batch_idx: 290 |  Loss: (0.1791) | Acc: (93.72%) (34910/37248)\n",
            "Epoch: 72 | Batch_idx: 300 |  Loss: (0.1786) | Acc: (93.74%) (36118/38528)\n",
            "Epoch: 72 | Batch_idx: 310 |  Loss: (0.1799) | Acc: (93.71%) (37303/39808)\n",
            "Epoch: 72 | Batch_idx: 320 |  Loss: (0.1809) | Acc: (93.68%) (38492/41088)\n",
            "Epoch: 72 | Batch_idx: 330 |  Loss: (0.1815) | Acc: (93.64%) (39674/42368)\n",
            "Epoch: 72 | Batch_idx: 340 |  Loss: (0.1819) | Acc: (93.65%) (40877/43648)\n",
            "Epoch: 72 | Batch_idx: 350 |  Loss: (0.1808) | Acc: (93.69%) (42093/44928)\n",
            "Epoch: 72 | Batch_idx: 360 |  Loss: (0.1797) | Acc: (93.73%) (43313/46208)\n",
            "Epoch: 72 | Batch_idx: 370 |  Loss: (0.1800) | Acc: (93.71%) (44502/47488)\n",
            "Epoch: 72 | Batch_idx: 380 |  Loss: (0.1803) | Acc: (93.68%) (45688/48768)\n",
            "Epoch: 72 | Batch_idx: 390 |  Loss: (0.1803) | Acc: (93.67%) (46835/50000)\n",
            "# TEST : Loss: (0.3996) | Acc: (88.04%) (8804/10000)\n",
            "Epoch: 73 | Batch_idx: 0 |  Loss: (0.1526) | Acc: (94.53%) (121/128)\n",
            "Epoch: 73 | Batch_idx: 10 |  Loss: (0.1518) | Acc: (94.60%) (1332/1408)\n",
            "Epoch: 73 | Batch_idx: 20 |  Loss: (0.1491) | Acc: (94.87%) (2550/2688)\n",
            "Epoch: 73 | Batch_idx: 30 |  Loss: (0.1509) | Acc: (94.68%) (3757/3968)\n",
            "Epoch: 73 | Batch_idx: 40 |  Loss: (0.1531) | Acc: (94.49%) (4959/5248)\n",
            "Epoch: 73 | Batch_idx: 50 |  Loss: (0.1570) | Acc: (94.50%) (6169/6528)\n",
            "Epoch: 73 | Batch_idx: 60 |  Loss: (0.1617) | Acc: (94.45%) (7375/7808)\n",
            "Epoch: 73 | Batch_idx: 70 |  Loss: (0.1654) | Acc: (94.22%) (8563/9088)\n",
            "Epoch: 73 | Batch_idx: 80 |  Loss: (0.1662) | Acc: (94.20%) (9767/10368)\n",
            "Epoch: 73 | Batch_idx: 90 |  Loss: (0.1673) | Acc: (94.14%) (10966/11648)\n",
            "Epoch: 73 | Batch_idx: 100 |  Loss: (0.1684) | Acc: (94.01%) (12154/12928)\n",
            "Epoch: 73 | Batch_idx: 110 |  Loss: (0.1714) | Acc: (93.96%) (13350/14208)\n",
            "Epoch: 73 | Batch_idx: 120 |  Loss: (0.1723) | Acc: (93.97%) (14554/15488)\n",
            "Epoch: 73 | Batch_idx: 130 |  Loss: (0.1740) | Acc: (93.89%) (15743/16768)\n",
            "Epoch: 73 | Batch_idx: 140 |  Loss: (0.1723) | Acc: (93.91%) (16948/18048)\n",
            "Epoch: 73 | Batch_idx: 150 |  Loss: (0.1742) | Acc: (93.80%) (18129/19328)\n",
            "Epoch: 73 | Batch_idx: 160 |  Loss: (0.1758) | Acc: (93.75%) (19319/20608)\n",
            "Epoch: 73 | Batch_idx: 170 |  Loss: (0.1759) | Acc: (93.76%) (20522/21888)\n",
            "Epoch: 73 | Batch_idx: 180 |  Loss: (0.1765) | Acc: (93.70%) (21708/23168)\n",
            "Epoch: 73 | Batch_idx: 190 |  Loss: (0.1769) | Acc: (93.69%) (22906/24448)\n",
            "Epoch: 73 | Batch_idx: 200 |  Loss: (0.1779) | Acc: (93.68%) (24102/25728)\n",
            "Epoch: 73 | Batch_idx: 210 |  Loss: (0.1780) | Acc: (93.71%) (25308/27008)\n",
            "Epoch: 73 | Batch_idx: 220 |  Loss: (0.1771) | Acc: (93.74%) (26517/28288)\n",
            "Epoch: 73 | Batch_idx: 230 |  Loss: (0.1780) | Acc: (93.72%) (27710/29568)\n",
            "Epoch: 73 | Batch_idx: 240 |  Loss: (0.1783) | Acc: (93.75%) (28920/30848)\n",
            "Epoch: 73 | Batch_idx: 250 |  Loss: (0.1792) | Acc: (93.70%) (30103/32128)\n",
            "Epoch: 73 | Batch_idx: 260 |  Loss: (0.1794) | Acc: (93.70%) (31303/33408)\n",
            "Epoch: 73 | Batch_idx: 270 |  Loss: (0.1798) | Acc: (93.68%) (32497/34688)\n",
            "Epoch: 73 | Batch_idx: 280 |  Loss: (0.1801) | Acc: (93.67%) (33692/35968)\n",
            "Epoch: 73 | Batch_idx: 290 |  Loss: (0.1801) | Acc: (93.68%) (34895/37248)\n",
            "Epoch: 73 | Batch_idx: 300 |  Loss: (0.1802) | Acc: (93.70%) (36102/38528)\n",
            "Epoch: 73 | Batch_idx: 310 |  Loss: (0.1808) | Acc: (93.67%) (37287/39808)\n",
            "Epoch: 73 | Batch_idx: 320 |  Loss: (0.1804) | Acc: (93.70%) (38500/41088)\n",
            "Epoch: 73 | Batch_idx: 330 |  Loss: (0.1793) | Acc: (93.73%) (39713/42368)\n",
            "Epoch: 73 | Batch_idx: 340 |  Loss: (0.1800) | Acc: (93.72%) (40908/43648)\n",
            "Epoch: 73 | Batch_idx: 350 |  Loss: (0.1803) | Acc: (93.71%) (42102/44928)\n",
            "Epoch: 73 | Batch_idx: 360 |  Loss: (0.1800) | Acc: (93.73%) (43311/46208)\n",
            "Epoch: 73 | Batch_idx: 370 |  Loss: (0.1799) | Acc: (93.73%) (44510/47488)\n",
            "Epoch: 73 | Batch_idx: 380 |  Loss: (0.1799) | Acc: (93.73%) (45709/48768)\n",
            "Epoch: 73 | Batch_idx: 390 |  Loss: (0.1806) | Acc: (93.72%) (46860/50000)\n",
            "# TEST : Loss: (0.4111) | Acc: (87.80%) (8780/10000)\n",
            "Epoch: 74 | Batch_idx: 0 |  Loss: (0.1161) | Acc: (92.97%) (119/128)\n",
            "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1689) | Acc: (93.61%) (1318/1408)\n",
            "Epoch: 74 | Batch_idx: 20 |  Loss: (0.1621) | Acc: (94.20%) (2532/2688)\n",
            "Epoch: 74 | Batch_idx: 30 |  Loss: (0.1597) | Acc: (94.13%) (3735/3968)\n",
            "Epoch: 74 | Batch_idx: 40 |  Loss: (0.1586) | Acc: (94.11%) (4939/5248)\n",
            "Epoch: 74 | Batch_idx: 50 |  Loss: (0.1589) | Acc: (94.13%) (6145/6528)\n",
            "Epoch: 74 | Batch_idx: 60 |  Loss: (0.1570) | Acc: (94.24%) (7358/7808)\n",
            "Epoch: 74 | Batch_idx: 70 |  Loss: (0.1584) | Acc: (94.22%) (8563/9088)\n",
            "Epoch: 74 | Batch_idx: 80 |  Loss: (0.1614) | Acc: (94.21%) (9768/10368)\n",
            "Epoch: 74 | Batch_idx: 90 |  Loss: (0.1637) | Acc: (94.21%) (10974/11648)\n",
            "Epoch: 74 | Batch_idx: 100 |  Loss: (0.1664) | Acc: (94.16%) (12173/12928)\n",
            "Epoch: 74 | Batch_idx: 110 |  Loss: (0.1646) | Acc: (94.30%) (13398/14208)\n",
            "Epoch: 74 | Batch_idx: 120 |  Loss: (0.1632) | Acc: (94.38%) (14618/15488)\n",
            "Epoch: 74 | Batch_idx: 130 |  Loss: (0.1649) | Acc: (94.30%) (15813/16768)\n",
            "Epoch: 74 | Batch_idx: 140 |  Loss: (0.1672) | Acc: (94.23%) (17007/18048)\n",
            "Epoch: 74 | Batch_idx: 150 |  Loss: (0.1677) | Acc: (94.24%) (18214/19328)\n",
            "Epoch: 74 | Batch_idx: 160 |  Loss: (0.1682) | Acc: (94.24%) (19421/20608)\n",
            "Epoch: 74 | Batch_idx: 170 |  Loss: (0.1683) | Acc: (94.24%) (20627/21888)\n",
            "Epoch: 74 | Batch_idx: 180 |  Loss: (0.1675) | Acc: (94.23%) (21831/23168)\n",
            "Epoch: 74 | Batch_idx: 190 |  Loss: (0.1674) | Acc: (94.21%) (23033/24448)\n",
            "Epoch: 74 | Batch_idx: 200 |  Loss: (0.1688) | Acc: (94.15%) (24224/25728)\n",
            "Epoch: 74 | Batch_idx: 210 |  Loss: (0.1690) | Acc: (94.13%) (25423/27008)\n",
            "Epoch: 74 | Batch_idx: 220 |  Loss: (0.1698) | Acc: (94.10%) (26618/28288)\n",
            "Epoch: 74 | Batch_idx: 230 |  Loss: (0.1695) | Acc: (94.11%) (27825/29568)\n",
            "Epoch: 74 | Batch_idx: 240 |  Loss: (0.1694) | Acc: (94.11%) (29031/30848)\n",
            "Epoch: 74 | Batch_idx: 250 |  Loss: (0.1699) | Acc: (94.09%) (30229/32128)\n",
            "Epoch: 74 | Batch_idx: 260 |  Loss: (0.1706) | Acc: (94.07%) (31428/33408)\n",
            "Epoch: 74 | Batch_idx: 270 |  Loss: (0.1720) | Acc: (94.01%) (32610/34688)\n",
            "Epoch: 74 | Batch_idx: 280 |  Loss: (0.1731) | Acc: (93.99%) (33805/35968)\n",
            "Epoch: 74 | Batch_idx: 290 |  Loss: (0.1739) | Acc: (93.96%) (35000/37248)\n",
            "Epoch: 74 | Batch_idx: 300 |  Loss: (0.1749) | Acc: (93.92%) (36187/38528)\n",
            "Epoch: 74 | Batch_idx: 310 |  Loss: (0.1756) | Acc: (93.90%) (37380/39808)\n",
            "Epoch: 74 | Batch_idx: 320 |  Loss: (0.1757) | Acc: (93.90%) (38581/41088)\n",
            "Epoch: 74 | Batch_idx: 330 |  Loss: (0.1763) | Acc: (93.90%) (39782/42368)\n",
            "Epoch: 74 | Batch_idx: 340 |  Loss: (0.1765) | Acc: (93.89%) (40980/43648)\n",
            "Epoch: 74 | Batch_idx: 350 |  Loss: (0.1763) | Acc: (93.91%) (42193/44928)\n",
            "Epoch: 74 | Batch_idx: 360 |  Loss: (0.1765) | Acc: (93.89%) (43386/46208)\n",
            "Epoch: 74 | Batch_idx: 370 |  Loss: (0.1765) | Acc: (93.90%) (44589/47488)\n",
            "Epoch: 74 | Batch_idx: 380 |  Loss: (0.1776) | Acc: (93.85%) (45771/48768)\n",
            "Epoch: 74 | Batch_idx: 390 |  Loss: (0.1768) | Acc: (93.88%) (46941/50000)\n",
            "# TEST : Loss: (0.4200) | Acc: (87.56%) (8756/10000)\n",
            "Epoch: 75 | Batch_idx: 0 |  Loss: (0.1930) | Acc: (93.75%) (120/128)\n",
            "Epoch: 75 | Batch_idx: 10 |  Loss: (0.1701) | Acc: (93.61%) (1318/1408)\n",
            "Epoch: 75 | Batch_idx: 20 |  Loss: (0.1645) | Acc: (94.12%) (2530/2688)\n",
            "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1556) | Acc: (94.58%) (3753/3968)\n",
            "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1549) | Acc: (94.55%) (4962/5248)\n",
            "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1573) | Acc: (94.56%) (6173/6528)\n",
            "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1598) | Acc: (94.44%) (7374/7808)\n",
            "Epoch: 75 | Batch_idx: 70 |  Loss: (0.1603) | Acc: (94.37%) (8576/9088)\n",
            "Epoch: 75 | Batch_idx: 80 |  Loss: (0.1616) | Acc: (94.18%) (9765/10368)\n",
            "Epoch: 75 | Batch_idx: 90 |  Loss: (0.1595) | Acc: (94.21%) (10974/11648)\n",
            "Epoch: 75 | Batch_idx: 100 |  Loss: (0.1583) | Acc: (94.31%) (12192/12928)\n",
            "Epoch: 75 | Batch_idx: 110 |  Loss: (0.1595) | Acc: (94.24%) (13389/14208)\n",
            "Epoch: 75 | Batch_idx: 120 |  Loss: (0.1609) | Acc: (94.23%) (14594/15488)\n",
            "Epoch: 75 | Batch_idx: 130 |  Loss: (0.1641) | Acc: (94.13%) (15783/16768)\n",
            "Epoch: 75 | Batch_idx: 140 |  Loss: (0.1661) | Acc: (94.04%) (16972/18048)\n",
            "Epoch: 75 | Batch_idx: 150 |  Loss: (0.1662) | Acc: (94.02%) (18172/19328)\n",
            "Epoch: 75 | Batch_idx: 160 |  Loss: (0.1663) | Acc: (94.04%) (19379/20608)\n",
            "Epoch: 75 | Batch_idx: 170 |  Loss: (0.1666) | Acc: (94.02%) (20579/21888)\n",
            "Epoch: 75 | Batch_idx: 180 |  Loss: (0.1677) | Acc: (93.98%) (21774/23168)\n",
            "Epoch: 75 | Batch_idx: 190 |  Loss: (0.1675) | Acc: (93.98%) (22977/24448)\n",
            "Epoch: 75 | Batch_idx: 200 |  Loss: (0.1676) | Acc: (93.98%) (24179/25728)\n",
            "Epoch: 75 | Batch_idx: 210 |  Loss: (0.1678) | Acc: (93.97%) (25379/27008)\n",
            "Epoch: 75 | Batch_idx: 220 |  Loss: (0.1681) | Acc: (93.96%) (26579/28288)\n",
            "Epoch: 75 | Batch_idx: 230 |  Loss: (0.1681) | Acc: (93.95%) (27778/29568)\n",
            "Epoch: 75 | Batch_idx: 240 |  Loss: (0.1673) | Acc: (93.97%) (28987/30848)\n",
            "Epoch: 75 | Batch_idx: 250 |  Loss: (0.1674) | Acc: (93.97%) (30192/32128)\n",
            "Epoch: 75 | Batch_idx: 260 |  Loss: (0.1686) | Acc: (93.95%) (31388/33408)\n",
            "Epoch: 75 | Batch_idx: 270 |  Loss: (0.1703) | Acc: (93.92%) (32579/34688)\n",
            "Epoch: 75 | Batch_idx: 280 |  Loss: (0.1708) | Acc: (93.93%) (33785/35968)\n",
            "Epoch: 75 | Batch_idx: 290 |  Loss: (0.1711) | Acc: (93.92%) (34983/37248)\n",
            "Epoch: 75 | Batch_idx: 300 |  Loss: (0.1715) | Acc: (93.90%) (36178/38528)\n",
            "Epoch: 75 | Batch_idx: 310 |  Loss: (0.1720) | Acc: (93.88%) (37370/39808)\n",
            "Epoch: 75 | Batch_idx: 320 |  Loss: (0.1728) | Acc: (93.85%) (38561/41088)\n",
            "Epoch: 75 | Batch_idx: 330 |  Loss: (0.1732) | Acc: (93.85%) (39763/42368)\n",
            "Epoch: 75 | Batch_idx: 340 |  Loss: (0.1740) | Acc: (93.83%) (40954/43648)\n",
            "Epoch: 75 | Batch_idx: 350 |  Loss: (0.1742) | Acc: (93.79%) (42140/44928)\n",
            "Epoch: 75 | Batch_idx: 360 |  Loss: (0.1740) | Acc: (93.79%) (43339/46208)\n",
            "Epoch: 75 | Batch_idx: 370 |  Loss: (0.1741) | Acc: (93.79%) (44541/47488)\n",
            "Epoch: 75 | Batch_idx: 380 |  Loss: (0.1744) | Acc: (93.78%) (45737/48768)\n",
            "Epoch: 75 | Batch_idx: 390 |  Loss: (0.1746) | Acc: (93.80%) (46898/50000)\n",
            "# TEST : Loss: (0.3518) | Acc: (89.62%) (8962/10000)\n",
            "Epoch: 76 | Batch_idx: 0 |  Loss: (0.2436) | Acc: (91.41%) (117/128)\n",
            "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1837) | Acc: (93.11%) (1311/1408)\n",
            "Epoch: 76 | Batch_idx: 20 |  Loss: (0.1854) | Acc: (93.34%) (2509/2688)\n",
            "Epoch: 76 | Batch_idx: 30 |  Loss: (0.1728) | Acc: (93.83%) (3723/3968)\n",
            "Epoch: 76 | Batch_idx: 40 |  Loss: (0.1675) | Acc: (94.19%) (4943/5248)\n",
            "Epoch: 76 | Batch_idx: 50 |  Loss: (0.1666) | Acc: (94.10%) (6143/6528)\n",
            "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1688) | Acc: (94.12%) (7349/7808)\n",
            "Epoch: 76 | Batch_idx: 70 |  Loss: (0.1643) | Acc: (94.26%) (8566/9088)\n",
            "Epoch: 76 | Batch_idx: 80 |  Loss: (0.1645) | Acc: (94.15%) (9761/10368)\n",
            "Epoch: 76 | Batch_idx: 90 |  Loss: (0.1632) | Acc: (94.21%) (10973/11648)\n",
            "Epoch: 76 | Batch_idx: 100 |  Loss: (0.1644) | Acc: (94.13%) (12169/12928)\n",
            "Epoch: 76 | Batch_idx: 110 |  Loss: (0.1639) | Acc: (94.19%) (13382/14208)\n",
            "Epoch: 76 | Batch_idx: 120 |  Loss: (0.1637) | Acc: (94.17%) (14585/15488)\n",
            "Epoch: 76 | Batch_idx: 130 |  Loss: (0.1645) | Acc: (94.19%) (15793/16768)\n",
            "Epoch: 76 | Batch_idx: 140 |  Loss: (0.1631) | Acc: (94.22%) (17004/18048)\n",
            "Epoch: 76 | Batch_idx: 150 |  Loss: (0.1647) | Acc: (94.16%) (18200/19328)\n",
            "Epoch: 76 | Batch_idx: 160 |  Loss: (0.1641) | Acc: (94.19%) (19410/20608)\n",
            "Epoch: 76 | Batch_idx: 170 |  Loss: (0.1649) | Acc: (94.12%) (20601/21888)\n",
            "Epoch: 76 | Batch_idx: 180 |  Loss: (0.1659) | Acc: (94.10%) (21801/23168)\n",
            "Epoch: 76 | Batch_idx: 190 |  Loss: (0.1660) | Acc: (94.08%) (23000/24448)\n",
            "Epoch: 76 | Batch_idx: 200 |  Loss: (0.1664) | Acc: (94.08%) (24206/25728)\n",
            "Epoch: 76 | Batch_idx: 210 |  Loss: (0.1677) | Acc: (94.02%) (25394/27008)\n",
            "Epoch: 76 | Batch_idx: 220 |  Loss: (0.1683) | Acc: (94.04%) (26601/28288)\n",
            "Epoch: 76 | Batch_idx: 230 |  Loss: (0.1703) | Acc: (93.97%) (27786/29568)\n",
            "Epoch: 76 | Batch_idx: 240 |  Loss: (0.1714) | Acc: (93.93%) (28974/30848)\n",
            "Epoch: 76 | Batch_idx: 250 |  Loss: (0.1716) | Acc: (93.91%) (30170/32128)\n",
            "Epoch: 76 | Batch_idx: 260 |  Loss: (0.1723) | Acc: (93.88%) (31365/33408)\n",
            "Epoch: 76 | Batch_idx: 270 |  Loss: (0.1741) | Acc: (93.82%) (32545/34688)\n",
            "Epoch: 76 | Batch_idx: 280 |  Loss: (0.1743) | Acc: (93.81%) (33742/35968)\n",
            "Epoch: 76 | Batch_idx: 290 |  Loss: (0.1749) | Acc: (93.80%) (34940/37248)\n",
            "Epoch: 76 | Batch_idx: 300 |  Loss: (0.1752) | Acc: (93.80%) (36138/38528)\n",
            "Epoch: 76 | Batch_idx: 310 |  Loss: (0.1751) | Acc: (93.80%) (37341/39808)\n",
            "Epoch: 76 | Batch_idx: 320 |  Loss: (0.1758) | Acc: (93.78%) (38532/41088)\n",
            "Epoch: 76 | Batch_idx: 330 |  Loss: (0.1759) | Acc: (93.75%) (39722/42368)\n",
            "Epoch: 76 | Batch_idx: 340 |  Loss: (0.1761) | Acc: (93.75%) (40920/43648)\n",
            "Epoch: 76 | Batch_idx: 350 |  Loss: (0.1762) | Acc: (93.75%) (42120/44928)\n",
            "Epoch: 76 | Batch_idx: 360 |  Loss: (0.1761) | Acc: (93.76%) (43325/46208)\n",
            "Epoch: 76 | Batch_idx: 370 |  Loss: (0.1765) | Acc: (93.76%) (44524/47488)\n",
            "Epoch: 76 | Batch_idx: 380 |  Loss: (0.1770) | Acc: (93.75%) (45719/48768)\n",
            "Epoch: 76 | Batch_idx: 390 |  Loss: (0.1775) | Acc: (93.72%) (46860/50000)\n",
            "# TEST : Loss: (0.4079) | Acc: (87.97%) (8797/10000)\n",
            "Epoch: 77 | Batch_idx: 0 |  Loss: (0.1884) | Acc: (92.19%) (118/128)\n",
            "Epoch: 77 | Batch_idx: 10 |  Loss: (0.1725) | Acc: (94.32%) (1328/1408)\n",
            "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1797) | Acc: (93.86%) (2523/2688)\n",
            "Epoch: 77 | Batch_idx: 30 |  Loss: (0.1788) | Acc: (93.67%) (3717/3968)\n",
            "Epoch: 77 | Batch_idx: 40 |  Loss: (0.1776) | Acc: (94.04%) (4935/5248)\n",
            "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1746) | Acc: (94.01%) (6137/6528)\n",
            "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1685) | Acc: (94.16%) (7352/7808)\n",
            "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1684) | Acc: (94.18%) (8559/9088)\n",
            "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1678) | Acc: (94.15%) (9761/10368)\n",
            "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1679) | Acc: (94.07%) (10957/11648)\n",
            "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1690) | Acc: (94.06%) (12160/12928)\n",
            "Epoch: 77 | Batch_idx: 110 |  Loss: (0.1691) | Acc: (94.07%) (13365/14208)\n",
            "Epoch: 77 | Batch_idx: 120 |  Loss: (0.1675) | Acc: (94.11%) (14575/15488)\n",
            "Epoch: 77 | Batch_idx: 130 |  Loss: (0.1669) | Acc: (94.09%) (15777/16768)\n",
            "Epoch: 77 | Batch_idx: 140 |  Loss: (0.1667) | Acc: (94.08%) (16980/18048)\n",
            "Epoch: 77 | Batch_idx: 150 |  Loss: (0.1667) | Acc: (94.08%) (18183/19328)\n",
            "Epoch: 77 | Batch_idx: 160 |  Loss: (0.1683) | Acc: (94.03%) (19377/20608)\n",
            "Epoch: 77 | Batch_idx: 170 |  Loss: (0.1679) | Acc: (93.96%) (20566/21888)\n",
            "Epoch: 77 | Batch_idx: 180 |  Loss: (0.1679) | Acc: (93.98%) (21774/23168)\n",
            "Epoch: 77 | Batch_idx: 190 |  Loss: (0.1685) | Acc: (93.95%) (22969/24448)\n",
            "Epoch: 77 | Batch_idx: 200 |  Loss: (0.1675) | Acc: (93.98%) (24179/25728)\n",
            "Epoch: 77 | Batch_idx: 210 |  Loss: (0.1688) | Acc: (93.91%) (25362/27008)\n",
            "Epoch: 77 | Batch_idx: 220 |  Loss: (0.1696) | Acc: (93.88%) (26557/28288)\n",
            "Epoch: 77 | Batch_idx: 230 |  Loss: (0.1706) | Acc: (93.83%) (27745/29568)\n",
            "Epoch: 77 | Batch_idx: 240 |  Loss: (0.1715) | Acc: (93.78%) (28930/30848)\n",
            "Epoch: 77 | Batch_idx: 250 |  Loss: (0.1723) | Acc: (93.76%) (30123/32128)\n",
            "Epoch: 77 | Batch_idx: 260 |  Loss: (0.1725) | Acc: (93.73%) (31314/33408)\n",
            "Epoch: 77 | Batch_idx: 270 |  Loss: (0.1728) | Acc: (93.72%) (32510/34688)\n",
            "Epoch: 77 | Batch_idx: 280 |  Loss: (0.1736) | Acc: (93.69%) (33700/35968)\n",
            "Epoch: 77 | Batch_idx: 290 |  Loss: (0.1748) | Acc: (93.67%) (34892/37248)\n",
            "Epoch: 77 | Batch_idx: 300 |  Loss: (0.1758) | Acc: (93.65%) (36081/38528)\n",
            "Epoch: 77 | Batch_idx: 310 |  Loss: (0.1758) | Acc: (93.65%) (37282/39808)\n",
            "Epoch: 77 | Batch_idx: 320 |  Loss: (0.1758) | Acc: (93.66%) (38484/41088)\n",
            "Epoch: 77 | Batch_idx: 330 |  Loss: (0.1757) | Acc: (93.65%) (39677/42368)\n",
            "Epoch: 77 | Batch_idx: 340 |  Loss: (0.1755) | Acc: (93.65%) (40877/43648)\n",
            "Epoch: 77 | Batch_idx: 350 |  Loss: (0.1761) | Acc: (93.61%) (42058/44928)\n",
            "Epoch: 77 | Batch_idx: 360 |  Loss: (0.1771) | Acc: (93.58%) (43242/46208)\n",
            "Epoch: 77 | Batch_idx: 370 |  Loss: (0.1779) | Acc: (93.56%) (44430/47488)\n",
            "Epoch: 77 | Batch_idx: 380 |  Loss: (0.1784) | Acc: (93.53%) (45614/48768)\n",
            "Epoch: 77 | Batch_idx: 390 |  Loss: (0.1783) | Acc: (93.55%) (46775/50000)\n",
            "# TEST : Loss: (0.4036) | Acc: (87.98%) (8798/10000)\n",
            "Epoch: 78 | Batch_idx: 0 |  Loss: (0.2349) | Acc: (92.97%) (119/128)\n",
            "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1801) | Acc: (93.75%) (1320/1408)\n",
            "Epoch: 78 | Batch_idx: 20 |  Loss: (0.1668) | Acc: (94.08%) (2529/2688)\n",
            "Epoch: 78 | Batch_idx: 30 |  Loss: (0.1686) | Acc: (93.93%) (3727/3968)\n",
            "Epoch: 78 | Batch_idx: 40 |  Loss: (0.1704) | Acc: (94.04%) (4935/5248)\n",
            "Epoch: 78 | Batch_idx: 50 |  Loss: (0.1723) | Acc: (93.86%) (6127/6528)\n",
            "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1754) | Acc: (93.80%) (7324/7808)\n",
            "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1742) | Acc: (93.83%) (8527/9088)\n",
            "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1732) | Acc: (93.89%) (9734/10368)\n",
            "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1724) | Acc: (93.88%) (10935/11648)\n",
            "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1716) | Acc: (93.94%) (12145/12928)\n",
            "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1724) | Acc: (93.91%) (13343/14208)\n",
            "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1708) | Acc: (93.95%) (14551/15488)\n",
            "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1687) | Acc: (94.01%) (15763/16768)\n",
            "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1691) | Acc: (94.02%) (16969/18048)\n",
            "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1705) | Acc: (93.97%) (18163/19328)\n",
            "Epoch: 78 | Batch_idx: 160 |  Loss: (0.1702) | Acc: (94.02%) (19375/20608)\n",
            "Epoch: 78 | Batch_idx: 170 |  Loss: (0.1713) | Acc: (93.96%) (20567/21888)\n",
            "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1721) | Acc: (93.94%) (21765/23168)\n",
            "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1736) | Acc: (93.86%) (22946/24448)\n",
            "Epoch: 78 | Batch_idx: 200 |  Loss: (0.1734) | Acc: (93.85%) (24147/25728)\n",
            "Epoch: 78 | Batch_idx: 210 |  Loss: (0.1737) | Acc: (93.86%) (25349/27008)\n",
            "Epoch: 78 | Batch_idx: 220 |  Loss: (0.1725) | Acc: (93.93%) (26570/28288)\n",
            "Epoch: 78 | Batch_idx: 230 |  Loss: (0.1725) | Acc: (93.94%) (27775/29568)\n",
            "Epoch: 78 | Batch_idx: 240 |  Loss: (0.1723) | Acc: (93.93%) (28974/30848)\n",
            "Epoch: 78 | Batch_idx: 250 |  Loss: (0.1730) | Acc: (93.91%) (30171/32128)\n",
            "Epoch: 78 | Batch_idx: 260 |  Loss: (0.1728) | Acc: (93.92%) (31377/33408)\n",
            "Epoch: 78 | Batch_idx: 270 |  Loss: (0.1739) | Acc: (93.91%) (32576/34688)\n",
            "Epoch: 78 | Batch_idx: 280 |  Loss: (0.1757) | Acc: (93.85%) (33755/35968)\n",
            "Epoch: 78 | Batch_idx: 290 |  Loss: (0.1771) | Acc: (93.81%) (34941/37248)\n",
            "Epoch: 78 | Batch_idx: 300 |  Loss: (0.1773) | Acc: (93.80%) (36138/38528)\n",
            "Epoch: 78 | Batch_idx: 310 |  Loss: (0.1771) | Acc: (93.81%) (37343/39808)\n",
            "Epoch: 78 | Batch_idx: 320 |  Loss: (0.1766) | Acc: (93.81%) (38545/41088)\n",
            "Epoch: 78 | Batch_idx: 330 |  Loss: (0.1764) | Acc: (93.81%) (39744/42368)\n",
            "Epoch: 78 | Batch_idx: 340 |  Loss: (0.1766) | Acc: (93.80%) (40940/43648)\n",
            "Epoch: 78 | Batch_idx: 350 |  Loss: (0.1763) | Acc: (93.80%) (42141/44928)\n",
            "Epoch: 78 | Batch_idx: 360 |  Loss: (0.1760) | Acc: (93.80%) (43343/46208)\n",
            "Epoch: 78 | Batch_idx: 370 |  Loss: (0.1757) | Acc: (93.81%) (44548/47488)\n",
            "Epoch: 78 | Batch_idx: 380 |  Loss: (0.1757) | Acc: (93.82%) (45753/48768)\n",
            "Epoch: 78 | Batch_idx: 390 |  Loss: (0.1763) | Acc: (93.78%) (46891/50000)\n",
            "# TEST : Loss: (0.3982) | Acc: (88.34%) (8834/10000)\n",
            "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1324) | Acc: (94.53%) (121/128)\n",
            "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1760) | Acc: (93.68%) (1319/1408)\n",
            "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1635) | Acc: (94.12%) (2530/2688)\n",
            "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1574) | Acc: (94.25%) (3740/3968)\n",
            "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1613) | Acc: (94.25%) (4946/5248)\n",
            "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1647) | Acc: (94.19%) (6149/6528)\n",
            "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1591) | Acc: (94.36%) (7368/7808)\n",
            "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1590) | Acc: (94.38%) (8577/9088)\n",
            "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1581) | Acc: (94.43%) (9791/10368)\n",
            "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1591) | Acc: (94.39%) (10994/11648)\n",
            "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1596) | Acc: (94.36%) (12199/12928)\n",
            "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1588) | Acc: (94.38%) (13409/14208)\n",
            "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1582) | Acc: (94.37%) (14616/15488)\n",
            "Epoch: 79 | Batch_idx: 130 |  Loss: (0.1572) | Acc: (94.36%) (15822/16768)\n",
            "Epoch: 79 | Batch_idx: 140 |  Loss: (0.1571) | Acc: (94.38%) (17033/18048)\n",
            "Epoch: 79 | Batch_idx: 150 |  Loss: (0.1583) | Acc: (94.37%) (18240/19328)\n",
            "Epoch: 79 | Batch_idx: 160 |  Loss: (0.1591) | Acc: (94.31%) (19435/20608)\n",
            "Epoch: 79 | Batch_idx: 170 |  Loss: (0.1603) | Acc: (94.28%) (20637/21888)\n",
            "Epoch: 79 | Batch_idx: 180 |  Loss: (0.1615) | Acc: (94.24%) (21834/23168)\n",
            "Epoch: 79 | Batch_idx: 190 |  Loss: (0.1637) | Acc: (94.20%) (23029/24448)\n",
            "Epoch: 79 | Batch_idx: 200 |  Loss: (0.1652) | Acc: (94.15%) (24223/25728)\n",
            "Epoch: 79 | Batch_idx: 210 |  Loss: (0.1657) | Acc: (94.12%) (25419/27008)\n",
            "Epoch: 79 | Batch_idx: 220 |  Loss: (0.1662) | Acc: (94.10%) (26619/28288)\n",
            "Epoch: 79 | Batch_idx: 230 |  Loss: (0.1657) | Acc: (94.14%) (27834/29568)\n",
            "Epoch: 79 | Batch_idx: 240 |  Loss: (0.1657) | Acc: (94.13%) (29037/30848)\n",
            "Epoch: 79 | Batch_idx: 250 |  Loss: (0.1659) | Acc: (94.14%) (30244/32128)\n",
            "Epoch: 79 | Batch_idx: 260 |  Loss: (0.1668) | Acc: (94.10%) (31436/33408)\n",
            "Epoch: 79 | Batch_idx: 270 |  Loss: (0.1670) | Acc: (94.10%) (32640/34688)\n",
            "Epoch: 79 | Batch_idx: 280 |  Loss: (0.1683) | Acc: (94.06%) (33832/35968)\n",
            "Epoch: 79 | Batch_idx: 290 |  Loss: (0.1683) | Acc: (94.06%) (35036/37248)\n",
            "Epoch: 79 | Batch_idx: 300 |  Loss: (0.1691) | Acc: (94.04%) (36230/38528)\n",
            "Epoch: 79 | Batch_idx: 310 |  Loss: (0.1704) | Acc: (93.99%) (37416/39808)\n",
            "Epoch: 79 | Batch_idx: 320 |  Loss: (0.1713) | Acc: (93.96%) (38606/41088)\n",
            "Epoch: 79 | Batch_idx: 330 |  Loss: (0.1725) | Acc: (93.94%) (39801/42368)\n",
            "Epoch: 79 | Batch_idx: 340 |  Loss: (0.1731) | Acc: (93.95%) (41007/43648)\n",
            "Epoch: 79 | Batch_idx: 350 |  Loss: (0.1732) | Acc: (93.92%) (42197/44928)\n",
            "Epoch: 79 | Batch_idx: 360 |  Loss: (0.1740) | Acc: (93.89%) (43386/46208)\n",
            "Epoch: 79 | Batch_idx: 370 |  Loss: (0.1744) | Acc: (93.88%) (44581/47488)\n",
            "Epoch: 79 | Batch_idx: 380 |  Loss: (0.1746) | Acc: (93.86%) (45773/48768)\n",
            "Epoch: 79 | Batch_idx: 390 |  Loss: (0.1752) | Acc: (93.83%) (46914/50000)\n",
            "# TEST : Loss: (0.3579) | Acc: (89.53%) (8953/10000)\n",
            "Epoch: 80 | Batch_idx: 0 |  Loss: (0.1348) | Acc: (95.31%) (122/128)\n",
            "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1248) | Acc: (95.88%) (1350/1408)\n",
            "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1385) | Acc: (95.35%) (2563/2688)\n",
            "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1340) | Acc: (95.44%) (3787/3968)\n",
            "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1275) | Acc: (95.73%) (5024/5248)\n",
            "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1290) | Acc: (95.65%) (6244/6528)\n",
            "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1251) | Acc: (95.75%) (7476/7808)\n",
            "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1226) | Acc: (95.82%) (8708/9088)\n",
            "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1236) | Acc: (95.79%) (9931/10368)\n",
            "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1204) | Acc: (95.96%) (11178/11648)\n",
            "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1183) | Acc: (96.00%) (12411/12928)\n",
            "Epoch: 80 | Batch_idx: 110 |  Loss: (0.1164) | Acc: (96.04%) (13645/14208)\n",
            "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1152) | Acc: (96.04%) (14875/15488)\n",
            "Epoch: 80 | Batch_idx: 130 |  Loss: (0.1151) | Acc: (96.04%) (16104/16768)\n",
            "Epoch: 80 | Batch_idx: 140 |  Loss: (0.1144) | Acc: (96.04%) (17333/18048)\n",
            "Epoch: 80 | Batch_idx: 150 |  Loss: (0.1132) | Acc: (96.06%) (18567/19328)\n",
            "Epoch: 80 | Batch_idx: 160 |  Loss: (0.1130) | Acc: (96.07%) (19798/20608)\n",
            "Epoch: 80 | Batch_idx: 170 |  Loss: (0.1110) | Acc: (96.16%) (21048/21888)\n",
            "Epoch: 80 | Batch_idx: 180 |  Loss: (0.1101) | Acc: (96.19%) (22286/23168)\n",
            "Epoch: 80 | Batch_idx: 190 |  Loss: (0.1083) | Acc: (96.25%) (23530/24448)\n",
            "Epoch: 80 | Batch_idx: 200 |  Loss: (0.1073) | Acc: (96.26%) (24765/25728)\n",
            "Epoch: 80 | Batch_idx: 210 |  Loss: (0.1061) | Acc: (96.31%) (26012/27008)\n",
            "Epoch: 80 | Batch_idx: 220 |  Loss: (0.1049) | Acc: (96.37%) (27260/28288)\n",
            "Epoch: 80 | Batch_idx: 230 |  Loss: (0.1046) | Acc: (96.38%) (28497/29568)\n",
            "Epoch: 80 | Batch_idx: 240 |  Loss: (0.1032) | Acc: (96.44%) (29750/30848)\n",
            "Epoch: 80 | Batch_idx: 250 |  Loss: (0.1023) | Acc: (96.49%) (30999/32128)\n",
            "Epoch: 80 | Batch_idx: 260 |  Loss: (0.1014) | Acc: (96.53%) (32248/33408)\n",
            "Epoch: 80 | Batch_idx: 270 |  Loss: (0.1006) | Acc: (96.57%) (33498/34688)\n",
            "Epoch: 80 | Batch_idx: 280 |  Loss: (0.0995) | Acc: (96.60%) (34744/35968)\n",
            "Epoch: 80 | Batch_idx: 290 |  Loss: (0.0985) | Acc: (96.64%) (35996/37248)\n",
            "Epoch: 80 | Batch_idx: 300 |  Loss: (0.0979) | Acc: (96.66%) (37241/38528)\n",
            "Epoch: 80 | Batch_idx: 310 |  Loss: (0.0979) | Acc: (96.67%) (38482/39808)\n",
            "Epoch: 80 | Batch_idx: 320 |  Loss: (0.0976) | Acc: (96.69%) (39728/41088)\n",
            "Epoch: 80 | Batch_idx: 330 |  Loss: (0.0969) | Acc: (96.71%) (40974/42368)\n",
            "Epoch: 80 | Batch_idx: 340 |  Loss: (0.0966) | Acc: (96.73%) (42219/43648)\n",
            "Epoch: 80 | Batch_idx: 350 |  Loss: (0.0961) | Acc: (96.74%) (43462/44928)\n",
            "Epoch: 80 | Batch_idx: 360 |  Loss: (0.0958) | Acc: (96.74%) (44703/46208)\n",
            "Epoch: 80 | Batch_idx: 370 |  Loss: (0.0950) | Acc: (96.78%) (45958/47488)\n",
            "Epoch: 80 | Batch_idx: 380 |  Loss: (0.0943) | Acc: (96.82%) (47216/48768)\n",
            "Epoch: 80 | Batch_idx: 390 |  Loss: (0.0935) | Acc: (96.85%) (48425/50000)\n",
            "# TEST : Loss: (0.2673) | Acc: (91.88%) (9188/10000)\n",
            "Epoch: 81 | Batch_idx: 0 |  Loss: (0.0778) | Acc: (96.88%) (124/128)\n",
            "Epoch: 81 | Batch_idx: 10 |  Loss: (0.0644) | Acc: (97.87%) (1378/1408)\n",
            "Epoch: 81 | Batch_idx: 20 |  Loss: (0.0676) | Acc: (97.88%) (2631/2688)\n",
            "Epoch: 81 | Batch_idx: 30 |  Loss: (0.0696) | Acc: (97.63%) (3874/3968)\n",
            "Epoch: 81 | Batch_idx: 40 |  Loss: (0.0675) | Acc: (97.75%) (5130/5248)\n",
            "Epoch: 81 | Batch_idx: 50 |  Loss: (0.0675) | Acc: (97.84%) (6387/6528)\n",
            "Epoch: 81 | Batch_idx: 60 |  Loss: (0.0696) | Acc: (97.72%) (7630/7808)\n",
            "Epoch: 81 | Batch_idx: 70 |  Loss: (0.0684) | Acc: (97.79%) (8887/9088)\n",
            "Epoch: 81 | Batch_idx: 80 |  Loss: (0.0698) | Acc: (97.73%) (10133/10368)\n",
            "Epoch: 81 | Batch_idx: 90 |  Loss: (0.0695) | Acc: (97.73%) (11384/11648)\n",
            "Epoch: 81 | Batch_idx: 100 |  Loss: (0.0690) | Acc: (97.79%) (12642/12928)\n",
            "Epoch: 81 | Batch_idx: 110 |  Loss: (0.0696) | Acc: (97.75%) (13889/14208)\n",
            "Epoch: 81 | Batch_idx: 120 |  Loss: (0.0692) | Acc: (97.80%) (15147/15488)\n",
            "Epoch: 81 | Batch_idx: 130 |  Loss: (0.0679) | Acc: (97.85%) (16408/16768)\n",
            "Epoch: 81 | Batch_idx: 140 |  Loss: (0.0665) | Acc: (97.90%) (17669/18048)\n",
            "Epoch: 81 | Batch_idx: 150 |  Loss: (0.0661) | Acc: (97.92%) (18926/19328)\n",
            "Epoch: 81 | Batch_idx: 160 |  Loss: (0.0660) | Acc: (97.92%) (20179/20608)\n",
            "Epoch: 81 | Batch_idx: 170 |  Loss: (0.0662) | Acc: (97.89%) (21426/21888)\n",
            "Epoch: 81 | Batch_idx: 180 |  Loss: (0.0662) | Acc: (97.89%) (22678/23168)\n",
            "Epoch: 81 | Batch_idx: 190 |  Loss: (0.0666) | Acc: (97.86%) (23924/24448)\n",
            "Epoch: 81 | Batch_idx: 200 |  Loss: (0.0667) | Acc: (97.83%) (25169/25728)\n",
            "Epoch: 81 | Batch_idx: 210 |  Loss: (0.0664) | Acc: (97.84%) (26424/27008)\n",
            "Epoch: 81 | Batch_idx: 220 |  Loss: (0.0661) | Acc: (97.85%) (27680/28288)\n",
            "Epoch: 81 | Batch_idx: 230 |  Loss: (0.0659) | Acc: (97.87%) (28937/29568)\n",
            "Epoch: 81 | Batch_idx: 240 |  Loss: (0.0658) | Acc: (97.88%) (30194/30848)\n",
            "Epoch: 81 | Batch_idx: 250 |  Loss: (0.0652) | Acc: (97.91%) (31455/32128)\n",
            "Epoch: 81 | Batch_idx: 260 |  Loss: (0.0656) | Acc: (97.89%) (32704/33408)\n",
            "Epoch: 81 | Batch_idx: 270 |  Loss: (0.0654) | Acc: (97.91%) (33964/34688)\n",
            "Epoch: 81 | Batch_idx: 280 |  Loss: (0.0653) | Acc: (97.91%) (35215/35968)\n",
            "Epoch: 81 | Batch_idx: 290 |  Loss: (0.0654) | Acc: (97.90%) (36464/37248)\n",
            "Epoch: 81 | Batch_idx: 300 |  Loss: (0.0653) | Acc: (97.90%) (37718/38528)\n",
            "Epoch: 81 | Batch_idx: 310 |  Loss: (0.0654) | Acc: (97.89%) (38967/39808)\n",
            "Epoch: 81 | Batch_idx: 320 |  Loss: (0.0655) | Acc: (97.89%) (40223/41088)\n",
            "Epoch: 81 | Batch_idx: 330 |  Loss: (0.0662) | Acc: (97.87%) (41464/42368)\n",
            "Epoch: 81 | Batch_idx: 340 |  Loss: (0.0661) | Acc: (97.85%) (42711/43648)\n",
            "Epoch: 81 | Batch_idx: 350 |  Loss: (0.0656) | Acc: (97.87%) (43971/44928)\n",
            "Epoch: 81 | Batch_idx: 360 |  Loss: (0.0655) | Acc: (97.87%) (45224/46208)\n",
            "Epoch: 81 | Batch_idx: 370 |  Loss: (0.0655) | Acc: (97.87%) (46477/47488)\n",
            "Epoch: 81 | Batch_idx: 380 |  Loss: (0.0652) | Acc: (97.88%) (47734/48768)\n",
            "Epoch: 81 | Batch_idx: 390 |  Loss: (0.0653) | Acc: (97.87%) (48934/50000)\n",
            "# TEST : Loss: (0.2686) | Acc: (92.27%) (9227/10000)\n",
            "Epoch: 82 | Batch_idx: 0 |  Loss: (0.0333) | Acc: (99.22%) (127/128)\n",
            "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0445) | Acc: (98.58%) (1388/1408)\n",
            "Epoch: 82 | Batch_idx: 20 |  Loss: (0.0416) | Acc: (98.70%) (2653/2688)\n",
            "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0486) | Acc: (98.44%) (3906/3968)\n",
            "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0505) | Acc: (98.38%) (5163/5248)\n",
            "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0521) | Acc: (98.35%) (6420/6528)\n",
            "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0525) | Acc: (98.32%) (7677/7808)\n",
            "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0533) | Acc: (98.33%) (8936/9088)\n",
            "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0535) | Acc: (98.32%) (10194/10368)\n",
            "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0526) | Acc: (98.33%) (11454/11648)\n",
            "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0540) | Acc: (98.25%) (12702/12928)\n",
            "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0546) | Acc: (98.22%) (13955/14208)\n",
            "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0542) | Acc: (98.23%) (15214/15488)\n",
            "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0542) | Acc: (98.23%) (16471/16768)\n",
            "Epoch: 82 | Batch_idx: 140 |  Loss: (0.0550) | Acc: (98.17%) (17718/18048)\n",
            "Epoch: 82 | Batch_idx: 150 |  Loss: (0.0547) | Acc: (98.20%) (18980/19328)\n",
            "Epoch: 82 | Batch_idx: 160 |  Loss: (0.0549) | Acc: (98.18%) (20233/20608)\n",
            "Epoch: 82 | Batch_idx: 170 |  Loss: (0.0547) | Acc: (98.16%) (21485/21888)\n",
            "Epoch: 82 | Batch_idx: 180 |  Loss: (0.0545) | Acc: (98.17%) (22745/23168)\n",
            "Epoch: 82 | Batch_idx: 190 |  Loss: (0.0543) | Acc: (98.20%) (24008/24448)\n",
            "Epoch: 82 | Batch_idx: 200 |  Loss: (0.0548) | Acc: (98.17%) (25258/25728)\n",
            "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0551) | Acc: (98.17%) (26513/27008)\n",
            "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0554) | Acc: (98.15%) (27764/28288)\n",
            "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0546) | Acc: (98.18%) (29029/29568)\n",
            "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0549) | Acc: (98.18%) (30286/30848)\n",
            "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0546) | Acc: (98.19%) (31546/32128)\n",
            "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0542) | Acc: (98.21%) (32809/33408)\n",
            "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0543) | Acc: (98.20%) (34065/34688)\n",
            "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0543) | Acc: (98.20%) (35321/35968)\n",
            "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0541) | Acc: (98.22%) (36584/37248)\n",
            "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0537) | Acc: (98.23%) (37847/38528)\n",
            "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0541) | Acc: (98.21%) (39097/39808)\n",
            "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0539) | Acc: (98.22%) (40356/41088)\n",
            "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0545) | Acc: (98.19%) (41603/42368)\n",
            "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0543) | Acc: (98.21%) (42865/43648)\n",
            "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0542) | Acc: (98.21%) (44124/44928)\n",
            "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0544) | Acc: (98.20%) (45374/46208)\n",
            "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0543) | Acc: (98.21%) (46637/47488)\n",
            "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0541) | Acc: (98.21%) (47895/48768)\n",
            "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0539) | Acc: (98.22%) (49110/50000)\n",
            "# TEST : Loss: (0.2725) | Acc: (92.36%) (9236/10000)\n",
            "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0539) | Acc: (97.66%) (125/128)\n",
            "Epoch: 83 | Batch_idx: 10 |  Loss: (0.0491) | Acc: (98.44%) (1386/1408)\n",
            "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0537) | Acc: (98.36%) (2644/2688)\n",
            "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0519) | Acc: (98.41%) (3905/3968)\n",
            "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0502) | Acc: (98.51%) (5170/5248)\n",
            "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0501) | Acc: (98.44%) (6426/6528)\n",
            "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0507) | Acc: (98.40%) (7683/7808)\n",
            "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0494) | Acc: (98.42%) (8944/9088)\n",
            "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0492) | Acc: (98.45%) (10207/10368)\n",
            "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0502) | Acc: (98.38%) (11459/11648)\n",
            "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0499) | Acc: (98.41%) (12723/12928)\n",
            "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0498) | Acc: (98.40%) (13981/14208)\n",
            "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0496) | Acc: (98.41%) (15241/15488)\n",
            "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0490) | Acc: (98.43%) (16505/16768)\n",
            "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0488) | Acc: (98.43%) (17764/18048)\n",
            "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0490) | Acc: (98.42%) (19022/19328)\n",
            "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0491) | Acc: (98.42%) (20282/20608)\n",
            "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0497) | Acc: (98.40%) (21538/21888)\n",
            "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0494) | Acc: (98.43%) (22805/23168)\n",
            "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0486) | Acc: (98.48%) (24076/24448)\n",
            "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0487) | Acc: (98.46%) (25332/25728)\n",
            "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0485) | Acc: (98.46%) (26591/27008)\n",
            "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0494) | Acc: (98.42%) (27840/28288)\n",
            "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0498) | Acc: (98.39%) (29093/29568)\n",
            "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0499) | Acc: (98.41%) (30356/30848)\n",
            "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0497) | Acc: (98.41%) (31616/32128)\n",
            "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0497) | Acc: (98.41%) (32878/33408)\n",
            "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0495) | Acc: (98.41%) (34138/34688)\n",
            "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0492) | Acc: (98.43%) (35405/35968)\n",
            "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0491) | Acc: (98.43%) (36664/37248)\n",
            "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0491) | Acc: (98.44%) (37927/38528)\n",
            "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0488) | Acc: (98.46%) (39196/39808)\n",
            "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0486) | Acc: (98.47%) (40460/41088)\n",
            "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0488) | Acc: (98.45%) (41713/42368)\n",
            "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0490) | Acc: (98.44%) (42969/43648)\n",
            "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0490) | Acc: (98.44%) (44228/44928)\n",
            "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0493) | Acc: (98.43%) (45484/46208)\n",
            "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0494) | Acc: (98.43%) (46742/47488)\n",
            "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0496) | Acc: (98.42%) (47997/48768)\n",
            "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0495) | Acc: (98.42%) (49211/50000)\n",
            "# TEST : Loss: (0.2707) | Acc: (92.43%) (9243/10000)\n",
            "Epoch: 84 | Batch_idx: 0 |  Loss: (0.0408) | Acc: (98.44%) (126/128)\n",
            "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0337) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0372) | Acc: (98.88%) (2658/2688)\n",
            "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0367) | Acc: (98.97%) (3927/3968)\n",
            "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0398) | Acc: (98.86%) (5188/5248)\n",
            "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0402) | Acc: (98.90%) (6456/6528)\n",
            "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0403) | Acc: (98.89%) (7721/7808)\n",
            "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0409) | Acc: (98.88%) (8986/9088)\n",
            "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0422) | Acc: (98.84%) (10248/10368)\n",
            "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0418) | Acc: (98.81%) (11509/11648)\n",
            "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0419) | Acc: (98.78%) (12770/12928)\n",
            "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0417) | Acc: (98.79%) (14036/14208)\n",
            "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0422) | Acc: (98.77%) (15298/15488)\n",
            "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0424) | Acc: (98.75%) (16559/16768)\n",
            "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0428) | Acc: (98.75%) (17823/18048)\n",
            "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0431) | Acc: (98.71%) (19079/19328)\n",
            "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0434) | Acc: (98.69%) (20338/20608)\n",
            "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0430) | Acc: (98.71%) (21606/21888)\n",
            "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0427) | Acc: (98.72%) (22871/23168)\n",
            "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0423) | Acc: (98.72%) (24136/24448)\n",
            "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0422) | Acc: (98.72%) (25399/25728)\n",
            "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0428) | Acc: (98.69%) (26655/27008)\n",
            "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0430) | Acc: (98.69%) (27917/28288)\n",
            "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0435) | Acc: (98.66%) (29172/29568)\n",
            "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0431) | Acc: (98.68%) (30442/30848)\n",
            "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0431) | Acc: (98.66%) (31699/32128)\n",
            "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0432) | Acc: (98.66%) (32959/33408)\n",
            "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0429) | Acc: (98.65%) (34221/34688)\n",
            "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0430) | Acc: (98.66%) (35486/35968)\n",
            "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0429) | Acc: (98.67%) (36753/37248)\n",
            "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0427) | Acc: (98.67%) (38017/38528)\n",
            "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0428) | Acc: (98.66%) (39275/39808)\n",
            "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0428) | Acc: (98.66%) (40537/41088)\n",
            "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0430) | Acc: (98.66%) (41800/42368)\n",
            "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0429) | Acc: (98.66%) (43063/43648)\n",
            "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0429) | Acc: (98.65%) (44323/44928)\n",
            "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0429) | Acc: (98.66%) (45588/46208)\n",
            "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0429) | Acc: (98.67%) (46855/47488)\n",
            "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0433) | Acc: (98.66%) (48113/48768)\n",
            "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0431) | Acc: (98.66%) (49330/50000)\n",
            "# TEST : Loss: (0.2790) | Acc: (92.47%) (9247/10000)\n",
            "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0462) | Acc: (98.44%) (126/128)\n",
            "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0381) | Acc: (98.79%) (1391/1408)\n",
            "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0353) | Acc: (98.92%) (2659/2688)\n",
            "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0337) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0352) | Acc: (98.84%) (5187/5248)\n",
            "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0381) | Acc: (98.76%) (6447/6528)\n",
            "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0385) | Acc: (98.78%) (7713/7808)\n",
            "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0386) | Acc: (98.76%) (8975/9088)\n",
            "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0392) | Acc: (98.75%) (10238/10368)\n",
            "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0393) | Acc: (98.74%) (11501/11648)\n",
            "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0398) | Acc: (98.72%) (12763/12928)\n",
            "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0399) | Acc: (98.72%) (14026/14208)\n",
            "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0398) | Acc: (98.73%) (15291/15488)\n",
            "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0393) | Acc: (98.75%) (16559/16768)\n",
            "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0385) | Acc: (98.79%) (17830/18048)\n",
            "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0393) | Acc: (98.76%) (19088/19328)\n",
            "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0393) | Acc: (98.77%) (20355/20608)\n",
            "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0392) | Acc: (98.79%) (21624/21888)\n",
            "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0394) | Acc: (98.79%) (22888/23168)\n",
            "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0392) | Acc: (98.80%) (24155/24448)\n",
            "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0392) | Acc: (98.79%) (25416/25728)\n",
            "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0390) | Acc: (98.80%) (26684/27008)\n",
            "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0391) | Acc: (98.79%) (27947/28288)\n",
            "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0389) | Acc: (98.80%) (29213/29568)\n",
            "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0393) | Acc: (98.80%) (30477/30848)\n",
            "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0394) | Acc: (98.79%) (31740/32128)\n",
            "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0392) | Acc: (98.80%) (33007/33408)\n",
            "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0392) | Acc: (98.80%) (34272/34688)\n",
            "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0390) | Acc: (98.80%) (35538/35968)\n",
            "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0390) | Acc: (98.80%) (36801/37248)\n",
            "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0391) | Acc: (98.79%) (38060/38528)\n",
            "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0392) | Acc: (98.78%) (39323/39808)\n",
            "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0393) | Acc: (98.76%) (40579/41088)\n",
            "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0395) | Acc: (98.76%) (41843/42368)\n",
            "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0394) | Acc: (98.76%) (43108/43648)\n",
            "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0394) | Acc: (98.76%) (44369/44928)\n",
            "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0398) | Acc: (98.74%) (45628/46208)\n",
            "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0396) | Acc: (98.75%) (46896/47488)\n",
            "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0399) | Acc: (98.73%) (48149/48768)\n",
            "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0397) | Acc: (98.74%) (49372/50000)\n",
            "# TEST : Loss: (0.2811) | Acc: (92.37%) (9237/10000)\n",
            "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0420) | Acc: (98.44%) (126/128)\n",
            "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0336) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0398) | Acc: (98.81%) (2656/2688)\n",
            "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0382) | Acc: (98.82%) (3921/3968)\n",
            "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0398) | Acc: (98.74%) (5182/5248)\n",
            "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0392) | Acc: (98.82%) (6451/6528)\n",
            "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0367) | Acc: (98.87%) (7720/7808)\n",
            "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0361) | Acc: (98.90%) (8988/9088)\n",
            "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0354) | Acc: (98.96%) (10260/10368)\n",
            "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0354) | Acc: (98.94%) (11525/11648)\n",
            "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0352) | Acc: (98.98%) (12796/12928)\n",
            "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0346) | Acc: (98.99%) (14065/14208)\n",
            "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0362) | Acc: (98.88%) (15315/15488)\n",
            "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0365) | Acc: (98.88%) (16580/16768)\n",
            "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0363) | Acc: (98.88%) (17845/18048)\n",
            "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0365) | Acc: (98.87%) (19109/19328)\n",
            "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0360) | Acc: (98.88%) (20377/20608)\n",
            "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0357) | Acc: (98.89%) (21646/21888)\n",
            "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0353) | Acc: (98.91%) (22915/23168)\n",
            "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0359) | Acc: (98.90%) (24178/24448)\n",
            "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0358) | Acc: (98.91%) (25447/25728)\n",
            "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0357) | Acc: (98.91%) (26713/27008)\n",
            "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0359) | Acc: (98.89%) (27975/28288)\n",
            "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0358) | Acc: (98.90%) (29244/29568)\n",
            "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0357) | Acc: (98.91%) (30511/30848)\n",
            "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0359) | Acc: (98.90%) (31774/32128)\n",
            "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0362) | Acc: (98.89%) (33038/33408)\n",
            "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0363) | Acc: (98.89%) (34303/34688)\n",
            "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0366) | Acc: (98.87%) (35561/35968)\n",
            "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0364) | Acc: (98.86%) (36825/37248)\n",
            "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0366) | Acc: (98.85%) (38086/38528)\n",
            "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0364) | Acc: (98.86%) (39356/39808)\n",
            "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0363) | Acc: (98.87%) (40622/41088)\n",
            "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0364) | Acc: (98.86%) (41887/42368)\n",
            "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0364) | Acc: (98.86%) (43152/43648)\n",
            "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0367) | Acc: (98.85%) (44411/44928)\n",
            "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0367) | Acc: (98.85%) (45675/46208)\n",
            "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0365) | Acc: (98.86%) (46945/47488)\n",
            "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0364) | Acc: (98.85%) (48209/48768)\n",
            "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0363) | Acc: (98.86%) (49429/50000)\n",
            "# TEST : Loss: (0.2812) | Acc: (92.45%) (9245/10000)\n",
            "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0498) | Acc: (97.66%) (125/128)\n",
            "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0363) | Acc: (98.79%) (1391/1408)\n",
            "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0361) | Acc: (98.85%) (2657/2688)\n",
            "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0344) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0338) | Acc: (98.97%) (5194/5248)\n",
            "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0319) | Acc: (99.05%) (6466/6528)\n",
            "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0329) | Acc: (99.04%) (7733/7808)\n",
            "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0326) | Acc: (99.04%) (9001/9088)\n",
            "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0325) | Acc: (99.05%) (10269/10368)\n",
            "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0316) | Acc: (99.10%) (11543/11648)\n",
            "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0321) | Acc: (99.07%) (12808/12928)\n",
            "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0325) | Acc: (99.03%) (14070/14208)\n",
            "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0324) | Acc: (99.04%) (15340/15488)\n",
            "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0322) | Acc: (99.03%) (16606/16768)\n",
            "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0320) | Acc: (99.05%) (17876/18048)\n",
            "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0324) | Acc: (99.04%) (19143/19328)\n",
            "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0319) | Acc: (99.05%) (20412/20608)\n",
            "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0320) | Acc: (99.05%) (21679/21888)\n",
            "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0323) | Acc: (99.03%) (22944/23168)\n",
            "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0324) | Acc: (99.04%) (24213/24448)\n",
            "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0324) | Acc: (99.03%) (25479/25728)\n",
            "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0329) | Acc: (99.00%) (26739/27008)\n",
            "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0328) | Acc: (99.00%) (28006/28288)\n",
            "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0327) | Acc: (99.01%) (29274/29568)\n",
            "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0328) | Acc: (98.99%) (30537/30848)\n",
            "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0329) | Acc: (98.98%) (31801/32128)\n",
            "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0330) | Acc: (98.97%) (33065/33408)\n",
            "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0334) | Acc: (98.96%) (34328/34688)\n",
            "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0334) | Acc: (98.95%) (35592/35968)\n",
            "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0335) | Acc: (98.94%) (36855/37248)\n",
            "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0335) | Acc: (98.94%) (38118/38528)\n",
            "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0334) | Acc: (98.95%) (39389/39808)\n",
            "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0334) | Acc: (98.95%) (40656/41088)\n",
            "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0331) | Acc: (98.97%) (41930/42368)\n",
            "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0330) | Acc: (98.97%) (43198/43648)\n",
            "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0330) | Acc: (98.96%) (44461/44928)\n",
            "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0331) | Acc: (98.96%) (45728/46208)\n",
            "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0330) | Acc: (98.97%) (46997/47488)\n",
            "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0327) | Acc: (98.98%) (48272/48768)\n",
            "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0326) | Acc: (98.99%) (49494/50000)\n",
            "# TEST : Loss: (0.2868) | Acc: (92.45%) (9245/10000)\n",
            "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0491) | Acc: (97.66%) (125/128)\n",
            "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0269) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0262) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0282) | Acc: (99.04%) (3930/3968)\n",
            "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0286) | Acc: (99.05%) (5198/5248)\n",
            "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0283) | Acc: (99.05%) (6466/6528)\n",
            "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0301) | Acc: (99.03%) (7732/7808)\n",
            "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0317) | Acc: (98.98%) (8995/9088)\n",
            "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0312) | Acc: (98.98%) (10262/10368)\n",
            "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0306) | Acc: (99.03%) (11535/11648)\n",
            "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0312) | Acc: (99.01%) (12800/12928)\n",
            "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0315) | Acc: (98.99%) (14064/14208)\n",
            "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0312) | Acc: (98.99%) (15331/15488)\n",
            "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0319) | Acc: (98.96%) (16594/16768)\n",
            "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0315) | Acc: (98.98%) (17864/18048)\n",
            "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0310) | Acc: (99.00%) (19135/19328)\n",
            "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0313) | Acc: (99.01%) (20403/20608)\n",
            "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0313) | Acc: (99.02%) (21674/21888)\n",
            "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0313) | Acc: (99.02%) (22942/23168)\n",
            "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0315) | Acc: (99.01%) (24207/24448)\n",
            "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0316) | Acc: (99.01%) (25474/25728)\n",
            "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0317) | Acc: (99.02%) (26742/27008)\n",
            "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0318) | Acc: (99.01%) (28009/28288)\n",
            "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0317) | Acc: (99.03%) (29281/29568)\n",
            "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0318) | Acc: (99.03%) (30549/30848)\n",
            "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0320) | Acc: (99.02%) (31813/32128)\n",
            "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0320) | Acc: (99.03%) (33083/33408)\n",
            "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0317) | Acc: (99.04%) (34355/34688)\n",
            "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0317) | Acc: (99.03%) (35619/35968)\n",
            "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0316) | Acc: (99.04%) (36889/37248)\n",
            "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0316) | Acc: (99.03%) (38156/38528)\n",
            "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0315) | Acc: (99.04%) (39425/39808)\n",
            "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0314) | Acc: (99.04%) (40695/41088)\n",
            "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0313) | Acc: (99.04%) (41963/42368)\n",
            "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0313) | Acc: (99.04%) (43231/43648)\n",
            "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0311) | Acc: (99.05%) (44503/44928)\n",
            "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0312) | Acc: (99.05%) (45768/46208)\n",
            "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0315) | Acc: (99.04%) (47032/47488)\n",
            "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0315) | Acc: (99.04%) (48301/48768)\n",
            "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0315) | Acc: (99.04%) (49519/50000)\n",
            "# TEST : Loss: (0.2878) | Acc: (92.47%) (9247/10000)\n",
            "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0266) | Acc: (98.44%) (126/128)\n",
            "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0320) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0286) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0272) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0272) | Acc: (99.20%) (5206/5248)\n",
            "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0272) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0268) | Acc: (99.21%) (7746/7808)\n",
            "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0272) | Acc: (99.15%) (9011/9088)\n",
            "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0277) | Acc: (99.14%) (10279/10368)\n",
            "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0278) | Acc: (99.13%) (11547/11648)\n",
            "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0281) | Acc: (99.13%) (12815/12928)\n",
            "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0285) | Acc: (99.11%) (14081/14208)\n",
            "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0282) | Acc: (99.12%) (15352/15488)\n",
            "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0286) | Acc: (99.10%) (16617/16768)\n",
            "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0287) | Acc: (99.10%) (17886/18048)\n",
            "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0293) | Acc: (99.07%) (19149/19328)\n",
            "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0297) | Acc: (99.05%) (20412/20608)\n",
            "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0298) | Acc: (99.05%) (21679/21888)\n",
            "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0300) | Acc: (99.04%) (22945/23168)\n",
            "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0302) | Acc: (99.03%) (24210/24448)\n",
            "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0302) | Acc: (99.03%) (25478/25728)\n",
            "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0301) | Acc: (99.03%) (26747/27008)\n",
            "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0300) | Acc: (99.05%) (28019/28288)\n",
            "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0301) | Acc: (99.04%) (29284/29568)\n",
            "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0304) | Acc: (99.03%) (30549/30848)\n",
            "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0304) | Acc: (99.03%) (31815/32128)\n",
            "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0304) | Acc: (99.03%) (33084/33408)\n",
            "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0300) | Acc: (99.05%) (34359/34688)\n",
            "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0298) | Acc: (99.07%) (35632/35968)\n",
            "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0299) | Acc: (99.06%) (36897/37248)\n",
            "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0302) | Acc: (99.05%) (38161/38528)\n",
            "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0303) | Acc: (99.02%) (39418/39808)\n",
            "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0300) | Acc: (99.03%) (40689/41088)\n",
            "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0300) | Acc: (99.03%) (41957/42368)\n",
            "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0300) | Acc: (99.03%) (43226/43648)\n",
            "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0300) | Acc: (99.04%) (44495/44928)\n",
            "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0300) | Acc: (99.04%) (45766/46208)\n",
            "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0298) | Acc: (99.05%) (47036/47488)\n",
            "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0300) | Acc: (99.04%) (48301/48768)\n",
            "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0299) | Acc: (99.04%) (49520/50000)\n",
            "# TEST : Loss: (0.2911) | Acc: (92.65%) (9265/10000)\n",
            "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0217) | Acc: (100.00%) (128/128)\n",
            "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0273) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0313) | Acc: (98.88%) (2658/2688)\n",
            "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0269) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0252) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0254) | Acc: (99.20%) (6476/6528)\n",
            "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0252) | Acc: (99.22%) (7747/7808)\n",
            "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0248) | Acc: (99.23%) (9018/9088)\n",
            "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0254) | Acc: (99.21%) (10286/10368)\n",
            "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0266) | Acc: (99.18%) (11552/11648)\n",
            "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0262) | Acc: (99.18%) (12822/12928)\n",
            "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0269) | Acc: (99.16%) (14088/14208)\n",
            "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0272) | Acc: (99.14%) (15355/15488)\n",
            "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0271) | Acc: (99.17%) (16628/16768)\n",
            "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0269) | Acc: (99.17%) (17899/18048)\n",
            "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0272) | Acc: (99.16%) (19166/19328)\n",
            "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0271) | Acc: (99.15%) (20433/20608)\n",
            "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0266) | Acc: (99.19%) (21710/21888)\n",
            "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0267) | Acc: (99.19%) (22980/23168)\n",
            "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0266) | Acc: (99.21%) (24254/24448)\n",
            "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0270) | Acc: (99.19%) (25520/25728)\n",
            "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0274) | Acc: (99.16%) (26782/27008)\n",
            "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0275) | Acc: (99.15%) (28048/28288)\n",
            "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0279) | Acc: (99.13%) (29311/29568)\n",
            "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0275) | Acc: (99.14%) (30583/30848)\n",
            "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0272) | Acc: (99.15%) (31854/32128)\n",
            "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0271) | Acc: (99.16%) (33126/33408)\n",
            "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0273) | Acc: (99.14%) (34390/34688)\n",
            "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0274) | Acc: (99.13%) (35656/35968)\n",
            "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0274) | Acc: (99.14%) (36926/37248)\n",
            "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0275) | Acc: (99.13%) (38193/38528)\n",
            "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0279) | Acc: (99.11%) (39455/39808)\n",
            "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0280) | Acc: (99.11%) (40722/41088)\n",
            "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0279) | Acc: (99.11%) (41991/42368)\n",
            "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0276) | Acc: (99.12%) (43264/43648)\n",
            "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0279) | Acc: (99.10%) (44524/44928)\n",
            "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0279) | Acc: (99.10%) (45792/46208)\n",
            "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0278) | Acc: (99.11%) (47065/47488)\n",
            "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0279) | Acc: (99.10%) (48330/48768)\n",
            "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0278) | Acc: (99.11%) (49555/50000)\n",
            "# TEST : Loss: (0.2910) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0267) | Acc: (99.22%) (127/128)\n",
            "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0132) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0214) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0209) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0210) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0218) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0236) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0240) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0241) | Acc: (99.30%) (10295/10368)\n",
            "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0235) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0240) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0242) | Acc: (99.30%) (14109/14208)\n",
            "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0242) | Acc: (99.30%) (15379/15488)\n",
            "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0249) | Acc: (99.26%) (16644/16768)\n",
            "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0251) | Acc: (99.26%) (17914/18048)\n",
            "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0253) | Acc: (99.24%) (19182/19328)\n",
            "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0253) | Acc: (99.24%) (20452/20608)\n",
            "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0250) | Acc: (99.26%) (21726/21888)\n",
            "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0253) | Acc: (99.24%) (22993/23168)\n",
            "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0253) | Acc: (99.26%) (24266/24448)\n",
            "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0252) | Acc: (99.27%) (25539/25728)\n",
            "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0255) | Acc: (99.26%) (26807/27008)\n",
            "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0254) | Acc: (99.26%) (28079/28288)\n",
            "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0255) | Acc: (99.25%) (29347/29568)\n",
            "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0252) | Acc: (99.27%) (30622/30848)\n",
            "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0256) | Acc: (99.25%) (31886/32128)\n",
            "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0256) | Acc: (99.24%) (33155/33408)\n",
            "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0260) | Acc: (99.23%) (34422/34688)\n",
            "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0256) | Acc: (99.25%) (35697/35968)\n",
            "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0254) | Acc: (99.26%) (36973/37248)\n",
            "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0254) | Acc: (99.27%) (38246/38528)\n",
            "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0254) | Acc: (99.26%) (39513/39808)\n",
            "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0257) | Acc: (99.24%) (40777/41088)\n",
            "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0255) | Acc: (99.25%) (42050/42368)\n",
            "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0255) | Acc: (99.25%) (43321/43648)\n",
            "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0256) | Acc: (99.25%) (44590/44928)\n",
            "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0258) | Acc: (99.24%) (45857/46208)\n",
            "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0256) | Acc: (99.25%) (47130/47488)\n",
            "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0258) | Acc: (99.24%) (48395/48768)\n",
            "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0259) | Acc: (99.23%) (49616/50000)\n",
            "# TEST : Loss: (0.2908) | Acc: (92.71%) (9271/10000)\n",
            "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0169) | Acc: (100.00%) (128/128)\n",
            "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0198) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0232) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0237) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0220) | Acc: (99.37%) (5215/5248)\n",
            "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0228) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0233) | Acc: (99.35%) (7757/7808)\n",
            "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0231) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0243) | Acc: (99.29%) (10294/10368)\n",
            "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0241) | Acc: (99.28%) (11564/11648)\n",
            "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0236) | Acc: (99.29%) (12836/12928)\n",
            "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0240) | Acc: (99.25%) (14102/14208)\n",
            "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0246) | Acc: (99.22%) (15367/15488)\n",
            "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0245) | Acc: (99.22%) (16638/16768)\n",
            "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0242) | Acc: (99.25%) (17912/18048)\n",
            "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0241) | Acc: (99.24%) (19182/19328)\n",
            "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0245) | Acc: (99.25%) (20453/20608)\n",
            "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0242) | Acc: (99.25%) (21723/21888)\n",
            "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0240) | Acc: (99.25%) (22995/23168)\n",
            "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0240) | Acc: (99.25%) (24265/24448)\n",
            "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0236) | Acc: (99.28%) (25542/25728)\n",
            "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0238) | Acc: (99.27%) (26810/27008)\n",
            "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0238) | Acc: (99.26%) (28080/28288)\n",
            "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0241) | Acc: (99.25%) (29347/29568)\n",
            "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0240) | Acc: (99.26%) (30619/30848)\n",
            "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0239) | Acc: (99.26%) (31889/32128)\n",
            "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0238) | Acc: (99.27%) (33164/33408)\n",
            "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0237) | Acc: (99.28%) (34437/34688)\n",
            "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0237) | Acc: (99.27%) (35707/35968)\n",
            "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0235) | Acc: (99.28%) (36980/37248)\n",
            "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0238) | Acc: (99.27%) (38246/38528)\n",
            "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0238) | Acc: (99.27%) (39516/39808)\n",
            "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0238) | Acc: (99.26%) (40786/41088)\n",
            "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0241) | Acc: (99.25%) (42052/42368)\n",
            "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0240) | Acc: (99.26%) (43323/43648)\n",
            "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0238) | Acc: (99.27%) (44599/44928)\n",
            "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0238) | Acc: (99.27%) (45869/46208)\n",
            "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0241) | Acc: (99.25%) (47134/47488)\n",
            "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0240) | Acc: (99.26%) (48407/48768)\n",
            "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0241) | Acc: (99.25%) (49625/50000)\n",
            "# TEST : Loss: (0.2937) | Acc: (92.78%) (9278/10000)\n",
            "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0169) | Acc: (100.00%) (128/128)\n",
            "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0144) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0182) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0176) | Acc: (99.70%) (3956/3968)\n",
            "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0161) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0168) | Acc: (99.65%) (6505/6528)\n",
            "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0173) | Acc: (99.63%) (7779/7808)\n",
            "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0170) | Acc: (99.64%) (9055/9088)\n",
            "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0175) | Acc: (99.61%) (10328/10368)\n",
            "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0183) | Acc: (99.59%) (11600/11648)\n",
            "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0186) | Acc: (99.60%) (12876/12928)\n",
            "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0189) | Acc: (99.58%) (14148/14208)\n",
            "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0186) | Acc: (99.57%) (15422/15488)\n",
            "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0187) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0192) | Acc: (99.54%) (17965/18048)\n",
            "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0192) | Acc: (99.55%) (19241/19328)\n",
            "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0198) | Acc: (99.52%) (20510/20608)\n",
            "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0203) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0201) | Acc: (99.50%) (23052/23168)\n",
            "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0206) | Acc: (99.48%) (24320/24448)\n",
            "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0208) | Acc: (99.46%) (25589/25728)\n",
            "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0207) | Acc: (99.47%) (26864/27008)\n",
            "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0209) | Acc: (99.44%) (28131/28288)\n",
            "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0213) | Acc: (99.43%) (29400/29568)\n",
            "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0212) | Acc: (99.43%) (30673/30848)\n",
            "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0213) | Acc: (99.42%) (31941/32128)\n",
            "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0215) | Acc: (99.41%) (33211/33408)\n",
            "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0214) | Acc: (99.41%) (34485/34688)\n",
            "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0218) | Acc: (99.40%) (35752/35968)\n",
            "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0217) | Acc: (99.40%) (37025/37248)\n",
            "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0220) | Acc: (99.40%) (38298/38528)\n",
            "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0222) | Acc: (99.39%) (39566/39808)\n",
            "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0223) | Acc: (99.39%) (40836/41088)\n",
            "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0223) | Acc: (99.38%) (42107/42368)\n",
            "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0225) | Acc: (99.37%) (43372/43648)\n",
            "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0225) | Acc: (99.37%) (44646/44928)\n",
            "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0224) | Acc: (99.38%) (45920/46208)\n",
            "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0224) | Acc: (99.37%) (47191/47488)\n",
            "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0227) | Acc: (99.37%) (48459/48768)\n",
            "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0228) | Acc: (99.37%) (49685/50000)\n",
            "# TEST : Loss: (0.2997) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0246) | Acc: (99.22%) (127/128)\n",
            "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0290) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0254) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0233) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0232) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0241) | Acc: (99.23%) (6478/6528)\n",
            "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0240) | Acc: (99.30%) (7753/7808)\n",
            "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0236) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0225) | Acc: (99.35%) (10301/10368)\n",
            "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0229) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0227) | Acc: (99.33%) (12842/12928)\n",
            "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0228) | Acc: (99.31%) (14110/14208)\n",
            "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0230) | Acc: (99.31%) (15381/15488)\n",
            "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0231) | Acc: (99.29%) (16649/16768)\n",
            "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0235) | Acc: (99.26%) (17914/18048)\n",
            "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0234) | Acc: (99.25%) (19184/19328)\n",
            "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0232) | Acc: (99.27%) (20457/20608)\n",
            "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0232) | Acc: (99.26%) (21726/21888)\n",
            "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0232) | Acc: (99.27%) (23000/23168)\n",
            "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0231) | Acc: (99.27%) (24270/24448)\n",
            "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0228) | Acc: (99.28%) (25544/25728)\n",
            "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0227) | Acc: (99.30%) (26819/27008)\n",
            "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0229) | Acc: (99.30%) (28089/28288)\n",
            "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0228) | Acc: (99.30%) (29360/29568)\n",
            "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0226) | Acc: (99.31%) (30634/30848)\n",
            "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0228) | Acc: (99.30%) (31902/32128)\n",
            "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0227) | Acc: (99.31%) (33176/33408)\n",
            "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0226) | Acc: (99.31%) (34449/34688)\n",
            "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0227) | Acc: (99.32%) (35722/35968)\n",
            "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0226) | Acc: (99.32%) (36994/37248)\n",
            "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0224) | Acc: (99.33%) (38269/38528)\n",
            "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0222) | Acc: (99.33%) (39541/39808)\n",
            "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0224) | Acc: (99.33%) (40811/41088)\n",
            "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0222) | Acc: (99.34%) (42087/42368)\n",
            "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0224) | Acc: (99.34%) (43360/43648)\n",
            "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0224) | Acc: (99.34%) (44630/44928)\n",
            "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0226) | Acc: (99.33%) (45900/46208)\n",
            "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0227) | Acc: (99.33%) (47170/47488)\n",
            "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0227) | Acc: (99.33%) (48442/48768)\n",
            "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0226) | Acc: (99.33%) (49666/50000)\n",
            "# TEST : Loss: (0.3079) | Acc: (92.63%) (9263/10000)\n",
            "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0257) | Acc: (99.22%) (127/128)\n",
            "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0132) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0136) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0170) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0167) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0185) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0183) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0201) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0197) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0199) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0190) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0205) | Acc: (99.42%) (14125/14208)\n",
            "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0209) | Acc: (99.40%) (15395/15488)\n",
            "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0212) | Acc: (99.38%) (16664/16768)\n",
            "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0213) | Acc: (99.38%) (17936/18048)\n",
            "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0210) | Acc: (99.38%) (19208/19328)\n",
            "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0207) | Acc: (99.38%) (20481/20608)\n",
            "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0211) | Acc: (99.36%) (21749/21888)\n",
            "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0209) | Acc: (99.36%) (23020/23168)\n",
            "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0209) | Acc: (99.35%) (24290/24448)\n",
            "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0211) | Acc: (99.35%) (25560/25728)\n",
            "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0211) | Acc: (99.33%) (26828/27008)\n",
            "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0212) | Acc: (99.33%) (28099/28288)\n",
            "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0214) | Acc: (99.33%) (29370/29568)\n",
            "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0215) | Acc: (99.33%) (30640/30848)\n",
            "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0215) | Acc: (99.32%) (31910/32128)\n",
            "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0213) | Acc: (99.32%) (33181/33408)\n",
            "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0212) | Acc: (99.32%) (34453/34688)\n",
            "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0216) | Acc: (99.31%) (35719/35968)\n",
            "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0215) | Acc: (99.31%) (36991/37248)\n",
            "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0216) | Acc: (99.30%) (38260/38528)\n",
            "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0217) | Acc: (99.30%) (39530/39808)\n",
            "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0217) | Acc: (99.30%) (40799/41088)\n",
            "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0217) | Acc: (99.30%) (42071/42368)\n",
            "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0215) | Acc: (99.31%) (43347/43648)\n",
            "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0216) | Acc: (99.31%) (44617/44928)\n",
            "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0215) | Acc: (99.31%) (45890/46208)\n",
            "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0214) | Acc: (99.31%) (47162/47488)\n",
            "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.33%) (48439/48768)\n",
            "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0215) | Acc: (99.33%) (49664/50000)\n",
            "# TEST : Loss: (0.3072) | Acc: (92.59%) (9259/10000)\n",
            "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
            "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0228) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0199) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0230) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0248) | Acc: (99.14%) (5203/5248)\n",
            "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0237) | Acc: (99.23%) (6478/6528)\n",
            "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0222) | Acc: (99.31%) (7754/7808)\n",
            "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0220) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0222) | Acc: (99.30%) (10295/10368)\n",
            "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0219) | Acc: (99.31%) (11568/11648)\n",
            "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0218) | Acc: (99.31%) (12839/12928)\n",
            "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0213) | Acc: (99.35%) (14115/14208)\n",
            "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0213) | Acc: (99.36%) (15389/15488)\n",
            "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0214) | Acc: (99.36%) (16661/16768)\n",
            "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0210) | Acc: (99.36%) (17932/18048)\n",
            "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0213) | Acc: (99.34%) (19200/19328)\n",
            "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0211) | Acc: (99.34%) (20473/20608)\n",
            "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0210) | Acc: (99.35%) (21746/21888)\n",
            "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0210) | Acc: (99.35%) (23017/23168)\n",
            "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0204) | Acc: (99.38%) (24297/24448)\n",
            "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0204) | Acc: (99.38%) (25568/25728)\n",
            "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0204) | Acc: (99.38%) (26841/27008)\n",
            "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0205) | Acc: (99.38%) (28112/28288)\n",
            "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0206) | Acc: (99.37%) (29382/29568)\n",
            "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0206) | Acc: (99.37%) (30653/30848)\n",
            "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0206) | Acc: (99.37%) (31927/32128)\n",
            "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.38%) (33200/33408)\n",
            "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0206) | Acc: (99.38%) (34472/34688)\n",
            "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0205) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0203) | Acc: (99.39%) (37021/37248)\n",
            "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0204) | Acc: (99.37%) (38287/38528)\n",
            "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0204) | Acc: (99.37%) (39558/39808)\n",
            "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0205) | Acc: (99.36%) (40827/41088)\n",
            "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0205) | Acc: (99.37%) (42100/42368)\n",
            "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0205) | Acc: (99.37%) (43371/43648)\n",
            "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0206) | Acc: (99.36%) (44640/44928)\n",
            "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0206) | Acc: (99.36%) (45912/46208)\n",
            "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0204) | Acc: (99.37%) (47187/47488)\n",
            "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0206) | Acc: (99.36%) (48454/48768)\n",
            "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0205) | Acc: (99.36%) (49681/50000)\n",
            "# TEST : Loss: (0.3042) | Acc: (92.81%) (9281/10000)\n",
            "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0084) | Acc: (100.00%) (128/128)\n",
            "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0169) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0166) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0180) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0177) | Acc: (99.50%) (5222/5248)\n",
            "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0167) | Acc: (99.53%) (6497/6528)\n",
            "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0174) | Acc: (99.51%) (7770/7808)\n",
            "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0178) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0184) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0181) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0185) | Acc: (99.44%) (12856/12928)\n",
            "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0186) | Acc: (99.44%) (14129/14208)\n",
            "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0193) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0194) | Acc: (99.42%) (16671/16768)\n",
            "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0197) | Acc: (99.42%) (17943/18048)\n",
            "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0196) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0197) | Acc: (99.39%) (20482/20608)\n",
            "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0193) | Acc: (99.41%) (21758/21888)\n",
            "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0199) | Acc: (99.39%) (23027/23168)\n",
            "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0199) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0200) | Acc: (99.38%) (25569/25728)\n",
            "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0201) | Acc: (99.39%) (26843/27008)\n",
            "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0201) | Acc: (99.39%) (28115/28288)\n",
            "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0202) | Acc: (99.38%) (29384/29568)\n",
            "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0202) | Acc: (99.38%) (30657/30848)\n",
            "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0201) | Acc: (99.38%) (31929/32128)\n",
            "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0201) | Acc: (99.38%) (33202/33408)\n",
            "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0201) | Acc: (99.38%) (34473/34688)\n",
            "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0202) | Acc: (99.37%) (35743/35968)\n",
            "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0204) | Acc: (99.37%) (37012/37248)\n",
            "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0206) | Acc: (99.36%) (38283/38528)\n",
            "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0208) | Acc: (99.35%) (39548/39808)\n",
            "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0210) | Acc: (99.34%) (40816/41088)\n",
            "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0211) | Acc: (99.34%) (42087/42368)\n",
            "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0211) | Acc: (99.34%) (43358/43648)\n",
            "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0209) | Acc: (99.34%) (44631/44928)\n",
            "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0209) | Acc: (99.33%) (45900/46208)\n",
            "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0208) | Acc: (99.33%) (47172/47488)\n",
            "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0208) | Acc: (99.34%) (48445/48768)\n",
            "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0209) | Acc: (99.33%) (49664/50000)\n",
            "# TEST : Loss: (0.3137) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0131) | Acc: (100.00%) (128/128)\n",
            "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0154) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0216) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0215) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0215) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0208) | Acc: (99.34%) (6485/6528)\n",
            "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0205) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0197) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0197) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0196) | Acc: (99.36%) (11573/11648)\n",
            "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0193) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0190) | Acc: (99.39%) (14122/14208)\n",
            "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0187) | Acc: (99.41%) (15397/15488)\n",
            "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0184) | Acc: (99.43%) (16672/16768)\n",
            "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0183) | Acc: (99.42%) (17943/18048)\n",
            "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0185) | Acc: (99.41%) (19214/19328)\n",
            "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0187) | Acc: (99.42%) (20488/20608)\n",
            "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0186) | Acc: (99.42%) (21761/21888)\n",
            "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0187) | Acc: (99.42%) (23034/23168)\n",
            "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0192) | Acc: (99.41%) (24303/24448)\n",
            "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0188) | Acc: (99.42%) (25578/25728)\n",
            "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0190) | Acc: (99.41%) (26849/27008)\n",
            "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0189) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0189) | Acc: (99.40%) (29392/29568)\n",
            "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0193) | Acc: (99.38%) (30658/30848)\n",
            "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0193) | Acc: (99.38%) (31928/32128)\n",
            "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0190) | Acc: (99.40%) (33207/33408)\n",
            "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0189) | Acc: (99.40%) (34481/34688)\n",
            "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0187) | Acc: (99.42%) (35758/35968)\n",
            "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0187) | Acc: (99.42%) (37031/37248)\n",
            "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0188) | Acc: (99.41%) (38301/38528)\n",
            "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0187) | Acc: (99.42%) (39577/39808)\n",
            "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0187) | Acc: (99.42%) (40850/41088)\n",
            "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0188) | Acc: (99.41%) (42120/42368)\n",
            "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0188) | Acc: (99.41%) (43392/43648)\n",
            "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0189) | Acc: (99.41%) (44665/44928)\n",
            "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0190) | Acc: (99.40%) (45933/46208)\n",
            "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0192) | Acc: (99.40%) (47201/47488)\n",
            "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0193) | Acc: (99.39%) (48472/48768)\n",
            "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0193) | Acc: (99.39%) (49697/50000)\n",
            "# TEST : Loss: (0.3135) | Acc: (92.64%) (9264/10000)\n",
            "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0036) | Acc: (100.00%) (128/128)\n",
            "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0127) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0157) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0172) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0172) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0167) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0175) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0179) | Acc: (99.45%) (9038/9088)\n",
            "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0180) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0169) | Acc: (99.50%) (11590/11648)\n",
            "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0174) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0179) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0181) | Acc: (99.45%) (15403/15488)\n",
            "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0183) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0185) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0185) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0183) | Acc: (99.44%) (20492/20608)\n",
            "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0185) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0185) | Acc: (99.42%) (23034/23168)\n",
            "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0185) | Acc: (99.41%) (24304/24448)\n",
            "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0187) | Acc: (99.41%) (25575/25728)\n",
            "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0185) | Acc: (99.42%) (26852/27008)\n",
            "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0185) | Acc: (99.42%) (28124/28288)\n",
            "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0185) | Acc: (99.42%) (29397/29568)\n",
            "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0187) | Acc: (99.40%) (30664/30848)\n",
            "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0186) | Acc: (99.41%) (31938/32128)\n",
            "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0186) | Acc: (99.40%) (33207/33408)\n",
            "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0184) | Acc: (99.42%) (34486/34688)\n",
            "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0181) | Acc: (99.43%) (35762/35968)\n",
            "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0179) | Acc: (99.44%) (37038/37248)\n",
            "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0180) | Acc: (99.43%) (38307/38528)\n",
            "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0182) | Acc: (99.42%) (39578/39808)\n",
            "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0182) | Acc: (99.42%) (40850/41088)\n",
            "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0181) | Acc: (99.43%) (42125/42368)\n",
            "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0181) | Acc: (99.43%) (43400/43648)\n",
            "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0182) | Acc: (99.43%) (44671/44928)\n",
            "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0181) | Acc: (99.44%) (45947/46208)\n",
            "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0181) | Acc: (99.44%) (47220/47488)\n",
            "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0182) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0183) | Acc: (99.44%) (49719/50000)\n",
            "# TEST : Loss: (0.3139) | Acc: (92.53%) (9253/10000)\n",
            "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0080) | Acc: (100.00%) (128/128)\n",
            "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0214) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0211) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0193) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0199) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0186) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0181) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0178) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0178) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0174) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0171) | Acc: (99.50%) (12863/12928)\n",
            "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0174) | Acc: (99.49%) (14136/14208)\n",
            "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0172) | Acc: (99.50%) (15411/15488)\n",
            "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0171) | Acc: (99.49%) (16683/16768)\n",
            "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0169) | Acc: (99.50%) (17958/18048)\n",
            "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0166) | Acc: (99.51%) (19234/19328)\n",
            "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0169) | Acc: (99.50%) (20504/20608)\n",
            "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0168) | Acc: (99.51%) (21780/21888)\n",
            "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0167) | Acc: (99.51%) (23055/23168)\n",
            "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0165) | Acc: (99.51%) (24329/24448)\n",
            "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0168) | Acc: (99.49%) (25598/25728)\n",
            "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0166) | Acc: (99.50%) (26873/27008)\n",
            "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0170) | Acc: (99.49%) (28144/28288)\n",
            "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0171) | Acc: (99.49%) (29417/29568)\n",
            "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0171) | Acc: (99.50%) (30693/30848)\n",
            "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0172) | Acc: (99.50%) (31966/32128)\n",
            "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0170) | Acc: (99.51%) (33244/33408)\n",
            "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0168) | Acc: (99.52%) (34521/34688)\n",
            "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0170) | Acc: (99.51%) (35790/35968)\n",
            "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0171) | Acc: (99.50%) (37061/37248)\n",
            "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0171) | Acc: (99.50%) (38337/38528)\n",
            "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0169) | Acc: (99.51%) (39613/39808)\n",
            "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0171) | Acc: (99.50%) (40883/41088)\n",
            "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0170) | Acc: (99.50%) (42157/42368)\n",
            "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0170) | Acc: (99.50%) (43429/43648)\n",
            "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0172) | Acc: (99.49%) (44699/44928)\n",
            "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0174) | Acc: (99.48%) (45969/46208)\n",
            "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0174) | Acc: (99.48%) (47241/47488)\n",
            "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0174) | Acc: (99.48%) (48515/48768)\n",
            "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0173) | Acc: (99.49%) (49744/50000)\n",
            "# TEST : Loss: (0.3166) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0119) | Acc: (100.00%) (128/128)\n",
            "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0173) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0164) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0167) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0165) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0168) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0174) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0165) | Acc: (99.50%) (9043/9088)\n",
            "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0164) | Acc: (99.50%) (10316/10368)\n",
            "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0161) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0164) | Acc: (99.50%) (12863/12928)\n",
            "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0166) | Acc: (99.47%) (14133/14208)\n",
            "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0162) | Acc: (99.48%) (15408/15488)\n",
            "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0158) | Acc: (99.51%) (16686/16768)\n",
            "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0157) | Acc: (99.51%) (17960/18048)\n",
            "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0159) | Acc: (99.50%) (19232/19328)\n",
            "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0156) | Acc: (99.51%) (20508/20608)\n",
            "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0157) | Acc: (99.51%) (21780/21888)\n",
            "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0157) | Acc: (99.50%) (23053/23168)\n",
            "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0161) | Acc: (99.50%) (24325/24448)\n",
            "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0162) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0162) | Acc: (99.50%) (26873/27008)\n",
            "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0161) | Acc: (99.50%) (28147/28288)\n",
            "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0160) | Acc: (99.51%) (29422/29568)\n",
            "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0163) | Acc: (99.48%) (30689/30848)\n",
            "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0164) | Acc: (99.47%) (31958/32128)\n",
            "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0167) | Acc: (99.47%) (33230/33408)\n",
            "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0165) | Acc: (99.47%) (34505/34688)\n",
            "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0164) | Acc: (99.48%) (35782/35968)\n",
            "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0165) | Acc: (99.48%) (37055/37248)\n",
            "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0164) | Acc: (99.49%) (38331/38528)\n",
            "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0163) | Acc: (99.49%) (39605/39808)\n",
            "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0164) | Acc: (99.49%) (40877/41088)\n",
            "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0162) | Acc: (99.50%) (42155/42368)\n",
            "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0162) | Acc: (99.50%) (43430/43648)\n",
            "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0161) | Acc: (99.50%) (44705/44928)\n",
            "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0161) | Acc: (99.50%) (45979/46208)\n",
            "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0161) | Acc: (99.50%) (47252/47488)\n",
            "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0162) | Acc: (99.50%) (48525/48768)\n",
            "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0162) | Acc: (99.50%) (49751/50000)\n",
            "# TEST : Loss: (0.3177) | Acc: (92.77%) (9277/10000)\n",
            "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0249) | Acc: (99.22%) (127/128)\n",
            "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0162) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0156) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0173) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0170) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0171) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0163) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0163) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0155) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0153) | Acc: (99.54%) (11594/11648)\n",
            "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0147) | Acc: (99.56%) (12871/12928)\n",
            "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0146) | Acc: (99.56%) (14145/14208)\n",
            "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0154) | Acc: (99.53%) (15415/15488)\n",
            "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0157) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0161) | Acc: (99.51%) (17959/18048)\n",
            "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0159) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0161) | Acc: (99.51%) (20508/20608)\n",
            "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.52%) (21782/21888)\n",
            "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0160) | Acc: (99.52%) (23057/23168)\n",
            "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0159) | Acc: (99.53%) (24332/24448)\n",
            "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0164) | Acc: (99.51%) (25602/25728)\n",
            "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0163) | Acc: (99.51%) (26877/27008)\n",
            "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0164) | Acc: (99.51%) (28150/28288)\n",
            "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0167) | Acc: (99.50%) (29420/29568)\n",
            "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0167) | Acc: (99.49%) (30692/30848)\n",
            "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0167) | Acc: (99.49%) (31964/32128)\n",
            "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0165) | Acc: (99.50%) (33241/33408)\n",
            "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0167) | Acc: (99.48%) (34509/34688)\n",
            "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0166) | Acc: (99.49%) (35783/35968)\n",
            "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0168) | Acc: (99.47%) (37052/37248)\n",
            "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0168) | Acc: (99.47%) (38324/38528)\n",
            "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0169) | Acc: (99.46%) (39593/39808)\n",
            "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0168) | Acc: (99.46%) (40868/41088)\n",
            "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0167) | Acc: (99.47%) (42145/42368)\n",
            "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0167) | Acc: (99.48%) (43419/43648)\n",
            "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0166) | Acc: (99.48%) (44694/44928)\n",
            "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0165) | Acc: (99.48%) (45970/46208)\n",
            "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0164) | Acc: (99.49%) (47246/47488)\n",
            "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0164) | Acc: (99.49%) (48521/48768)\n",
            "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0164) | Acc: (99.49%) (49747/50000)\n",
            "# TEST : Loss: (0.3255) | Acc: (92.45%) (9245/10000)\n",
            "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0214) | Acc: (98.44%) (126/128)\n",
            "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0164) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0151) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0155) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0149) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0149) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0151) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0150) | Acc: (99.50%) (9043/9088)\n",
            "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0148) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0156) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0154) | Acc: (99.53%) (12867/12928)\n",
            "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0153) | Acc: (99.54%) (14143/14208)\n",
            "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0150) | Acc: (99.55%) (15419/15488)\n",
            "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0147) | Acc: (99.58%) (16697/16768)\n",
            "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0145) | Acc: (99.58%) (17973/18048)\n",
            "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0148) | Acc: (99.57%) (19244/19328)\n",
            "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0148) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0148) | Acc: (99.56%) (21791/21888)\n",
            "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0151) | Acc: (99.55%) (23063/23168)\n",
            "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0155) | Acc: (99.53%) (24334/24448)\n",
            "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0153) | Acc: (99.54%) (25609/25728)\n",
            "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0154) | Acc: (99.53%) (26882/27008)\n",
            "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0156) | Acc: (99.53%) (28156/28288)\n",
            "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0154) | Acc: (99.54%) (29433/29568)\n",
            "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0153) | Acc: (99.55%) (30709/30848)\n",
            "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0154) | Acc: (99.55%) (31982/32128)\n",
            "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0156) | Acc: (99.54%) (33253/33408)\n",
            "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0158) | Acc: (99.54%) (34529/34688)\n",
            "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0157) | Acc: (99.55%) (35806/35968)\n",
            "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0160) | Acc: (99.54%) (37077/37248)\n",
            "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0158) | Acc: (99.55%) (38353/38528)\n",
            "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0158) | Acc: (99.54%) (39625/39808)\n",
            "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0157) | Acc: (99.54%) (40899/41088)\n",
            "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0156) | Acc: (99.54%) (42174/42368)\n",
            "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0158) | Acc: (99.52%) (43440/43648)\n",
            "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0158) | Acc: (99.52%) (44712/44928)\n",
            "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0158) | Acc: (99.52%) (45986/46208)\n",
            "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0157) | Acc: (99.52%) (47261/47488)\n",
            "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0155) | Acc: (99.53%) (48540/48768)\n",
            "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0157) | Acc: (99.52%) (49761/50000)\n",
            "# TEST : Loss: (0.3243) | Acc: (92.71%) (9271/10000)\n",
            "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0098) | Acc: (100.00%) (128/128)\n",
            "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0131) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0152) | Acc: (99.52%) (2675/2688)\n",
            "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0164) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0155) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0171) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0162) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0171) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0170) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0159) | Acc: (99.53%) (11593/11648)\n",
            "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0160) | Acc: (99.53%) (12867/12928)\n",
            "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0157) | Acc: (99.54%) (14143/14208)\n",
            "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0162) | Acc: (99.52%) (15413/15488)\n",
            "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0161) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0160) | Acc: (99.53%) (17963/18048)\n",
            "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0158) | Acc: (99.54%) (19239/19328)\n",
            "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0156) | Acc: (99.56%) (20517/20608)\n",
            "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0162) | Acc: (99.52%) (21783/21888)\n",
            "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0159) | Acc: (99.53%) (23058/23168)\n",
            "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0158) | Acc: (99.53%) (24333/24448)\n",
            "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0157) | Acc: (99.54%) (25610/25728)\n",
            "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0157) | Acc: (99.54%) (26883/27008)\n",
            "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0156) | Acc: (99.53%) (28156/28288)\n",
            "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0155) | Acc: (99.54%) (29431/29568)\n",
            "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0155) | Acc: (99.54%) (30705/30848)\n",
            "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0157) | Acc: (99.51%) (31971/32128)\n",
            "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0156) | Acc: (99.52%) (33248/33408)\n",
            "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0154) | Acc: (99.52%) (34522/34688)\n",
            "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0153) | Acc: (99.53%) (35798/35968)\n",
            "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0153) | Acc: (99.54%) (37075/37248)\n",
            "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0153) | Acc: (99.53%) (38347/38528)\n",
            "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0152) | Acc: (99.53%) (39622/39808)\n",
            "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0150) | Acc: (99.54%) (40900/41088)\n",
            "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0149) | Acc: (99.54%) (42174/42368)\n",
            "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0150) | Acc: (99.55%) (43450/43648)\n",
            "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0148) | Acc: (99.56%) (44729/44928)\n",
            "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0147) | Acc: (99.56%) (46006/46208)\n",
            "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0147) | Acc: (99.56%) (47281/47488)\n",
            "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0148) | Acc: (99.56%) (48553/48768)\n",
            "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0151) | Acc: (99.55%) (49773/50000)\n",
            "# TEST : Loss: (0.3292) | Acc: (92.64%) (9264/10000)\n",
            "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0196) | Acc: (98.44%) (126/128)\n",
            "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0140) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0116) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0122) | Acc: (99.65%) (3954/3968)\n",
            "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0125) | Acc: (99.64%) (5229/5248)\n",
            "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0122) | Acc: (99.68%) (6507/6528)\n",
            "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0123) | Acc: (99.63%) (7779/7808)\n",
            "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0122) | Acc: (99.64%) (9055/9088)\n",
            "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0128) | Acc: (99.60%) (10327/10368)\n",
            "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0129) | Acc: (99.57%) (11598/11648)\n",
            "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0126) | Acc: (99.59%) (12875/12928)\n",
            "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0132) | Acc: (99.57%) (14147/14208)\n",
            "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0129) | Acc: (99.58%) (15423/15488)\n",
            "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0131) | Acc: (99.58%) (16697/16768)\n",
            "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0132) | Acc: (99.57%) (17971/18048)\n",
            "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0131) | Acc: (99.59%) (19248/19328)\n",
            "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0132) | Acc: (99.58%) (20521/20608)\n",
            "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0132) | Acc: (99.58%) (21796/21888)\n",
            "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0132) | Acc: (99.57%) (23069/23168)\n",
            "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0133) | Acc: (99.58%) (24346/24448)\n",
            "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0133) | Acc: (99.58%) (25620/25728)\n",
            "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0131) | Acc: (99.58%) (26894/27008)\n",
            "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0132) | Acc: (99.57%) (28166/28288)\n",
            "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0132) | Acc: (99.57%) (29442/29568)\n",
            "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.57%) (30716/30848)\n",
            "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.56%) (31986/32128)\n",
            "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.56%) (33261/33408)\n",
            "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0136) | Acc: (99.56%) (34537/34688)\n",
            "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0135) | Acc: (99.57%) (35812/35968)\n",
            "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0136) | Acc: (99.57%) (37086/37248)\n",
            "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0137) | Acc: (99.57%) (38361/38528)\n",
            "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0137) | Acc: (99.57%) (39638/39808)\n",
            "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0138) | Acc: (99.57%) (40911/41088)\n",
            "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0139) | Acc: (99.57%) (42184/42368)\n",
            "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0139) | Acc: (99.57%) (43459/43648)\n",
            "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0138) | Acc: (99.57%) (44737/44928)\n",
            "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0138) | Acc: (99.58%) (46012/46208)\n",
            "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0138) | Acc: (99.58%) (47288/47488)\n",
            "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0138) | Acc: (99.58%) (48561/48768)\n",
            "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0137) | Acc: (99.58%) (49791/50000)\n",
            "# TEST : Loss: (0.3217) | Acc: (92.58%) (9258/10000)\n",
            "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0073) | Acc: (100.00%) (128/128)\n",
            "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0195) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0161) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0188) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0169) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0157) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0147) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0145) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0146) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0145) | Acc: (99.54%) (11595/11648)\n",
            "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0142) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0138) | Acc: (99.57%) (14147/14208)\n",
            "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0136) | Acc: (99.59%) (15424/15488)\n",
            "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0136) | Acc: (99.58%) (16698/16768)\n",
            "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0134) | Acc: (99.59%) (17974/18048)\n",
            "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0136) | Acc: (99.59%) (19249/19328)\n",
            "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0140) | Acc: (99.57%) (20520/20608)\n",
            "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0140) | Acc: (99.58%) (21796/21888)\n",
            "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0139) | Acc: (99.59%) (23072/23168)\n",
            "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0139) | Acc: (99.58%) (24346/24448)\n",
            "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0140) | Acc: (99.57%) (25618/25728)\n",
            "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0139) | Acc: (99.58%) (26894/27008)\n",
            "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0140) | Acc: (99.58%) (28168/28288)\n",
            "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0141) | Acc: (99.57%) (29442/29568)\n",
            "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0144) | Acc: (99.56%) (30713/30848)\n",
            "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0144) | Acc: (99.56%) (31986/32128)\n",
            "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0143) | Acc: (99.55%) (33258/33408)\n",
            "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0143) | Acc: (99.56%) (34534/34688)\n",
            "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0143) | Acc: (99.55%) (35807/35968)\n",
            "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0144) | Acc: (99.55%) (37079/37248)\n",
            "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0144) | Acc: (99.55%) (38355/38528)\n",
            "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0142) | Acc: (99.56%) (39632/39808)\n",
            "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0141) | Acc: (99.57%) (40910/41088)\n",
            "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0141) | Acc: (99.57%) (42186/42368)\n",
            "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0141) | Acc: (99.57%) (43459/43648)\n",
            "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0141) | Acc: (99.56%) (44732/44928)\n",
            "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0142) | Acc: (99.56%) (46004/46208)\n",
            "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0141) | Acc: (99.56%) (47278/47488)\n",
            "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0143) | Acc: (99.55%) (48550/48768)\n",
            "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0144) | Acc: (99.56%) (49778/50000)\n",
            "# TEST : Loss: (0.3297) | Acc: (92.68%) (9268/10000)\n",
            "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0064) | Acc: (100.00%) (128/128)\n",
            "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0132) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0160) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0149) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0142) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0136) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0155) | Acc: (99.50%) (7769/7808)\n",
            "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0155) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0151) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0152) | Acc: (99.54%) (11594/11648)\n",
            "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0150) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0146) | Acc: (99.56%) (14145/14208)\n",
            "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0146) | Acc: (99.55%) (15418/15488)\n",
            "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0142) | Acc: (99.56%) (16695/16768)\n",
            "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0138) | Acc: (99.58%) (17972/18048)\n",
            "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0137) | Acc: (99.59%) (19248/19328)\n",
            "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0136) | Acc: (99.59%) (20524/20608)\n",
            "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.59%) (21799/21888)\n",
            "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0136) | Acc: (99.59%) (23074/23168)\n",
            "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0136) | Acc: (99.60%) (24351/24448)\n",
            "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0136) | Acc: (99.60%) (25624/25728)\n",
            "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0135) | Acc: (99.60%) (26900/27008)\n",
            "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0133) | Acc: (99.61%) (28178/28288)\n",
            "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0133) | Acc: (99.61%) (29454/29568)\n",
            "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.61%) (30727/30848)\n",
            "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0136) | Acc: (99.59%) (31997/32128)\n",
            "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0135) | Acc: (99.60%) (33275/33408)\n",
            "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0137) | Acc: (99.59%) (34546/34688)\n",
            "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0137) | Acc: (99.58%) (35818/35968)\n",
            "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0137) | Acc: (99.59%) (37094/37248)\n",
            "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0136) | Acc: (99.59%) (38370/38528)\n",
            "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0135) | Acc: (99.60%) (39647/39808)\n",
            "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0134) | Acc: (99.60%) (40924/41088)\n",
            "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0132) | Acc: (99.61%) (42202/42368)\n",
            "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0131) | Acc: (99.62%) (43480/43648)\n",
            "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.61%) (44752/44928)\n",
            "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.61%) (46027/46208)\n",
            "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.61%) (47301/47488)\n",
            "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0136) | Acc: (99.60%) (48573/48768)\n",
            "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0135) | Acc: (99.60%) (49800/50000)\n",
            "# TEST : Loss: (0.3291) | Acc: (92.66%) (9266/10000)\n",
            "Epoch: 108 | Batch_idx: 0 |  Loss: (0.0038) | Acc: (100.00%) (128/128)\n",
            "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0109) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0113) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0109) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0107) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0119) | Acc: (99.73%) (7787/7808)\n",
            "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0116) | Acc: (99.74%) (9064/9088)\n",
            "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0116) | Acc: (99.73%) (10340/10368)\n",
            "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0116) | Acc: (99.72%) (11615/11648)\n",
            "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0114) | Acc: (99.73%) (12893/12928)\n",
            "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0112) | Acc: (99.73%) (14169/14208)\n",
            "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0113) | Acc: (99.70%) (15442/15488)\n",
            "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.70%) (16717/16768)\n",
            "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0117) | Acc: (99.69%) (17992/18048)\n",
            "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0118) | Acc: (99.68%) (19267/19328)\n",
            "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0118) | Acc: (99.69%) (20544/20608)\n",
            "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0120) | Acc: (99.68%) (21817/21888)\n",
            "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0123) | Acc: (99.66%) (23090/23168)\n",
            "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0124) | Acc: (99.65%) (24363/24448)\n",
            "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0124) | Acc: (99.65%) (25638/25728)\n",
            "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0124) | Acc: (99.64%) (26912/27008)\n",
            "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0125) | Acc: (99.64%) (28186/28288)\n",
            "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0126) | Acc: (99.64%) (29461/29568)\n",
            "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0127) | Acc: (99.64%) (30737/30848)\n",
            "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0128) | Acc: (99.63%) (32008/32128)\n",
            "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0128) | Acc: (99.63%) (33284/33408)\n",
            "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0127) | Acc: (99.63%) (34560/34688)\n",
            "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0127) | Acc: (99.64%) (35837/35968)\n",
            "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0126) | Acc: (99.64%) (37115/37248)\n",
            "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0125) | Acc: (99.64%) (38390/38528)\n",
            "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0125) | Acc: (99.64%) (39663/39808)\n",
            "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0126) | Acc: (99.64%) (40939/41088)\n",
            "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0125) | Acc: (99.64%) (42216/42368)\n",
            "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0126) | Acc: (99.64%) (43490/43648)\n",
            "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0125) | Acc: (99.64%) (44767/44928)\n",
            "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0127) | Acc: (99.64%) (46040/46208)\n",
            "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0128) | Acc: (99.63%) (47312/47488)\n",
            "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0129) | Acc: (99.62%) (48585/48768)\n",
            "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0128) | Acc: (99.62%) (49812/50000)\n",
            "# TEST : Loss: (0.3363) | Acc: (92.86%) (9286/10000)\n",
            "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0267) | Acc: (98.44%) (126/128)\n",
            "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0147) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0127) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0137) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0139) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0139) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0137) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0140) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0136) | Acc: (99.49%) (10315/10368)\n",
            "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0135) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0132) | Acc: (99.53%) (12867/12928)\n",
            "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0136) | Acc: (99.53%) (14141/14208)\n",
            "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0145) | Acc: (99.50%) (15411/15488)\n",
            "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0143) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0148) | Acc: (99.51%) (17959/18048)\n",
            "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0145) | Acc: (99.53%) (19237/19328)\n",
            "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0143) | Acc: (99.53%) (20511/20608)\n",
            "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0141) | Acc: (99.55%) (21789/21888)\n",
            "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0141) | Acc: (99.55%) (23063/23168)\n",
            "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0141) | Acc: (99.55%) (24337/24448)\n",
            "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0141) | Acc: (99.55%) (25613/25728)\n",
            "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0139) | Acc: (99.57%) (26891/27008)\n",
            "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0137) | Acc: (99.57%) (28167/28288)\n",
            "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0135) | Acc: (99.58%) (29445/29568)\n",
            "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0133) | Acc: (99.59%) (30723/30848)\n",
            "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0135) | Acc: (99.59%) (31996/32128)\n",
            "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0133) | Acc: (99.60%) (33273/33408)\n",
            "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0133) | Acc: (99.61%) (34551/34688)\n",
            "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0131) | Acc: (99.61%) (35828/35968)\n",
            "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0132) | Acc: (99.62%) (37105/37248)\n",
            "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0131) | Acc: (99.62%) (38381/38528)\n",
            "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.61%) (39651/39808)\n",
            "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0135) | Acc: (99.59%) (40921/41088)\n",
            "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0135) | Acc: (99.59%) (42196/42368)\n",
            "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0135) | Acc: (99.60%) (43472/43648)\n",
            "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0133) | Acc: (99.60%) (44749/44928)\n",
            "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0133) | Acc: (99.60%) (46025/46208)\n",
            "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0133) | Acc: (99.60%) (47298/47488)\n",
            "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.61%) (48576/48768)\n",
            "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.60%) (49801/50000)\n",
            "# TEST : Loss: (0.3426) | Acc: (92.41%) (9241/10000)\n",
            "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0077) | Acc: (100.00%) (128/128)\n",
            "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0076) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0081) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0092) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0110) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0121) | Acc: (99.77%) (6513/6528)\n",
            "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0120) | Acc: (99.74%) (7788/7808)\n",
            "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0120) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0137) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0138) | Acc: (99.64%) (11606/11648)\n",
            "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0135) | Acc: (99.66%) (12884/12928)\n",
            "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0134) | Acc: (99.66%) (14159/14208)\n",
            "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0134) | Acc: (99.66%) (15435/15488)\n",
            "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0131) | Acc: (99.66%) (16711/16768)\n",
            "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0131) | Acc: (99.67%) (17988/18048)\n",
            "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0130) | Acc: (99.67%) (19264/19328)\n",
            "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0133) | Acc: (99.65%) (20535/20608)\n",
            "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0136) | Acc: (99.64%) (21809/21888)\n",
            "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0132) | Acc: (99.66%) (23089/23168)\n",
            "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0133) | Acc: (99.65%) (24362/24448)\n",
            "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0135) | Acc: (99.64%) (25635/25728)\n",
            "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0136) | Acc: (99.64%) (26911/27008)\n",
            "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0134) | Acc: (99.65%) (28190/28288)\n",
            "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0133) | Acc: (99.66%) (29466/29568)\n",
            "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0134) | Acc: (99.65%) (30739/30848)\n",
            "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0134) | Acc: (99.64%) (32012/32128)\n",
            "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0132) | Acc: (99.64%) (33289/33408)\n",
            "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0132) | Acc: (99.64%) (34563/34688)\n",
            "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0133) | Acc: (99.63%) (35835/35968)\n",
            "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0133) | Acc: (99.62%) (37108/37248)\n",
            "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0133) | Acc: (99.62%) (38382/38528)\n",
            "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0132) | Acc: (99.62%) (39658/39808)\n",
            "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0132) | Acc: (99.63%) (40934/41088)\n",
            "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0134) | Acc: (99.62%) (42207/42368)\n",
            "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0132) | Acc: (99.63%) (43487/43648)\n",
            "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0132) | Acc: (99.63%) (44762/44928)\n",
            "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0132) | Acc: (99.63%) (46036/46208)\n",
            "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0132) | Acc: (99.63%) (47312/47488)\n",
            "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0132) | Acc: (99.63%) (48586/48768)\n",
            "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0133) | Acc: (99.62%) (49812/50000)\n",
            "# TEST : Loss: (0.3433) | Acc: (92.63%) (9263/10000)\n",
            "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0032) | Acc: (100.00%) (128/128)\n",
            "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0069) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0091) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0079) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0091) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0102) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0104) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0111) | Acc: (99.69%) (9060/9088)\n",
            "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0112) | Acc: (99.68%) (10335/10368)\n",
            "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.70%) (11613/11648)\n",
            "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0109) | Acc: (99.71%) (12891/12928)\n",
            "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0111) | Acc: (99.70%) (14166/14208)\n",
            "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0111) | Acc: (99.70%) (15441/15488)\n",
            "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0111) | Acc: (99.70%) (16718/16768)\n",
            "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0112) | Acc: (99.70%) (17993/18048)\n",
            "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0112) | Acc: (99.67%) (19265/19328)\n",
            "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0111) | Acc: (99.68%) (20543/20608)\n",
            "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0113) | Acc: (99.67%) (21816/21888)\n",
            "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0110) | Acc: (99.68%) (23094/23168)\n",
            "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0115) | Acc: (99.67%) (24368/24448)\n",
            "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0114) | Acc: (99.67%) (25644/25728)\n",
            "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0115) | Acc: (99.67%) (26919/27008)\n",
            "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0116) | Acc: (99.66%) (28192/28288)\n",
            "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0117) | Acc: (99.66%) (29466/29568)\n",
            "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0119) | Acc: (99.65%) (30741/30848)\n",
            "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0119) | Acc: (99.65%) (32016/32128)\n",
            "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0120) | Acc: (99.65%) (33290/33408)\n",
            "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0120) | Acc: (99.65%) (34566/34688)\n",
            "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0121) | Acc: (99.65%) (35841/35968)\n",
            "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0123) | Acc: (99.64%) (37114/37248)\n",
            "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0123) | Acc: (99.64%) (38390/38528)\n",
            "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0123) | Acc: (99.65%) (39667/39808)\n",
            "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0122) | Acc: (99.65%) (40946/41088)\n",
            "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0121) | Acc: (99.66%) (42225/42368)\n",
            "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0121) | Acc: (99.67%) (43502/43648)\n",
            "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0120) | Acc: (99.67%) (44779/44928)\n",
            "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0120) | Acc: (99.67%) (46054/46208)\n",
            "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0121) | Acc: (99.67%) (47329/47488)\n",
            "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0121) | Acc: (99.67%) (48605/48768)\n",
            "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0122) | Acc: (99.66%) (49832/50000)\n",
            "# TEST : Loss: (0.3382) | Acc: (92.65%) (9265/10000)\n",
            "Epoch: 112 | Batch_idx: 0 |  Loss: (0.0067) | Acc: (100.00%) (128/128)\n",
            "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0120) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0125) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0136) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0143) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0138) | Acc: (99.60%) (6502/6528)\n",
            "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0137) | Acc: (99.60%) (7777/7808)\n",
            "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0126) | Acc: (99.66%) (9057/9088)\n",
            "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0125) | Acc: (99.65%) (10332/10368)\n",
            "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0129) | Acc: (99.63%) (11605/11648)\n",
            "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0129) | Acc: (99.64%) (12881/12928)\n",
            "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0130) | Acc: (99.63%) (14156/14208)\n",
            "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0127) | Acc: (99.64%) (15433/15488)\n",
            "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0123) | Acc: (99.66%) (16711/16768)\n",
            "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0120) | Acc: (99.68%) (17990/18048)\n",
            "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0120) | Acc: (99.68%) (19266/19328)\n",
            "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0121) | Acc: (99.67%) (20540/20608)\n",
            "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0121) | Acc: (99.67%) (21815/21888)\n",
            "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0126) | Acc: (99.67%) (23091/23168)\n",
            "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0124) | Acc: (99.68%) (24370/24448)\n",
            "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0125) | Acc: (99.67%) (25644/25728)\n",
            "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0124) | Acc: (99.67%) (26918/27008)\n",
            "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0125) | Acc: (99.66%) (28193/28288)\n",
            "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0124) | Acc: (99.67%) (29469/29568)\n",
            "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0121) | Acc: (99.68%) (30749/30848)\n",
            "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0123) | Acc: (99.67%) (32021/32128)\n",
            "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0121) | Acc: (99.68%) (33301/33408)\n",
            "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0120) | Acc: (99.68%) (34578/34688)\n",
            "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0122) | Acc: (99.67%) (35851/35968)\n",
            "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0123) | Acc: (99.68%) (37127/37248)\n",
            "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0125) | Acc: (99.67%) (38399/38528)\n",
            "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0124) | Acc: (99.67%) (39678/39808)\n",
            "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0123) | Acc: (99.68%) (40955/41088)\n",
            "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0122) | Acc: (99.67%) (42230/42368)\n",
            "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0124) | Acc: (99.66%) (43501/43648)\n",
            "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0124) | Acc: (99.66%) (44776/44928)\n",
            "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0125) | Acc: (99.65%) (46048/46208)\n",
            "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0124) | Acc: (99.65%) (47324/47488)\n",
            "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0125) | Acc: (99.65%) (48599/48768)\n",
            "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0125) | Acc: (99.66%) (49828/50000)\n",
            "# TEST : Loss: (0.3440) | Acc: (92.66%) (9266/10000)\n",
            "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0129) | Acc: (100.00%) (128/128)\n",
            "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0139) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0119) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0103) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0108) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0107) | Acc: (99.74%) (6511/6528)\n",
            "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0111) | Acc: (99.73%) (7787/7808)\n",
            "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0120) | Acc: (99.68%) (9059/9088)\n",
            "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0116) | Acc: (99.70%) (10337/10368)\n",
            "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0111) | Acc: (99.71%) (11614/11648)\n",
            "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0107) | Acc: (99.73%) (12893/12928)\n",
            "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0107) | Acc: (99.73%) (14169/14208)\n",
            "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0113) | Acc: (99.70%) (15441/15488)\n",
            "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0114) | Acc: (99.68%) (16715/16768)\n",
            "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0114) | Acc: (99.68%) (17991/18048)\n",
            "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0112) | Acc: (99.69%) (19269/19328)\n",
            "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0109) | Acc: (99.70%) (20547/20608)\n",
            "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0109) | Acc: (99.71%) (21824/21888)\n",
            "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0108) | Acc: (99.71%) (23101/23168)\n",
            "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0110) | Acc: (99.71%) (24377/24448)\n",
            "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0110) | Acc: (99.71%) (25653/25728)\n",
            "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0112) | Acc: (99.70%) (26926/27008)\n",
            "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0111) | Acc: (99.70%) (28203/28288)\n",
            "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0111) | Acc: (99.70%) (29480/29568)\n",
            "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0110) | Acc: (99.71%) (30758/30848)\n",
            "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0111) | Acc: (99.71%) (32036/32128)\n",
            "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0112) | Acc: (99.70%) (33309/33408)\n",
            "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0112) | Acc: (99.70%) (34585/34688)\n",
            "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0112) | Acc: (99.71%) (35862/35968)\n",
            "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0112) | Acc: (99.70%) (37138/37248)\n",
            "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0113) | Acc: (99.70%) (38413/38528)\n",
            "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0111) | Acc: (99.71%) (39691/39808)\n",
            "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0110) | Acc: (99.71%) (40968/41088)\n",
            "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0110) | Acc: (99.71%) (42246/42368)\n",
            "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0111) | Acc: (99.71%) (43523/43648)\n",
            "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0111) | Acc: (99.71%) (44798/44928)\n",
            "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0111) | Acc: (99.71%) (46073/46208)\n",
            "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0111) | Acc: (99.71%) (47349/47488)\n",
            "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0111) | Acc: (99.71%) (48626/48768)\n",
            "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0111) | Acc: (99.70%) (49852/50000)\n",
            "# TEST : Loss: (0.3413) | Acc: (92.74%) (9274/10000)\n",
            "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0043) | Acc: (100.00%) (128/128)\n",
            "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0072) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0063) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0083) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0084) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0090) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0091) | Acc: (99.78%) (7791/7808)\n",
            "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0098) | Acc: (99.76%) (9066/9088)\n",
            "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0096) | Acc: (99.76%) (10343/10368)\n",
            "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0100) | Acc: (99.73%) (11617/11648)\n",
            "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0100) | Acc: (99.75%) (12896/12928)\n",
            "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0098) | Acc: (99.75%) (14173/14208)\n",
            "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0096) | Acc: (99.77%) (15453/15488)\n",
            "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0096) | Acc: (99.77%) (16730/16768)\n",
            "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0097) | Acc: (99.77%) (18007/18048)\n",
            "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0098) | Acc: (99.77%) (19284/19328)\n",
            "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0097) | Acc: (99.77%) (20561/20608)\n",
            "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0097) | Acc: (99.77%) (21837/21888)\n",
            "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0097) | Acc: (99.77%) (23114/23168)\n",
            "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0100) | Acc: (99.75%) (24386/24448)\n",
            "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0101) | Acc: (99.74%) (25662/25728)\n",
            "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0100) | Acc: (99.74%) (26938/27008)\n",
            "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0099) | Acc: (99.75%) (28216/28288)\n",
            "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0099) | Acc: (99.75%) (29493/29568)\n",
            "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0100) | Acc: (99.74%) (30768/30848)\n",
            "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0099) | Acc: (99.74%) (32046/32128)\n",
            "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0099) | Acc: (99.75%) (33323/33408)\n",
            "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0098) | Acc: (99.75%) (34601/34688)\n",
            "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0098) | Acc: (99.75%) (35879/35968)\n",
            "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0097) | Acc: (99.76%) (37158/37248)\n",
            "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0097) | Acc: (99.76%) (38436/38528)\n",
            "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0097) | Acc: (99.76%) (39714/39808)\n",
            "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0099) | Acc: (99.75%) (40984/41088)\n",
            "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0100) | Acc: (99.74%) (42258/42368)\n",
            "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0101) | Acc: (99.74%) (43534/43648)\n",
            "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0101) | Acc: (99.74%) (44811/44928)\n",
            "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0101) | Acc: (99.74%) (46086/46208)\n",
            "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0105) | Acc: (99.73%) (47358/47488)\n",
            "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0104) | Acc: (99.73%) (48637/48768)\n",
            "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0103) | Acc: (99.73%) (49866/50000)\n",
            "# TEST : Loss: (0.3376) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0082) | Acc: (99.22%) (127/128)\n",
            "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0084) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0084) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0096) | Acc: (99.70%) (3956/3968)\n",
            "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0090) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0090) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0090) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0088) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0093) | Acc: (99.70%) (10337/10368)\n",
            "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0094) | Acc: (99.71%) (11614/11648)\n",
            "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0097) | Acc: (99.71%) (12890/12928)\n",
            "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0099) | Acc: (99.69%) (14164/14208)\n",
            "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0102) | Acc: (99.68%) (15439/15488)\n",
            "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0102) | Acc: (99.69%) (16716/16768)\n",
            "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0099) | Acc: (99.71%) (17996/18048)\n",
            "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0098) | Acc: (99.71%) (19272/19328)\n",
            "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0099) | Acc: (99.71%) (20549/20608)\n",
            "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0098) | Acc: (99.71%) (21825/21888)\n",
            "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0099) | Acc: (99.71%) (23100/23168)\n",
            "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0098) | Acc: (99.71%) (24378/24448)\n",
            "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0099) | Acc: (99.70%) (25651/25728)\n",
            "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0097) | Acc: (99.71%) (26930/27008)\n",
            "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0097) | Acc: (99.71%) (28206/28288)\n",
            "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0098) | Acc: (99.70%) (29479/29568)\n",
            "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0098) | Acc: (99.70%) (30756/30848)\n",
            "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0098) | Acc: (99.71%) (32034/32128)\n",
            "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0098) | Acc: (99.71%) (33312/33408)\n",
            "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0098) | Acc: (99.71%) (34587/34688)\n",
            "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0098) | Acc: (99.71%) (35865/35968)\n",
            "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0097) | Acc: (99.71%) (37141/37248)\n",
            "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0098) | Acc: (99.71%) (38415/38528)\n",
            "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0098) | Acc: (99.71%) (39692/39808)\n",
            "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0099) | Acc: (99.71%) (40968/41088)\n",
            "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0100) | Acc: (99.70%) (42243/42368)\n",
            "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0101) | Acc: (99.69%) (43514/43648)\n",
            "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0102) | Acc: (99.69%) (44788/44928)\n",
            "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0101) | Acc: (99.69%) (46066/46208)\n",
            "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0101) | Acc: (99.69%) (47341/47488)\n",
            "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0101) | Acc: (99.69%) (48618/48768)\n",
            "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0103) | Acc: (99.68%) (49841/50000)\n",
            "# TEST : Loss: (0.3403) | Acc: (92.60%) (9260/10000)\n",
            "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0105) | Acc: (100.00%) (128/128)\n",
            "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0097) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0099) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0104) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0097) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0098) | Acc: (99.69%) (7784/7808)\n",
            "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0102) | Acc: (99.69%) (9060/9088)\n",
            "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0101) | Acc: (99.68%) (10335/10368)\n",
            "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0101) | Acc: (99.68%) (11611/11648)\n",
            "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0099) | Acc: (99.70%) (12889/12928)\n",
            "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0098) | Acc: (99.70%) (14166/14208)\n",
            "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0101) | Acc: (99.70%) (15441/15488)\n",
            "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0101) | Acc: (99.69%) (16716/16768)\n",
            "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0101) | Acc: (99.68%) (17991/18048)\n",
            "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0098) | Acc: (99.71%) (19271/19328)\n",
            "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0098) | Acc: (99.71%) (20548/20608)\n",
            "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0097) | Acc: (99.71%) (21825/21888)\n",
            "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0097) | Acc: (99.72%) (23102/23168)\n",
            "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0099) | Acc: (99.70%) (24375/24448)\n",
            "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0099) | Acc: (99.70%) (25651/25728)\n",
            "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0098) | Acc: (99.71%) (26930/27008)\n",
            "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0097) | Acc: (99.72%) (28208/28288)\n",
            "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0097) | Acc: (99.72%) (29485/29568)\n",
            "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0097) | Acc: (99.72%) (30762/30848)\n",
            "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0096) | Acc: (99.72%) (32039/32128)\n",
            "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0097) | Acc: (99.72%) (33316/33408)\n",
            "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0096) | Acc: (99.73%) (34593/34688)\n",
            "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0096) | Acc: (99.72%) (35869/35968)\n",
            "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0098) | Acc: (99.72%) (37144/37248)\n",
            "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0099) | Acc: (99.72%) (38419/38528)\n",
            "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0102) | Acc: (99.71%) (39691/39808)\n",
            "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0102) | Acc: (99.71%) (40968/41088)\n",
            "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0103) | Acc: (99.70%) (42240/42368)\n",
            "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0103) | Acc: (99.70%) (43517/43648)\n",
            "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0103) | Acc: (99.70%) (44792/44928)\n",
            "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0103) | Acc: (99.70%) (46070/46208)\n",
            "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0103) | Acc: (99.70%) (47346/47488)\n",
            "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0102) | Acc: (99.70%) (48624/48768)\n",
            "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0102) | Acc: (99.71%) (49853/50000)\n",
            "# TEST : Loss: (0.3409) | Acc: (92.79%) (9279/10000)\n",
            "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0012) | Acc: (100.00%) (128/128)\n",
            "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0076) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0096) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0092) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0094) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0091) | Acc: (99.71%) (6509/6528)\n",
            "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0096) | Acc: (99.68%) (7783/7808)\n",
            "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0092) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0092) | Acc: (99.72%) (10339/10368)\n",
            "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0098) | Acc: (99.71%) (11614/11648)\n",
            "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0098) | Acc: (99.70%) (12889/12928)\n",
            "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0094) | Acc: (99.72%) (14168/14208)\n",
            "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0093) | Acc: (99.73%) (15446/15488)\n",
            "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0094) | Acc: (99.71%) (16720/16768)\n",
            "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0097) | Acc: (99.71%) (17995/18048)\n",
            "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0100) | Acc: (99.69%) (19269/19328)\n",
            "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0100) | Acc: (99.69%) (20544/20608)\n",
            "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0101) | Acc: (99.68%) (21818/21888)\n",
            "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0102) | Acc: (99.68%) (23093/23168)\n",
            "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0102) | Acc: (99.67%) (24368/24448)\n",
            "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0102) | Acc: (99.68%) (25645/25728)\n",
            "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0105) | Acc: (99.67%) (26919/27008)\n",
            "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0107) | Acc: (99.67%) (28194/28288)\n",
            "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0108) | Acc: (99.67%) (29469/29568)\n",
            "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0109) | Acc: (99.67%) (30745/30848)\n",
            "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0108) | Acc: (99.67%) (32023/32128)\n",
            "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0106) | Acc: (99.68%) (33302/33408)\n",
            "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0106) | Acc: (99.69%) (34580/34688)\n",
            "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0105) | Acc: (99.69%) (35855/35968)\n",
            "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0106) | Acc: (99.69%) (37134/37248)\n",
            "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0105) | Acc: (99.69%) (38410/38528)\n",
            "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0104) | Acc: (99.70%) (39689/39808)\n",
            "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0103) | Acc: (99.71%) (40968/41088)\n",
            "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0103) | Acc: (99.71%) (42244/42368)\n",
            "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0101) | Acc: (99.71%) (43523/43648)\n",
            "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0103) | Acc: (99.70%) (44794/44928)\n",
            "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0104) | Acc: (99.70%) (46071/46208)\n",
            "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0103) | Acc: (99.70%) (47347/47488)\n",
            "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0103) | Acc: (99.70%) (48622/48768)\n",
            "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0102) | Acc: (99.70%) (49851/50000)\n",
            "# TEST : Loss: (0.3425) | Acc: (92.76%) (9276/10000)\n",
            "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0054) | Acc: (100.00%) (128/128)\n",
            "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0086) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0091) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0087) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0101) | Acc: (99.68%) (5231/5248)\n",
            "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0091) | Acc: (99.71%) (6509/6528)\n",
            "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0099) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0100) | Acc: (99.68%) (9059/9088)\n",
            "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0100) | Acc: (99.69%) (10336/10368)\n",
            "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0101) | Acc: (99.71%) (11614/11648)\n",
            "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0101) | Acc: (99.71%) (12891/12928)\n",
            "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0100) | Acc: (99.73%) (14169/14208)\n",
            "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0100) | Acc: (99.72%) (15445/15488)\n",
            "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0098) | Acc: (99.73%) (16722/16768)\n",
            "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0095) | Acc: (99.75%) (18002/18048)\n",
            "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0096) | Acc: (99.74%) (19278/19328)\n",
            "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0096) | Acc: (99.74%) (20555/20608)\n",
            "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0099) | Acc: (99.73%) (21828/21888)\n",
            "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0099) | Acc: (99.73%) (23105/23168)\n",
            "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0099) | Acc: (99.73%) (24381/24448)\n",
            "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0098) | Acc: (99.73%) (25659/25728)\n",
            "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0100) | Acc: (99.73%) (26935/27008)\n",
            "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0102) | Acc: (99.72%) (28209/28288)\n",
            "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0102) | Acc: (99.72%) (29486/29568)\n",
            "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0101) | Acc: (99.73%) (30764/30848)\n",
            "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0103) | Acc: (99.72%) (32039/32128)\n",
            "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0103) | Acc: (99.72%) (33316/33408)\n",
            "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0104) | Acc: (99.72%) (34590/34688)\n",
            "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0105) | Acc: (99.71%) (35863/35968)\n",
            "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0105) | Acc: (99.71%) (37139/37248)\n",
            "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0104) | Acc: (99.71%) (38416/38528)\n",
            "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0106) | Acc: (99.70%) (39690/39808)\n",
            "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0106) | Acc: (99.70%) (40966/41088)\n",
            "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0106) | Acc: (99.71%) (42244/42368)\n",
            "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0106) | Acc: (99.71%) (43520/43648)\n",
            "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0107) | Acc: (99.70%) (44795/44928)\n",
            "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0106) | Acc: (99.71%) (46072/46208)\n",
            "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0105) | Acc: (99.71%) (47348/47488)\n",
            "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0105) | Acc: (99.70%) (48624/48768)\n",
            "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0106) | Acc: (99.70%) (49852/50000)\n",
            "# TEST : Loss: (0.3477) | Acc: (92.55%) (9255/10000)\n",
            "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0013) | Acc: (100.00%) (128/128)\n",
            "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0085) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0085) | Acc: (99.70%) (2680/2688)\n",
            "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0081) | Acc: (99.72%) (3957/3968)\n",
            "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0094) | Acc: (99.71%) (5233/5248)\n",
            "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0098) | Acc: (99.71%) (6509/6528)\n",
            "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0102) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0103) | Acc: (99.70%) (9061/9088)\n",
            "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0105) | Acc: (99.70%) (10337/10368)\n",
            "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0101) | Acc: (99.71%) (11614/11648)\n",
            "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0100) | Acc: (99.69%) (12888/12928)\n",
            "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0098) | Acc: (99.70%) (14165/14208)\n",
            "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0096) | Acc: (99.71%) (15443/15488)\n",
            "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0093) | Acc: (99.73%) (16722/16768)\n",
            "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0093) | Acc: (99.72%) (17998/18048)\n",
            "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0092) | Acc: (99.73%) (19276/19328)\n",
            "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0093) | Acc: (99.73%) (20553/20608)\n",
            "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0092) | Acc: (99.74%) (21831/21888)\n",
            "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0092) | Acc: (99.74%) (23107/23168)\n",
            "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0091) | Acc: (99.74%) (24385/24448)\n",
            "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0092) | Acc: (99.74%) (25662/25728)\n",
            "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0093) | Acc: (99.74%) (26938/27008)\n",
            "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0094) | Acc: (99.74%) (28214/28288)\n",
            "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0093) | Acc: (99.74%) (29492/29568)\n",
            "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0096) | Acc: (99.72%) (30763/30848)\n",
            "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0096) | Acc: (99.73%) (32041/32128)\n",
            "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0096) | Acc: (99.72%) (33315/33408)\n",
            "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0095) | Acc: (99.73%) (34593/34688)\n",
            "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0095) | Acc: (99.73%) (35870/35968)\n",
            "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0094) | Acc: (99.73%) (37149/37248)\n",
            "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0096) | Acc: (99.72%) (38422/38528)\n",
            "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0097) | Acc: (99.72%) (39697/39808)\n",
            "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0097) | Acc: (99.72%) (40975/41088)\n",
            "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0098) | Acc: (99.71%) (42247/42368)\n",
            "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0098) | Acc: (99.71%) (43522/43648)\n",
            "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0098) | Acc: (99.71%) (44798/44928)\n",
            "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0097) | Acc: (99.71%) (46075/46208)\n",
            "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0099) | Acc: (99.70%) (47347/47488)\n",
            "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0098) | Acc: (99.71%) (48626/48768)\n",
            "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0097) | Acc: (99.71%) (49857/50000)\n",
            "# TEST : Loss: (0.3475) | Acc: (92.66%) (9266/10000)\n",
            "Epoch: 120 | Batch_idx: 0 |  Loss: (0.0042) | Acc: (100.00%) (128/128)\n",
            "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0066) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0088) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0085) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0114) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0107) | Acc: (99.72%) (6510/6528)\n",
            "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0096) | Acc: (99.77%) (7790/7808)\n",
            "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0091) | Acc: (99.79%) (9069/9088)\n",
            "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0105) | Acc: (99.75%) (10342/10368)\n",
            "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0103) | Acc: (99.75%) (11619/11648)\n",
            "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0101) | Acc: (99.75%) (12896/12928)\n",
            "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0097) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0098) | Acc: (99.76%) (15451/15488)\n",
            "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0096) | Acc: (99.77%) (16729/16768)\n",
            "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0093) | Acc: (99.78%) (18009/18048)\n",
            "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0092) | Acc: (99.79%) (19287/19328)\n",
            "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0095) | Acc: (99.76%) (20559/20608)\n",
            "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0093) | Acc: (99.77%) (21838/21888)\n",
            "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0094) | Acc: (99.77%) (23115/23168)\n",
            "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0094) | Acc: (99.76%) (24390/24448)\n",
            "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0094) | Acc: (99.77%) (25669/25728)\n",
            "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0092) | Acc: (99.78%) (26949/27008)\n",
            "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0095) | Acc: (99.77%) (28224/28288)\n",
            "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0096) | Acc: (99.76%) (29497/29568)\n",
            "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0098) | Acc: (99.76%) (30773/30848)\n",
            "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0097) | Acc: (99.76%) (32052/32128)\n",
            "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0096) | Acc: (99.76%) (33329/33408)\n",
            "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0095) | Acc: (99.77%) (34607/34688)\n",
            "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0095) | Acc: (99.77%) (35885/35968)\n",
            "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0096) | Acc: (99.77%) (37161/37248)\n",
            "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0096) | Acc: (99.76%) (38437/38528)\n",
            "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0096) | Acc: (99.76%) (39711/39808)\n",
            "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0095) | Acc: (99.76%) (40990/41088)\n",
            "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0096) | Acc: (99.76%) (42265/42368)\n",
            "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0096) | Acc: (99.76%) (43543/43648)\n",
            "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0096) | Acc: (99.75%) (44817/44928)\n",
            "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0096) | Acc: (99.75%) (46094/46208)\n",
            "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0096) | Acc: (99.75%) (47371/47488)\n",
            "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0096) | Acc: (99.76%) (48650/48768)\n",
            "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0095) | Acc: (99.76%) (49879/50000)\n",
            "# TEST : Loss: (0.3390) | Acc: (92.84%) (9284/10000)\n",
            "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0025) | Acc: (100.00%) (128/128)\n",
            "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0052) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0073) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0095) | Acc: (99.70%) (3956/3968)\n",
            "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0101) | Acc: (99.70%) (5232/5248)\n",
            "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0100) | Acc: (99.69%) (6508/6528)\n",
            "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0102) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0098) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0097) | Acc: (99.72%) (10339/10368)\n",
            "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0094) | Acc: (99.74%) (11618/11648)\n",
            "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0090) | Acc: (99.76%) (12897/12928)\n",
            "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0088) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0090) | Acc: (99.75%) (15450/15488)\n",
            "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0089) | Acc: (99.76%) (16727/16768)\n",
            "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0092) | Acc: (99.74%) (18001/18048)\n",
            "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0092) | Acc: (99.75%) (19280/19328)\n",
            "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0090) | Acc: (99.76%) (20559/20608)\n",
            "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0090) | Acc: (99.75%) (21834/21888)\n",
            "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0089) | Acc: (99.76%) (23112/23168)\n",
            "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0090) | Acc: (99.75%) (24388/24448)\n",
            "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0089) | Acc: (99.76%) (25666/25728)\n",
            "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0088) | Acc: (99.77%) (26945/27008)\n",
            "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0086) | Acc: (99.78%) (28225/28288)\n",
            "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0086) | Acc: (99.78%) (29503/29568)\n",
            "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0085) | Acc: (99.78%) (30780/30848)\n",
            "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0086) | Acc: (99.78%) (32058/32128)\n",
            "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0087) | Acc: (99.78%) (33333/33408)\n",
            "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0087) | Acc: (99.78%) (34611/34688)\n",
            "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0086) | Acc: (99.78%) (35890/35968)\n",
            "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0086) | Acc: (99.79%) (37169/37248)\n",
            "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0086) | Acc: (99.78%) (38445/38528)\n",
            "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0087) | Acc: (99.78%) (39720/39808)\n",
            "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0086) | Acc: (99.78%) (40997/41088)\n",
            "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0086) | Acc: (99.78%) (42276/42368)\n",
            "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0086) | Acc: (99.78%) (43554/43648)\n",
            "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0086) | Acc: (99.78%) (44831/44928)\n",
            "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0085) | Acc: (99.78%) (46108/46208)\n",
            "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0085) | Acc: (99.79%) (47386/47488)\n",
            "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0085) | Acc: (99.79%) (48665/48768)\n",
            "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0085) | Acc: (99.79%) (49894/50000)\n",
            "# TEST : Loss: (0.3361) | Acc: (92.95%) (9295/10000)\n",
            "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0066) | Acc: (100.00%) (128/128)\n",
            "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0097) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0104) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0092) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0089) | Acc: (99.73%) (5234/5248)\n",
            "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0089) | Acc: (99.71%) (6509/6528)\n",
            "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0086) | Acc: (99.71%) (7785/7808)\n",
            "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0084) | Acc: (99.71%) (9062/9088)\n",
            "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0092) | Acc: (99.68%) (10335/10368)\n",
            "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0095) | Acc: (99.67%) (11609/11648)\n",
            "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0092) | Acc: (99.69%) (12888/12928)\n",
            "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0091) | Acc: (99.70%) (14165/14208)\n",
            "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0089) | Acc: (99.71%) (15443/15488)\n",
            "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0087) | Acc: (99.72%) (16721/16768)\n",
            "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0088) | Acc: (99.72%) (17998/18048)\n",
            "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0087) | Acc: (99.73%) (19275/19328)\n",
            "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0085) | Acc: (99.74%) (20554/20608)\n",
            "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0085) | Acc: (99.74%) (21830/21888)\n",
            "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0085) | Acc: (99.74%) (23108/23168)\n",
            "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0084) | Acc: (99.75%) (24387/24448)\n",
            "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0083) | Acc: (99.76%) (25665/25728)\n",
            "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0082) | Acc: (99.77%) (26945/27008)\n",
            "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0081) | Acc: (99.77%) (28223/28288)\n",
            "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0081) | Acc: (99.78%) (29503/29568)\n",
            "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0080) | Acc: (99.78%) (30781/30848)\n",
            "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0079) | Acc: (99.79%) (32060/32128)\n",
            "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0081) | Acc: (99.78%) (33333/33408)\n",
            "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0082) | Acc: (99.78%) (34610/34688)\n",
            "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0082) | Acc: (99.78%) (35888/35968)\n",
            "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0081) | Acc: (99.78%) (37166/37248)\n",
            "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0081) | Acc: (99.78%) (38444/38528)\n",
            "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0081) | Acc: (99.78%) (39722/39808)\n",
            "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0080) | Acc: (99.79%) (41001/41088)\n",
            "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0079) | Acc: (99.79%) (42280/42368)\n",
            "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0078) | Acc: (99.80%) (43559/43648)\n",
            "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0078) | Acc: (99.80%) (44837/44928)\n",
            "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0078) | Acc: (99.79%) (46113/46208)\n",
            "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0077) | Acc: (99.80%) (47391/47488)\n",
            "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0078) | Acc: (99.79%) (48667/48768)\n",
            "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0078) | Acc: (99.79%) (49894/50000)\n",
            "# TEST : Loss: (0.3384) | Acc: (92.88%) (9288/10000)\n",
            "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0087) | Acc: (100.00%) (128/128)\n",
            "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0068) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0079) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0078) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0076) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0082) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0078) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0077) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0081) | Acc: (99.78%) (10345/10368)\n",
            "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0079) | Acc: (99.79%) (11623/11648)\n",
            "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0081) | Acc: (99.78%) (12899/12928)\n",
            "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0082) | Acc: (99.77%) (14175/14208)\n",
            "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0080) | Acc: (99.78%) (15454/15488)\n",
            "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0084) | Acc: (99.77%) (16730/16768)\n",
            "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0083) | Acc: (99.77%) (18007/18048)\n",
            "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0082) | Acc: (99.78%) (19285/19328)\n",
            "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0083) | Acc: (99.76%) (20559/20608)\n",
            "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0082) | Acc: (99.77%) (21838/21888)\n",
            "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0081) | Acc: (99.78%) (23116/23168)\n",
            "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0082) | Acc: (99.78%) (24394/24448)\n",
            "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0083) | Acc: (99.78%) (25671/25728)\n",
            "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0082) | Acc: (99.78%) (26949/27008)\n",
            "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0083) | Acc: (99.78%) (28226/28288)\n",
            "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0083) | Acc: (99.78%) (29503/29568)\n",
            "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0083) | Acc: (99.78%) (30779/30848)\n",
            "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0083) | Acc: (99.78%) (32057/32128)\n",
            "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0082) | Acc: (99.78%) (33335/33408)\n",
            "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0082) | Acc: (99.78%) (34612/34688)\n",
            "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0083) | Acc: (99.78%) (35889/35968)\n",
            "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0082) | Acc: (99.79%) (37169/37248)\n",
            "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0080) | Acc: (99.79%) (38449/38528)\n",
            "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0080) | Acc: (99.80%) (39727/39808)\n",
            "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0081) | Acc: (99.80%) (41004/41088)\n",
            "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0080) | Acc: (99.79%) (42281/42368)\n",
            "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0079) | Acc: (99.80%) (43561/43648)\n",
            "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0079) | Acc: (99.80%) (44838/44928)\n",
            "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0079) | Acc: (99.80%) (46114/46208)\n",
            "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0079) | Acc: (99.80%) (47392/47488)\n",
            "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0080) | Acc: (99.79%) (48667/48768)\n",
            "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0079) | Acc: (99.80%) (49899/50000)\n",
            "# TEST : Loss: (0.3381) | Acc: (92.90%) (9290/10000)\n",
            "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0042) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0065) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0070) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0063) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0067) | Acc: (99.87%) (11633/11648)\n",
            "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0066) | Acc: (99.87%) (12911/12928)\n",
            "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0067) | Acc: (99.87%) (14190/14208)\n",
            "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0066) | Acc: (99.88%) (15469/15488)\n",
            "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0068) | Acc: (99.87%) (16746/16768)\n",
            "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0069) | Acc: (99.86%) (18022/18048)\n",
            "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0068) | Acc: (99.86%) (19300/19328)\n",
            "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0067) | Acc: (99.86%) (20580/20608)\n",
            "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0067) | Acc: (99.86%) (21858/21888)\n",
            "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.86%) (23136/23168)\n",
            "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0067) | Acc: (99.87%) (24415/24448)\n",
            "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0067) | Acc: (99.86%) (25693/25728)\n",
            "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.87%) (26972/27008)\n",
            "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0066) | Acc: (99.87%) (28251/28288)\n",
            "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.87%) (29531/29568)\n",
            "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.87%) (30809/30848)\n",
            "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0065) | Acc: (99.88%) (32088/32128)\n",
            "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0065) | Acc: (99.88%) (33367/33408)\n",
            "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0065) | Acc: (99.87%) (34644/34688)\n",
            "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0065) | Acc: (99.87%) (35923/35968)\n",
            "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.88%) (37202/37248)\n",
            "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0065) | Acc: (99.88%) (38481/38528)\n",
            "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0065) | Acc: (99.88%) (39759/39808)\n",
            "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0065) | Acc: (99.88%) (41038/41088)\n",
            "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0065) | Acc: (99.88%) (42317/42368)\n",
            "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0064) | Acc: (99.88%) (43595/43648)\n",
            "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0066) | Acc: (99.87%) (44870/44928)\n",
            "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0066) | Acc: (99.87%) (46147/46208)\n",
            "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0067) | Acc: (99.87%) (47424/47488)\n",
            "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0067) | Acc: (99.87%) (48703/48768)\n",
            "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0067) | Acc: (99.86%) (49931/50000)\n",
            "# TEST : Loss: (0.3366) | Acc: (92.87%) (9287/10000)\n",
            "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0060) | Acc: (100.00%) (128/128)\n",
            "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0061) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0063) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0066) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0066) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0068) | Acc: (99.85%) (7796/7808)\n",
            "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0067) | Acc: (99.86%) (9075/9088)\n",
            "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0070) | Acc: (99.86%) (10353/10368)\n",
            "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0068) | Acc: (99.87%) (11633/11648)\n",
            "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0067) | Acc: (99.88%) (12912/12928)\n",
            "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0066) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0066) | Acc: (99.87%) (15468/15488)\n",
            "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0069) | Acc: (99.86%) (16744/16768)\n",
            "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0068) | Acc: (99.86%) (18023/18048)\n",
            "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0067) | Acc: (99.87%) (19303/19328)\n",
            "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0066) | Acc: (99.88%) (20583/20608)\n",
            "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0067) | Acc: (99.87%) (21860/21888)\n",
            "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.88%) (23140/23168)\n",
            "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0067) | Acc: (99.88%) (24419/24448)\n",
            "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0068) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0068) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0068) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0069) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0068) | Acc: (99.87%) (30808/30848)\n",
            "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.88%) (32088/32128)\n",
            "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0067) | Acc: (99.87%) (33365/33408)\n",
            "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0068) | Acc: (99.87%) (34643/34688)\n",
            "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0069) | Acc: (99.87%) (35920/35968)\n",
            "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0069) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0069) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0071) | Acc: (99.86%) (39753/39808)\n",
            "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0072) | Acc: (99.86%) (41030/41088)\n",
            "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0072) | Acc: (99.86%) (42307/42368)\n",
            "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0072) | Acc: (99.85%) (43583/43648)\n",
            "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0072) | Acc: (99.86%) (44863/44928)\n",
            "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0073) | Acc: (99.86%) (46141/46208)\n",
            "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0074) | Acc: (99.84%) (47414/47488)\n",
            "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0075) | Acc: (99.84%) (48691/48768)\n",
            "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0076) | Acc: (99.83%) (49917/50000)\n",
            "# TEST : Loss: (0.3399) | Acc: (92.89%) (9289/10000)\n",
            "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0139) | Acc: (100.00%) (128/128)\n",
            "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0109) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0088) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0073) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0073) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0067) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.89%) (10357/10368)\n",
            "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0066) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0065) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0067) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0069) | Acc: (99.88%) (15469/15488)\n",
            "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0067) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0070) | Acc: (99.87%) (18025/18048)\n",
            "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0070) | Acc: (99.87%) (19303/19328)\n",
            "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0071) | Acc: (99.86%) (20579/20608)\n",
            "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0073) | Acc: (99.84%) (21853/21888)\n",
            "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0071) | Acc: (99.84%) (23132/23168)\n",
            "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0071) | Acc: (99.85%) (24411/24448)\n",
            "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0071) | Acc: (99.85%) (25690/25728)\n",
            "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0072) | Acc: (99.84%) (26966/27008)\n",
            "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0072) | Acc: (99.84%) (28243/28288)\n",
            "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0073) | Acc: (99.83%) (29519/29568)\n",
            "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0072) | Acc: (99.83%) (30797/30848)\n",
            "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0074) | Acc: (99.83%) (32072/32128)\n",
            "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0073) | Acc: (99.83%) (33350/33408)\n",
            "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0072) | Acc: (99.83%) (34630/34688)\n",
            "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0071) | Acc: (99.83%) (35907/35968)\n",
            "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0072) | Acc: (99.83%) (37186/37248)\n",
            "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0072) | Acc: (99.84%) (38465/38528)\n",
            "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0073) | Acc: (99.83%) (39741/39808)\n",
            "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0073) | Acc: (99.83%) (41018/41088)\n",
            "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0073) | Acc: (99.83%) (42298/42368)\n",
            "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0072) | Acc: (99.84%) (43577/43648)\n",
            "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0071) | Acc: (99.84%) (44855/44928)\n",
            "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0072) | Acc: (99.84%) (46132/46208)\n",
            "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0072) | Acc: (99.83%) (47408/47488)\n",
            "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0072) | Acc: (99.83%) (48685/48768)\n",
            "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0071) | Acc: (99.83%) (49916/50000)\n",
            "# TEST : Loss: (0.3388) | Acc: (92.71%) (9271/10000)\n",
            "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0027) | Acc: (100.00%) (128/128)\n",
            "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0064) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0054) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0052) | Acc: (99.96%) (5246/5248)\n",
            "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0051) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0058) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0062) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0063) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0061) | Acc: (99.91%) (14195/14208)\n",
            "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.91%) (15474/15488)\n",
            "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0059) | Acc: (99.92%) (16754/16768)\n",
            "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0059) | Acc: (99.92%) (18033/18048)\n",
            "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0059) | Acc: (99.92%) (19312/19328)\n",
            "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0059) | Acc: (99.91%) (20590/20608)\n",
            "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0060) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0059) | Acc: (99.91%) (23147/23168)\n",
            "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0060) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0061) | Acc: (99.90%) (25702/25728)\n",
            "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0063) | Acc: (99.89%) (26979/27008)\n",
            "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0062) | Acc: (99.89%) (28257/28288)\n",
            "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0063) | Acc: (99.89%) (29536/29568)\n",
            "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0062) | Acc: (99.90%) (30816/30848)\n",
            "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0061) | Acc: (99.90%) (32096/32128)\n",
            "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0061) | Acc: (99.90%) (33373/33408)\n",
            "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0063) | Acc: (99.89%) (34649/34688)\n",
            "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0063) | Acc: (99.89%) (35929/35968)\n",
            "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0063) | Acc: (99.90%) (37209/37248)\n",
            "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0064) | Acc: (99.89%) (38485/38528)\n",
            "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0064) | Acc: (99.89%) (39763/39808)\n",
            "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0064) | Acc: (99.89%) (41041/41088)\n",
            "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0064) | Acc: (99.89%) (42320/42368)\n",
            "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0063) | Acc: (99.89%) (43599/43648)\n",
            "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0064) | Acc: (99.88%) (44876/44928)\n",
            "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.88%) (46154/46208)\n",
            "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0064) | Acc: (99.88%) (47433/47488)\n",
            "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0065) | Acc: (99.88%) (48710/48768)\n",
            "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0065) | Acc: (99.88%) (49940/50000)\n",
            "# TEST : Loss: (0.3406) | Acc: (92.89%) (9289/10000)\n",
            "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (128/128)\n",
            "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0054) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0063) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0072) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0068) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0067) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0069) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0069) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0072) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0070) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0069) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0067) | Acc: (99.89%) (15471/15488)\n",
            "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0067) | Acc: (99.89%) (16750/16768)\n",
            "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0066) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0065) | Acc: (99.89%) (19306/19328)\n",
            "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0068) | Acc: (99.86%) (20580/20608)\n",
            "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0068) | Acc: (99.86%) (21857/21888)\n",
            "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.87%) (23137/23168)\n",
            "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0067) | Acc: (99.87%) (24416/24448)\n",
            "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0066) | Acc: (99.87%) (25694/25728)\n",
            "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0066) | Acc: (99.87%) (26972/27008)\n",
            "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0066) | Acc: (99.87%) (28251/28288)\n",
            "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0066) | Acc: (99.86%) (29528/29568)\n",
            "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0067) | Acc: (99.86%) (30805/30848)\n",
            "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.86%) (32082/32128)\n",
            "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0068) | Acc: (99.85%) (33359/33408)\n",
            "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0068) | Acc: (99.85%) (34636/34688)\n",
            "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0069) | Acc: (99.85%) (35913/35968)\n",
            "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0070) | Acc: (99.85%) (37191/37248)\n",
            "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0070) | Acc: (99.85%) (38469/38528)\n",
            "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0070) | Acc: (99.85%) (39747/39808)\n",
            "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0069) | Acc: (99.85%) (41026/41088)\n",
            "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0069) | Acc: (99.85%) (42304/42368)\n",
            "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0069) | Acc: (99.85%) (43583/43648)\n",
            "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0070) | Acc: (99.85%) (44859/44928)\n",
            "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0071) | Acc: (99.84%) (46134/46208)\n",
            "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0071) | Acc: (99.84%) (47410/47488)\n",
            "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0070) | Acc: (99.83%) (48687/48768)\n",
            "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0070) | Acc: (99.83%) (49916/50000)\n",
            "# TEST : Loss: (0.3413) | Acc: (92.75%) (9275/10000)\n",
            "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0068) | Acc: (100.00%) (128/128)\n",
            "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0043) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0048) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0052) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0047) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0047) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0045) | Acc: (99.94%) (7803/7808)\n",
            "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0049) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0048) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0048) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0052) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0054) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.89%) (19306/19328)\n",
            "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.89%) (20585/20608)\n",
            "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0059) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0059) | Acc: (99.89%) (23143/23168)\n",
            "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0060) | Acc: (99.88%) (24419/24448)\n",
            "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0062) | Acc: (99.88%) (25697/25728)\n",
            "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0062) | Acc: (99.88%) (26975/27008)\n",
            "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0063) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.86%) (29527/29568)\n",
            "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0063) | Acc: (99.87%) (30807/30848)\n",
            "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0063) | Acc: (99.87%) (32086/32128)\n",
            "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0064) | Acc: (99.87%) (33363/33408)\n",
            "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0064) | Acc: (99.86%) (34641/34688)\n",
            "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0064) | Acc: (99.87%) (35921/35968)\n",
            "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0063) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0063) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0063) | Acc: (99.87%) (39756/39808)\n",
            "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.87%) (41033/41088)\n",
            "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0062) | Acc: (99.87%) (42312/42368)\n",
            "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0062) | Acc: (99.87%) (43591/43648)\n",
            "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0062) | Acc: (99.87%) (44870/44928)\n",
            "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0063) | Acc: (99.87%) (46148/46208)\n",
            "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.87%) (47425/47488)\n",
            "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0064) | Acc: (99.87%) (48703/48768)\n",
            "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0064) | Acc: (99.87%) (49933/50000)\n",
            "# TEST : Loss: (0.3397) | Acc: (92.73%) (9273/10000)\n",
            "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0055) | Acc: (100.00%) (128/128)\n",
            "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0058) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0061) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0064) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0064) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0069) | Acc: (99.86%) (9075/9088)\n",
            "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0072) | Acc: (99.84%) (10351/10368)\n",
            "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0071) | Acc: (99.84%) (11629/11648)\n",
            "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0070) | Acc: (99.85%) (12908/12928)\n",
            "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0068) | Acc: (99.85%) (14187/14208)\n",
            "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0067) | Acc: (99.86%) (15466/15488)\n",
            "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0065) | Acc: (99.86%) (16745/16768)\n",
            "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0064) | Acc: (99.87%) (18024/18048)\n",
            "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0063) | Acc: (99.87%) (19303/19328)\n",
            "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0063) | Acc: (99.87%) (20582/20608)\n",
            "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0064) | Acc: (99.87%) (21859/21888)\n",
            "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0065) | Acc: (99.86%) (23135/23168)\n",
            "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0066) | Acc: (99.85%) (24412/24448)\n",
            "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0066) | Acc: (99.86%) (25691/25728)\n",
            "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.86%) (26969/27008)\n",
            "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0067) | Acc: (99.86%) (28247/28288)\n",
            "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0065) | Acc: (99.86%) (29526/29568)\n",
            "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.85%) (30802/30848)\n",
            "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.84%) (32078/32128)\n",
            "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.84%) (33356/33408)\n",
            "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.85%) (34635/34688)\n",
            "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0065) | Acc: (99.85%) (35915/35968)\n",
            "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.85%) (37193/37248)\n",
            "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0066) | Acc: (99.85%) (38470/38528)\n",
            "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0065) | Acc: (99.85%) (39749/39808)\n",
            "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0065) | Acc: (99.85%) (41028/41088)\n",
            "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0064) | Acc: (99.86%) (42307/42368)\n",
            "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0064) | Acc: (99.86%) (43585/43648)\n",
            "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0063) | Acc: (99.86%) (44865/44928)\n",
            "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.86%) (46142/46208)\n",
            "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0064) | Acc: (99.85%) (47419/47488)\n",
            "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0063) | Acc: (99.86%) (48699/48768)\n",
            "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0063) | Acc: (99.86%) (49929/50000)\n",
            "# TEST : Loss: (0.3393) | Acc: (92.81%) (9281/10000)\n",
            "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0027) | Acc: (100.00%) (128/128)\n",
            "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0081) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0080) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0077) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0073) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0077) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0075) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0076) | Acc: (99.86%) (9075/9088)\n",
            "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0076) | Acc: (99.86%) (10353/10368)\n",
            "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0075) | Acc: (99.85%) (11631/11648)\n",
            "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0076) | Acc: (99.85%) (12908/12928)\n",
            "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0075) | Acc: (99.84%) (14185/14208)\n",
            "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0074) | Acc: (99.83%) (15462/15488)\n",
            "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0072) | Acc: (99.84%) (16742/16768)\n",
            "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0071) | Acc: (99.85%) (18021/18048)\n",
            "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0072) | Acc: (99.86%) (19300/19328)\n",
            "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0071) | Acc: (99.85%) (20578/20608)\n",
            "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0070) | Acc: (99.86%) (21858/21888)\n",
            "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0069) | Acc: (99.87%) (23137/23168)\n",
            "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0068) | Acc: (99.87%) (24416/24448)\n",
            "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0067) | Acc: (99.86%) (25693/25728)\n",
            "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.87%) (26972/27008)\n",
            "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0068) | Acc: (99.87%) (28250/28288)\n",
            "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0068) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0068) | Acc: (99.87%) (30807/30848)\n",
            "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0069) | Acc: (99.86%) (32084/32128)\n",
            "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0069) | Acc: (99.86%) (33361/33408)\n",
            "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0071) | Acc: (99.85%) (34635/34688)\n",
            "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0070) | Acc: (99.85%) (35915/35968)\n",
            "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0070) | Acc: (99.85%) (37192/37248)\n",
            "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0069) | Acc: (99.85%) (38470/38528)\n",
            "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0069) | Acc: (99.85%) (39749/39808)\n",
            "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0069) | Acc: (99.85%) (41028/41088)\n",
            "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0068) | Acc: (99.86%) (42308/42368)\n",
            "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0068) | Acc: (99.86%) (43586/43648)\n",
            "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0068) | Acc: (99.86%) (44866/44928)\n",
            "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0068) | Acc: (99.86%) (46142/46208)\n",
            "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0068) | Acc: (99.85%) (47418/47488)\n",
            "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0068) | Acc: (99.85%) (48695/48768)\n",
            "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0068) | Acc: (99.85%) (49927/50000)\n",
            "# TEST : Loss: (0.3402) | Acc: (92.76%) (9276/10000)\n",
            "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0063) | Acc: (100.00%) (128/128)\n",
            "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0069) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0060) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0054) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0055) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0059) | Acc: (99.89%) (10357/10368)\n",
            "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0059) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0057) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0060) | Acc: (99.87%) (14190/14208)\n",
            "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0059) | Acc: (99.88%) (15469/15488)\n",
            "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.88%) (19305/19328)\n",
            "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.89%) (20585/20608)\n",
            "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0058) | Acc: (99.88%) (21862/21888)\n",
            "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0059) | Acc: (99.88%) (23140/23168)\n",
            "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0059) | Acc: (99.88%) (24419/24448)\n",
            "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0060) | Acc: (99.88%) (25696/25728)\n",
            "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0060) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0061) | Acc: (99.86%) (28249/28288)\n",
            "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0061) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.87%) (30808/30848)\n",
            "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0060) | Acc: (99.87%) (32086/32128)\n",
            "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.87%) (33366/33408)\n",
            "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0060) | Acc: (99.87%) (34642/34688)\n",
            "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0061) | Acc: (99.87%) (35920/35968)\n",
            "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0061) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0061) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0062) | Acc: (99.86%) (39753/39808)\n",
            "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.86%) (41031/41088)\n",
            "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0063) | Acc: (99.86%) (42309/42368)\n",
            "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0063) | Acc: (99.86%) (43588/43648)\n",
            "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0064) | Acc: (99.86%) (44865/44928)\n",
            "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.86%) (46143/46208)\n",
            "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.86%) (47423/47488)\n",
            "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0062) | Acc: (99.86%) (48702/48768)\n",
            "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0063) | Acc: (99.86%) (49932/50000)\n",
            "# TEST : Loss: (0.3421) | Acc: (92.82%) (9282/10000)\n",
            "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0061) | Acc: (100.00%) (128/128)\n",
            "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0065) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0061) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0065) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0056) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0054) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0058) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0064) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0065) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0066) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0063) | Acc: (99.87%) (14189/14208)\n",
            "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0062) | Acc: (99.87%) (15468/15488)\n",
            "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0061) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0061) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0060) | Acc: (99.88%) (19304/19328)\n",
            "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0059) | Acc: (99.88%) (20584/20608)\n",
            "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0059) | Acc: (99.88%) (21862/21888)\n",
            "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0060) | Acc: (99.87%) (23139/23168)\n",
            "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0061) | Acc: (99.87%) (24416/24448)\n",
            "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0060) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0060) | Acc: (99.87%) (26974/27008)\n",
            "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0060) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0060) | Acc: (99.87%) (29530/29568)\n",
            "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.87%) (30809/30848)\n",
            "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0060) | Acc: (99.88%) (32088/32128)\n",
            "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.87%) (33366/33408)\n",
            "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0060) | Acc: (99.87%) (34644/34688)\n",
            "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0060) | Acc: (99.87%) (35923/35968)\n",
            "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0060) | Acc: (99.88%) (37202/37248)\n",
            "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0060) | Acc: (99.88%) (38480/38528)\n",
            "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0059) | Acc: (99.88%) (39759/39808)\n",
            "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0059) | Acc: (99.88%) (41037/41088)\n",
            "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0060) | Acc: (99.87%) (42315/42368)\n",
            "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0060) | Acc: (99.87%) (43593/43648)\n",
            "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.87%) (44870/44928)\n",
            "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.87%) (46148/46208)\n",
            "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0060) | Acc: (99.87%) (47427/47488)\n",
            "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0060) | Acc: (99.87%) (48705/48768)\n",
            "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0061) | Acc: (99.87%) (49934/50000)\n",
            "# TEST : Loss: (0.3409) | Acc: (92.81%) (9281/10000)\n",
            "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0053) | Acc: (100.00%) (128/128)\n",
            "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0066) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0063) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0060) | Acc: (99.79%) (5237/5248)\n",
            "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0055) | Acc: (99.82%) (6516/6528)\n",
            "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0059) | Acc: (99.82%) (7794/7808)\n",
            "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0064) | Acc: (99.79%) (9069/9088)\n",
            "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0063) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.83%) (11628/11648)\n",
            "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.82%) (12905/12928)\n",
            "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0060) | Acc: (99.84%) (14185/14208)\n",
            "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.85%) (15465/15488)\n",
            "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.86%) (16745/16768)\n",
            "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0060) | Acc: (99.86%) (18023/18048)\n",
            "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.87%) (20582/20608)\n",
            "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0058) | Acc: (99.87%) (21860/21888)\n",
            "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0057) | Acc: (99.87%) (23139/23168)\n",
            "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0057) | Acc: (99.87%) (24417/24448)\n",
            "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.87%) (25694/25728)\n",
            "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.87%) (26974/27008)\n",
            "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.88%) (28253/28288)\n",
            "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.87%) (29531/29568)\n",
            "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0057) | Acc: (99.88%) (30811/30848)\n",
            "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0057) | Acc: (99.88%) (32090/32128)\n",
            "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0058) | Acc: (99.88%) (33367/33408)\n",
            "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.88%) (34645/34688)\n",
            "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.87%) (35921/35968)\n",
            "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0062) | Acc: (99.86%) (37196/37248)\n",
            "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0062) | Acc: (99.86%) (38474/38528)\n",
            "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0061) | Acc: (99.86%) (39754/39808)\n",
            "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0061) | Acc: (99.87%) (41033/41088)\n",
            "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0062) | Acc: (99.87%) (42311/42368)\n",
            "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0063) | Acc: (99.86%) (43589/43648)\n",
            "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0062) | Acc: (99.86%) (44866/44928)\n",
            "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0063) | Acc: (99.86%) (46141/46208)\n",
            "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.86%) (47421/47488)\n",
            "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0063) | Acc: (99.86%) (48699/48768)\n",
            "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0064) | Acc: (99.86%) (49928/50000)\n",
            "# TEST : Loss: (0.3413) | Acc: (92.75%) (9275/10000)\n",
            "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0045) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0047) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0047) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0051) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0052) | Acc: (99.93%) (9082/9088)\n",
            "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0053) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0055) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0054) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0057) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0059) | Acc: (99.89%) (16750/16768)\n",
            "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0060) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0059) | Acc: (99.90%) (19309/19328)\n",
            "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0062) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0062) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0063) | Acc: (99.87%) (23139/23168)\n",
            "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0064) | Acc: (99.87%) (24417/24448)\n",
            "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0063) | Acc: (99.88%) (25696/25728)\n",
            "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0062) | Acc: (99.88%) (26975/27008)\n",
            "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0063) | Acc: (99.87%) (28251/28288)\n",
            "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0063) | Acc: (99.87%) (29531/29568)\n",
            "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0064) | Acc: (99.87%) (30807/30848)\n",
            "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0065) | Acc: (99.86%) (32083/32128)\n",
            "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.86%) (33360/33408)\n",
            "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.85%) (34637/34688)\n",
            "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0066) | Acc: (99.86%) (35916/35968)\n",
            "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.86%) (37194/37248)\n",
            "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0065) | Acc: (99.85%) (38472/38528)\n",
            "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0064) | Acc: (99.86%) (39751/39808)\n",
            "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0064) | Acc: (99.86%) (41029/41088)\n",
            "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0065) | Acc: (99.85%) (42306/42368)\n",
            "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0064) | Acc: (99.86%) (43586/43648)\n",
            "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0063) | Acc: (99.86%) (44866/44928)\n",
            "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0063) | Acc: (99.86%) (46142/46208)\n",
            "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.86%) (47422/47488)\n",
            "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0062) | Acc: (99.86%) (48702/48768)\n",
            "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0063) | Acc: (99.86%) (49931/50000)\n",
            "# TEST : Loss: (0.3382) | Acc: (92.79%) (9279/10000)\n",
            "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0029) | Acc: (100.00%) (128/128)\n",
            "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0061) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0065) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0059) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0065) | Acc: (99.79%) (5237/5248)\n",
            "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.83%) (6517/6528)\n",
            "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0060) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0057) | Acc: (99.86%) (9075/9088)\n",
            "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0058) | Acc: (99.86%) (10353/10368)\n",
            "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0057) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0059) | Acc: (99.85%) (14187/14208)\n",
            "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.86%) (15467/15488)\n",
            "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.86%) (16745/16768)\n",
            "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.87%) (18024/18048)\n",
            "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0057) | Acc: (99.87%) (20581/20608)\n",
            "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0056) | Acc: (99.87%) (21860/21888)\n",
            "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.87%) (23138/23168)\n",
            "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0057) | Acc: (99.87%) (24417/24448)\n",
            "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0058) | Acc: (99.86%) (25693/25728)\n",
            "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0057) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0056) | Acc: (99.88%) (28253/28288)\n",
            "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0056) | Acc: (99.88%) (29533/29568)\n",
            "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.89%) (30813/30848)\n",
            "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0057) | Acc: (99.88%) (32089/32128)\n",
            "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.87%) (33365/33408)\n",
            "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.87%) (34643/34688)\n",
            "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0060) | Acc: (99.87%) (35920/35968)\n",
            "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0060) | Acc: (99.87%) (37198/37248)\n",
            "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0062) | Acc: (99.85%) (38472/38528)\n",
            "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0062) | Acc: (99.86%) (39751/39808)\n",
            "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0061) | Acc: (99.86%) (41030/41088)\n",
            "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0062) | Acc: (99.86%) (42308/42368)\n",
            "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0061) | Acc: (99.86%) (43588/43648)\n",
            "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0062) | Acc: (99.86%) (44865/44928)\n",
            "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0062) | Acc: (99.86%) (46144/46208)\n",
            "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0062) | Acc: (99.86%) (47423/47488)\n",
            "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0062) | Acc: (99.86%) (48702/48768)\n",
            "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0062) | Acc: (99.86%) (49932/50000)\n",
            "# TEST : Loss: (0.3402) | Acc: (92.88%) (9288/10000)\n",
            "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0076) | Acc: (100.00%) (128/128)\n",
            "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0078) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0059) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0060) | Acc: (99.92%) (5244/5248)\n",
            "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0058) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0066) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0064) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.89%) (10357/10368)\n",
            "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0059) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0065) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0063) | Acc: (99.88%) (18027/18048)\n",
            "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0064) | Acc: (99.88%) (19305/19328)\n",
            "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0064) | Acc: (99.88%) (20583/20608)\n",
            "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0062) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0061) | Acc: (99.88%) (23141/23168)\n",
            "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0060) | Acc: (99.89%) (24420/24448)\n",
            "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0062) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0063) | Acc: (99.86%) (26971/27008)\n",
            "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0062) | Acc: (99.87%) (28250/28288)\n",
            "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0060) | Acc: (99.87%) (29530/29568)\n",
            "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0062) | Acc: (99.86%) (30806/30848)\n",
            "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0065) | Acc: (99.85%) (32081/32128)\n",
            "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0064) | Acc: (99.86%) (33360/33408)\n",
            "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0065) | Acc: (99.85%) (34636/34688)\n",
            "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0064) | Acc: (99.85%) (35915/35968)\n",
            "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0065) | Acc: (99.86%) (37194/37248)\n",
            "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0066) | Acc: (99.85%) (38470/38528)\n",
            "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0066) | Acc: (99.85%) (39749/39808)\n",
            "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0066) | Acc: (99.85%) (41028/41088)\n",
            "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0066) | Acc: (99.86%) (42307/42368)\n",
            "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0065) | Acc: (99.86%) (43587/43648)\n",
            "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0066) | Acc: (99.86%) (44864/44928)\n",
            "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0066) | Acc: (99.86%) (46142/46208)\n",
            "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0066) | Acc: (99.85%) (47419/47488)\n",
            "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0066) | Acc: (99.86%) (48698/48768)\n",
            "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0066) | Acc: (99.86%) (49930/50000)\n",
            "# TEST : Loss: (0.3423) | Acc: (92.74%) (9274/10000)\n",
            "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0037) | Acc: (100.00%) (128/128)\n",
            "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0072) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0070) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0059) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0063) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0062) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0060) | Acc: (99.86%) (9075/9088)\n",
            "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0063) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0061) | Acc: (99.85%) (11631/11648)\n",
            "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.85%) (12908/12928)\n",
            "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0060) | Acc: (99.85%) (14187/14208)\n",
            "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0060) | Acc: (99.86%) (15466/15488)\n",
            "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.87%) (16746/16768)\n",
            "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0058) | Acc: (99.87%) (18025/18048)\n",
            "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0057) | Acc: (99.87%) (20582/20608)\n",
            "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.87%) (21860/21888)\n",
            "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0060) | Acc: (99.87%) (23137/23168)\n",
            "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0061) | Acc: (99.86%) (24414/24448)\n",
            "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0061) | Acc: (99.86%) (25693/25728)\n",
            "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0061) | Acc: (99.86%) (26971/27008)\n",
            "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0061) | Acc: (99.86%) (28249/28288)\n",
            "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0061) | Acc: (99.86%) (29527/29568)\n",
            "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.86%) (30806/30848)\n",
            "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0059) | Acc: (99.87%) (32086/32128)\n",
            "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.87%) (33364/33408)\n",
            "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.87%) (34642/34688)\n",
            "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.87%) (35920/35968)\n",
            "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0059) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0059) | Acc: (99.87%) (38477/38528)\n",
            "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0058) | Acc: (99.87%) (39757/39808)\n",
            "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0058) | Acc: (99.87%) (41035/41088)\n",
            "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0057) | Acc: (99.87%) (42315/42368)\n",
            "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0058) | Acc: (99.87%) (43593/43648)\n",
            "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0058) | Acc: (99.87%) (44871/44928)\n",
            "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0058) | Acc: (99.87%) (46150/46208)\n",
            "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0058) | Acc: (99.88%) (47429/47488)\n",
            "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0058) | Acc: (99.87%) (48707/48768)\n",
            "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.87%) (49937/50000)\n",
            "# TEST : Loss: (0.3406) | Acc: (92.78%) (9278/10000)\n",
            "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0011) | Acc: (100.00%) (128/128)\n",
            "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0070) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0098) | Acc: (99.74%) (2681/2688)\n",
            "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0086) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0082) | Acc: (99.75%) (5235/5248)\n",
            "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0076) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0070) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0077) | Acc: (99.78%) (9068/9088)\n",
            "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0077) | Acc: (99.78%) (10345/10368)\n",
            "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0073) | Acc: (99.79%) (11624/11648)\n",
            "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0070) | Acc: (99.81%) (12904/12928)\n",
            "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0069) | Acc: (99.82%) (14183/14208)\n",
            "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0071) | Acc: (99.82%) (15460/15488)\n",
            "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0070) | Acc: (99.82%) (16738/16768)\n",
            "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0069) | Acc: (99.83%) (18017/18048)\n",
            "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0069) | Acc: (99.83%) (19295/19328)\n",
            "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0068) | Acc: (99.84%) (20574/20608)\n",
            "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0067) | Acc: (99.84%) (21853/21888)\n",
            "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0067) | Acc: (99.83%) (23129/23168)\n",
            "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0068) | Acc: (99.83%) (24406/24448)\n",
            "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0066) | Acc: (99.84%) (25686/25728)\n",
            "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0067) | Acc: (99.82%) (26960/27008)\n",
            "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0068) | Acc: (99.82%) (28238/28288)\n",
            "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0067) | Acc: (99.83%) (29517/29568)\n",
            "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0067) | Acc: (99.82%) (30793/30848)\n",
            "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0069) | Acc: (99.82%) (32070/32128)\n",
            "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0068) | Acc: (99.82%) (33349/33408)\n",
            "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0069) | Acc: (99.82%) (34626/34688)\n",
            "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0069) | Acc: (99.82%) (35905/35968)\n",
            "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0068) | Acc: (99.83%) (37184/37248)\n",
            "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0067) | Acc: (99.83%) (38462/38528)\n",
            "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0067) | Acc: (99.83%) (39741/39808)\n",
            "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0067) | Acc: (99.84%) (41021/41088)\n",
            "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0066) | Acc: (99.84%) (42300/42368)\n",
            "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0065) | Acc: (99.84%) (43580/43648)\n",
            "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0065) | Acc: (99.84%) (44858/44928)\n",
            "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0064) | Acc: (99.85%) (46138/46208)\n",
            "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0064) | Acc: (99.85%) (47417/47488)\n",
            "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0064) | Acc: (99.85%) (48696/48768)\n",
            "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0064) | Acc: (99.85%) (49927/50000)\n",
            "# TEST : Loss: (0.3411) | Acc: (92.70%) (9270/10000)\n",
            "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0035) | Acc: (100.00%) (128/128)\n",
            "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0032) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0051) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0060) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0058) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0060) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0054) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0052) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0056) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0056) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0054) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0056) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.88%) (20584/20608)\n",
            "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0056) | Acc: (99.89%) (21864/21888)\n",
            "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.88%) (23141/23168)\n",
            "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.89%) (24420/24448)\n",
            "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0058) | Acc: (99.88%) (25698/25728)\n",
            "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0057) | Acc: (99.89%) (26978/27008)\n",
            "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.88%) (28255/28288)\n",
            "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.88%) (29532/29568)\n",
            "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.88%) (30810/30848)\n",
            "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0059) | Acc: (99.87%) (32086/32128)\n",
            "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.87%) (33364/33408)\n",
            "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.87%) (34644/34688)\n",
            "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0060) | Acc: (99.87%) (35923/35968)\n",
            "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0060) | Acc: (99.87%) (37201/37248)\n",
            "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0062) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0062) | Acc: (99.87%) (39757/39808)\n",
            "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0061) | Acc: (99.87%) (41036/41088)\n",
            "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0061) | Acc: (99.88%) (42316/42368)\n",
            "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0061) | Acc: (99.87%) (43592/43648)\n",
            "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0061) | Acc: (99.87%) (44871/44928)\n",
            "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0061) | Acc: (99.87%) (46149/46208)\n",
            "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0061) | Acc: (99.87%) (47426/47488)\n",
            "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0061) | Acc: (99.87%) (48705/48768)\n",
            "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0061) | Acc: (99.87%) (49934/50000)\n",
            "# TEST : Loss: (0.3400) | Acc: (92.84%) (9284/10000)\n",
            "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0048) | Acc: (100.00%) (128/128)\n",
            "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0078) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0069) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0057) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0056) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0057) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0056) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0056) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0058) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0057) | Acc: (99.91%) (14195/14208)\n",
            "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.91%) (15474/15488)\n",
            "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0057) | Acc: (99.90%) (16752/16768)\n",
            "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.91%) (18032/18048)\n",
            "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.91%) (19311/19328)\n",
            "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0058) | Acc: (99.89%) (21865/21888)\n",
            "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.90%) (23144/23168)\n",
            "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.89%) (24421/24448)\n",
            "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0058) | Acc: (99.90%) (25701/25728)\n",
            "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0059) | Acc: (99.89%) (26979/27008)\n",
            "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0060) | Acc: (99.89%) (28256/28288)\n",
            "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0061) | Acc: (99.88%) (29533/29568)\n",
            "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0063) | Acc: (99.88%) (30810/30848)\n",
            "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0062) | Acc: (99.88%) (32090/32128)\n",
            "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0061) | Acc: (99.88%) (33367/33408)\n",
            "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0063) | Acc: (99.87%) (34643/34688)\n",
            "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0063) | Acc: (99.87%) (35921/35968)\n",
            "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0063) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0063) | Acc: (99.87%) (38477/38528)\n",
            "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0063) | Acc: (99.87%) (39755/39808)\n",
            "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0063) | Acc: (99.86%) (41032/41088)\n",
            "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0063) | Acc: (99.86%) (42310/42368)\n",
            "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0064) | Acc: (99.86%) (43588/43648)\n",
            "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0063) | Acc: (99.87%) (44868/44928)\n",
            "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0063) | Acc: (99.87%) (46146/46208)\n",
            "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0063) | Acc: (99.87%) (47424/47488)\n",
            "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0063) | Acc: (99.86%) (48702/48768)\n",
            "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0063) | Acc: (99.86%) (49932/50000)\n",
            "# TEST : Loss: (0.3403) | Acc: (92.85%) (9285/10000)\n",
            "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0087) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0067) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0060) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0071) | Acc: (99.83%) (5239/5248)\n",
            "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0068) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0068) | Acc: (99.85%) (7796/7808)\n",
            "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0065) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0063) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0061) | Acc: (99.88%) (12912/12928)\n",
            "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0061) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0061) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0061) | Acc: (99.87%) (16747/16768)\n",
            "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0061) | Acc: (99.87%) (18025/18048)\n",
            "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0061) | Acc: (99.87%) (19303/19328)\n",
            "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0061) | Acc: (99.87%) (20582/20608)\n",
            "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0061) | Acc: (99.87%) (21859/21888)\n",
            "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0061) | Acc: (99.86%) (23136/23168)\n",
            "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0062) | Acc: (99.86%) (24413/24448)\n",
            "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0062) | Acc: (99.86%) (25693/25728)\n",
            "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.86%) (26970/27008)\n",
            "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0064) | Acc: (99.87%) (28250/28288)\n",
            "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0064) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0066) | Acc: (99.87%) (30807/30848)\n",
            "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0067) | Acc: (99.86%) (32083/32128)\n",
            "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0066) | Acc: (99.86%) (33361/33408)\n",
            "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0066) | Acc: (99.86%) (34639/34688)\n",
            "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0066) | Acc: (99.85%) (35915/35968)\n",
            "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0066) | Acc: (99.85%) (37193/37248)\n",
            "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0066) | Acc: (99.85%) (38472/38528)\n",
            "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0066) | Acc: (99.85%) (39750/39808)\n",
            "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0066) | Acc: (99.85%) (41028/41088)\n",
            "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0068) | Acc: (99.84%) (42302/42368)\n",
            "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0067) | Acc: (99.85%) (43581/43648)\n",
            "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0066) | Acc: (99.85%) (44860/44928)\n",
            "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0067) | Acc: (99.84%) (46136/46208)\n",
            "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0067) | Acc: (99.84%) (47414/47488)\n",
            "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0066) | Acc: (99.85%) (48694/48768)\n",
            "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0066) | Acc: (99.85%) (49924/50000)\n",
            "# TEST : Loss: (0.3412) | Acc: (92.80%) (9280/10000)\n",
            "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0009) | Acc: (100.00%) (128/128)\n",
            "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0064) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0049) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0048) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0049) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0054) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0057) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0056) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0057) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0059) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.89%) (19306/19328)\n",
            "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0057) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.89%) (21864/21888)\n",
            "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0057) | Acc: (99.89%) (23143/23168)\n",
            "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.89%) (24422/24448)\n",
            "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0058) | Acc: (99.89%) (25699/25728)\n",
            "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0057) | Acc: (99.89%) (26979/27008)\n",
            "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.89%) (28257/28288)\n",
            "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.89%) (29535/29568)\n",
            "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.89%) (30813/30848)\n",
            "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0060) | Acc: (99.87%) (32087/32128)\n",
            "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.87%) (33366/33408)\n",
            "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.88%) (34645/34688)\n",
            "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0060) | Acc: (99.87%) (35923/35968)\n",
            "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0060) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0059) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0059) | Acc: (99.87%) (39756/39808)\n",
            "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0060) | Acc: (99.87%) (41033/41088)\n",
            "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0060) | Acc: (99.86%) (42310/42368)\n",
            "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0060) | Acc: (99.86%) (43589/43648)\n",
            "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.87%) (44868/44928)\n",
            "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.87%) (46146/46208)\n",
            "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0060) | Acc: (99.86%) (47421/47488)\n",
            "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0060) | Acc: (99.86%) (48700/48768)\n",
            "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0060) | Acc: (99.86%) (49932/50000)\n",
            "# TEST : Loss: (0.3425) | Acc: (92.69%) (9269/10000)\n",
            "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0081) | Acc: (100.00%) (128/128)\n",
            "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0051) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0077) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0085) | Acc: (99.77%) (3959/3968)\n",
            "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0077) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0071) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0066) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0063) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0063) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0061) | Acc: (99.88%) (11634/11648)\n",
            "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0058) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0059) | Acc: (99.87%) (14190/14208)\n",
            "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0059) | Acc: (99.88%) (15469/15488)\n",
            "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.88%) (16748/16768)\n",
            "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.88%) (18027/18048)\n",
            "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.89%) (19306/19328)\n",
            "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0055) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0056) | Acc: (99.89%) (21864/21888)\n",
            "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.89%) (23142/23168)\n",
            "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.89%) (24421/24448)\n",
            "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.90%) (25701/25728)\n",
            "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0054) | Acc: (99.90%) (26981/27008)\n",
            "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0055) | Acc: (99.89%) (28258/28288)\n",
            "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.89%) (29536/29568)\n",
            "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.89%) (30815/30848)\n",
            "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0055) | Acc: (99.89%) (32094/32128)\n",
            "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.90%) (33374/33408)\n",
            "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0055) | Acc: (99.90%) (34652/34688)\n",
            "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.89%) (35930/35968)\n",
            "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.90%) (37209/37248)\n",
            "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0055) | Acc: (99.90%) (38489/38528)\n",
            "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0055) | Acc: (99.89%) (39766/39808)\n",
            "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0055) | Acc: (99.89%) (41042/41088)\n",
            "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.89%) (42321/42368)\n",
            "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0057) | Acc: (99.88%) (43595/43648)\n",
            "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0057) | Acc: (99.88%) (44874/44928)\n",
            "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0057) | Acc: (99.88%) (46153/46208)\n",
            "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0056) | Acc: (99.88%) (47433/47488)\n",
            "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0057) | Acc: (99.88%) (48709/48768)\n",
            "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0057) | Acc: (99.88%) (49940/50000)\n",
            "# TEST : Loss: (0.3426) | Acc: (92.84%) (9284/10000)\n",
            "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0064) | Acc: (99.22%) (127/128)\n",
            "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0083) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0093) | Acc: (99.78%) (2682/2688)\n",
            "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0080) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0072) | Acc: (99.83%) (5239/5248)\n",
            "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0067) | Acc: (99.85%) (9074/9088)\n",
            "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0065) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0062) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.88%) (12912/12928)\n",
            "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0057) | Acc: (99.89%) (16749/16768)\n",
            "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0056) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.90%) (20587/20608)\n",
            "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.90%) (21866/21888)\n",
            "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0054) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0053) | Acc: (99.91%) (26983/27008)\n",
            "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.91%) (28262/28288)\n",
            "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0053) | Acc: (99.91%) (29541/29568)\n",
            "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0053) | Acc: (99.91%) (30820/30848)\n",
            "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0055) | Acc: (99.90%) (32095/32128)\n",
            "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.90%) (33375/33408)\n",
            "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0055) | Acc: (99.90%) (34653/34688)\n",
            "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0056) | Acc: (99.90%) (35931/35968)\n",
            "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0056) | Acc: (99.89%) (37208/37248)\n",
            "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.89%) (38485/38528)\n",
            "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0056) | Acc: (99.89%) (39764/39808)\n",
            "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0055) | Acc: (99.89%) (41044/41088)\n",
            "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.89%) (42323/42368)\n",
            "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.89%) (43601/43648)\n",
            "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0057) | Acc: (99.89%) (44879/44928)\n",
            "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0057) | Acc: (99.89%) (46158/46208)\n",
            "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0057) | Acc: (99.89%) (47435/47488)\n",
            "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0057) | Acc: (99.89%) (48714/48768)\n",
            "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0057) | Acc: (99.89%) (49946/50000)\n",
            "# TEST : Loss: (0.3442) | Acc: (92.91%) (9291/10000)\n",
            "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0072) | Acc: (100.00%) (128/128)\n",
            "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0054) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0050) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0045) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0044) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0049) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0052) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0052) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0050) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.90%) (11636/11648)\n",
            "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0053) | Acc: (99.88%) (12913/12928)\n",
            "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0056) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0055) | Acc: (99.89%) (16749/16768)\n",
            "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0058) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0057) | Acc: (99.87%) (20581/20608)\n",
            "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0057) | Acc: (99.87%) (21860/21888)\n",
            "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0056) | Acc: (99.87%) (23139/23168)\n",
            "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.87%) (24417/24448)\n",
            "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0057) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0057) | Acc: (99.87%) (26972/27008)\n",
            "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.86%) (30805/30848)\n",
            "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.86%) (32084/32128)\n",
            "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.86%) (33362/33408)\n",
            "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0060) | Acc: (99.86%) (34638/34688)\n",
            "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.86%) (35918/35968)\n",
            "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0059) | Acc: (99.86%) (37197/37248)\n",
            "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0058) | Acc: (99.87%) (38477/38528)\n",
            "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0058) | Acc: (99.87%) (39756/39808)\n",
            "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0058) | Acc: (99.87%) (41033/41088)\n",
            "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0058) | Acc: (99.86%) (42309/42368)\n",
            "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0059) | Acc: (99.86%) (43587/43648)\n",
            "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0060) | Acc: (99.85%) (44861/44928)\n",
            "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0060) | Acc: (99.85%) (46140/46208)\n",
            "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0061) | Acc: (99.85%) (47418/47488)\n",
            "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0060) | Acc: (99.85%) (48697/48768)\n",
            "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0061) | Acc: (99.86%) (49929/50000)\n",
            "# TEST : Loss: (0.3431) | Acc: (92.95%) (9295/10000)\n",
            "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0135) | Acc: (99.22%) (127/128)\n",
            "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0065) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0055) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0047) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0047) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0051) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0050) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0049) | Acc: (99.89%) (10357/10368)\n",
            "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0051) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0052) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0049) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0052) | Acc: (99.89%) (16749/16768)\n",
            "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0053) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0052) | Acc: (99.89%) (19307/19328)\n",
            "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0052) | Acc: (99.89%) (20585/20608)\n",
            "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.88%) (21862/21888)\n",
            "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.88%) (23141/23168)\n",
            "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.89%) (24421/24448)\n",
            "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.89%) (25699/25728)\n",
            "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0054) | Acc: (99.89%) (26979/27008)\n",
            "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0055) | Acc: (99.89%) (28257/28288)\n",
            "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0053) | Acc: (99.90%) (29537/29568)\n",
            "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0052) | Acc: (99.90%) (30817/30848)\n",
            "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.90%) (32095/32128)\n",
            "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.90%) (33373/33408)\n",
            "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0054) | Acc: (99.89%) (34651/34688)\n",
            "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.90%) (35931/35968)\n",
            "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.90%) (37209/37248)\n",
            "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.89%) (38486/38528)\n",
            "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.89%) (39765/39808)\n",
            "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.89%) (41044/41088)\n",
            "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.90%) (42324/42368)\n",
            "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0054) | Acc: (99.89%) (43599/43648)\n",
            "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0055) | Acc: (99.88%) (44875/44928)\n",
            "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0056) | Acc: (99.88%) (46151/46208)\n",
            "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.88%) (47431/47488)\n",
            "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.88%) (48710/48768)\n",
            "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0056) | Acc: (99.88%) (49939/50000)\n",
            "# TEST : Loss: (0.3432) | Acc: (92.95%) (9295/10000)\n",
            "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0195) | Acc: (98.44%) (126/128)\n",
            "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0108) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0081) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0075) | Acc: (99.75%) (3958/3968)\n",
            "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0075) | Acc: (99.77%) (5236/5248)\n",
            "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0073) | Acc: (99.80%) (6515/6528)\n",
            "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0069) | Acc: (99.81%) (7793/7808)\n",
            "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0065) | Acc: (99.81%) (9071/9088)\n",
            "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0065) | Acc: (99.81%) (10348/10368)\n",
            "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0065) | Acc: (99.81%) (11626/11648)\n",
            "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0067) | Acc: (99.81%) (12904/12928)\n",
            "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0063) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0063) | Acc: (99.83%) (15462/15488)\n",
            "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0063) | Acc: (99.83%) (16740/16768)\n",
            "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0062) | Acc: (99.83%) (18018/18048)\n",
            "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0061) | Acc: (99.84%) (19298/19328)\n",
            "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0060) | Acc: (99.84%) (20576/20608)\n",
            "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0059) | Acc: (99.85%) (21856/21888)\n",
            "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0059) | Acc: (99.86%) (23136/23168)\n",
            "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.87%) (24415/24448)\n",
            "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0057) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0056) | Acc: (99.87%) (26974/27008)\n",
            "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.87%) (29530/29568)\n",
            "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0057) | Acc: (99.87%) (30809/30848)\n",
            "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.87%) (32087/32128)\n",
            "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0060) | Acc: (99.87%) (33365/33408)\n",
            "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0060) | Acc: (99.87%) (34643/34688)\n",
            "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.87%) (35922/35968)\n",
            "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0058) | Acc: (99.88%) (37202/37248)\n",
            "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0058) | Acc: (99.88%) (38481/38528)\n",
            "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0057) | Acc: (99.88%) (39760/39808)\n",
            "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0058) | Acc: (99.88%) (41039/41088)\n",
            "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0059) | Acc: (99.87%) (42313/42368)\n",
            "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0059) | Acc: (99.87%) (43591/43648)\n",
            "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0059) | Acc: (99.87%) (44871/44928)\n",
            "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0059) | Acc: (99.87%) (46147/46208)\n",
            "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0059) | Acc: (99.87%) (47427/47488)\n",
            "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0059) | Acc: (99.87%) (48704/48768)\n",
            "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0059) | Acc: (99.87%) (49936/50000)\n",
            "# TEST : Loss: (0.3444) | Acc: (92.88%) (9288/10000)\n",
            "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0068) | Acc: (100.00%) (128/128)\n",
            "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0073) | Acc: (99.81%) (2683/2688)\n",
            "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0064) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0066) | Acc: (99.83%) (5239/5248)\n",
            "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0062) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0059) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0058) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0057) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0058) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0062) | Acc: (99.87%) (12911/12928)\n",
            "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0061) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0059) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0059) | Acc: (99.89%) (16749/16768)\n",
            "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0060) | Acc: (99.88%) (18026/18048)\n",
            "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0060) | Acc: (99.87%) (19303/19328)\n",
            "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0060) | Acc: (99.86%) (20580/20608)\n",
            "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0060) | Acc: (99.87%) (21859/21888)\n",
            "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0061) | Acc: (99.86%) (23136/23168)\n",
            "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0061) | Acc: (99.87%) (24415/24448)\n",
            "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.87%) (26974/27008)\n",
            "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0059) | Acc: (99.87%) (28252/28288)\n",
            "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0059) | Acc: (99.87%) (29531/29568)\n",
            "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0060) | Acc: (99.87%) (30808/30848)\n",
            "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0059) | Acc: (99.88%) (32088/32128)\n",
            "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.88%) (33367/33408)\n",
            "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.88%) (34645/34688)\n",
            "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.88%) (35924/35968)\n",
            "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0060) | Acc: (99.87%) (37201/37248)\n",
            "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0059) | Acc: (99.88%) (38481/38528)\n",
            "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0059) | Acc: (99.88%) (39760/39808)\n",
            "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0059) | Acc: (99.88%) (41039/41088)\n",
            "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0059) | Acc: (99.88%) (42316/42368)\n",
            "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0058) | Acc: (99.88%) (43596/43648)\n",
            "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0059) | Acc: (99.88%) (44872/44928)\n",
            "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0059) | Acc: (99.88%) (46151/46208)\n",
            "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0059) | Acc: (99.88%) (47429/47488)\n",
            "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0058) | Acc: (99.88%) (48709/48768)\n",
            "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0058) | Acc: (99.88%) (49939/50000)\n",
            "# TEST : Loss: (0.3433) | Acc: (92.85%) (9285/10000)\n",
            "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0035) | Acc: (100.00%) (128/128)\n",
            "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0048) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0056) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0050) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0044) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0044) | Acc: (99.94%) (6524/6528)\n",
            "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0050) | Acc: (99.91%) (7801/7808)\n",
            "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0051) | Acc: (99.90%) (9079/9088)\n",
            "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0049) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.91%) (11638/11648)\n",
            "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0053) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0051) | Acc: (99.91%) (14195/14208)\n",
            "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0051) | Acc: (99.91%) (15474/15488)\n",
            "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.89%) (16750/16768)\n",
            "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0054) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0053) | Acc: (99.89%) (19307/19328)\n",
            "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.89%) (21865/21888)\n",
            "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.88%) (23140/23168)\n",
            "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.88%) (24418/24448)\n",
            "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0057) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.88%) (28253/28288)\n",
            "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.87%) (29531/29568)\n",
            "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.87%) (30809/30848)\n",
            "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0057) | Acc: (99.87%) (32087/32128)\n",
            "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0057) | Acc: (99.87%) (33366/33408)\n",
            "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0057) | Acc: (99.88%) (34645/34688)\n",
            "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0056) | Acc: (99.88%) (35925/35968)\n",
            "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.88%) (37205/37248)\n",
            "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.88%) (38482/38528)\n",
            "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0056) | Acc: (99.88%) (39761/39808)\n",
            "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.88%) (41038/41088)\n",
            "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0056) | Acc: (99.88%) (42317/42368)\n",
            "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0056) | Acc: (99.88%) (43595/43648)\n",
            "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0056) | Acc: (99.88%) (44875/44928)\n",
            "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.89%) (46155/46208)\n",
            "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.88%) (47432/47488)\n",
            "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.88%) (48711/48768)\n",
            "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.88%) (49942/50000)\n",
            "# TEST : Loss: (0.3437) | Acc: (92.97%) (9297/10000)\n",
            "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0044) | Acc: (100.00%) (128/128)\n",
            "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0050) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0050) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0050) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0056) | Acc: (99.86%) (6519/6528)\n",
            "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0051) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0053) | Acc: (99.87%) (14190/14208)\n",
            "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0054) | Acc: (99.89%) (16750/16768)\n",
            "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0054) | Acc: (99.88%) (18027/18048)\n",
            "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0054) | Acc: (99.89%) (19306/19328)\n",
            "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.89%) (20585/20608)\n",
            "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.89%) (21863/21888)\n",
            "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.89%) (23142/23168)\n",
            "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0056) | Acc: (99.89%) (24420/24448)\n",
            "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.88%) (25697/25728)\n",
            "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0059) | Acc: (99.88%) (26976/27008)\n",
            "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.89%) (28256/28288)\n",
            "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.89%) (29535/29568)\n",
            "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0056) | Acc: (99.89%) (30815/30848)\n",
            "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0055) | Acc: (99.89%) (32094/32128)\n",
            "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0055) | Acc: (99.90%) (33373/33408)\n",
            "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0054) | Acc: (99.90%) (34653/34688)\n",
            "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.90%) (35933/35968)\n",
            "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.90%) (37212/37248)\n",
            "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0054) | Acc: (99.90%) (38488/38528)\n",
            "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0054) | Acc: (99.90%) (39768/39808)\n",
            "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.90%) (41046/41088)\n",
            "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.90%) (42326/42368)\n",
            "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0053) | Acc: (99.90%) (43604/43648)\n",
            "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0053) | Acc: (99.90%) (44882/44928)\n",
            "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0053) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.90%) (47441/47488)\n",
            "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.90%) (48719/48768)\n",
            "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.90%) (49950/50000)\n",
            "# TEST : Loss: (0.3431) | Acc: (92.88%) (9288/10000)\n",
            "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0027) | Acc: (100.00%) (128/128)\n",
            "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0047) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0054) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0056) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0057) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.88%) (9077/9088)\n",
            "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0057) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0058) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.88%) (12912/12928)\n",
            "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.87%) (14189/14208)\n",
            "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0062) | Acc: (99.85%) (15465/15488)\n",
            "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0060) | Acc: (99.86%) (16744/16768)\n",
            "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0061) | Acc: (99.86%) (18022/18048)\n",
            "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0060) | Acc: (99.86%) (19301/19328)\n",
            "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0060) | Acc: (99.84%) (20576/20608)\n",
            "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0060) | Acc: (99.85%) (21855/21888)\n",
            "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0059) | Acc: (99.85%) (23134/23168)\n",
            "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.86%) (24413/24448)\n",
            "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0059) | Acc: (99.86%) (25692/25728)\n",
            "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0059) | Acc: (99.85%) (26968/27008)\n",
            "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0058) | Acc: (99.86%) (28248/28288)\n",
            "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.86%) (29527/29568)\n",
            "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.86%) (30806/30848)\n",
            "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0057) | Acc: (99.87%) (32085/32128)\n",
            "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0057) | Acc: (99.87%) (33363/33408)\n",
            "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0058) | Acc: (99.86%) (34641/34688)\n",
            "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0057) | Acc: (99.87%) (35920/35968)\n",
            "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0057) | Acc: (99.87%) (37199/37248)\n",
            "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.87%) (38477/38528)\n",
            "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0056) | Acc: (99.87%) (39755/39808)\n",
            "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0056) | Acc: (99.87%) (41035/41088)\n",
            "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.87%) (42315/42368)\n",
            "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0055) | Acc: (99.88%) (43594/43648)\n",
            "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.88%) (44873/44928)\n",
            "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.88%) (46151/46208)\n",
            "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.88%) (47430/47488)\n",
            "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.88%) (48709/48768)\n",
            "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.88%) (49940/50000)\n",
            "# TEST : Loss: (0.3464) | Acc: (92.81%) (9281/10000)\n",
            "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0018) | Acc: (100.00%) (128/128)\n",
            "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0052) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0053) | Acc: (99.93%) (2686/2688)\n",
            "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0058) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0053) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0051) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0049) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0048) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0049) | Acc: (99.91%) (10359/10368)\n",
            "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.90%) (12915/12928)\n",
            "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0050) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0050) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0051) | Acc: (99.90%) (16751/16768)\n",
            "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0050) | Acc: (99.90%) (18030/18048)\n",
            "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0051) | Acc: (99.89%) (19307/19328)\n",
            "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.90%) (20587/20608)\n",
            "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0051) | Acc: (99.90%) (21866/21888)\n",
            "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.90%) (23145/23168)\n",
            "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.90%) (24424/24448)\n",
            "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.90%) (25701/25728)\n",
            "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0053) | Acc: (99.89%) (26977/27008)\n",
            "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0052) | Acc: (99.89%) (28257/28288)\n",
            "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0052) | Acc: (99.89%) (29536/29568)\n",
            "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.90%) (30816/30848)\n",
            "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0052) | Acc: (99.90%) (32095/32128)\n",
            "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0052) | Acc: (99.90%) (33375/33408)\n",
            "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0052) | Acc: (99.90%) (34653/34688)\n",
            "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0052) | Acc: (99.90%) (35932/35968)\n",
            "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.89%) (37208/37248)\n",
            "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.89%) (38485/38528)\n",
            "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.89%) (39764/39808)\n",
            "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.89%) (41043/41088)\n",
            "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.89%) (42323/42368)\n",
            "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0052) | Acc: (99.90%) (43603/43648)\n",
            "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0052) | Acc: (99.90%) (44883/44928)\n",
            "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0052) | Acc: (99.90%) (46162/46208)\n",
            "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0052) | Acc: (99.90%) (47440/47488)\n",
            "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0052) | Acc: (99.90%) (48717/48768)\n",
            "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0052) | Acc: (99.90%) (49948/50000)\n",
            "# TEST : Loss: (0.3444) | Acc: (92.93%) (9293/10000)\n",
            "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0087) | Acc: (100.00%) (128/128)\n",
            "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0075) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0057) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0056) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0052) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0056) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0059) | Acc: (99.85%) (9074/9088)\n",
            "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0060) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.85%) (11630/11648)\n",
            "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.85%) (12908/12928)\n",
            "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0059) | Acc: (99.85%) (14186/14208)\n",
            "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.85%) (15465/15488)\n",
            "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.86%) (16744/16768)\n",
            "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0054) | Acc: (99.87%) (18024/18048)\n",
            "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0054) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0055) | Acc: (99.86%) (20579/20608)\n",
            "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0056) | Acc: (99.86%) (21857/21888)\n",
            "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.87%) (23137/23168)\n",
            "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.87%) (24415/24448)\n",
            "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0054) | Acc: (99.87%) (25695/25728)\n",
            "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.88%) (28253/28288)\n",
            "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.88%) (29532/29568)\n",
            "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.87%) (30809/30848)\n",
            "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0054) | Acc: (99.88%) (32089/32128)\n",
            "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.88%) (33369/33408)\n",
            "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0055) | Acc: (99.88%) (34646/34688)\n",
            "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.88%) (35924/35968)\n",
            "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.88%) (37204/37248)\n",
            "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.88%) (38482/38528)\n",
            "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0055) | Acc: (99.87%) (39757/39808)\n",
            "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0055) | Acc: (99.87%) (41035/41088)\n",
            "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.87%) (42315/42368)\n",
            "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0054) | Acc: (99.88%) (43595/43648)\n",
            "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.88%) (44873/44928)\n",
            "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.88%) (46152/46208)\n",
            "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0053) | Acc: (99.88%) (47432/47488)\n",
            "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.88%) (48711/48768)\n",
            "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.88%) (49942/50000)\n",
            "# TEST : Loss: (0.3479) | Acc: (92.85%) (9285/10000)\n",
            "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0093) | Acc: (100.00%) (128/128)\n",
            "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0042) | Acc: (100.00%) (1408/1408)\n",
            "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0067) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0067) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0057) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.91%) (6522/6528)\n",
            "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0060) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0058) | Acc: (99.91%) (9080/9088)\n",
            "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0055) | Acc: (99.92%) (10360/10368)\n",
            "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0052) | Acc: (99.93%) (11640/11648)\n",
            "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0054) | Acc: (99.91%) (12917/12928)\n",
            "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0056) | Acc: (99.90%) (14194/14208)\n",
            "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0055) | Acc: (99.90%) (15473/15488)\n",
            "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0054) | Acc: (99.91%) (16753/16768)\n",
            "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0054) | Acc: (99.91%) (18032/18048)\n",
            "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0054) | Acc: (99.91%) (19311/19328)\n",
            "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0053) | Acc: (99.92%) (20591/20608)\n",
            "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.92%) (21871/21888)\n",
            "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0054) | Acc: (99.92%) (23149/23168)\n",
            "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0056) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0056) | Acc: (99.90%) (26981/27008)\n",
            "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0056) | Acc: (99.90%) (28259/28288)\n",
            "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.90%) (29539/29568)\n",
            "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.91%) (30819/30848)\n",
            "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0054) | Acc: (99.91%) (32098/32128)\n",
            "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.90%) (33375/33408)\n",
            "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.90%) (34654/34688)\n",
            "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.91%) (35934/35968)\n",
            "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0052) | Acc: (99.91%) (37214/37248)\n",
            "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0053) | Acc: (99.90%) (38490/38528)\n",
            "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0054) | Acc: (99.90%) (39768/39808)\n",
            "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0054) | Acc: (99.90%) (41046/41088)\n",
            "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0054) | Acc: (99.89%) (42323/42368)\n",
            "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0055) | Acc: (99.89%) (43600/43648)\n",
            "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0054) | Acc: (99.89%) (44879/44928)\n",
            "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0055) | Acc: (99.89%) (46157/46208)\n",
            "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.89%) (47434/47488)\n",
            "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0056) | Acc: (99.88%) (48711/48768)\n",
            "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0057) | Acc: (99.88%) (49940/50000)\n",
            "# TEST : Loss: (0.3427) | Acc: (92.84%) (9284/10000)\n",
            "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0026) | Acc: (100.00%) (128/128)\n",
            "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0050) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0053) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0050) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0050) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0051) | Acc: (99.85%) (6518/6528)\n",
            "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0053) | Acc: (99.86%) (7797/7808)\n",
            "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0057) | Acc: (99.82%) (9072/9088)\n",
            "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0055) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0056) | Acc: (99.83%) (11628/11648)\n",
            "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0057) | Acc: (99.84%) (12907/12928)\n",
            "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.85%) (14186/14208)\n",
            "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0054) | Acc: (99.85%) (15465/15488)\n",
            "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0054) | Acc: (99.85%) (16743/16768)\n",
            "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.85%) (18021/18048)\n",
            "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0057) | Acc: (99.85%) (19299/19328)\n",
            "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0058) | Acc: (99.85%) (20577/20608)\n",
            "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0058) | Acc: (99.84%) (21854/21888)\n",
            "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0058) | Acc: (99.84%) (23131/23168)\n",
            "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0058) | Acc: (99.84%) (24408/24448)\n",
            "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0058) | Acc: (99.84%) (25686/25728)\n",
            "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0058) | Acc: (99.84%) (26966/27008)\n",
            "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.85%) (28246/28288)\n",
            "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0057) | Acc: (99.85%) (29525/29568)\n",
            "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0057) | Acc: (99.86%) (30805/30848)\n",
            "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0056) | Acc: (99.87%) (32085/32128)\n",
            "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0056) | Acc: (99.86%) (33362/33408)\n",
            "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0057) | Acc: (99.86%) (34641/34688)\n",
            "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0056) | Acc: (99.87%) (35921/35968)\n",
            "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.87%) (37200/37248)\n",
            "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0056) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0056) | Acc: (99.87%) (39757/39808)\n",
            "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0055) | Acc: (99.88%) (41037/41088)\n",
            "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0055) | Acc: (99.88%) (42316/42368)\n",
            "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0055) | Acc: (99.88%) (43595/43648)\n",
            "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0055) | Acc: (99.88%) (44875/44928)\n",
            "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.88%) (46154/46208)\n",
            "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0055) | Acc: (99.88%) (47432/47488)\n",
            "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0055) | Acc: (99.88%) (48711/48768)\n",
            "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0055) | Acc: (99.88%) (49942/50000)\n",
            "# TEST : Loss: (0.3455) | Acc: (92.90%) (9290/10000)\n",
            "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0015) | Acc: (100.00%) (128/128)\n",
            "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.79%) (1405/1408)\n",
            "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0054) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0069) | Acc: (99.80%) (3960/3968)\n",
            "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0060) | Acc: (99.85%) (5240/5248)\n",
            "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0053) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0055) | Acc: (99.87%) (7798/7808)\n",
            "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0050) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0049) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0050) | Acc: (99.91%) (11637/11648)\n",
            "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.91%) (12916/12928)\n",
            "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0052) | Acc: (99.89%) (14192/14208)\n",
            "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0054) | Acc: (99.88%) (15470/15488)\n",
            "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0053) | Acc: (99.89%) (16749/16768)\n",
            "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0054) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0052) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0051) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0052) | Acc: (99.89%) (21864/21888)\n",
            "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0051) | Acc: (99.90%) (23144/23168)\n",
            "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0051) | Acc: (99.90%) (24423/24448)\n",
            "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0051) | Acc: (99.90%) (25702/25728)\n",
            "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.90%) (26982/27008)\n",
            "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0050) | Acc: (99.91%) (28262/28288)\n",
            "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0049) | Acc: (99.91%) (29542/29568)\n",
            "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0049) | Acc: (99.92%) (30822/30848)\n",
            "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.92%) (32101/32128)\n",
            "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0048) | Acc: (99.92%) (33381/33408)\n",
            "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0048) | Acc: (99.92%) (34659/34688)\n",
            "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.91%) (35936/35968)\n",
            "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.91%) (37216/37248)\n",
            "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.91%) (38494/38528)\n",
            "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0050) | Acc: (99.91%) (39771/39808)\n",
            "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.91%) (41050/41088)\n",
            "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.91%) (42329/42368)\n",
            "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.91%) (44887/44928)\n",
            "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.91%) (46166/46208)\n",
            "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.91%) (47446/47488)\n",
            "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.91%) (48725/48768)\n",
            "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.91%) (49954/50000)\n",
            "# TEST : Loss: (0.3445) | Acc: (92.75%) (9275/10000)\n",
            "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0066) | Acc: (100.00%) (128/128)\n",
            "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0053) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0047) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0057) | Acc: (99.85%) (3962/3968)\n",
            "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0052) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.83%) (6517/6528)\n",
            "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0055) | Acc: (99.85%) (7796/7808)\n",
            "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0061) | Acc: (99.82%) (9072/9088)\n",
            "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0060) | Acc: (99.83%) (10350/10368)\n",
            "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.83%) (11628/11648)\n",
            "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.83%) (12906/12928)\n",
            "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0060) | Acc: (99.83%) (14184/14208)\n",
            "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.85%) (15464/15488)\n",
            "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.84%) (16742/16768)\n",
            "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.85%) (18021/18048)\n",
            "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.86%) (19301/19328)\n",
            "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.87%) (20581/20608)\n",
            "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0053) | Acc: (99.87%) (21860/21888)\n",
            "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.87%) (23139/23168)\n",
            "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0053) | Acc: (99.87%) (24417/24448)\n",
            "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0055) | Acc: (99.88%) (25696/25728)\n",
            "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0054) | Acc: (99.87%) (26973/27008)\n",
            "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0055) | Acc: (99.87%) (28251/28288)\n",
            "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.87%) (29529/29568)\n",
            "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0054) | Acc: (99.87%) (30809/30848)\n",
            "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0053) | Acc: (99.88%) (32089/32128)\n",
            "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.88%) (33368/33408)\n",
            "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0054) | Acc: (99.88%) (34646/34688)\n",
            "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0055) | Acc: (99.87%) (35923/35968)\n",
            "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0055) | Acc: (99.88%) (37203/37248)\n",
            "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0055) | Acc: (99.88%) (38482/38528)\n",
            "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0054) | Acc: (99.88%) (39762/39808)\n",
            "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.89%) (41041/41088)\n",
            "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0053) | Acc: (99.89%) (42321/42368)\n",
            "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0053) | Acc: (99.89%) (43601/43648)\n",
            "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0053) | Acc: (99.89%) (44878/44928)\n",
            "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0054) | Acc: (99.89%) (46155/46208)\n",
            "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0054) | Acc: (99.88%) (47433/47488)\n",
            "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0054) | Acc: (99.89%) (48712/48768)\n",
            "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0054) | Acc: (99.89%) (49944/50000)\n",
            "# TEST : Loss: (0.3442) | Acc: (92.90%) (9290/10000)\n",
            "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0019) | Acc: (100.00%) (128/128)\n",
            "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0045) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0040) | Acc: (99.96%) (2687/2688)\n",
            "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0039) | Acc: (99.95%) (3966/3968)\n",
            "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0040) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0041) | Acc: (99.92%) (6523/6528)\n",
            "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0043) | Acc: (99.92%) (7802/7808)\n",
            "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0043) | Acc: (99.92%) (9081/9088)\n",
            "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0042) | Acc: (99.93%) (10361/10368)\n",
            "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0044) | Acc: (99.92%) (11639/11648)\n",
            "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.92%) (12918/12928)\n",
            "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0046) | Acc: (99.92%) (14196/14208)\n",
            "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0046) | Acc: (99.92%) (15475/15488)\n",
            "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0046) | Acc: (99.92%) (16755/16768)\n",
            "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0046) | Acc: (99.93%) (18035/18048)\n",
            "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0046) | Acc: (99.93%) (19314/19328)\n",
            "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0047) | Acc: (99.93%) (20593/20608)\n",
            "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0047) | Acc: (99.93%) (21873/21888)\n",
            "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0048) | Acc: (99.93%) (23152/23168)\n",
            "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0049) | Acc: (99.93%) (24430/24448)\n",
            "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0048) | Acc: (99.93%) (25710/25728)\n",
            "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0048) | Acc: (99.93%) (26989/27008)\n",
            "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0048) | Acc: (99.93%) (28268/28288)\n",
            "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0048) | Acc: (99.93%) (29546/29568)\n",
            "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0047) | Acc: (99.93%) (30825/30848)\n",
            "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.93%) (32104/32128)\n",
            "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0049) | Acc: (99.93%) (33383/33408)\n",
            "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0049) | Acc: (99.93%) (34662/34688)\n",
            "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0048) | Acc: (99.93%) (35942/35968)\n",
            "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.92%) (37219/37248)\n",
            "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.92%) (38497/38528)\n",
            "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.92%) (39776/39808)\n",
            "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0049) | Acc: (99.92%) (41056/41088)\n",
            "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0049) | Acc: (99.92%) (42335/42368)\n",
            "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.92%) (43614/43648)\n",
            "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.92%) (44893/44928)\n",
            "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0050) | Acc: (99.92%) (46173/46208)\n",
            "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0051) | Acc: (99.92%) (47448/47488)\n",
            "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0051) | Acc: (99.92%) (48728/48768)\n",
            "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.92%) (49958/50000)\n",
            "# TEST : Loss: (0.3428) | Acc: (92.76%) (9276/10000)\n",
            "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0021) | Acc: (100.00%) (128/128)\n",
            "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0054) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0057) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0052) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0056) | Acc: (99.87%) (5241/5248)\n",
            "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0050) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0052) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0058) | Acc: (99.87%) (9076/9088)\n",
            "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0055) | Acc: (99.88%) (10356/10368)\n",
            "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0056) | Acc: (99.88%) (11634/11648)\n",
            "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0055) | Acc: (99.88%) (12913/12928)\n",
            "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0055) | Acc: (99.89%) (14192/14208)\n",
            "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0053) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.89%) (16750/16768)\n",
            "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0055) | Acc: (99.89%) (18029/18048)\n",
            "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0055) | Acc: (99.89%) (20586/20608)\n",
            "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.89%) (21864/21888)\n",
            "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0053) | Acc: (99.90%) (23144/23168)\n",
            "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0052) | Acc: (99.90%) (24424/24448)\n",
            "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0052) | Acc: (99.90%) (25703/25728)\n",
            "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0051) | Acc: (99.91%) (26983/27008)\n",
            "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0051) | Acc: (99.90%) (28261/28288)\n",
            "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0051) | Acc: (99.90%) (29539/29568)\n",
            "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0051) | Acc: (99.91%) (30819/30848)\n",
            "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0050) | Acc: (99.91%) (32098/32128)\n",
            "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0050) | Acc: (99.91%) (33378/33408)\n",
            "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0051) | Acc: (99.91%) (34657/34688)\n",
            "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0050) | Acc: (99.91%) (35937/35968)\n",
            "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.92%) (37217/37248)\n",
            "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0049) | Acc: (99.91%) (38495/38528)\n",
            "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.91%) (39774/39808)\n",
            "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0050) | Acc: (99.91%) (41049/41088)\n",
            "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0049) | Acc: (99.91%) (43608/43648)\n",
            "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0049) | Acc: (99.91%) (44887/44928)\n",
            "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0049) | Acc: (99.91%) (46165/46208)\n",
            "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0050) | Acc: (99.90%) (47442/47488)\n",
            "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.90%) (48721/48768)\n",
            "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0050) | Acc: (99.90%) (49952/50000)\n",
            "# TEST : Loss: (0.3470) | Acc: (92.72%) (9272/10000)\n",
            "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0077) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0072) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0067) | Acc: (99.87%) (3963/3968)\n",
            "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0065) | Acc: (99.89%) (5242/5248)\n",
            "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0067) | Acc: (99.88%) (6520/6528)\n",
            "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0063) | Acc: (99.88%) (7799/7808)\n",
            "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0061) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0061) | Acc: (99.87%) (10355/10368)\n",
            "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0060) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0060) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.89%) (14193/14208)\n",
            "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0058) | Acc: (99.90%) (15472/15488)\n",
            "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.90%) (16752/16768)\n",
            "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.90%) (18030/18048)\n",
            "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0055) | Acc: (99.91%) (19310/19328)\n",
            "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0054) | Acc: (99.91%) (20590/20608)\n",
            "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0054) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.91%) (23146/23168)\n",
            "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0055) | Acc: (99.91%) (24425/24448)\n",
            "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0056) | Acc: (99.91%) (25704/25728)\n",
            "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0056) | Acc: (99.90%) (26981/27008)\n",
            "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0057) | Acc: (99.90%) (28259/28288)\n",
            "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0058) | Acc: (99.89%) (29536/29568)\n",
            "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0058) | Acc: (99.89%) (30813/30848)\n",
            "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0058) | Acc: (99.89%) (32092/32128)\n",
            "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0059) | Acc: (99.89%) (33370/33408)\n",
            "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0059) | Acc: (99.88%) (34646/34688)\n",
            "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0059) | Acc: (99.87%) (35921/35968)\n",
            "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0058) | Acc: (99.87%) (37200/37248)\n",
            "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0058) | Acc: (99.87%) (38478/38528)\n",
            "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0059) | Acc: (99.87%) (39755/39808)\n",
            "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0058) | Acc: (99.87%) (41035/41088)\n",
            "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0059) | Acc: (99.87%) (42313/42368)\n",
            "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0058) | Acc: (99.87%) (43593/43648)\n",
            "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0057) | Acc: (99.88%) (44873/44928)\n",
            "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0058) | Acc: (99.87%) (46150/46208)\n",
            "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0057) | Acc: (99.88%) (47430/47488)\n",
            "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0057) | Acc: (99.88%) (48709/48768)\n",
            "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0056) | Acc: (99.88%) (49941/50000)\n",
            "# TEST : Loss: (0.3462) | Acc: (92.86%) (9286/10000)\n",
            "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0066) | Acc: (99.22%) (127/128)\n",
            "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0082) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0066) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0068) | Acc: (99.82%) (3961/3968)\n",
            "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0069) | Acc: (99.81%) (5238/5248)\n",
            "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0068) | Acc: (99.82%) (6516/6528)\n",
            "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0065) | Acc: (99.83%) (7795/7808)\n",
            "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0065) | Acc: (99.83%) (9073/9088)\n",
            "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0062) | Acc: (99.85%) (10352/10368)\n",
            "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0059) | Acc: (99.86%) (11632/11648)\n",
            "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0059) | Acc: (99.85%) (12909/12928)\n",
            "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0058) | Acc: (99.85%) (14187/14208)\n",
            "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0057) | Acc: (99.86%) (15466/15488)\n",
            "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0056) | Acc: (99.87%) (16746/16768)\n",
            "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0057) | Acc: (99.87%) (18024/18048)\n",
            "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0057) | Acc: (99.87%) (19302/19328)\n",
            "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0056) | Acc: (99.87%) (20581/20608)\n",
            "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0055) | Acc: (99.88%) (21861/21888)\n",
            "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0055) | Acc: (99.88%) (23140/23168)\n",
            "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0054) | Acc: (99.88%) (24419/24448)\n",
            "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0056) | Acc: (99.87%) (25694/25728)\n",
            "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0055) | Acc: (99.87%) (26974/27008)\n",
            "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0054) | Acc: (99.88%) (28254/28288)\n",
            "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0055) | Acc: (99.88%) (29533/29568)\n",
            "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0055) | Acc: (99.88%) (30811/30848)\n",
            "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0054) | Acc: (99.88%) (32091/32128)\n",
            "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0054) | Acc: (99.89%) (33371/33408)\n",
            "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0053) | Acc: (99.89%) (34650/34688)\n",
            "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0053) | Acc: (99.89%) (35929/35968)\n",
            "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0053) | Acc: (99.89%) (37206/37248)\n",
            "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0054) | Acc: (99.88%) (38483/38528)\n",
            "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0053) | Acc: (99.89%) (39763/39808)\n",
            "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0053) | Acc: (99.89%) (41042/41088)\n",
            "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0052) | Acc: (99.89%) (42322/42368)\n",
            "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0052) | Acc: (99.89%) (43601/43648)\n",
            "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0052) | Acc: (99.89%) (44879/44928)\n",
            "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0052) | Acc: (99.89%) (46159/46208)\n",
            "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0053) | Acc: (99.89%) (47435/47488)\n",
            "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.89%) (48713/48768)\n",
            "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0053) | Acc: (99.89%) (49943/50000)\n",
            "# TEST : Loss: (0.3450) | Acc: (92.77%) (9277/10000)\n",
            "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0045) | Acc: (100.00%) (128/128)\n",
            "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0044) | Acc: (99.93%) (1407/1408)\n",
            "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0049) | Acc: (99.89%) (2685/2688)\n",
            "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0046) | Acc: (99.92%) (3965/3968)\n",
            "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0042) | Acc: (99.94%) (5245/5248)\n",
            "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0040) | Acc: (99.95%) (6525/6528)\n",
            "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0041) | Acc: (99.95%) (7804/7808)\n",
            "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0040) | Acc: (99.96%) (9084/9088)\n",
            "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0042) | Acc: (99.95%) (10363/10368)\n",
            "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0043) | Acc: (99.95%) (11642/11648)\n",
            "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0044) | Acc: (99.94%) (12920/12928)\n",
            "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0044) | Acc: (99.94%) (14199/14208)\n",
            "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0044) | Acc: (99.94%) (15478/15488)\n",
            "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0044) | Acc: (99.94%) (16758/16768)\n",
            "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0044) | Acc: (99.93%) (18036/18048)\n",
            "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0043) | Acc: (99.94%) (19316/19328)\n",
            "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0043) | Acc: (99.94%) (20595/20608)\n",
            "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0044) | Acc: (99.93%) (21873/21888)\n",
            "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0044) | Acc: (99.93%) (23152/23168)\n",
            "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0043) | Acc: (99.93%) (24431/24448)\n",
            "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0043) | Acc: (99.93%) (25710/25728)\n",
            "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0043) | Acc: (99.93%) (26990/27008)\n",
            "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0044) | Acc: (99.93%) (28268/28288)\n",
            "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0045) | Acc: (99.92%) (29544/29568)\n",
            "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0045) | Acc: (99.92%) (30823/30848)\n",
            "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0047) | Acc: (99.91%) (32099/32128)\n",
            "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0047) | Acc: (99.90%) (33376/33408)\n",
            "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0048) | Acc: (99.90%) (34654/34688)\n",
            "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.90%) (35932/35968)\n",
            "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0048) | Acc: (99.90%) (37211/37248)\n",
            "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0048) | Acc: (99.90%) (38491/38528)\n",
            "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0049) | Acc: (99.91%) (39771/39808)\n",
            "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0049) | Acc: (99.91%) (41051/41088)\n",
            "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0050) | Acc: (99.91%) (42328/42368)\n",
            "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0050) | Acc: (99.90%) (43605/43648)\n",
            "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0050) | Acc: (99.90%) (44884/44928)\n",
            "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0051) | Acc: (99.90%) (46161/46208)\n",
            "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0051) | Acc: (99.89%) (47438/47488)\n",
            "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0050) | Acc: (99.90%) (48718/48768)\n",
            "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0051) | Acc: (99.90%) (49948/50000)\n",
            "# TEST : Loss: (0.3446) | Acc: (92.86%) (9286/10000)\n",
            "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0151) | Acc: (99.22%) (127/128)\n",
            "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0049) | Acc: (99.86%) (1406/1408)\n",
            "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0053) | Acc: (99.85%) (2684/2688)\n",
            "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0054) | Acc: (99.90%) (3964/3968)\n",
            "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0052) | Acc: (99.90%) (5243/5248)\n",
            "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0051) | Acc: (99.89%) (6521/6528)\n",
            "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0052) | Acc: (99.90%) (7800/7808)\n",
            "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0053) | Acc: (99.89%) (9078/9088)\n",
            "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0051) | Acc: (99.90%) (10358/10368)\n",
            "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0051) | Acc: (99.89%) (11635/11648)\n",
            "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0050) | Acc: (99.89%) (12914/12928)\n",
            "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0050) | Acc: (99.88%) (14191/14208)\n",
            "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0048) | Acc: (99.89%) (15471/15488)\n",
            "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0049) | Acc: (99.89%) (16750/16768)\n",
            "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0050) | Acc: (99.89%) (18028/18048)\n",
            "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0049) | Acc: (99.90%) (19308/19328)\n",
            "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0047) | Acc: (99.90%) (20588/20608)\n",
            "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0047) | Acc: (99.91%) (21868/21888)\n",
            "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0046) | Acc: (99.91%) (23148/23168)\n",
            "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0046) | Acc: (99.91%) (24426/24448)\n",
            "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0047) | Acc: (99.91%) (25704/25728)\n",
            "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0048) | Acc: (99.91%) (26983/27008)\n",
            "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0047) | Acc: (99.91%) (28263/28288)\n",
            "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0047) | Acc: (99.91%) (29542/29568)\n",
            "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0047) | Acc: (99.91%) (30820/30848)\n",
            "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0048) | Acc: (99.91%) (32100/32128)\n",
            "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0047) | Acc: (99.92%) (33380/33408)\n",
            "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0048) | Acc: (99.91%) (34656/34688)\n",
            "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0049) | Acc: (99.91%) (35935/35968)\n",
            "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0049) | Acc: (99.91%) (37215/37248)\n",
            "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0051) | Acc: (99.90%) (38490/38528)\n",
            "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0052) | Acc: (99.90%) (39767/39808)\n",
            "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0052) | Acc: (99.90%) (41046/41088)\n",
            "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0051) | Acc: (99.90%) (42325/42368)\n",
            "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0053) | Acc: (99.89%) (43602/43648)\n",
            "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0053) | Acc: (99.89%) (44879/44928)\n",
            "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0053) | Acc: (99.89%) (46159/46208)\n",
            "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0053) | Acc: (99.89%) (47437/47488)\n",
            "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0053) | Acc: (99.89%) (48716/48768)\n",
            "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0052) | Acc: (99.89%) (49947/50000)\n",
            "# TEST : Loss: (0.3464) | Acc: (92.89%) (9289/10000)\n",
            "1 hours 34 mins 0 secs for training\n"
          ]
        }
      ]
    }
  ]
}