{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YSW2/ResNet_sample/blob/master/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag85N15pLKus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5422f4-009d-476f-9249-060c031b9911"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.get_device_name(0))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12JvW1tgLXTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132838d1-fe17-46a2-fadb-365a63fa8fdb"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number\n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "learning_rate = 0.1\n",
        "root_dir = '/content/app/'\n",
        "#default_directory = 'drive/app/torch/save_models'\n",
        "\n",
        "# Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),               # Random Position Crop\n",
        "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
        "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467), # RGB Normalize MEAN\n",
        "                         std=(0.2471, 0.2436, 0.2616))  # RGB Normalize Standard Deviation\n",
        "])\n",
        "\n",
        "# automatically download\n",
        "train_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                 train=True,\n",
        "                                 transform=transform_train,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=root_dir,\n",
        "                                train=False,\n",
        "                                transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
        "                                           num_workers=4)           # CPU loader number\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
        "                                          num_workers=4)            # CPU loader number\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels) #\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "        if downsample is not None:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False), #avgPooling?\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=16, out_channels=16, stride=1, downsample=None)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            BasicBlock(in_channels=16, out_channels=32, stride=2, downsample=True),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=32, out_channels=32, stride=1, downsample=None)\n",
        "\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            BasicBlock(in_channels=32, out_channels=64, stride=2, downsample=True),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None),\n",
        "            BasicBlock(in_channels=64, out_channels=64, stride=1, downsample=None)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=8, stride=1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = ResNet()\n",
        "optimizer = optim.SGD(model.parameters(), learning_rate,\n",
        "                                momentum=0.9,\n",
        "                                weight_decay=1e-4,\n",
        "                                nesterov=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if torch.cuda.device_count() > 0:\n",
        "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model).cuda()\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    print(\"USE ONLY CPU!\")\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    #change to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
        "        else:\n",
        "            data, target = Variable(data), Variable(target)\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target.data).cpu().sum()\n",
        "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
        "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
        "\n",
        "\n",
        "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
        "\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    torch.save(state, model_filename)\n",
        "    print(\"=> saving checkpoint\")\n",
        "\n",
        "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
        "\n",
        "    model_filename = os.path.join(directory, filename)\n",
        "    if os.path.exists(model_filename):\n",
        "        print(\"=> loading checkpoint\")\n",
        "        state = torch.load(model_filename)\n",
        "        return state\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "#checkpoint = load_checkpoint(default_directory)\n",
        "#if not checkpoint:\n",
        "#    pass\n",
        "#else:\n",
        "#    start_epoch = checkpoint['epoch'] + 1\n",
        "#    model.load_state_dict(checkpoint['state_dict'])\n",
        "#    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "for epoch in range(start_epoch, 165):\n",
        "\n",
        "    if epoch < 80:\n",
        "        lr = learning_rate\n",
        "    elif epoch < 120:\n",
        "        lr = learning_rate * 0.1\n",
        "    else:\n",
        "        lr = learning_rate * 0.01\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    train(epoch)\n",
        "#    save_checkpoint(default_directory, {\n",
        "#        'epoch': epoch,\n",
        "#        'model': model,\n",
        "#        'state_dict': model.state_dict(),\n",
        "#        'optimizer': optimizer.state_dict(),\n",
        "#    })\n",
        "    test()\n",
        "\n",
        "now = time.gmtime(time.time() - start_time)\n",
        "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/app/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 93498217.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/app/cifar-10-python.tar.gz to /content/app/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch: 43 | Batch_idx: 30 |  Loss: (0.2333) | Acc: (91.99%) (3650/3968)\n",
            "Epoch: 43 | Batch_idx: 40 |  Loss: (0.2443) | Acc: (91.62%) (4808/5248)\n",
            "Epoch: 43 | Batch_idx: 50 |  Loss: (0.2445) | Acc: (91.56%) (5977/6528)\n",
            "Epoch: 43 | Batch_idx: 60 |  Loss: (0.2405) | Acc: (91.69%) (7159/7808)\n",
            "Epoch: 43 | Batch_idx: 70 |  Loss: (0.2438) | Acc: (91.55%) (8320/9088)\n",
            "Epoch: 43 | Batch_idx: 80 |  Loss: (0.2422) | Acc: (91.54%) (9491/10368)\n",
            "Epoch: 43 | Batch_idx: 90 |  Loss: (0.2420) | Acc: (91.47%) (10655/11648)\n",
            "Epoch: 43 | Batch_idx: 100 |  Loss: (0.2419) | Acc: (91.44%) (11821/12928)\n",
            "Epoch: 43 | Batch_idx: 110 |  Loss: (0.2402) | Acc: (91.48%) (12998/14208)\n",
            "Epoch: 43 | Batch_idx: 120 |  Loss: (0.2392) | Acc: (91.55%) (14179/15488)\n",
            "Epoch: 43 | Batch_idx: 130 |  Loss: (0.2390) | Acc: (91.57%) (15354/16768)\n",
            "Epoch: 43 | Batch_idx: 140 |  Loss: (0.2403) | Acc: (91.46%) (16507/18048)\n",
            "Epoch: 43 | Batch_idx: 150 |  Loss: (0.2418) | Acc: (91.38%) (17661/19328)\n",
            "Epoch: 43 | Batch_idx: 160 |  Loss: (0.2413) | Acc: (91.44%) (18844/20608)\n",
            "Epoch: 43 | Batch_idx: 170 |  Loss: (0.2430) | Acc: (91.35%) (19995/21888)\n",
            "Epoch: 43 | Batch_idx: 180 |  Loss: (0.2436) | Acc: (91.33%) (21159/23168)\n",
            "Epoch: 43 | Batch_idx: 190 |  Loss: (0.2450) | Acc: (91.27%) (22313/24448)\n",
            "Epoch: 43 | Batch_idx: 200 |  Loss: (0.2437) | Acc: (91.29%) (23486/25728)\n",
            "Epoch: 43 | Batch_idx: 210 |  Loss: (0.2445) | Acc: (91.21%) (24633/27008)\n",
            "Epoch: 43 | Batch_idx: 220 |  Loss: (0.2448) | Acc: (91.18%) (25794/28288)\n",
            "Epoch: 43 | Batch_idx: 230 |  Loss: (0.2444) | Acc: (91.18%) (26960/29568)\n",
            "Epoch: 43 | Batch_idx: 240 |  Loss: (0.2441) | Acc: (91.21%) (28135/30848)\n",
            "Epoch: 43 | Batch_idx: 250 |  Loss: (0.2455) | Acc: (91.16%) (29288/32128)\n",
            "Epoch: 43 | Batch_idx: 260 |  Loss: (0.2460) | Acc: (91.13%) (30445/33408)\n",
            "Epoch: 43 | Batch_idx: 270 |  Loss: (0.2473) | Acc: (91.13%) (31612/34688)\n",
            "Epoch: 43 | Batch_idx: 280 |  Loss: (0.2481) | Acc: (91.10%) (32767/35968)\n",
            "Epoch: 43 | Batch_idx: 290 |  Loss: (0.2479) | Acc: (91.11%) (33937/37248)\n",
            "Epoch: 43 | Batch_idx: 300 |  Loss: (0.2481) | Acc: (91.11%) (35104/38528)\n",
            "Epoch: 43 | Batch_idx: 310 |  Loss: (0.2489) | Acc: (91.09%) (36262/39808)\n",
            "Epoch: 43 | Batch_idx: 320 |  Loss: (0.2485) | Acc: (91.12%) (37440/41088)\n",
            "Epoch: 43 | Batch_idx: 330 |  Loss: (0.2484) | Acc: (91.14%) (38613/42368)\n",
            "Epoch: 43 | Batch_idx: 340 |  Loss: (0.2489) | Acc: (91.11%) (39769/43648)\n",
            "Epoch: 43 | Batch_idx: 350 |  Loss: (0.2495) | Acc: (91.09%) (40923/44928)\n",
            "Epoch: 43 | Batch_idx: 360 |  Loss: (0.2489) | Acc: (91.10%) (42094/46208)\n",
            "Epoch: 43 | Batch_idx: 370 |  Loss: (0.2489) | Acc: (91.07%) (43245/47488)\n",
            "Epoch: 43 | Batch_idx: 380 |  Loss: (0.2489) | Acc: (91.10%) (44428/48768)\n",
            "Epoch: 43 | Batch_idx: 390 |  Loss: (0.2492) | Acc: (91.11%) (45553/50000)\n",
            "# TEST : Loss: (0.4498) | Acc: (85.89%) (8589/10000)\n",
            "Epoch: 44 | Batch_idx: 0 |  Loss: (0.2034) | Acc: (94.53%) (121/128)\n",
            "Epoch: 44 | Batch_idx: 10 |  Loss: (0.2608) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 44 | Batch_idx: 20 |  Loss: (0.2575) | Acc: (91.59%) (2462/2688)\n",
            "Epoch: 44 | Batch_idx: 30 |  Loss: (0.2438) | Acc: (91.81%) (3643/3968)\n",
            "Epoch: 44 | Batch_idx: 40 |  Loss: (0.2399) | Acc: (91.67%) (4811/5248)\n",
            "Epoch: 44 | Batch_idx: 50 |  Loss: (0.2349) | Acc: (91.74%) (5989/6528)\n",
            "Epoch: 44 | Batch_idx: 60 |  Loss: (0.2317) | Acc: (91.83%) (7170/7808)\n",
            "Epoch: 44 | Batch_idx: 70 |  Loss: (0.2318) | Acc: (91.77%) (8340/9088)\n",
            "Epoch: 44 | Batch_idx: 80 |  Loss: (0.2345) | Acc: (91.59%) (9496/10368)\n",
            "Epoch: 44 | Batch_idx: 90 |  Loss: (0.2346) | Acc: (91.59%) (10668/11648)\n",
            "Epoch: 44 | Batch_idx: 100 |  Loss: (0.2358) | Acc: (91.53%) (11833/12928)\n",
            "Epoch: 44 | Batch_idx: 110 |  Loss: (0.2356) | Acc: (91.55%) (13007/14208)\n",
            "Epoch: 44 | Batch_idx: 120 |  Loss: (0.2346) | Acc: (91.58%) (14184/15488)\n",
            "Epoch: 44 | Batch_idx: 130 |  Loss: (0.2330) | Acc: (91.58%) (15356/16768)\n",
            "Epoch: 44 | Batch_idx: 140 |  Loss: (0.2333) | Acc: (91.56%) (16525/18048)\n",
            "Epoch: 44 | Batch_idx: 150 |  Loss: (0.2339) | Acc: (91.52%) (17689/19328)\n",
            "Epoch: 44 | Batch_idx: 160 |  Loss: (0.2344) | Acc: (91.57%) (18871/20608)\n",
            "Epoch: 44 | Batch_idx: 170 |  Loss: (0.2338) | Acc: (91.61%) (20052/21888)\n",
            "Epoch: 44 | Batch_idx: 180 |  Loss: (0.2352) | Acc: (91.52%) (21203/23168)\n",
            "Epoch: 44 | Batch_idx: 190 |  Loss: (0.2364) | Acc: (91.47%) (22363/24448)\n",
            "Epoch: 44 | Batch_idx: 200 |  Loss: (0.2367) | Acc: (91.48%) (23537/25728)\n",
            "Epoch: 44 | Batch_idx: 210 |  Loss: (0.2365) | Acc: (91.53%) (24720/27008)\n",
            "Epoch: 44 | Batch_idx: 220 |  Loss: (0.2360) | Acc: (91.54%) (25895/28288)\n",
            "Epoch: 44 | Batch_idx: 230 |  Loss: (0.2372) | Acc: (91.50%) (27056/29568)\n",
            "Epoch: 44 | Batch_idx: 240 |  Loss: (0.2384) | Acc: (91.45%) (28212/30848)\n",
            "Epoch: 44 | Batch_idx: 250 |  Loss: (0.2403) | Acc: (91.40%) (29365/32128)\n",
            "Epoch: 44 | Batch_idx: 260 |  Loss: (0.2405) | Acc: (91.40%) (30536/33408)\n",
            "Epoch: 44 | Batch_idx: 270 |  Loss: (0.2411) | Acc: (91.38%) (31698/34688)\n",
            "Epoch: 44 | Batch_idx: 280 |  Loss: (0.2401) | Acc: (91.43%) (32884/35968)\n",
            "Epoch: 44 | Batch_idx: 290 |  Loss: (0.2410) | Acc: (91.39%) (34041/37248)\n",
            "Epoch: 44 | Batch_idx: 300 |  Loss: (0.2425) | Acc: (91.34%) (35193/38528)\n",
            "Epoch: 44 | Batch_idx: 310 |  Loss: (0.2432) | Acc: (91.32%) (36352/39808)\n",
            "Epoch: 44 | Batch_idx: 320 |  Loss: (0.2438) | Acc: (91.28%) (37506/41088)\n",
            "Epoch: 44 | Batch_idx: 330 |  Loss: (0.2445) | Acc: (91.28%) (38674/42368)\n",
            "Epoch: 44 | Batch_idx: 340 |  Loss: (0.2449) | Acc: (91.27%) (39837/43648)\n",
            "Epoch: 44 | Batch_idx: 350 |  Loss: (0.2458) | Acc: (91.22%) (40984/44928)\n",
            "Epoch: 44 | Batch_idx: 360 |  Loss: (0.2468) | Acc: (91.20%) (42140/46208)\n",
            "Epoch: 44 | Batch_idx: 370 |  Loss: (0.2471) | Acc: (91.20%) (43307/47488)\n",
            "Epoch: 44 | Batch_idx: 380 |  Loss: (0.2469) | Acc: (91.20%) (44475/48768)\n",
            "Epoch: 44 | Batch_idx: 390 |  Loss: (0.2474) | Acc: (91.18%) (45589/50000)\n",
            "# TEST : Loss: (0.3921) | Acc: (87.61%) (8761/10000)\n",
            "Epoch: 45 | Batch_idx: 0 |  Loss: (0.2269) | Acc: (90.62%) (116/128)\n",
            "Epoch: 45 | Batch_idx: 10 |  Loss: (0.2485) | Acc: (91.12%) (1283/1408)\n",
            "Epoch: 45 | Batch_idx: 20 |  Loss: (0.2399) | Acc: (91.26%) (2453/2688)\n",
            "Epoch: 45 | Batch_idx: 30 |  Loss: (0.2441) | Acc: (91.26%) (3621/3968)\n",
            "Epoch: 45 | Batch_idx: 40 |  Loss: (0.2367) | Acc: (91.50%) (4802/5248)\n",
            "Epoch: 45 | Batch_idx: 50 |  Loss: (0.2366) | Acc: (91.50%) (5973/6528)\n",
            "Epoch: 45 | Batch_idx: 60 |  Loss: (0.2336) | Acc: (91.59%) (7151/7808)\n",
            "Epoch: 45 | Batch_idx: 70 |  Loss: (0.2310) | Acc: (91.69%) (8333/9088)\n",
            "Epoch: 45 | Batch_idx: 80 |  Loss: (0.2313) | Acc: (91.64%) (9501/10368)\n",
            "Epoch: 45 | Batch_idx: 90 |  Loss: (0.2340) | Acc: (91.60%) (10669/11648)\n",
            "Epoch: 45 | Batch_idx: 100 |  Loss: (0.2367) | Acc: (91.51%) (11831/12928)\n",
            "Epoch: 45 | Batch_idx: 110 |  Loss: (0.2383) | Acc: (91.43%) (12991/14208)\n",
            "Epoch: 45 | Batch_idx: 120 |  Loss: (0.2390) | Acc: (91.42%) (14159/15488)\n",
            "Epoch: 45 | Batch_idx: 130 |  Loss: (0.2374) | Acc: (91.44%) (15332/16768)\n",
            "Epoch: 45 | Batch_idx: 140 |  Loss: (0.2402) | Acc: (91.39%) (16494/18048)\n",
            "Epoch: 45 | Batch_idx: 150 |  Loss: (0.2437) | Acc: (91.23%) (17633/19328)\n",
            "Epoch: 45 | Batch_idx: 160 |  Loss: (0.2466) | Acc: (91.15%) (18784/20608)\n",
            "Epoch: 45 | Batch_idx: 170 |  Loss: (0.2463) | Acc: (91.12%) (19945/21888)\n",
            "Epoch: 45 | Batch_idx: 180 |  Loss: (0.2481) | Acc: (91.12%) (21110/23168)\n",
            "Epoch: 45 | Batch_idx: 190 |  Loss: (0.2467) | Acc: (91.21%) (22300/24448)\n",
            "Epoch: 45 | Batch_idx: 200 |  Loss: (0.2477) | Acc: (91.19%) (23461/25728)\n",
            "Epoch: 45 | Batch_idx: 210 |  Loss: (0.2472) | Acc: (91.24%) (24643/27008)\n",
            "Epoch: 45 | Batch_idx: 220 |  Loss: (0.2475) | Acc: (91.21%) (25801/28288)\n",
            "Epoch: 45 | Batch_idx: 230 |  Loss: (0.2481) | Acc: (91.16%) (26954/29568)\n",
            "Epoch: 45 | Batch_idx: 240 |  Loss: (0.2468) | Acc: (91.21%) (28136/30848)\n",
            "Epoch: 45 | Batch_idx: 250 |  Loss: (0.2470) | Acc: (91.22%) (29307/32128)\n",
            "Epoch: 45 | Batch_idx: 260 |  Loss: (0.2468) | Acc: (91.24%) (30483/33408)\n",
            "Epoch: 45 | Batch_idx: 270 |  Loss: (0.2475) | Acc: (91.20%) (31637/34688)\n",
            "Epoch: 45 | Batch_idx: 280 |  Loss: (0.2473) | Acc: (91.24%) (32819/35968)\n",
            "Epoch: 45 | Batch_idx: 290 |  Loss: (0.2483) | Acc: (91.23%) (33980/37248)\n",
            "Epoch: 45 | Batch_idx: 300 |  Loss: (0.2479) | Acc: (91.25%) (35155/38528)\n",
            "Epoch: 45 | Batch_idx: 310 |  Loss: (0.2479) | Acc: (91.27%) (36332/39808)\n",
            "Epoch: 45 | Batch_idx: 320 |  Loss: (0.2483) | Acc: (91.25%) (37493/41088)\n",
            "Epoch: 45 | Batch_idx: 330 |  Loss: (0.2481) | Acc: (91.26%) (38666/42368)\n",
            "Epoch: 45 | Batch_idx: 340 |  Loss: (0.2482) | Acc: (91.27%) (39839/43648)\n",
            "Epoch: 45 | Batch_idx: 350 |  Loss: (0.2482) | Acc: (91.26%) (41002/44928)\n",
            "Epoch: 45 | Batch_idx: 360 |  Loss: (0.2487) | Acc: (91.22%) (42153/46208)\n",
            "Epoch: 45 | Batch_idx: 370 |  Loss: (0.2487) | Acc: (91.22%) (43320/47488)\n",
            "Epoch: 45 | Batch_idx: 380 |  Loss: (0.2480) | Acc: (91.26%) (44506/48768)\n",
            "Epoch: 45 | Batch_idx: 390 |  Loss: (0.2478) | Acc: (91.25%) (45626/50000)\n",
            "# TEST : Loss: (0.4616) | Acc: (85.71%) (8571/10000)\n",
            "Epoch: 46 | Batch_idx: 0 |  Loss: (0.2687) | Acc: (89.84%) (115/128)\n",
            "Epoch: 46 | Batch_idx: 10 |  Loss: (0.2344) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 46 | Batch_idx: 20 |  Loss: (0.2396) | Acc: (91.44%) (2458/2688)\n",
            "Epoch: 46 | Batch_idx: 30 |  Loss: (0.2335) | Acc: (91.89%) (3646/3968)\n",
            "Epoch: 46 | Batch_idx: 40 |  Loss: (0.2263) | Acc: (92.26%) (4842/5248)\n",
            "Epoch: 46 | Batch_idx: 50 |  Loss: (0.2265) | Acc: (92.33%) (6027/6528)\n",
            "Epoch: 46 | Batch_idx: 60 |  Loss: (0.2225) | Acc: (92.57%) (7228/7808)\n",
            "Epoch: 46 | Batch_idx: 70 |  Loss: (0.2237) | Acc: (92.46%) (8403/9088)\n",
            "Epoch: 46 | Batch_idx: 80 |  Loss: (0.2272) | Acc: (92.28%) (9568/10368)\n",
            "Epoch: 46 | Batch_idx: 90 |  Loss: (0.2269) | Acc: (92.26%) (10747/11648)\n",
            "Epoch: 46 | Batch_idx: 100 |  Loss: (0.2263) | Acc: (92.16%) (11914/12928)\n",
            "Epoch: 46 | Batch_idx: 110 |  Loss: (0.2297) | Acc: (92.06%) (13080/14208)\n",
            "Epoch: 46 | Batch_idx: 120 |  Loss: (0.2345) | Acc: (91.80%) (14218/15488)\n",
            "Epoch: 46 | Batch_idx: 130 |  Loss: (0.2357) | Acc: (91.71%) (15378/16768)\n",
            "Epoch: 46 | Batch_idx: 140 |  Loss: (0.2407) | Acc: (91.51%) (16516/18048)\n",
            "Epoch: 46 | Batch_idx: 150 |  Loss: (0.2412) | Acc: (91.44%) (17674/19328)\n",
            "Epoch: 46 | Batch_idx: 160 |  Loss: (0.2410) | Acc: (91.46%) (18848/20608)\n",
            "Epoch: 46 | Batch_idx: 170 |  Loss: (0.2414) | Acc: (91.45%) (20017/21888)\n",
            "Epoch: 46 | Batch_idx: 180 |  Loss: (0.2409) | Acc: (91.45%) (21188/23168)\n",
            "Epoch: 46 | Batch_idx: 190 |  Loss: (0.2409) | Acc: (91.45%) (22358/24448)\n",
            "Epoch: 46 | Batch_idx: 200 |  Loss: (0.2408) | Acc: (91.44%) (23525/25728)\n",
            "Epoch: 46 | Batch_idx: 210 |  Loss: (0.2406) | Acc: (91.47%) (24704/27008)\n",
            "Epoch: 46 | Batch_idx: 220 |  Loss: (0.2418) | Acc: (91.42%) (25862/28288)\n",
            "Epoch: 46 | Batch_idx: 230 |  Loss: (0.2420) | Acc: (91.40%) (27026/29568)\n",
            "Epoch: 46 | Batch_idx: 240 |  Loss: (0.2422) | Acc: (91.41%) (28199/30848)\n",
            "Epoch: 46 | Batch_idx: 250 |  Loss: (0.2434) | Acc: (91.35%) (29348/32128)\n",
            "Epoch: 46 | Batch_idx: 260 |  Loss: (0.2432) | Acc: (91.36%) (30523/33408)\n",
            "Epoch: 46 | Batch_idx: 270 |  Loss: (0.2435) | Acc: (91.37%) (31693/34688)\n",
            "Epoch: 46 | Batch_idx: 280 |  Loss: (0.2440) | Acc: (91.36%) (32859/35968)\n",
            "Epoch: 46 | Batch_idx: 290 |  Loss: (0.2451) | Acc: (91.35%) (34026/37248)\n",
            "Epoch: 46 | Batch_idx: 300 |  Loss: (0.2449) | Acc: (91.35%) (35194/38528)\n",
            "Epoch: 46 | Batch_idx: 310 |  Loss: (0.2455) | Acc: (91.32%) (36351/39808)\n",
            "Epoch: 46 | Batch_idx: 320 |  Loss: (0.2454) | Acc: (91.33%) (37524/41088)\n",
            "Epoch: 46 | Batch_idx: 330 |  Loss: (0.2449) | Acc: (91.35%) (38703/42368)\n",
            "Epoch: 46 | Batch_idx: 340 |  Loss: (0.2454) | Acc: (91.34%) (39870/43648)\n",
            "Epoch: 46 | Batch_idx: 350 |  Loss: (0.2452) | Acc: (91.35%) (41040/44928)\n",
            "Epoch: 46 | Batch_idx: 360 |  Loss: (0.2445) | Acc: (91.35%) (42212/46208)\n",
            "Epoch: 46 | Batch_idx: 370 |  Loss: (0.2446) | Acc: (91.34%) (43374/47488)\n",
            "Epoch: 46 | Batch_idx: 380 |  Loss: (0.2448) | Acc: (91.34%) (44547/48768)\n",
            "Epoch: 46 | Batch_idx: 390 |  Loss: (0.2453) | Acc: (91.32%) (45660/50000)\n",
            "# TEST : Loss: (0.5579) | Acc: (84.12%) (8412/10000)\n",
            "Epoch: 47 | Batch_idx: 0 |  Loss: (0.2004) | Acc: (94.53%) (121/128)\n",
            "Epoch: 47 | Batch_idx: 10 |  Loss: (0.2236) | Acc: (92.83%) (1307/1408)\n",
            "Epoch: 47 | Batch_idx: 20 |  Loss: (0.2367) | Acc: (91.85%) (2469/2688)\n",
            "Epoch: 47 | Batch_idx: 30 |  Loss: (0.2397) | Acc: (91.51%) (3631/3968)\n",
            "Epoch: 47 | Batch_idx: 40 |  Loss: (0.2352) | Acc: (91.79%) (4817/5248)\n",
            "Epoch: 47 | Batch_idx: 50 |  Loss: (0.2358) | Acc: (91.79%) (5992/6528)\n",
            "Epoch: 47 | Batch_idx: 60 |  Loss: (0.2318) | Acc: (91.88%) (7174/7808)\n",
            "Epoch: 47 | Batch_idx: 70 |  Loss: (0.2303) | Acc: (91.87%) (8349/9088)\n",
            "Epoch: 47 | Batch_idx: 80 |  Loss: (0.2363) | Acc: (91.62%) (9499/10368)\n",
            "Epoch: 47 | Batch_idx: 90 |  Loss: (0.2417) | Acc: (91.56%) (10665/11648)\n",
            "Epoch: 47 | Batch_idx: 100 |  Loss: (0.2433) | Acc: (91.46%) (11824/12928)\n",
            "Epoch: 47 | Batch_idx: 110 |  Loss: (0.2421) | Acc: (91.46%) (12995/14208)\n",
            "Epoch: 47 | Batch_idx: 120 |  Loss: (0.2426) | Acc: (91.42%) (14159/15488)\n",
            "Epoch: 47 | Batch_idx: 130 |  Loss: (0.2421) | Acc: (91.50%) (15342/16768)\n",
            "Epoch: 47 | Batch_idx: 140 |  Loss: (0.2430) | Acc: (91.40%) (16496/18048)\n",
            "Epoch: 47 | Batch_idx: 150 |  Loss: (0.2395) | Acc: (91.59%) (17703/19328)\n",
            "Epoch: 47 | Batch_idx: 160 |  Loss: (0.2383) | Acc: (91.61%) (18879/20608)\n",
            "Epoch: 47 | Batch_idx: 170 |  Loss: (0.2395) | Acc: (91.56%) (20041/21888)\n",
            "Epoch: 47 | Batch_idx: 180 |  Loss: (0.2400) | Acc: (91.54%) (21207/23168)\n",
            "Epoch: 47 | Batch_idx: 190 |  Loss: (0.2427) | Acc: (91.42%) (22351/24448)\n",
            "Epoch: 47 | Batch_idx: 200 |  Loss: (0.2460) | Acc: (91.27%) (23482/25728)\n",
            "Epoch: 47 | Batch_idx: 210 |  Loss: (0.2458) | Acc: (91.29%) (24656/27008)\n",
            "Epoch: 47 | Batch_idx: 220 |  Loss: (0.2453) | Acc: (91.29%) (25825/28288)\n",
            "Epoch: 47 | Batch_idx: 230 |  Loss: (0.2441) | Acc: (91.36%) (27013/29568)\n",
            "Epoch: 47 | Batch_idx: 240 |  Loss: (0.2424) | Acc: (91.44%) (28208/30848)\n",
            "Epoch: 47 | Batch_idx: 250 |  Loss: (0.2435) | Acc: (91.45%) (29381/32128)\n",
            "Epoch: 47 | Batch_idx: 260 |  Loss: (0.2435) | Acc: (91.48%) (30563/33408)\n",
            "Epoch: 47 | Batch_idx: 270 |  Loss: (0.2443) | Acc: (91.43%) (31714/34688)\n",
            "Epoch: 47 | Batch_idx: 280 |  Loss: (0.2436) | Acc: (91.47%) (32899/35968)\n",
            "Epoch: 47 | Batch_idx: 290 |  Loss: (0.2445) | Acc: (91.41%) (34049/37248)\n",
            "Epoch: 47 | Batch_idx: 300 |  Loss: (0.2443) | Acc: (91.42%) (35221/38528)\n",
            "Epoch: 47 | Batch_idx: 310 |  Loss: (0.2446) | Acc: (91.41%) (36390/39808)\n",
            "Epoch: 47 | Batch_idx: 320 |  Loss: (0.2453) | Acc: (91.39%) (37549/41088)\n",
            "Epoch: 47 | Batch_idx: 330 |  Loss: (0.2455) | Acc: (91.39%) (38721/42368)\n",
            "Epoch: 47 | Batch_idx: 340 |  Loss: (0.2449) | Acc: (91.39%) (39891/43648)\n",
            "Epoch: 47 | Batch_idx: 350 |  Loss: (0.2457) | Acc: (91.39%) (41058/44928)\n",
            "Epoch: 47 | Batch_idx: 360 |  Loss: (0.2462) | Acc: (91.36%) (42215/46208)\n",
            "Epoch: 47 | Batch_idx: 370 |  Loss: (0.2473) | Acc: (91.33%) (43370/47488)\n",
            "Epoch: 47 | Batch_idx: 380 |  Loss: (0.2472) | Acc: (91.31%) (44529/48768)\n",
            "Epoch: 47 | Batch_idx: 390 |  Loss: (0.2471) | Acc: (91.31%) (45657/50000)\n",
            "# TEST : Loss: (0.4302) | Acc: (87.04%) (8704/10000)\n",
            "Epoch: 48 | Batch_idx: 0 |  Loss: (0.2668) | Acc: (86.72%) (111/128)\n",
            "Epoch: 48 | Batch_idx: 10 |  Loss: (0.2395) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 48 | Batch_idx: 20 |  Loss: (0.2363) | Acc: (91.56%) (2461/2688)\n",
            "Epoch: 48 | Batch_idx: 30 |  Loss: (0.2391) | Acc: (91.58%) (3634/3968)\n",
            "Epoch: 48 | Batch_idx: 40 |  Loss: (0.2414) | Acc: (91.41%) (4797/5248)\n",
            "Epoch: 48 | Batch_idx: 50 |  Loss: (0.2356) | Acc: (91.68%) (5985/6528)\n",
            "Epoch: 48 | Batch_idx: 60 |  Loss: (0.2307) | Acc: (91.91%) (7176/7808)\n",
            "Epoch: 48 | Batch_idx: 70 |  Loss: (0.2349) | Acc: (91.64%) (8328/9088)\n",
            "Epoch: 48 | Batch_idx: 80 |  Loss: (0.2317) | Acc: (91.75%) (9513/10368)\n",
            "Epoch: 48 | Batch_idx: 90 |  Loss: (0.2308) | Acc: (91.78%) (10690/11648)\n",
            "Epoch: 48 | Batch_idx: 100 |  Loss: (0.2299) | Acc: (91.88%) (11878/12928)\n",
            "Epoch: 48 | Batch_idx: 110 |  Loss: (0.2296) | Acc: (91.93%) (13062/14208)\n",
            "Epoch: 48 | Batch_idx: 120 |  Loss: (0.2327) | Acc: (91.79%) (14216/15488)\n",
            "Epoch: 48 | Batch_idx: 130 |  Loss: (0.2368) | Acc: (91.59%) (15357/16768)\n",
            "Epoch: 48 | Batch_idx: 140 |  Loss: (0.2392) | Acc: (91.52%) (16518/18048)\n",
            "Epoch: 48 | Batch_idx: 150 |  Loss: (0.2395) | Acc: (91.55%) (17694/19328)\n",
            "Epoch: 48 | Batch_idx: 160 |  Loss: (0.2391) | Acc: (91.56%) (18868/20608)\n",
            "Epoch: 48 | Batch_idx: 170 |  Loss: (0.2403) | Acc: (91.53%) (20034/21888)\n",
            "Epoch: 48 | Batch_idx: 180 |  Loss: (0.2412) | Acc: (91.48%) (21195/23168)\n",
            "Epoch: 48 | Batch_idx: 190 |  Loss: (0.2426) | Acc: (91.43%) (22352/24448)\n",
            "Epoch: 48 | Batch_idx: 200 |  Loss: (0.2437) | Acc: (91.39%) (23512/25728)\n",
            "Epoch: 48 | Batch_idx: 210 |  Loss: (0.2440) | Acc: (91.39%) (24682/27008)\n",
            "Epoch: 48 | Batch_idx: 220 |  Loss: (0.2436) | Acc: (91.43%) (25864/28288)\n",
            "Epoch: 48 | Batch_idx: 230 |  Loss: (0.2436) | Acc: (91.42%) (27030/29568)\n",
            "Epoch: 48 | Batch_idx: 240 |  Loss: (0.2427) | Acc: (91.44%) (28207/30848)\n",
            "Epoch: 48 | Batch_idx: 250 |  Loss: (0.2433) | Acc: (91.45%) (29381/32128)\n",
            "Epoch: 48 | Batch_idx: 260 |  Loss: (0.2433) | Acc: (91.47%) (30558/33408)\n",
            "Epoch: 48 | Batch_idx: 270 |  Loss: (0.2430) | Acc: (91.50%) (31740/34688)\n",
            "Epoch: 48 | Batch_idx: 280 |  Loss: (0.2438) | Acc: (91.51%) (32914/35968)\n",
            "Epoch: 48 | Batch_idx: 290 |  Loss: (0.2440) | Acc: (91.49%) (34080/37248)\n",
            "Epoch: 48 | Batch_idx: 300 |  Loss: (0.2453) | Acc: (91.45%) (35232/38528)\n",
            "Epoch: 48 | Batch_idx: 310 |  Loss: (0.2453) | Acc: (91.44%) (36399/39808)\n",
            "Epoch: 48 | Batch_idx: 320 |  Loss: (0.2445) | Acc: (91.47%) (37582/41088)\n",
            "Epoch: 48 | Batch_idx: 330 |  Loss: (0.2442) | Acc: (91.48%) (38758/42368)\n",
            "Epoch: 48 | Batch_idx: 340 |  Loss: (0.2427) | Acc: (91.53%) (39951/43648)\n",
            "Epoch: 48 | Batch_idx: 350 |  Loss: (0.2421) | Acc: (91.54%) (41126/44928)\n",
            "Epoch: 48 | Batch_idx: 360 |  Loss: (0.2427) | Acc: (91.51%) (42284/46208)\n",
            "Epoch: 48 | Batch_idx: 370 |  Loss: (0.2438) | Acc: (91.48%) (43443/47488)\n",
            "Epoch: 48 | Batch_idx: 380 |  Loss: (0.2443) | Acc: (91.46%) (44603/48768)\n",
            "Epoch: 48 | Batch_idx: 390 |  Loss: (0.2438) | Acc: (91.48%) (45739/50000)\n",
            "# TEST : Loss: (0.5012) | Acc: (84.87%) (8487/10000)\n",
            "Epoch: 49 | Batch_idx: 0 |  Loss: (0.3010) | Acc: (89.06%) (114/128)\n",
            "Epoch: 49 | Batch_idx: 10 |  Loss: (0.2628) | Acc: (91.90%) (1294/1408)\n",
            "Epoch: 49 | Batch_idx: 20 |  Loss: (0.2484) | Acc: (91.82%) (2468/2688)\n",
            "Epoch: 49 | Batch_idx: 30 |  Loss: (0.2505) | Acc: (91.53%) (3632/3968)\n",
            "Epoch: 49 | Batch_idx: 40 |  Loss: (0.2392) | Acc: (91.92%) (4824/5248)\n",
            "Epoch: 49 | Batch_idx: 50 |  Loss: (0.2373) | Acc: (91.93%) (6001/6528)\n",
            "Epoch: 49 | Batch_idx: 60 |  Loss: (0.2364) | Acc: (91.88%) (7174/7808)\n",
            "Epoch: 49 | Batch_idx: 70 |  Loss: (0.2313) | Acc: (92.06%) (8366/9088)\n",
            "Epoch: 49 | Batch_idx: 80 |  Loss: (0.2327) | Acc: (92.02%) (9541/10368)\n",
            "Epoch: 49 | Batch_idx: 90 |  Loss: (0.2339) | Acc: (92.03%) (10720/11648)\n",
            "Epoch: 49 | Batch_idx: 100 |  Loss: (0.2352) | Acc: (91.98%) (11891/12928)\n",
            "Epoch: 49 | Batch_idx: 110 |  Loss: (0.2333) | Acc: (92.02%) (13074/14208)\n",
            "Epoch: 49 | Batch_idx: 120 |  Loss: (0.2317) | Acc: (92.01%) (14251/15488)\n",
            "Epoch: 49 | Batch_idx: 130 |  Loss: (0.2303) | Acc: (92.06%) (15436/16768)\n",
            "Epoch: 49 | Batch_idx: 140 |  Loss: (0.2268) | Acc: (92.18%) (16637/18048)\n",
            "Epoch: 49 | Batch_idx: 150 |  Loss: (0.2275) | Acc: (92.18%) (17817/19328)\n",
            "Epoch: 49 | Batch_idx: 160 |  Loss: (0.2292) | Acc: (92.13%) (18986/20608)\n",
            "Epoch: 49 | Batch_idx: 170 |  Loss: (0.2303) | Acc: (92.10%) (20159/21888)\n",
            "Epoch: 49 | Batch_idx: 180 |  Loss: (0.2277) | Acc: (92.20%) (21361/23168)\n",
            "Epoch: 49 | Batch_idx: 190 |  Loss: (0.2279) | Acc: (92.16%) (22531/24448)\n",
            "Epoch: 49 | Batch_idx: 200 |  Loss: (0.2292) | Acc: (92.11%) (23699/25728)\n",
            "Epoch: 49 | Batch_idx: 210 |  Loss: (0.2288) | Acc: (92.12%) (24880/27008)\n",
            "Epoch: 49 | Batch_idx: 220 |  Loss: (0.2302) | Acc: (92.05%) (26040/28288)\n",
            "Epoch: 49 | Batch_idx: 230 |  Loss: (0.2310) | Acc: (92.03%) (27211/29568)\n",
            "Epoch: 49 | Batch_idx: 240 |  Loss: (0.2318) | Acc: (91.98%) (28373/30848)\n",
            "Epoch: 49 | Batch_idx: 250 |  Loss: (0.2319) | Acc: (91.95%) (29543/32128)\n",
            "Epoch: 49 | Batch_idx: 260 |  Loss: (0.2335) | Acc: (91.89%) (30697/33408)\n",
            "Epoch: 49 | Batch_idx: 270 |  Loss: (0.2335) | Acc: (91.88%) (31872/34688)\n",
            "Epoch: 49 | Batch_idx: 280 |  Loss: (0.2338) | Acc: (91.87%) (33043/35968)\n",
            "Epoch: 49 | Batch_idx: 290 |  Loss: (0.2340) | Acc: (91.88%) (34223/37248)\n",
            "Epoch: 49 | Batch_idx: 300 |  Loss: (0.2333) | Acc: (91.91%) (35410/38528)\n",
            "Epoch: 49 | Batch_idx: 310 |  Loss: (0.2337) | Acc: (91.88%) (36576/39808)\n",
            "Epoch: 49 | Batch_idx: 320 |  Loss: (0.2350) | Acc: (91.84%) (37736/41088)\n",
            "Epoch: 49 | Batch_idx: 330 |  Loss: (0.2355) | Acc: (91.80%) (38895/42368)\n",
            "Epoch: 49 | Batch_idx: 340 |  Loss: (0.2360) | Acc: (91.79%) (40064/43648)\n",
            "Epoch: 49 | Batch_idx: 350 |  Loss: (0.2362) | Acc: (91.78%) (41234/44928)\n",
            "Epoch: 49 | Batch_idx: 360 |  Loss: (0.2368) | Acc: (91.74%) (42392/46208)\n",
            "Epoch: 49 | Batch_idx: 370 |  Loss: (0.2383) | Acc: (91.69%) (43540/47488)\n",
            "Epoch: 49 | Batch_idx: 380 |  Loss: (0.2388) | Acc: (91.69%) (44713/48768)\n",
            "Epoch: 49 | Batch_idx: 390 |  Loss: (0.2395) | Acc: (91.67%) (45833/50000)\n",
            "# TEST : Loss: (0.3820) | Acc: (87.61%) (8761/10000)\n",
            "Epoch: 50 | Batch_idx: 0 |  Loss: (0.2570) | Acc: (92.19%) (118/128)\n",
            "Epoch: 50 | Batch_idx: 10 |  Loss: (0.2371) | Acc: (91.69%) (1291/1408)\n",
            "Epoch: 50 | Batch_idx: 20 |  Loss: (0.2485) | Acc: (91.07%) (2448/2688)\n",
            "Epoch: 50 | Batch_idx: 30 |  Loss: (0.2433) | Acc: (91.36%) (3625/3968)\n",
            "Epoch: 50 | Batch_idx: 40 |  Loss: (0.2355) | Acc: (91.52%) (4803/5248)\n",
            "Epoch: 50 | Batch_idx: 50 |  Loss: (0.2331) | Acc: (91.70%) (5986/6528)\n",
            "Epoch: 50 | Batch_idx: 60 |  Loss: (0.2326) | Acc: (91.68%) (7158/7808)\n",
            "Epoch: 50 | Batch_idx: 70 |  Loss: (0.2271) | Acc: (91.84%) (8346/9088)\n",
            "Epoch: 50 | Batch_idx: 80 |  Loss: (0.2258) | Acc: (91.92%) (9530/10368)\n",
            "Epoch: 50 | Batch_idx: 90 |  Loss: (0.2268) | Acc: (91.91%) (10706/11648)\n",
            "Epoch: 50 | Batch_idx: 100 |  Loss: (0.2279) | Acc: (91.96%) (11889/12928)\n",
            "Epoch: 50 | Batch_idx: 110 |  Loss: (0.2307) | Acc: (91.88%) (13055/14208)\n",
            "Epoch: 50 | Batch_idx: 120 |  Loss: (0.2316) | Acc: (91.86%) (14227/15488)\n",
            "Epoch: 50 | Batch_idx: 130 |  Loss: (0.2356) | Acc: (91.75%) (15384/16768)\n",
            "Epoch: 50 | Batch_idx: 140 |  Loss: (0.2362) | Acc: (91.77%) (16563/18048)\n",
            "Epoch: 50 | Batch_idx: 150 |  Loss: (0.2352) | Acc: (91.80%) (17744/19328)\n",
            "Epoch: 50 | Batch_idx: 160 |  Loss: (0.2336) | Acc: (91.81%) (18920/20608)\n",
            "Epoch: 50 | Batch_idx: 170 |  Loss: (0.2346) | Acc: (91.77%) (20087/21888)\n",
            "Epoch: 50 | Batch_idx: 180 |  Loss: (0.2356) | Acc: (91.75%) (21256/23168)\n",
            "Epoch: 50 | Batch_idx: 190 |  Loss: (0.2367) | Acc: (91.69%) (22416/24448)\n",
            "Epoch: 50 | Batch_idx: 200 |  Loss: (0.2357) | Acc: (91.75%) (23605/25728)\n",
            "Epoch: 50 | Batch_idx: 210 |  Loss: (0.2352) | Acc: (91.73%) (24775/27008)\n",
            "Epoch: 50 | Batch_idx: 220 |  Loss: (0.2345) | Acc: (91.76%) (25957/28288)\n",
            "Epoch: 50 | Batch_idx: 230 |  Loss: (0.2345) | Acc: (91.76%) (27131/29568)\n",
            "Epoch: 50 | Batch_idx: 240 |  Loss: (0.2333) | Acc: (91.77%) (28309/30848)\n",
            "Epoch: 50 | Batch_idx: 250 |  Loss: (0.2342) | Acc: (91.73%) (29472/32128)\n",
            "Epoch: 50 | Batch_idx: 260 |  Loss: (0.2351) | Acc: (91.70%) (30636/33408)\n",
            "Epoch: 50 | Batch_idx: 270 |  Loss: (0.2349) | Acc: (91.71%) (31812/34688)\n",
            "Epoch: 50 | Batch_idx: 280 |  Loss: (0.2353) | Acc: (91.67%) (32972/35968)\n",
            "Epoch: 50 | Batch_idx: 290 |  Loss: (0.2349) | Acc: (91.64%) (34135/37248)\n",
            "Epoch: 50 | Batch_idx: 300 |  Loss: (0.2345) | Acc: (91.66%) (35315/38528)\n",
            "Epoch: 50 | Batch_idx: 310 |  Loss: (0.2347) | Acc: (91.67%) (36491/39808)\n",
            "Epoch: 50 | Batch_idx: 320 |  Loss: (0.2358) | Acc: (91.62%) (37644/41088)\n",
            "Epoch: 50 | Batch_idx: 330 |  Loss: (0.2374) | Acc: (91.56%) (38794/42368)\n",
            "Epoch: 50 | Batch_idx: 340 |  Loss: (0.2387) | Acc: (91.49%) (39934/43648)\n",
            "Epoch: 50 | Batch_idx: 350 |  Loss: (0.2386) | Acc: (91.52%) (41116/44928)\n",
            "Epoch: 50 | Batch_idx: 360 |  Loss: (0.2385) | Acc: (91.53%) (42293/46208)\n",
            "Epoch: 50 | Batch_idx: 370 |  Loss: (0.2397) | Acc: (91.48%) (43442/47488)\n",
            "Epoch: 50 | Batch_idx: 380 |  Loss: (0.2405) | Acc: (91.47%) (44607/48768)\n",
            "Epoch: 50 | Batch_idx: 390 |  Loss: (0.2414) | Acc: (91.45%) (45723/50000)\n",
            "# TEST : Loss: (0.4247) | Acc: (86.55%) (8655/10000)\n",
            "Epoch: 51 | Batch_idx: 0 |  Loss: (0.2076) | Acc: (93.75%) (120/128)\n",
            "Epoch: 51 | Batch_idx: 10 |  Loss: (0.2202) | Acc: (92.61%) (1304/1408)\n",
            "Epoch: 51 | Batch_idx: 20 |  Loss: (0.2184) | Acc: (92.63%) (2490/2688)\n",
            "Epoch: 51 | Batch_idx: 30 |  Loss: (0.2194) | Acc: (92.64%) (3676/3968)\n",
            "Epoch: 51 | Batch_idx: 40 |  Loss: (0.2220) | Acc: (92.49%) (4854/5248)\n",
            "Epoch: 51 | Batch_idx: 50 |  Loss: (0.2271) | Acc: (92.29%) (6025/6528)\n",
            "Epoch: 51 | Batch_idx: 60 |  Loss: (0.2294) | Acc: (92.17%) (7197/7808)\n",
            "Epoch: 51 | Batch_idx: 70 |  Loss: (0.2258) | Acc: (92.30%) (8388/9088)\n",
            "Epoch: 51 | Batch_idx: 80 |  Loss: (0.2290) | Acc: (92.15%) (9554/10368)\n",
            "Epoch: 51 | Batch_idx: 90 |  Loss: (0.2265) | Acc: (92.20%) (10740/11648)\n",
            "Epoch: 51 | Batch_idx: 100 |  Loss: (0.2266) | Acc: (92.13%) (11911/12928)\n",
            "Epoch: 51 | Batch_idx: 110 |  Loss: (0.2255) | Acc: (92.22%) (13102/14208)\n",
            "Epoch: 51 | Batch_idx: 120 |  Loss: (0.2258) | Acc: (92.21%) (14281/15488)\n",
            "Epoch: 51 | Batch_idx: 130 |  Loss: (0.2267) | Acc: (92.16%) (15454/16768)\n",
            "Epoch: 51 | Batch_idx: 140 |  Loss: (0.2261) | Acc: (92.17%) (16635/18048)\n",
            "Epoch: 51 | Batch_idx: 150 |  Loss: (0.2251) | Acc: (92.21%) (17822/19328)\n",
            "Epoch: 51 | Batch_idx: 160 |  Loss: (0.2244) | Acc: (92.22%) (19005/20608)\n",
            "Epoch: 51 | Batch_idx: 170 |  Loss: (0.2239) | Acc: (92.24%) (20189/21888)\n",
            "Epoch: 51 | Batch_idx: 180 |  Loss: (0.2276) | Acc: (92.07%) (21330/23168)\n",
            "Epoch: 51 | Batch_idx: 190 |  Loss: (0.2284) | Acc: (92.04%) (22502/24448)\n",
            "Epoch: 51 | Batch_idx: 200 |  Loss: (0.2298) | Acc: (92.00%) (23671/25728)\n",
            "Epoch: 51 | Batch_idx: 210 |  Loss: (0.2303) | Acc: (91.92%) (24827/27008)\n",
            "Epoch: 51 | Batch_idx: 220 |  Loss: (0.2308) | Acc: (91.92%) (26002/28288)\n",
            "Epoch: 51 | Batch_idx: 230 |  Loss: (0.2322) | Acc: (91.91%) (27175/29568)\n",
            "Epoch: 51 | Batch_idx: 240 |  Loss: (0.2321) | Acc: (91.92%) (28355/30848)\n",
            "Epoch: 51 | Batch_idx: 250 |  Loss: (0.2318) | Acc: (91.94%) (29540/32128)\n",
            "Epoch: 51 | Batch_idx: 260 |  Loss: (0.2327) | Acc: (91.90%) (30703/33408)\n",
            "Epoch: 51 | Batch_idx: 270 |  Loss: (0.2332) | Acc: (91.89%) (31875/34688)\n",
            "Epoch: 51 | Batch_idx: 280 |  Loss: (0.2339) | Acc: (91.87%) (33044/35968)\n",
            "Epoch: 51 | Batch_idx: 290 |  Loss: (0.2333) | Acc: (91.88%) (34225/37248)\n",
            "Epoch: 51 | Batch_idx: 300 |  Loss: (0.2338) | Acc: (91.84%) (35386/38528)\n",
            "Epoch: 51 | Batch_idx: 310 |  Loss: (0.2332) | Acc: (91.87%) (36573/39808)\n",
            "Epoch: 51 | Batch_idx: 320 |  Loss: (0.2330) | Acc: (91.88%) (37752/41088)\n",
            "Epoch: 51 | Batch_idx: 330 |  Loss: (0.2340) | Acc: (91.83%) (38905/42368)\n",
            "Epoch: 51 | Batch_idx: 340 |  Loss: (0.2356) | Acc: (91.76%) (40052/43648)\n",
            "Epoch: 51 | Batch_idx: 350 |  Loss: (0.2367) | Acc: (91.70%) (41199/44928)\n",
            "Epoch: 51 | Batch_idx: 360 |  Loss: (0.2377) | Acc: (91.65%) (42349/46208)\n",
            "Epoch: 51 | Batch_idx: 370 |  Loss: (0.2387) | Acc: (91.63%) (43511/47488)\n",
            "Epoch: 51 | Batch_idx: 380 |  Loss: (0.2380) | Acc: (91.64%) (44693/48768)\n",
            "Epoch: 51 | Batch_idx: 390 |  Loss: (0.2380) | Acc: (91.63%) (45815/50000)\n",
            "# TEST : Loss: (0.4915) | Acc: (85.60%) (8560/10000)\n",
            "Epoch: 52 | Batch_idx: 0 |  Loss: (0.2769) | Acc: (90.62%) (116/128)\n",
            "Epoch: 52 | Batch_idx: 10 |  Loss: (0.2243) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 52 | Batch_idx: 20 |  Loss: (0.2323) | Acc: (91.70%) (2465/2688)\n",
            "Epoch: 52 | Batch_idx: 30 |  Loss: (0.2350) | Acc: (91.61%) (3635/3968)\n",
            "Epoch: 52 | Batch_idx: 40 |  Loss: (0.2422) | Acc: (91.56%) (4805/5248)\n",
            "Epoch: 52 | Batch_idx: 50 |  Loss: (0.2419) | Acc: (91.61%) (5980/6528)\n",
            "Epoch: 52 | Batch_idx: 60 |  Loss: (0.2350) | Acc: (91.73%) (7162/7808)\n",
            "Epoch: 52 | Batch_idx: 70 |  Loss: (0.2302) | Acc: (91.98%) (8359/9088)\n",
            "Epoch: 52 | Batch_idx: 80 |  Loss: (0.2337) | Acc: (91.89%) (9527/10368)\n",
            "Epoch: 52 | Batch_idx: 90 |  Loss: (0.2353) | Acc: (91.85%) (10699/11648)\n",
            "Epoch: 52 | Batch_idx: 100 |  Loss: (0.2320) | Acc: (91.93%) (11885/12928)\n",
            "Epoch: 52 | Batch_idx: 110 |  Loss: (0.2352) | Acc: (91.79%) (13041/14208)\n",
            "Epoch: 52 | Batch_idx: 120 |  Loss: (0.2370) | Acc: (91.67%) (14198/15488)\n",
            "Epoch: 52 | Batch_idx: 130 |  Loss: (0.2374) | Acc: (91.65%) (15368/16768)\n",
            "Epoch: 52 | Batch_idx: 140 |  Loss: (0.2367) | Acc: (91.67%) (16545/18048)\n",
            "Epoch: 52 | Batch_idx: 150 |  Loss: (0.2353) | Acc: (91.74%) (17731/19328)\n",
            "Epoch: 52 | Batch_idx: 160 |  Loss: (0.2348) | Acc: (91.76%) (18909/20608)\n",
            "Epoch: 52 | Batch_idx: 170 |  Loss: (0.2342) | Acc: (91.77%) (20087/21888)\n",
            "Epoch: 52 | Batch_idx: 180 |  Loss: (0.2335) | Acc: (91.81%) (21270/23168)\n",
            "Epoch: 52 | Batch_idx: 190 |  Loss: (0.2320) | Acc: (91.86%) (22457/24448)\n",
            "Epoch: 52 | Batch_idx: 200 |  Loss: (0.2323) | Acc: (91.84%) (23629/25728)\n",
            "Epoch: 52 | Batch_idx: 210 |  Loss: (0.2315) | Acc: (91.88%) (24815/27008)\n",
            "Epoch: 52 | Batch_idx: 220 |  Loss: (0.2317) | Acc: (91.88%) (25991/28288)\n",
            "Epoch: 52 | Batch_idx: 230 |  Loss: (0.2330) | Acc: (91.84%) (27156/29568)\n",
            "Epoch: 52 | Batch_idx: 240 |  Loss: (0.2335) | Acc: (91.83%) (28328/30848)\n",
            "Epoch: 52 | Batch_idx: 250 |  Loss: (0.2335) | Acc: (91.81%) (29496/32128)\n",
            "Epoch: 52 | Batch_idx: 260 |  Loss: (0.2339) | Acc: (91.80%) (30668/33408)\n",
            "Epoch: 52 | Batch_idx: 270 |  Loss: (0.2336) | Acc: (91.80%) (31845/34688)\n",
            "Epoch: 52 | Batch_idx: 280 |  Loss: (0.2331) | Acc: (91.84%) (33032/35968)\n",
            "Epoch: 52 | Batch_idx: 290 |  Loss: (0.2342) | Acc: (91.81%) (34199/37248)\n",
            "Epoch: 52 | Batch_idx: 300 |  Loss: (0.2339) | Acc: (91.83%) (35381/38528)\n",
            "Epoch: 52 | Batch_idx: 310 |  Loss: (0.2340) | Acc: (91.82%) (36551/39808)\n",
            "Epoch: 52 | Batch_idx: 320 |  Loss: (0.2344) | Acc: (91.80%) (37717/41088)\n",
            "Epoch: 52 | Batch_idx: 330 |  Loss: (0.2346) | Acc: (91.79%) (38891/42368)\n",
            "Epoch: 52 | Batch_idx: 340 |  Loss: (0.2345) | Acc: (91.78%) (40060/43648)\n",
            "Epoch: 52 | Batch_idx: 350 |  Loss: (0.2343) | Acc: (91.77%) (41231/44928)\n",
            "Epoch: 52 | Batch_idx: 360 |  Loss: (0.2352) | Acc: (91.74%) (42389/46208)\n",
            "Epoch: 52 | Batch_idx: 370 |  Loss: (0.2350) | Acc: (91.76%) (43575/47488)\n",
            "Epoch: 52 | Batch_idx: 380 |  Loss: (0.2353) | Acc: (91.74%) (44741/48768)\n",
            "Epoch: 52 | Batch_idx: 390 |  Loss: (0.2359) | Acc: (91.71%) (45857/50000)\n",
            "# TEST : Loss: (0.4632) | Acc: (85.76%) (8576/10000)\n",
            "Epoch: 53 | Batch_idx: 0 |  Loss: (0.2188) | Acc: (92.19%) (118/128)\n",
            "Epoch: 53 | Batch_idx: 10 |  Loss: (0.2267) | Acc: (91.62%) (1290/1408)\n",
            "Epoch: 53 | Batch_idx: 20 |  Loss: (0.2312) | Acc: (91.33%) (2455/2688)\n",
            "Epoch: 53 | Batch_idx: 30 |  Loss: (0.2311) | Acc: (91.58%) (3634/3968)\n",
            "Epoch: 53 | Batch_idx: 40 |  Loss: (0.2411) | Acc: (91.67%) (4811/5248)\n",
            "Epoch: 53 | Batch_idx: 50 |  Loss: (0.2380) | Acc: (91.84%) (5995/6528)\n",
            "Epoch: 53 | Batch_idx: 60 |  Loss: (0.2369) | Acc: (91.88%) (7174/7808)\n",
            "Epoch: 53 | Batch_idx: 70 |  Loss: (0.2400) | Acc: (91.75%) (8338/9088)\n",
            "Epoch: 53 | Batch_idx: 80 |  Loss: (0.2379) | Acc: (91.71%) (9509/10368)\n",
            "Epoch: 53 | Batch_idx: 90 |  Loss: (0.2342) | Acc: (91.83%) (10696/11648)\n",
            "Epoch: 53 | Batch_idx: 100 |  Loss: (0.2318) | Acc: (91.92%) (11883/12928)\n",
            "Epoch: 53 | Batch_idx: 110 |  Loss: (0.2305) | Acc: (91.91%) (13058/14208)\n",
            "Epoch: 53 | Batch_idx: 120 |  Loss: (0.2284) | Acc: (92.01%) (14250/15488)\n",
            "Epoch: 53 | Batch_idx: 130 |  Loss: (0.2283) | Acc: (92.00%) (15427/16768)\n",
            "Epoch: 53 | Batch_idx: 140 |  Loss: (0.2285) | Acc: (91.99%) (16602/18048)\n",
            "Epoch: 53 | Batch_idx: 150 |  Loss: (0.2289) | Acc: (91.97%) (17776/19328)\n",
            "Epoch: 53 | Batch_idx: 160 |  Loss: (0.2305) | Acc: (91.91%) (18940/20608)\n",
            "Epoch: 53 | Batch_idx: 170 |  Loss: (0.2306) | Acc: (91.89%) (20113/21888)\n",
            "Epoch: 53 | Batch_idx: 180 |  Loss: (0.2308) | Acc: (91.89%) (21288/23168)\n",
            "Epoch: 53 | Batch_idx: 190 |  Loss: (0.2318) | Acc: (91.83%) (22451/24448)\n",
            "Epoch: 53 | Batch_idx: 200 |  Loss: (0.2332) | Acc: (91.81%) (23621/25728)\n",
            "Epoch: 53 | Batch_idx: 210 |  Loss: (0.2353) | Acc: (91.79%) (24790/27008)\n",
            "Epoch: 53 | Batch_idx: 220 |  Loss: (0.2338) | Acc: (91.81%) (25971/28288)\n",
            "Epoch: 53 | Batch_idx: 230 |  Loss: (0.2349) | Acc: (91.76%) (27131/29568)\n",
            "Epoch: 53 | Batch_idx: 240 |  Loss: (0.2344) | Acc: (91.78%) (28313/30848)\n",
            "Epoch: 53 | Batch_idx: 250 |  Loss: (0.2337) | Acc: (91.79%) (29491/32128)\n",
            "Epoch: 53 | Batch_idx: 260 |  Loss: (0.2333) | Acc: (91.83%) (30678/33408)\n",
            "Epoch: 53 | Batch_idx: 270 |  Loss: (0.2338) | Acc: (91.84%) (31856/34688)\n",
            "Epoch: 53 | Batch_idx: 280 |  Loss: (0.2331) | Acc: (91.83%) (33031/35968)\n",
            "Epoch: 53 | Batch_idx: 290 |  Loss: (0.2338) | Acc: (91.81%) (34196/37248)\n",
            "Epoch: 53 | Batch_idx: 300 |  Loss: (0.2334) | Acc: (91.81%) (35374/38528)\n",
            "Epoch: 53 | Batch_idx: 310 |  Loss: (0.2338) | Acc: (91.79%) (36539/39808)\n",
            "Epoch: 53 | Batch_idx: 320 |  Loss: (0.2336) | Acc: (91.81%) (37722/41088)\n",
            "Epoch: 53 | Batch_idx: 330 |  Loss: (0.2337) | Acc: (91.81%) (38900/42368)\n",
            "Epoch: 53 | Batch_idx: 340 |  Loss: (0.2339) | Acc: (91.82%) (40076/43648)\n",
            "Epoch: 53 | Batch_idx: 350 |  Loss: (0.2346) | Acc: (91.82%) (41252/44928)\n",
            "Epoch: 53 | Batch_idx: 360 |  Loss: (0.2361) | Acc: (91.73%) (42385/46208)\n",
            "Epoch: 53 | Batch_idx: 370 |  Loss: (0.2361) | Acc: (91.72%) (43555/47488)\n",
            "Epoch: 53 | Batch_idx: 380 |  Loss: (0.2365) | Acc: (91.70%) (44721/48768)\n",
            "Epoch: 53 | Batch_idx: 390 |  Loss: (0.2371) | Acc: (91.69%) (45843/50000)\n",
            "# TEST : Loss: (0.4387) | Acc: (86.66%) (8666/10000)\n",
            "Epoch: 54 | Batch_idx: 0 |  Loss: (0.2732) | Acc: (88.28%) (113/128)\n",
            "Epoch: 54 | Batch_idx: 10 |  Loss: (0.2230) | Acc: (91.83%) (1293/1408)\n",
            "Epoch: 54 | Batch_idx: 20 |  Loss: (0.2252) | Acc: (92.00%) (2473/2688)\n",
            "Epoch: 54 | Batch_idx: 30 |  Loss: (0.2175) | Acc: (92.19%) (3658/3968)\n",
            "Epoch: 54 | Batch_idx: 40 |  Loss: (0.2096) | Acc: (92.42%) (4850/5248)\n",
            "Epoch: 54 | Batch_idx: 50 |  Loss: (0.2122) | Acc: (92.45%) (6035/6528)\n",
            "Epoch: 54 | Batch_idx: 60 |  Loss: (0.2115) | Acc: (92.56%) (7227/7808)\n",
            "Epoch: 54 | Batch_idx: 70 |  Loss: (0.2142) | Acc: (92.54%) (8410/9088)\n",
            "Epoch: 54 | Batch_idx: 80 |  Loss: (0.2160) | Acc: (92.47%) (9587/10368)\n",
            "Epoch: 54 | Batch_idx: 90 |  Loss: (0.2162) | Acc: (92.43%) (10766/11648)\n",
            "Epoch: 54 | Batch_idx: 100 |  Loss: (0.2146) | Acc: (92.51%) (11960/12928)\n",
            "Epoch: 54 | Batch_idx: 110 |  Loss: (0.2181) | Acc: (92.28%) (13111/14208)\n",
            "Epoch: 54 | Batch_idx: 120 |  Loss: (0.2199) | Acc: (92.17%) (14275/15488)\n",
            "Epoch: 54 | Batch_idx: 130 |  Loss: (0.2197) | Acc: (92.16%) (15454/16768)\n",
            "Epoch: 54 | Batch_idx: 140 |  Loss: (0.2199) | Acc: (92.14%) (16630/18048)\n",
            "Epoch: 54 | Batch_idx: 150 |  Loss: (0.2217) | Acc: (92.06%) (17793/19328)\n",
            "Epoch: 54 | Batch_idx: 160 |  Loss: (0.2223) | Acc: (92.02%) (18963/20608)\n",
            "Epoch: 54 | Batch_idx: 170 |  Loss: (0.2230) | Acc: (92.03%) (20143/21888)\n",
            "Epoch: 54 | Batch_idx: 180 |  Loss: (0.2235) | Acc: (92.05%) (21326/23168)\n",
            "Epoch: 54 | Batch_idx: 190 |  Loss: (0.2237) | Acc: (92.02%) (22498/24448)\n",
            "Epoch: 54 | Batch_idx: 200 |  Loss: (0.2241) | Acc: (92.01%) (23672/25728)\n",
            "Epoch: 54 | Batch_idx: 210 |  Loss: (0.2252) | Acc: (91.97%) (24839/27008)\n",
            "Epoch: 54 | Batch_idx: 220 |  Loss: (0.2266) | Acc: (91.94%) (26007/28288)\n",
            "Epoch: 54 | Batch_idx: 230 |  Loss: (0.2266) | Acc: (91.96%) (27191/29568)\n",
            "Epoch: 54 | Batch_idx: 240 |  Loss: (0.2260) | Acc: (91.98%) (28375/30848)\n",
            "Epoch: 54 | Batch_idx: 250 |  Loss: (0.2257) | Acc: (91.99%) (29555/32128)\n",
            "Epoch: 54 | Batch_idx: 260 |  Loss: (0.2252) | Acc: (92.03%) (30746/33408)\n",
            "Epoch: 54 | Batch_idx: 270 |  Loss: (0.2260) | Acc: (91.99%) (31910/34688)\n",
            "Epoch: 54 | Batch_idx: 280 |  Loss: (0.2267) | Acc: (91.98%) (33084/35968)\n",
            "Epoch: 54 | Batch_idx: 290 |  Loss: (0.2277) | Acc: (91.90%) (34230/37248)\n",
            "Epoch: 54 | Batch_idx: 300 |  Loss: (0.2282) | Acc: (91.90%) (35409/38528)\n",
            "Epoch: 54 | Batch_idx: 310 |  Loss: (0.2291) | Acc: (91.87%) (36571/39808)\n",
            "Epoch: 54 | Batch_idx: 320 |  Loss: (0.2295) | Acc: (91.86%) (37744/41088)\n",
            "Epoch: 54 | Batch_idx: 330 |  Loss: (0.2298) | Acc: (91.87%) (38924/42368)\n",
            "Epoch: 54 | Batch_idx: 340 |  Loss: (0.2302) | Acc: (91.85%) (40090/43648)\n",
            "Epoch: 54 | Batch_idx: 350 |  Loss: (0.2304) | Acc: (91.84%) (41263/44928)\n",
            "Epoch: 54 | Batch_idx: 360 |  Loss: (0.2300) | Acc: (91.85%) (42443/46208)\n",
            "Epoch: 54 | Batch_idx: 370 |  Loss: (0.2301) | Acc: (91.84%) (43615/47488)\n",
            "Epoch: 54 | Batch_idx: 380 |  Loss: (0.2304) | Acc: (91.86%) (44797/48768)\n",
            "Epoch: 54 | Batch_idx: 390 |  Loss: (0.2308) | Acc: (91.85%) (45924/50000)\n",
            "# TEST : Loss: (0.4215) | Acc: (86.93%) (8693/10000)\n",
            "Epoch: 55 | Batch_idx: 0 |  Loss: (0.1990) | Acc: (92.19%) (118/128)\n",
            "Epoch: 55 | Batch_idx: 10 |  Loss: (0.2133) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 55 | Batch_idx: 20 |  Loss: (0.2332) | Acc: (91.59%) (2462/2688)\n",
            "Epoch: 55 | Batch_idx: 30 |  Loss: (0.2234) | Acc: (92.11%) (3655/3968)\n",
            "Epoch: 55 | Batch_idx: 40 |  Loss: (0.2236) | Acc: (92.11%) (4834/5248)\n",
            "Epoch: 55 | Batch_idx: 50 |  Loss: (0.2230) | Acc: (92.14%) (6015/6528)\n",
            "Epoch: 55 | Batch_idx: 60 |  Loss: (0.2256) | Acc: (92.14%) (7194/7808)\n",
            "Epoch: 55 | Batch_idx: 70 |  Loss: (0.2271) | Acc: (92.07%) (8367/9088)\n",
            "Epoch: 55 | Batch_idx: 80 |  Loss: (0.2257) | Acc: (92.12%) (9551/10368)\n",
            "Epoch: 55 | Batch_idx: 90 |  Loss: (0.2292) | Acc: (91.97%) (10713/11648)\n",
            "Epoch: 55 | Batch_idx: 100 |  Loss: (0.2284) | Acc: (92.02%) (11896/12928)\n",
            "Epoch: 55 | Batch_idx: 110 |  Loss: (0.2315) | Acc: (91.88%) (13055/14208)\n",
            "Epoch: 55 | Batch_idx: 120 |  Loss: (0.2311) | Acc: (91.90%) (14234/15488)\n",
            "Epoch: 55 | Batch_idx: 130 |  Loss: (0.2288) | Acc: (91.93%) (15415/16768)\n",
            "Epoch: 55 | Batch_idx: 140 |  Loss: (0.2285) | Acc: (91.89%) (16585/18048)\n",
            "Epoch: 55 | Batch_idx: 150 |  Loss: (0.2297) | Acc: (91.86%) (17754/19328)\n",
            "Epoch: 55 | Batch_idx: 160 |  Loss: (0.2299) | Acc: (91.88%) (18934/20608)\n",
            "Epoch: 55 | Batch_idx: 170 |  Loss: (0.2302) | Acc: (91.87%) (20108/21888)\n",
            "Epoch: 55 | Batch_idx: 180 |  Loss: (0.2321) | Acc: (91.80%) (21269/23168)\n",
            "Epoch: 55 | Batch_idx: 190 |  Loss: (0.2307) | Acc: (91.89%) (22465/24448)\n",
            "Epoch: 55 | Batch_idx: 200 |  Loss: (0.2317) | Acc: (91.88%) (23638/25728)\n",
            "Epoch: 55 | Batch_idx: 210 |  Loss: (0.2311) | Acc: (91.90%) (24821/27008)\n",
            "Epoch: 55 | Batch_idx: 220 |  Loss: (0.2309) | Acc: (91.87%) (25988/28288)\n",
            "Epoch: 55 | Batch_idx: 230 |  Loss: (0.2307) | Acc: (91.91%) (27175/29568)\n",
            "Epoch: 55 | Batch_idx: 240 |  Loss: (0.2308) | Acc: (91.93%) (28360/30848)\n",
            "Epoch: 55 | Batch_idx: 250 |  Loss: (0.2316) | Acc: (91.88%) (29520/32128)\n",
            "Epoch: 55 | Batch_idx: 260 |  Loss: (0.2318) | Acc: (91.90%) (30701/33408)\n",
            "Epoch: 55 | Batch_idx: 270 |  Loss: (0.2321) | Acc: (91.88%) (31870/34688)\n",
            "Epoch: 55 | Batch_idx: 280 |  Loss: (0.2332) | Acc: (91.83%) (33029/35968)\n",
            "Epoch: 55 | Batch_idx: 290 |  Loss: (0.2339) | Acc: (91.82%) (34202/37248)\n",
            "Epoch: 55 | Batch_idx: 300 |  Loss: (0.2343) | Acc: (91.80%) (35369/38528)\n",
            "Epoch: 55 | Batch_idx: 310 |  Loss: (0.2343) | Acc: (91.80%) (36542/39808)\n",
            "Epoch: 55 | Batch_idx: 320 |  Loss: (0.2347) | Acc: (91.79%) (37713/41088)\n",
            "Epoch: 55 | Batch_idx: 330 |  Loss: (0.2351) | Acc: (91.78%) (38884/42368)\n",
            "Epoch: 55 | Batch_idx: 340 |  Loss: (0.2352) | Acc: (91.75%) (40049/43648)\n",
            "Epoch: 55 | Batch_idx: 350 |  Loss: (0.2345) | Acc: (91.80%) (41246/44928)\n",
            "Epoch: 55 | Batch_idx: 360 |  Loss: (0.2347) | Acc: (91.82%) (42426/46208)\n",
            "Epoch: 55 | Batch_idx: 370 |  Loss: (0.2347) | Acc: (91.82%) (43605/47488)\n",
            "Epoch: 55 | Batch_idx: 380 |  Loss: (0.2350) | Acc: (91.80%) (44767/48768)\n",
            "Epoch: 55 | Batch_idx: 390 |  Loss: (0.2346) | Acc: (91.82%) (45910/50000)\n",
            "# TEST : Loss: (0.3900) | Acc: (87.64%) (8764/10000)\n",
            "Epoch: 56 | Batch_idx: 0 |  Loss: (0.2265) | Acc: (95.31%) (122/128)\n",
            "Epoch: 56 | Batch_idx: 10 |  Loss: (0.2121) | Acc: (92.61%) (1304/1408)\n",
            "Epoch: 56 | Batch_idx: 20 |  Loss: (0.2031) | Acc: (93.01%) (2500/2688)\n",
            "Epoch: 56 | Batch_idx: 30 |  Loss: (0.2062) | Acc: (92.89%) (3686/3968)\n",
            "Epoch: 56 | Batch_idx: 40 |  Loss: (0.2091) | Acc: (92.74%) (4867/5248)\n",
            "Epoch: 56 | Batch_idx: 50 |  Loss: (0.2101) | Acc: (92.77%) (6056/6528)\n",
            "Epoch: 56 | Batch_idx: 60 |  Loss: (0.2131) | Acc: (92.55%) (7226/7808)\n",
            "Epoch: 56 | Batch_idx: 70 |  Loss: (0.2138) | Acc: (92.53%) (8409/9088)\n",
            "Epoch: 56 | Batch_idx: 80 |  Loss: (0.2131) | Acc: (92.44%) (9584/10368)\n",
            "Epoch: 56 | Batch_idx: 90 |  Loss: (0.2150) | Acc: (92.33%) (10755/11648)\n",
            "Epoch: 56 | Batch_idx: 100 |  Loss: (0.2158) | Acc: (92.37%) (11942/12928)\n",
            "Epoch: 56 | Batch_idx: 110 |  Loss: (0.2161) | Acc: (92.45%) (13136/14208)\n",
            "Epoch: 56 | Batch_idx: 120 |  Loss: (0.2185) | Acc: (92.37%) (14306/15488)\n",
            "Epoch: 56 | Batch_idx: 130 |  Loss: (0.2227) | Acc: (92.24%) (15467/16768)\n",
            "Epoch: 56 | Batch_idx: 140 |  Loss: (0.2231) | Acc: (92.24%) (16648/18048)\n",
            "Epoch: 56 | Batch_idx: 150 |  Loss: (0.2229) | Acc: (92.23%) (17826/19328)\n",
            "Epoch: 56 | Batch_idx: 160 |  Loss: (0.2256) | Acc: (92.15%) (18991/20608)\n",
            "Epoch: 56 | Batch_idx: 170 |  Loss: (0.2251) | Acc: (92.14%) (20167/21888)\n",
            "Epoch: 56 | Batch_idx: 180 |  Loss: (0.2259) | Acc: (92.13%) (21344/23168)\n",
            "Epoch: 56 | Batch_idx: 190 |  Loss: (0.2255) | Acc: (92.20%) (22540/24448)\n",
            "Epoch: 56 | Batch_idx: 200 |  Loss: (0.2246) | Acc: (92.24%) (23731/25728)\n",
            "Epoch: 56 | Batch_idx: 210 |  Loss: (0.2253) | Acc: (92.24%) (24913/27008)\n",
            "Epoch: 56 | Batch_idx: 220 |  Loss: (0.2253) | Acc: (92.23%) (26091/28288)\n",
            "Epoch: 56 | Batch_idx: 230 |  Loss: (0.2258) | Acc: (92.20%) (27263/29568)\n",
            "Epoch: 56 | Batch_idx: 240 |  Loss: (0.2259) | Acc: (92.19%) (28440/30848)\n",
            "Epoch: 56 | Batch_idx: 250 |  Loss: (0.2260) | Acc: (92.17%) (29612/32128)\n",
            "Epoch: 56 | Batch_idx: 260 |  Loss: (0.2275) | Acc: (92.13%) (30779/33408)\n",
            "Epoch: 56 | Batch_idx: 270 |  Loss: (0.2277) | Acc: (92.13%) (31959/34688)\n",
            "Epoch: 56 | Batch_idx: 280 |  Loss: (0.2273) | Acc: (92.13%) (33136/35968)\n",
            "Epoch: 56 | Batch_idx: 290 |  Loss: (0.2276) | Acc: (92.09%) (34302/37248)\n",
            "Epoch: 56 | Batch_idx: 300 |  Loss: (0.2276) | Acc: (92.09%) (35479/38528)\n",
            "Epoch: 56 | Batch_idx: 310 |  Loss: (0.2288) | Acc: (92.04%) (36641/39808)\n",
            "Epoch: 56 | Batch_idx: 320 |  Loss: (0.2290) | Acc: (92.01%) (37805/41088)\n",
            "Epoch: 56 | Batch_idx: 330 |  Loss: (0.2299) | Acc: (91.99%) (38975/42368)\n",
            "Epoch: 56 | Batch_idx: 340 |  Loss: (0.2316) | Acc: (91.95%) (40134/43648)\n",
            "Epoch: 56 | Batch_idx: 350 |  Loss: (0.2325) | Acc: (91.95%) (41312/44928)\n",
            "Epoch: 56 | Batch_idx: 360 |  Loss: (0.2327) | Acc: (91.93%) (42481/46208)\n",
            "Epoch: 56 | Batch_idx: 370 |  Loss: (0.2321) | Acc: (91.95%) (43665/47488)\n",
            "Epoch: 56 | Batch_idx: 380 |  Loss: (0.2324) | Acc: (91.93%) (44831/48768)\n",
            "Epoch: 56 | Batch_idx: 390 |  Loss: (0.2326) | Acc: (91.93%) (45963/50000)\n",
            "# TEST : Loss: (0.5357) | Acc: (84.92%) (8492/10000)\n",
            "Epoch: 57 | Batch_idx: 0 |  Loss: (0.2441) | Acc: (92.97%) (119/128)\n",
            "Epoch: 57 | Batch_idx: 10 |  Loss: (0.1953) | Acc: (93.04%) (1310/1408)\n",
            "Epoch: 57 | Batch_idx: 20 |  Loss: (0.2031) | Acc: (92.75%) (2493/2688)\n",
            "Epoch: 57 | Batch_idx: 30 |  Loss: (0.2102) | Acc: (92.49%) (3670/3968)\n",
            "Epoch: 57 | Batch_idx: 40 |  Loss: (0.2133) | Acc: (92.30%) (4844/5248)\n",
            "Epoch: 57 | Batch_idx: 50 |  Loss: (0.2139) | Acc: (92.42%) (6033/6528)\n",
            "Epoch: 57 | Batch_idx: 60 |  Loss: (0.2141) | Acc: (92.41%) (7215/7808)\n",
            "Epoch: 57 | Batch_idx: 70 |  Loss: (0.2155) | Acc: (92.42%) (8399/9088)\n",
            "Epoch: 57 | Batch_idx: 80 |  Loss: (0.2139) | Acc: (92.46%) (9586/10368)\n",
            "Epoch: 57 | Batch_idx: 90 |  Loss: (0.2177) | Acc: (92.30%) (10751/11648)\n",
            "Epoch: 57 | Batch_idx: 100 |  Loss: (0.2184) | Acc: (92.27%) (11929/12928)\n",
            "Epoch: 57 | Batch_idx: 110 |  Loss: (0.2183) | Acc: (92.36%) (13122/14208)\n",
            "Epoch: 57 | Batch_idx: 120 |  Loss: (0.2219) | Acc: (92.18%) (14277/15488)\n",
            "Epoch: 57 | Batch_idx: 130 |  Loss: (0.2221) | Acc: (92.17%) (15455/16768)\n",
            "Epoch: 57 | Batch_idx: 140 |  Loss: (0.2224) | Acc: (92.19%) (16638/18048)\n",
            "Epoch: 57 | Batch_idx: 150 |  Loss: (0.2227) | Acc: (92.20%) (17820/19328)\n",
            "Epoch: 57 | Batch_idx: 160 |  Loss: (0.2220) | Acc: (92.23%) (19006/20608)\n",
            "Epoch: 57 | Batch_idx: 170 |  Loss: (0.2234) | Acc: (92.15%) (20170/21888)\n",
            "Epoch: 57 | Batch_idx: 180 |  Loss: (0.2235) | Acc: (92.14%) (21347/23168)\n",
            "Epoch: 57 | Batch_idx: 190 |  Loss: (0.2245) | Acc: (92.10%) (22516/24448)\n",
            "Epoch: 57 | Batch_idx: 200 |  Loss: (0.2236) | Acc: (92.13%) (23703/25728)\n",
            "Epoch: 57 | Batch_idx: 210 |  Loss: (0.2248) | Acc: (92.07%) (24866/27008)\n",
            "Epoch: 57 | Batch_idx: 220 |  Loss: (0.2246) | Acc: (92.07%) (26046/28288)\n",
            "Epoch: 57 | Batch_idx: 230 |  Loss: (0.2259) | Acc: (92.05%) (27217/29568)\n",
            "Epoch: 57 | Batch_idx: 240 |  Loss: (0.2266) | Acc: (92.04%) (28394/30848)\n",
            "Epoch: 57 | Batch_idx: 250 |  Loss: (0.2269) | Acc: (92.04%) (29571/32128)\n",
            "Epoch: 57 | Batch_idx: 260 |  Loss: (0.2276) | Acc: (92.02%) (30743/33408)\n",
            "Epoch: 57 | Batch_idx: 270 |  Loss: (0.2293) | Acc: (91.94%) (31891/34688)\n",
            "Epoch: 57 | Batch_idx: 280 |  Loss: (0.2297) | Acc: (91.92%) (33060/35968)\n",
            "Epoch: 57 | Batch_idx: 290 |  Loss: (0.2298) | Acc: (91.94%) (34245/37248)\n",
            "Epoch: 57 | Batch_idx: 300 |  Loss: (0.2298) | Acc: (91.92%) (35416/38528)\n",
            "Epoch: 57 | Batch_idx: 310 |  Loss: (0.2302) | Acc: (91.93%) (36594/39808)\n",
            "Epoch: 57 | Batch_idx: 320 |  Loss: (0.2307) | Acc: (91.89%) (37757/41088)\n",
            "Epoch: 57 | Batch_idx: 330 |  Loss: (0.2311) | Acc: (91.89%) (38930/42368)\n",
            "Epoch: 57 | Batch_idx: 340 |  Loss: (0.2307) | Acc: (91.91%) (40116/43648)\n",
            "Epoch: 57 | Batch_idx: 350 |  Loss: (0.2312) | Acc: (91.88%) (41282/44928)\n",
            "Epoch: 57 | Batch_idx: 360 |  Loss: (0.2315) | Acc: (91.87%) (42450/46208)\n",
            "Epoch: 57 | Batch_idx: 370 |  Loss: (0.2311) | Acc: (91.87%) (43629/47488)\n",
            "Epoch: 57 | Batch_idx: 380 |  Loss: (0.2312) | Acc: (91.87%) (44803/48768)\n",
            "Epoch: 57 | Batch_idx: 390 |  Loss: (0.2312) | Acc: (91.88%) (45940/50000)\n",
            "# TEST : Loss: (0.4465) | Acc: (86.00%) (8600/10000)\n",
            "Epoch: 58 | Batch_idx: 0 |  Loss: (0.1696) | Acc: (95.31%) (122/128)\n",
            "Epoch: 58 | Batch_idx: 10 |  Loss: (0.2060) | Acc: (93.47%) (1316/1408)\n",
            "Epoch: 58 | Batch_idx: 20 |  Loss: (0.2141) | Acc: (92.56%) (2488/2688)\n",
            "Epoch: 58 | Batch_idx: 30 |  Loss: (0.2103) | Acc: (93.02%) (3691/3968)\n",
            "Epoch: 58 | Batch_idx: 40 |  Loss: (0.2122) | Acc: (92.80%) (4870/5248)\n",
            "Epoch: 58 | Batch_idx: 50 |  Loss: (0.2112) | Acc: (92.91%) (6065/6528)\n",
            "Epoch: 58 | Batch_idx: 60 |  Loss: (0.2102) | Acc: (92.71%) (7239/7808)\n",
            "Epoch: 58 | Batch_idx: 70 |  Loss: (0.2162) | Acc: (92.64%) (8419/9088)\n",
            "Epoch: 58 | Batch_idx: 80 |  Loss: (0.2144) | Acc: (92.70%) (9611/10368)\n",
            "Epoch: 58 | Batch_idx: 90 |  Loss: (0.2173) | Acc: (92.45%) (10768/11648)\n",
            "Epoch: 58 | Batch_idx: 100 |  Loss: (0.2189) | Acc: (92.29%) (11931/12928)\n",
            "Epoch: 58 | Batch_idx: 110 |  Loss: (0.2195) | Acc: (92.33%) (13118/14208)\n",
            "Epoch: 58 | Batch_idx: 120 |  Loss: (0.2192) | Acc: (92.32%) (14299/15488)\n",
            "Epoch: 58 | Batch_idx: 130 |  Loss: (0.2184) | Acc: (92.37%) (15489/16768)\n",
            "Epoch: 58 | Batch_idx: 140 |  Loss: (0.2188) | Acc: (92.33%) (16664/18048)\n",
            "Epoch: 58 | Batch_idx: 150 |  Loss: (0.2169) | Acc: (92.38%) (17856/19328)\n",
            "Epoch: 58 | Batch_idx: 160 |  Loss: (0.2162) | Acc: (92.46%) (19055/20608)\n",
            "Epoch: 58 | Batch_idx: 170 |  Loss: (0.2180) | Acc: (92.43%) (20231/21888)\n",
            "Epoch: 58 | Batch_idx: 180 |  Loss: (0.2207) | Acc: (92.34%) (21393/23168)\n",
            "Epoch: 58 | Batch_idx: 190 |  Loss: (0.2222) | Acc: (92.26%) (22556/24448)\n",
            "Epoch: 58 | Batch_idx: 200 |  Loss: (0.2226) | Acc: (92.26%) (23736/25728)\n",
            "Epoch: 58 | Batch_idx: 210 |  Loss: (0.2221) | Acc: (92.23%) (24909/27008)\n",
            "Epoch: 58 | Batch_idx: 220 |  Loss: (0.2229) | Acc: (92.17%) (26074/28288)\n",
            "Epoch: 58 | Batch_idx: 230 |  Loss: (0.2245) | Acc: (92.11%) (27236/29568)\n",
            "Epoch: 58 | Batch_idx: 240 |  Loss: (0.2251) | Acc: (92.08%) (28405/30848)\n",
            "Epoch: 58 | Batch_idx: 250 |  Loss: (0.2256) | Acc: (92.03%) (29567/32128)\n",
            "Epoch: 58 | Batch_idx: 260 |  Loss: (0.2270) | Acc: (91.97%) (30725/33408)\n",
            "Epoch: 58 | Batch_idx: 270 |  Loss: (0.2286) | Acc: (91.90%) (31879/34688)\n",
            "Epoch: 58 | Batch_idx: 280 |  Loss: (0.2295) | Acc: (91.88%) (33047/35968)\n",
            "Epoch: 58 | Batch_idx: 290 |  Loss: (0.2303) | Acc: (91.86%) (34215/37248)\n",
            "Epoch: 58 | Batch_idx: 300 |  Loss: (0.2320) | Acc: (91.82%) (35378/38528)\n",
            "Epoch: 58 | Batch_idx: 310 |  Loss: (0.2317) | Acc: (91.83%) (36556/39808)\n",
            "Epoch: 58 | Batch_idx: 320 |  Loss: (0.2319) | Acc: (91.82%) (37725/41088)\n",
            "Epoch: 58 | Batch_idx: 330 |  Loss: (0.2317) | Acc: (91.82%) (38901/42368)\n",
            "Epoch: 58 | Batch_idx: 340 |  Loss: (0.2315) | Acc: (91.81%) (40074/43648)\n",
            "Epoch: 58 | Batch_idx: 350 |  Loss: (0.2316) | Acc: (91.83%) (41256/44928)\n",
            "Epoch: 58 | Batch_idx: 360 |  Loss: (0.2304) | Acc: (91.86%) (42445/46208)\n",
            "Epoch: 58 | Batch_idx: 370 |  Loss: (0.2307) | Acc: (91.85%) (43619/47488)\n",
            "Epoch: 58 | Batch_idx: 380 |  Loss: (0.2308) | Acc: (91.84%) (44788/48768)\n",
            "Epoch: 58 | Batch_idx: 390 |  Loss: (0.2313) | Acc: (91.83%) (45917/50000)\n",
            "# TEST : Loss: (0.4379) | Acc: (86.43%) (8643/10000)\n",
            "Epoch: 59 | Batch_idx: 0 |  Loss: (0.2077) | Acc: (89.06%) (114/128)\n",
            "Epoch: 59 | Batch_idx: 10 |  Loss: (0.2202) | Acc: (91.55%) (1289/1408)\n",
            "Epoch: 59 | Batch_idx: 20 |  Loss: (0.2185) | Acc: (91.82%) (2468/2688)\n",
            "Epoch: 59 | Batch_idx: 30 |  Loss: (0.2193) | Acc: (91.99%) (3650/3968)\n",
            "Epoch: 59 | Batch_idx: 40 |  Loss: (0.2153) | Acc: (92.15%) (4836/5248)\n",
            "Epoch: 59 | Batch_idx: 50 |  Loss: (0.2225) | Acc: (91.94%) (6002/6528)\n",
            "Epoch: 59 | Batch_idx: 60 |  Loss: (0.2258) | Acc: (91.94%) (7179/7808)\n",
            "Epoch: 59 | Batch_idx: 70 |  Loss: (0.2252) | Acc: (92.01%) (8362/9088)\n",
            "Epoch: 59 | Batch_idx: 80 |  Loss: (0.2247) | Acc: (91.96%) (9534/10368)\n",
            "Epoch: 59 | Batch_idx: 90 |  Loss: (0.2218) | Acc: (92.09%) (10727/11648)\n",
            "Epoch: 59 | Batch_idx: 100 |  Loss: (0.2235) | Acc: (92.09%) (11905/12928)\n",
            "Epoch: 59 | Batch_idx: 110 |  Loss: (0.2242) | Acc: (92.01%) (13073/14208)\n",
            "Epoch: 59 | Batch_idx: 120 |  Loss: (0.2225) | Acc: (92.07%) (14260/15488)\n",
            "Epoch: 59 | Batch_idx: 130 |  Loss: (0.2227) | Acc: (92.09%) (15441/16768)\n",
            "Epoch: 59 | Batch_idx: 140 |  Loss: (0.2223) | Acc: (92.09%) (16621/18048)\n",
            "Epoch: 59 | Batch_idx: 150 |  Loss: (0.2238) | Acc: (92.01%) (17784/19328)\n",
            "Epoch: 59 | Batch_idx: 160 |  Loss: (0.2239) | Acc: (92.04%) (18968/20608)\n",
            "Epoch: 59 | Batch_idx: 170 |  Loss: (0.2249) | Acc: (92.02%) (20142/21888)\n",
            "Epoch: 59 | Batch_idx: 180 |  Loss: (0.2279) | Acc: (91.91%) (21293/23168)\n",
            "Epoch: 59 | Batch_idx: 190 |  Loss: (0.2282) | Acc: (91.92%) (22472/24448)\n",
            "Epoch: 59 | Batch_idx: 200 |  Loss: (0.2291) | Acc: (91.90%) (23643/25728)\n",
            "Epoch: 59 | Batch_idx: 210 |  Loss: (0.2287) | Acc: (91.90%) (24821/27008)\n",
            "Epoch: 59 | Batch_idx: 220 |  Loss: (0.2280) | Acc: (91.91%) (25999/28288)\n",
            "Epoch: 59 | Batch_idx: 230 |  Loss: (0.2288) | Acc: (91.88%) (27167/29568)\n",
            "Epoch: 59 | Batch_idx: 240 |  Loss: (0.2291) | Acc: (91.89%) (28345/30848)\n",
            "Epoch: 59 | Batch_idx: 250 |  Loss: (0.2293) | Acc: (91.86%) (29513/32128)\n",
            "Epoch: 59 | Batch_idx: 260 |  Loss: (0.2292) | Acc: (91.88%) (30694/33408)\n",
            "Epoch: 59 | Batch_idx: 270 |  Loss: (0.2293) | Acc: (91.88%) (31871/34688)\n",
            "Epoch: 59 | Batch_idx: 280 |  Loss: (0.2299) | Acc: (91.84%) (33033/35968)\n",
            "Epoch: 59 | Batch_idx: 290 |  Loss: (0.2297) | Acc: (91.83%) (34206/37248)\n",
            "Epoch: 59 | Batch_idx: 300 |  Loss: (0.2309) | Acc: (91.81%) (35372/38528)\n",
            "Epoch: 59 | Batch_idx: 310 |  Loss: (0.2304) | Acc: (91.83%) (36555/39808)\n",
            "Epoch: 59 | Batch_idx: 320 |  Loss: (0.2303) | Acc: (91.83%) (37732/41088)\n",
            "Epoch: 59 | Batch_idx: 330 |  Loss: (0.2304) | Acc: (91.84%) (38912/42368)\n",
            "Epoch: 59 | Batch_idx: 340 |  Loss: (0.2310) | Acc: (91.83%) (40084/43648)\n",
            "Epoch: 59 | Batch_idx: 350 |  Loss: (0.2304) | Acc: (91.83%) (41257/44928)\n",
            "Epoch: 59 | Batch_idx: 360 |  Loss: (0.2317) | Acc: (91.80%) (42421/46208)\n",
            "Epoch: 59 | Batch_idx: 370 |  Loss: (0.2313) | Acc: (91.84%) (43611/47488)\n",
            "Epoch: 59 | Batch_idx: 380 |  Loss: (0.2322) | Acc: (91.80%) (44768/48768)\n",
            "Epoch: 59 | Batch_idx: 390 |  Loss: (0.2325) | Acc: (91.78%) (45891/50000)\n",
            "# TEST : Loss: (0.4483) | Acc: (86.57%) (8657/10000)\n",
            "Epoch: 60 | Batch_idx: 0 |  Loss: (0.2571) | Acc: (90.62%) (116/128)\n",
            "Epoch: 60 | Batch_idx: 10 |  Loss: (0.2174) | Acc: (92.68%) (1305/1408)\n",
            "Epoch: 60 | Batch_idx: 20 |  Loss: (0.2210) | Acc: (92.45%) (2485/2688)\n",
            "Epoch: 60 | Batch_idx: 30 |  Loss: (0.2262) | Acc: (92.06%) (3653/3968)\n",
            "Epoch: 60 | Batch_idx: 40 |  Loss: (0.2340) | Acc: (91.83%) (4819/5248)\n",
            "Epoch: 60 | Batch_idx: 50 |  Loss: (0.2234) | Acc: (92.11%) (6013/6528)\n",
            "Epoch: 60 | Batch_idx: 60 |  Loss: (0.2237) | Acc: (92.11%) (7192/7808)\n",
            "Epoch: 60 | Batch_idx: 70 |  Loss: (0.2196) | Acc: (92.24%) (8383/9088)\n",
            "Epoch: 60 | Batch_idx: 80 |  Loss: (0.2185) | Acc: (92.22%) (9561/10368)\n",
            "Epoch: 60 | Batch_idx: 90 |  Loss: (0.2174) | Acc: (92.14%) (10732/11648)\n",
            "Epoch: 60 | Batch_idx: 100 |  Loss: (0.2166) | Acc: (92.11%) (11908/12928)\n",
            "Epoch: 60 | Batch_idx: 110 |  Loss: (0.2155) | Acc: (92.15%) (13093/14208)\n",
            "Epoch: 60 | Batch_idx: 120 |  Loss: (0.2160) | Acc: (92.12%) (14267/15488)\n",
            "Epoch: 60 | Batch_idx: 130 |  Loss: (0.2155) | Acc: (92.17%) (15455/16768)\n",
            "Epoch: 60 | Batch_idx: 140 |  Loss: (0.2150) | Acc: (92.20%) (16641/18048)\n",
            "Epoch: 60 | Batch_idx: 150 |  Loss: (0.2180) | Acc: (92.16%) (17813/19328)\n",
            "Epoch: 60 | Batch_idx: 160 |  Loss: (0.2185) | Acc: (92.17%) (18995/20608)\n",
            "Epoch: 60 | Batch_idx: 170 |  Loss: (0.2210) | Acc: (92.10%) (20158/21888)\n",
            "Epoch: 60 | Batch_idx: 180 |  Loss: (0.2227) | Acc: (92.04%) (21324/23168)\n",
            "Epoch: 60 | Batch_idx: 190 |  Loss: (0.2227) | Acc: (92.02%) (22498/24448)\n",
            "Epoch: 60 | Batch_idx: 200 |  Loss: (0.2205) | Acc: (92.13%) (23703/25728)\n",
            "Epoch: 60 | Batch_idx: 210 |  Loss: (0.2208) | Acc: (92.10%) (24875/27008)\n",
            "Epoch: 60 | Batch_idx: 220 |  Loss: (0.2210) | Acc: (92.07%) (26046/28288)\n",
            "Epoch: 60 | Batch_idx: 230 |  Loss: (0.2219) | Acc: (92.06%) (27220/29568)\n",
            "Epoch: 60 | Batch_idx: 240 |  Loss: (0.2212) | Acc: (92.07%) (28401/30848)\n",
            "Epoch: 60 | Batch_idx: 250 |  Loss: (0.2214) | Acc: (92.07%) (29580/32128)\n",
            "Epoch: 60 | Batch_idx: 260 |  Loss: (0.2223) | Acc: (92.05%) (30751/33408)\n",
            "Epoch: 60 | Batch_idx: 270 |  Loss: (0.2231) | Acc: (92.02%) (31920/34688)\n",
            "Epoch: 60 | Batch_idx: 280 |  Loss: (0.2236) | Acc: (91.98%) (33083/35968)\n",
            "Epoch: 60 | Batch_idx: 290 |  Loss: (0.2234) | Acc: (92.00%) (34269/37248)\n",
            "Epoch: 60 | Batch_idx: 300 |  Loss: (0.2224) | Acc: (92.06%) (35469/38528)\n",
            "Epoch: 60 | Batch_idx: 310 |  Loss: (0.2229) | Acc: (92.06%) (36646/39808)\n",
            "Epoch: 60 | Batch_idx: 320 |  Loss: (0.2236) | Acc: (92.04%) (37817/41088)\n",
            "Epoch: 60 | Batch_idx: 330 |  Loss: (0.2253) | Acc: (91.96%) (38963/42368)\n",
            "Epoch: 60 | Batch_idx: 340 |  Loss: (0.2264) | Acc: (91.93%) (40126/43648)\n",
            "Epoch: 60 | Batch_idx: 350 |  Loss: (0.2270) | Acc: (91.91%) (41295/44928)\n",
            "Epoch: 60 | Batch_idx: 360 |  Loss: (0.2277) | Acc: (91.88%) (42454/46208)\n",
            "Epoch: 60 | Batch_idx: 370 |  Loss: (0.2285) | Acc: (91.84%) (43614/47488)\n",
            "Epoch: 60 | Batch_idx: 380 |  Loss: (0.2298) | Acc: (91.79%) (44766/48768)\n",
            "Epoch: 60 | Batch_idx: 390 |  Loss: (0.2300) | Acc: (91.81%) (45905/50000)\n",
            "# TEST : Loss: (0.4278) | Acc: (86.81%) (8681/10000)\n",
            "Epoch: 61 | Batch_idx: 0 |  Loss: (0.1768) | Acc: (92.19%) (118/128)\n",
            "Epoch: 61 | Batch_idx: 10 |  Loss: (0.1939) | Acc: (93.04%) (1310/1408)\n",
            "Epoch: 61 | Batch_idx: 20 |  Loss: (0.1985) | Acc: (93.04%) (2501/2688)\n",
            "Epoch: 61 | Batch_idx: 30 |  Loss: (0.2045) | Acc: (92.89%) (3686/3968)\n",
            "Epoch: 61 | Batch_idx: 40 |  Loss: (0.2073) | Acc: (92.59%) (4859/5248)\n",
            "Epoch: 61 | Batch_idx: 50 |  Loss: (0.2029) | Acc: (92.71%) (6052/6528)\n",
            "Epoch: 61 | Batch_idx: 60 |  Loss: (0.2042) | Acc: (92.61%) (7231/7808)\n",
            "Epoch: 61 | Batch_idx: 70 |  Loss: (0.2089) | Acc: (92.55%) (8411/9088)\n",
            "Epoch: 61 | Batch_idx: 80 |  Loss: (0.2087) | Acc: (92.58%) (9599/10368)\n",
            "Epoch: 61 | Batch_idx: 90 |  Loss: (0.2095) | Acc: (92.53%) (10778/11648)\n",
            "Epoch: 61 | Batch_idx: 100 |  Loss: (0.2116) | Acc: (92.37%) (11941/12928)\n",
            "Epoch: 61 | Batch_idx: 110 |  Loss: (0.2132) | Acc: (92.29%) (13113/14208)\n",
            "Epoch: 61 | Batch_idx: 120 |  Loss: (0.2147) | Acc: (92.25%) (14287/15488)\n",
            "Epoch: 61 | Batch_idx: 130 |  Loss: (0.2162) | Acc: (92.27%) (15472/16768)\n",
            "Epoch: 61 | Batch_idx: 140 |  Loss: (0.2173) | Acc: (92.26%) (16651/18048)\n",
            "Epoch: 61 | Batch_idx: 150 |  Loss: (0.2172) | Acc: (92.28%) (17835/19328)\n",
            "Epoch: 61 | Batch_idx: 160 |  Loss: (0.2165) | Acc: (92.34%) (19029/20608)\n",
            "Epoch: 61 | Batch_idx: 170 |  Loss: (0.2161) | Acc: (92.31%) (20205/21888)\n",
            "Epoch: 61 | Batch_idx: 180 |  Loss: (0.2162) | Acc: (92.29%) (21382/23168)\n",
            "Epoch: 61 | Batch_idx: 190 |  Loss: (0.2170) | Acc: (92.24%) (22552/24448)\n",
            "Epoch: 61 | Batch_idx: 200 |  Loss: (0.2168) | Acc: (92.32%) (23751/25728)\n",
            "Epoch: 61 | Batch_idx: 210 |  Loss: (0.2174) | Acc: (92.24%) (24913/27008)\n",
            "Epoch: 61 | Batch_idx: 220 |  Loss: (0.2167) | Acc: (92.28%) (26103/28288)\n",
            "Epoch: 61 | Batch_idx: 230 |  Loss: (0.2185) | Acc: (92.21%) (27265/29568)\n",
            "Epoch: 61 | Batch_idx: 240 |  Loss: (0.2186) | Acc: (92.22%) (28448/30848)\n",
            "Epoch: 61 | Batch_idx: 250 |  Loss: (0.2192) | Acc: (92.20%) (29621/32128)\n",
            "Epoch: 61 | Batch_idx: 260 |  Loss: (0.2197) | Acc: (92.16%) (30790/33408)\n",
            "Epoch: 61 | Batch_idx: 270 |  Loss: (0.2212) | Acc: (92.12%) (31954/34688)\n",
            "Epoch: 61 | Batch_idx: 280 |  Loss: (0.2198) | Acc: (92.16%) (33148/35968)\n",
            "Epoch: 61 | Batch_idx: 290 |  Loss: (0.2205) | Acc: (92.16%) (34329/37248)\n",
            "Epoch: 61 | Batch_idx: 300 |  Loss: (0.2212) | Acc: (92.13%) (35496/38528)\n",
            "Epoch: 61 | Batch_idx: 310 |  Loss: (0.2213) | Acc: (92.12%) (36670/39808)\n",
            "Epoch: 61 | Batch_idx: 320 |  Loss: (0.2205) | Acc: (92.16%) (37865/41088)\n",
            "Epoch: 61 | Batch_idx: 330 |  Loss: (0.2204) | Acc: (92.15%) (39044/42368)\n",
            "Epoch: 61 | Batch_idx: 340 |  Loss: (0.2203) | Acc: (92.16%) (40227/43648)\n",
            "Epoch: 61 | Batch_idx: 350 |  Loss: (0.2208) | Acc: (92.14%) (41395/44928)\n",
            "Epoch: 61 | Batch_idx: 360 |  Loss: (0.2214) | Acc: (92.11%) (42561/46208)\n",
            "Epoch: 61 | Batch_idx: 370 |  Loss: (0.2220) | Acc: (92.09%) (43730/47488)\n",
            "Epoch: 61 | Batch_idx: 380 |  Loss: (0.2226) | Acc: (92.07%) (44901/48768)\n",
            "Epoch: 61 | Batch_idx: 390 |  Loss: (0.2230) | Acc: (92.08%) (46039/50000)\n",
            "# TEST : Loss: (0.5864) | Acc: (83.30%) (8330/10000)\n",
            "Epoch: 62 | Batch_idx: 0 |  Loss: (0.2275) | Acc: (92.97%) (119/128)\n",
            "Epoch: 62 | Batch_idx: 10 |  Loss: (0.2270) | Acc: (92.61%) (1304/1408)\n",
            "Epoch: 62 | Batch_idx: 20 |  Loss: (0.2122) | Acc: (92.49%) (2486/2688)\n",
            "Epoch: 62 | Batch_idx: 30 |  Loss: (0.2202) | Acc: (92.19%) (3658/3968)\n",
            "Epoch: 62 | Batch_idx: 40 |  Loss: (0.2146) | Acc: (92.44%) (4851/5248)\n",
            "Epoch: 62 | Batch_idx: 50 |  Loss: (0.2137) | Acc: (92.34%) (6028/6528)\n",
            "Epoch: 62 | Batch_idx: 60 |  Loss: (0.2131) | Acc: (92.23%) (7201/7808)\n",
            "Epoch: 62 | Batch_idx: 70 |  Loss: (0.2099) | Acc: (92.35%) (8393/9088)\n",
            "Epoch: 62 | Batch_idx: 80 |  Loss: (0.2108) | Acc: (92.27%) (9567/10368)\n",
            "Epoch: 62 | Batch_idx: 90 |  Loss: (0.2129) | Acc: (92.23%) (10743/11648)\n",
            "Epoch: 62 | Batch_idx: 100 |  Loss: (0.2154) | Acc: (92.15%) (11913/12928)\n",
            "Epoch: 62 | Batch_idx: 110 |  Loss: (0.2138) | Acc: (92.21%) (13101/14208)\n",
            "Epoch: 62 | Batch_idx: 120 |  Loss: (0.2149) | Acc: (92.18%) (14277/15488)\n",
            "Epoch: 62 | Batch_idx: 130 |  Loss: (0.2146) | Acc: (92.21%) (15462/16768)\n",
            "Epoch: 62 | Batch_idx: 140 |  Loss: (0.2127) | Acc: (92.31%) (16661/18048)\n",
            "Epoch: 62 | Batch_idx: 150 |  Loss: (0.2135) | Acc: (92.27%) (17833/19328)\n",
            "Epoch: 62 | Batch_idx: 160 |  Loss: (0.2138) | Acc: (92.26%) (19013/20608)\n",
            "Epoch: 62 | Batch_idx: 170 |  Loss: (0.2150) | Acc: (92.18%) (20176/21888)\n",
            "Epoch: 62 | Batch_idx: 180 |  Loss: (0.2155) | Acc: (92.20%) (21362/23168)\n",
            "Epoch: 62 | Batch_idx: 190 |  Loss: (0.2155) | Acc: (92.23%) (22548/24448)\n",
            "Epoch: 62 | Batch_idx: 200 |  Loss: (0.2161) | Acc: (92.21%) (23725/25728)\n",
            "Epoch: 62 | Batch_idx: 210 |  Loss: (0.2179) | Acc: (92.19%) (24899/27008)\n",
            "Epoch: 62 | Batch_idx: 220 |  Loss: (0.2181) | Acc: (92.19%) (26078/28288)\n",
            "Epoch: 62 | Batch_idx: 230 |  Loss: (0.2170) | Acc: (92.22%) (27269/29568)\n",
            "Epoch: 62 | Batch_idx: 240 |  Loss: (0.2176) | Acc: (92.23%) (28451/30848)\n",
            "Epoch: 62 | Batch_idx: 250 |  Loss: (0.2181) | Acc: (92.21%) (29624/32128)\n",
            "Epoch: 62 | Batch_idx: 260 |  Loss: (0.2185) | Acc: (92.20%) (30801/33408)\n",
            "Epoch: 62 | Batch_idx: 270 |  Loss: (0.2207) | Acc: (92.13%) (31959/34688)\n",
            "Epoch: 62 | Batch_idx: 280 |  Loss: (0.2229) | Acc: (92.03%) (33103/35968)\n",
            "Epoch: 62 | Batch_idx: 290 |  Loss: (0.2243) | Acc: (92.00%) (34269/37248)\n",
            "Epoch: 62 | Batch_idx: 300 |  Loss: (0.2250) | Acc: (91.97%) (35436/38528)\n",
            "Epoch: 62 | Batch_idx: 310 |  Loss: (0.2248) | Acc: (91.99%) (36621/39808)\n",
            "Epoch: 62 | Batch_idx: 320 |  Loss: (0.2252) | Acc: (91.98%) (37793/41088)\n",
            "Epoch: 62 | Batch_idx: 330 |  Loss: (0.2259) | Acc: (91.94%) (38955/42368)\n",
            "Epoch: 62 | Batch_idx: 340 |  Loss: (0.2261) | Acc: (91.94%) (40129/43648)\n",
            "Epoch: 62 | Batch_idx: 350 |  Loss: (0.2261) | Acc: (91.94%) (41306/44928)\n",
            "Epoch: 62 | Batch_idx: 360 |  Loss: (0.2275) | Acc: (91.89%) (42459/46208)\n",
            "Epoch: 62 | Batch_idx: 370 |  Loss: (0.2281) | Acc: (91.87%) (43625/47488)\n",
            "Epoch: 62 | Batch_idx: 380 |  Loss: (0.2285) | Acc: (91.86%) (44797/48768)\n",
            "Epoch: 62 | Batch_idx: 390 |  Loss: (0.2287) | Acc: (91.82%) (45911/50000)\n",
            "# TEST : Loss: (0.5198) | Acc: (83.79%) (8379/10000)\n",
            "Epoch: 63 | Batch_idx: 0 |  Loss: (0.2595) | Acc: (89.84%) (115/128)\n",
            "Epoch: 63 | Batch_idx: 10 |  Loss: (0.2550) | Acc: (90.91%) (1280/1408)\n",
            "Epoch: 63 | Batch_idx: 20 |  Loss: (0.2286) | Acc: (91.70%) (2465/2688)\n",
            "Epoch: 63 | Batch_idx: 30 |  Loss: (0.2200) | Acc: (91.94%) (3648/3968)\n",
            "Epoch: 63 | Batch_idx: 40 |  Loss: (0.2189) | Acc: (92.17%) (4837/5248)\n",
            "Epoch: 63 | Batch_idx: 50 |  Loss: (0.2213) | Acc: (92.13%) (6014/6528)\n",
            "Epoch: 63 | Batch_idx: 60 |  Loss: (0.2198) | Acc: (92.24%) (7202/7808)\n",
            "Epoch: 63 | Batch_idx: 70 |  Loss: (0.2162) | Acc: (92.42%) (8399/9088)\n",
            "Epoch: 63 | Batch_idx: 80 |  Loss: (0.2132) | Acc: (92.57%) (9598/10368)\n",
            "Epoch: 63 | Batch_idx: 90 |  Loss: (0.2153) | Acc: (92.45%) (10768/11648)\n",
            "Epoch: 63 | Batch_idx: 100 |  Loss: (0.2176) | Acc: (92.33%) (11936/12928)\n",
            "Epoch: 63 | Batch_idx: 110 |  Loss: (0.2157) | Acc: (92.44%) (13134/14208)\n",
            "Epoch: 63 | Batch_idx: 120 |  Loss: (0.2154) | Acc: (92.45%) (14318/15488)\n",
            "Epoch: 63 | Batch_idx: 130 |  Loss: (0.2145) | Acc: (92.44%) (15501/16768)\n",
            "Epoch: 63 | Batch_idx: 140 |  Loss: (0.2161) | Acc: (92.45%) (16686/18048)\n",
            "Epoch: 63 | Batch_idx: 150 |  Loss: (0.2159) | Acc: (92.45%) (17868/19328)\n",
            "Epoch: 63 | Batch_idx: 160 |  Loss: (0.2178) | Acc: (92.34%) (19030/20608)\n",
            "Epoch: 63 | Batch_idx: 170 |  Loss: (0.2183) | Acc: (92.33%) (20209/21888)\n",
            "Epoch: 63 | Batch_idx: 180 |  Loss: (0.2175) | Acc: (92.38%) (21402/23168)\n",
            "Epoch: 63 | Batch_idx: 190 |  Loss: (0.2179) | Acc: (92.40%) (22590/24448)\n",
            "Epoch: 63 | Batch_idx: 200 |  Loss: (0.2176) | Acc: (92.41%) (23774/25728)\n",
            "Epoch: 63 | Batch_idx: 210 |  Loss: (0.2188) | Acc: (92.38%) (24949/27008)\n",
            "Epoch: 63 | Batch_idx: 220 |  Loss: (0.2181) | Acc: (92.37%) (26131/28288)\n",
            "Epoch: 63 | Batch_idx: 230 |  Loss: (0.2180) | Acc: (92.35%) (27306/29568)\n",
            "Epoch: 63 | Batch_idx: 240 |  Loss: (0.2183) | Acc: (92.34%) (28485/30848)\n",
            "Epoch: 63 | Batch_idx: 250 |  Loss: (0.2200) | Acc: (92.30%) (29653/32128)\n",
            "Epoch: 63 | Batch_idx: 260 |  Loss: (0.2198) | Acc: (92.29%) (30831/33408)\n",
            "Epoch: 63 | Batch_idx: 270 |  Loss: (0.2200) | Acc: (92.29%) (32012/34688)\n",
            "Epoch: 63 | Batch_idx: 280 |  Loss: (0.2204) | Acc: (92.25%) (33181/35968)\n",
            "Epoch: 63 | Batch_idx: 290 |  Loss: (0.2210) | Acc: (92.23%) (34353/37248)\n",
            "Epoch: 63 | Batch_idx: 300 |  Loss: (0.2216) | Acc: (92.20%) (35524/38528)\n",
            "Epoch: 63 | Batch_idx: 310 |  Loss: (0.2226) | Acc: (92.15%) (36684/39808)\n",
            "Epoch: 63 | Batch_idx: 320 |  Loss: (0.2238) | Acc: (92.13%) (37853/41088)\n",
            "Epoch: 63 | Batch_idx: 330 |  Loss: (0.2239) | Acc: (92.15%) (39044/42368)\n",
            "Epoch: 63 | Batch_idx: 340 |  Loss: (0.2244) | Acc: (92.14%) (40217/43648)\n",
            "Epoch: 63 | Batch_idx: 350 |  Loss: (0.2250) | Acc: (92.13%) (41393/44928)\n",
            "Epoch: 63 | Batch_idx: 360 |  Loss: (0.2251) | Acc: (92.12%) (42569/46208)\n",
            "Epoch: 63 | Batch_idx: 370 |  Loss: (0.2244) | Acc: (92.15%) (43761/47488)\n",
            "Epoch: 63 | Batch_idx: 380 |  Loss: (0.2241) | Acc: (92.16%) (44945/48768)\n",
            "Epoch: 63 | Batch_idx: 390 |  Loss: (0.2238) | Acc: (92.16%) (46082/50000)\n",
            "# TEST : Loss: (0.4916) | Acc: (85.20%) (8520/10000)\n",
            "Epoch: 64 | Batch_idx: 0 |  Loss: (0.1563) | Acc: (95.31%) (122/128)\n",
            "Epoch: 64 | Batch_idx: 10 |  Loss: (0.2382) | Acc: (91.76%) (1292/1408)\n",
            "Epoch: 64 | Batch_idx: 20 |  Loss: (0.2081) | Acc: (92.52%) (2487/2688)\n",
            "Epoch: 64 | Batch_idx: 30 |  Loss: (0.2060) | Acc: (92.82%) (3683/3968)\n",
            "Epoch: 64 | Batch_idx: 40 |  Loss: (0.2108) | Acc: (92.45%) (4852/5248)\n",
            "Epoch: 64 | Batch_idx: 50 |  Loss: (0.2042) | Acc: (92.80%) (6058/6528)\n",
            "Epoch: 64 | Batch_idx: 60 |  Loss: (0.2069) | Acc: (92.66%) (7235/7808)\n",
            "Epoch: 64 | Batch_idx: 70 |  Loss: (0.2087) | Acc: (92.53%) (8409/9088)\n",
            "Epoch: 64 | Batch_idx: 80 |  Loss: (0.2108) | Acc: (92.40%) (9580/10368)\n",
            "Epoch: 64 | Batch_idx: 90 |  Loss: (0.2109) | Acc: (92.35%) (10757/11648)\n",
            "Epoch: 64 | Batch_idx: 100 |  Loss: (0.2094) | Acc: (92.41%) (11947/12928)\n",
            "Epoch: 64 | Batch_idx: 110 |  Loss: (0.2092) | Acc: (92.38%) (13125/14208)\n",
            "Epoch: 64 | Batch_idx: 120 |  Loss: (0.2100) | Acc: (92.36%) (14304/15488)\n",
            "Epoch: 64 | Batch_idx: 130 |  Loss: (0.2117) | Acc: (92.34%) (15484/16768)\n",
            "Epoch: 64 | Batch_idx: 140 |  Loss: (0.2126) | Acc: (92.38%) (16672/18048)\n",
            "Epoch: 64 | Batch_idx: 150 |  Loss: (0.2160) | Acc: (92.28%) (17835/19328)\n",
            "Epoch: 64 | Batch_idx: 160 |  Loss: (0.2140) | Acc: (92.32%) (19025/20608)\n",
            "Epoch: 64 | Batch_idx: 170 |  Loss: (0.2147) | Acc: (92.29%) (20200/21888)\n",
            "Epoch: 64 | Batch_idx: 180 |  Loss: (0.2169) | Acc: (92.22%) (21365/23168)\n",
            "Epoch: 64 | Batch_idx: 190 |  Loss: (0.2179) | Acc: (92.23%) (22548/24448)\n",
            "Epoch: 64 | Batch_idx: 200 |  Loss: (0.2190) | Acc: (92.19%) (23718/25728)\n",
            "Epoch: 64 | Batch_idx: 210 |  Loss: (0.2188) | Acc: (92.19%) (24900/27008)\n",
            "Epoch: 64 | Batch_idx: 220 |  Loss: (0.2190) | Acc: (92.20%) (26081/28288)\n",
            "Epoch: 64 | Batch_idx: 230 |  Loss: (0.2209) | Acc: (92.14%) (27245/29568)\n",
            "Epoch: 64 | Batch_idx: 240 |  Loss: (0.2207) | Acc: (92.15%) (28427/30848)\n",
            "Epoch: 64 | Batch_idx: 250 |  Loss: (0.2207) | Acc: (92.17%) (29612/32128)\n",
            "Epoch: 64 | Batch_idx: 260 |  Loss: (0.2209) | Acc: (92.16%) (30788/33408)\n",
            "Epoch: 64 | Batch_idx: 270 |  Loss: (0.2212) | Acc: (92.14%) (31962/34688)\n",
            "Epoch: 64 | Batch_idx: 280 |  Loss: (0.2221) | Acc: (92.13%) (33137/35968)\n",
            "Epoch: 64 | Batch_idx: 290 |  Loss: (0.2223) | Acc: (92.12%) (34311/37248)\n",
            "Epoch: 64 | Batch_idx: 300 |  Loss: (0.2231) | Acc: (92.09%) (35481/38528)\n",
            "Epoch: 64 | Batch_idx: 310 |  Loss: (0.2238) | Acc: (92.06%) (36646/39808)\n",
            "Epoch: 64 | Batch_idx: 320 |  Loss: (0.2240) | Acc: (92.07%) (37829/41088)\n",
            "Epoch: 64 | Batch_idx: 330 |  Loss: (0.2248) | Acc: (92.04%) (38997/42368)\n",
            "Epoch: 64 | Batch_idx: 340 |  Loss: (0.2251) | Acc: (92.03%) (40171/43648)\n",
            "Epoch: 64 | Batch_idx: 350 |  Loss: (0.2257) | Acc: (92.00%) (41336/44928)\n",
            "Epoch: 64 | Batch_idx: 360 |  Loss: (0.2257) | Acc: (92.00%) (42512/46208)\n",
            "Epoch: 64 | Batch_idx: 370 |  Loss: (0.2261) | Acc: (92.01%) (43695/47488)\n",
            "Epoch: 64 | Batch_idx: 380 |  Loss: (0.2260) | Acc: (92.01%) (44871/48768)\n",
            "Epoch: 64 | Batch_idx: 390 |  Loss: (0.2260) | Acc: (92.01%) (46005/50000)\n",
            "# TEST : Loss: (0.4337) | Acc: (87.04%) (8704/10000)\n",
            "Epoch: 65 | Batch_idx: 0 |  Loss: (0.3391) | Acc: (88.28%) (113/128)\n",
            "Epoch: 65 | Batch_idx: 10 |  Loss: (0.2094) | Acc: (92.33%) (1300/1408)\n",
            "Epoch: 65 | Batch_idx: 20 |  Loss: (0.2057) | Acc: (92.89%) (2497/2688)\n",
            "Epoch: 65 | Batch_idx: 30 |  Loss: (0.2013) | Acc: (93.12%) (3695/3968)\n",
            "Epoch: 65 | Batch_idx: 40 |  Loss: (0.2079) | Acc: (92.84%) (4872/5248)\n",
            "Epoch: 65 | Batch_idx: 50 |  Loss: (0.2097) | Acc: (92.78%) (6057/6528)\n",
            "Epoch: 65 | Batch_idx: 60 |  Loss: (0.2079) | Acc: (92.79%) (7245/7808)\n",
            "Epoch: 65 | Batch_idx: 70 |  Loss: (0.2106) | Acc: (92.64%) (8419/9088)\n",
            "Epoch: 65 | Batch_idx: 80 |  Loss: (0.2127) | Acc: (92.55%) (9596/10368)\n",
            "Epoch: 65 | Batch_idx: 90 |  Loss: (0.2111) | Acc: (92.56%) (10781/11648)\n",
            "Epoch: 65 | Batch_idx: 100 |  Loss: (0.2118) | Acc: (92.50%) (11959/12928)\n",
            "Epoch: 65 | Batch_idx: 110 |  Loss: (0.2130) | Acc: (92.50%) (13143/14208)\n",
            "Epoch: 65 | Batch_idx: 120 |  Loss: (0.2123) | Acc: (92.56%) (14336/15488)\n",
            "Epoch: 65 | Batch_idx: 130 |  Loss: (0.2141) | Acc: (92.50%) (15511/16768)\n",
            "Epoch: 65 | Batch_idx: 140 |  Loss: (0.2132) | Acc: (92.53%) (16700/18048)\n",
            "Epoch: 65 | Batch_idx: 150 |  Loss: (0.2124) | Acc: (92.59%) (17895/19328)\n",
            "Epoch: 65 | Batch_idx: 160 |  Loss: (0.2105) | Acc: (92.67%) (19097/20608)\n",
            "Epoch: 65 | Batch_idx: 170 |  Loss: (0.2121) | Acc: (92.61%) (20270/21888)\n",
            "Epoch: 65 | Batch_idx: 180 |  Loss: (0.2125) | Acc: (92.57%) (21446/23168)\n",
            "Epoch: 65 | Batch_idx: 190 |  Loss: (0.2125) | Acc: (92.59%) (22637/24448)\n",
            "Epoch: 65 | Batch_idx: 200 |  Loss: (0.2160) | Acc: (92.49%) (23796/25728)\n",
            "Epoch: 65 | Batch_idx: 210 |  Loss: (0.2179) | Acc: (92.44%) (24966/27008)\n",
            "Epoch: 65 | Batch_idx: 220 |  Loss: (0.2168) | Acc: (92.45%) (26152/28288)\n",
            "Epoch: 65 | Batch_idx: 230 |  Loss: (0.2165) | Acc: (92.44%) (27334/29568)\n",
            "Epoch: 65 | Batch_idx: 240 |  Loss: (0.2175) | Acc: (92.42%) (28510/30848)\n",
            "Epoch: 65 | Batch_idx: 250 |  Loss: (0.2178) | Acc: (92.43%) (29696/32128)\n",
            "Epoch: 65 | Batch_idx: 260 |  Loss: (0.2176) | Acc: (92.44%) (30883/33408)\n",
            "Epoch: 65 | Batch_idx: 270 |  Loss: (0.2199) | Acc: (92.34%) (32032/34688)\n",
            "Epoch: 65 | Batch_idx: 280 |  Loss: (0.2207) | Acc: (92.32%) (33204/35968)\n",
            "Epoch: 65 | Batch_idx: 290 |  Loss: (0.2217) | Acc: (92.28%) (34371/37248)\n",
            "Epoch: 65 | Batch_idx: 300 |  Loss: (0.2213) | Acc: (92.30%) (35562/38528)\n",
            "Epoch: 65 | Batch_idx: 310 |  Loss: (0.2225) | Acc: (92.25%) (36723/39808)\n",
            "Epoch: 65 | Batch_idx: 320 |  Loss: (0.2215) | Acc: (92.26%) (37907/41088)\n",
            "Epoch: 65 | Batch_idx: 330 |  Loss: (0.2211) | Acc: (92.29%) (39102/42368)\n",
            "Epoch: 65 | Batch_idx: 340 |  Loss: (0.2212) | Acc: (92.29%) (40281/43648)\n",
            "Epoch: 65 | Batch_idx: 350 |  Loss: (0.2225) | Acc: (92.23%) (41437/44928)\n",
            "Epoch: 65 | Batch_idx: 360 |  Loss: (0.2226) | Acc: (92.25%) (42628/46208)\n",
            "Epoch: 65 | Batch_idx: 370 |  Loss: (0.2227) | Acc: (92.25%) (43806/47488)\n",
            "Epoch: 65 | Batch_idx: 380 |  Loss: (0.2228) | Acc: (92.24%) (44983/48768)\n",
            "Epoch: 65 | Batch_idx: 390 |  Loss: (0.2232) | Acc: (92.21%) (46106/50000)\n",
            "# TEST : Loss: (0.4059) | Acc: (87.48%) (8748/10000)\n",
            "Epoch: 66 | Batch_idx: 0 |  Loss: (0.1704) | Acc: (95.31%) (122/128)\n",
            "Epoch: 66 | Batch_idx: 10 |  Loss: (0.2137) | Acc: (92.40%) (1301/1408)\n",
            "Epoch: 66 | Batch_idx: 20 |  Loss: (0.2126) | Acc: (92.60%) (2489/2688)\n",
            "Epoch: 66 | Batch_idx: 30 |  Loss: (0.2099) | Acc: (92.84%) (3684/3968)\n",
            "Epoch: 66 | Batch_idx: 40 |  Loss: (0.2085) | Acc: (92.76%) (4868/5248)\n",
            "Epoch: 66 | Batch_idx: 50 |  Loss: (0.2103) | Acc: (92.60%) (6045/6528)\n",
            "Epoch: 66 | Batch_idx: 60 |  Loss: (0.2077) | Acc: (92.62%) (7232/7808)\n",
            "Epoch: 66 | Batch_idx: 70 |  Loss: (0.2066) | Acc: (92.67%) (8422/9088)\n",
            "Epoch: 66 | Batch_idx: 80 |  Loss: (0.2084) | Acc: (92.51%) (9591/10368)\n",
            "Epoch: 66 | Batch_idx: 90 |  Loss: (0.2092) | Acc: (92.47%) (10771/11648)\n",
            "Epoch: 66 | Batch_idx: 100 |  Loss: (0.2103) | Acc: (92.50%) (11958/12928)\n",
            "Epoch: 66 | Batch_idx: 110 |  Loss: (0.2113) | Acc: (92.50%) (13143/14208)\n",
            "Epoch: 66 | Batch_idx: 120 |  Loss: (0.2111) | Acc: (92.56%) (14335/15488)\n",
            "Epoch: 66 | Batch_idx: 130 |  Loss: (0.2137) | Acc: (92.52%) (15513/16768)\n",
            "Epoch: 66 | Batch_idx: 140 |  Loss: (0.2125) | Acc: (92.53%) (16700/18048)\n",
            "Epoch: 66 | Batch_idx: 150 |  Loss: (0.2129) | Acc: (92.54%) (17886/19328)\n",
            "Epoch: 66 | Batch_idx: 160 |  Loss: (0.2144) | Acc: (92.48%) (19059/20608)\n",
            "Epoch: 66 | Batch_idx: 170 |  Loss: (0.2165) | Acc: (92.43%) (20231/21888)\n",
            "Epoch: 66 | Batch_idx: 180 |  Loss: (0.2176) | Acc: (92.43%) (21415/23168)\n",
            "Epoch: 66 | Batch_idx: 190 |  Loss: (0.2199) | Acc: (92.35%) (22578/24448)\n",
            "Epoch: 66 | Batch_idx: 200 |  Loss: (0.2187) | Acc: (92.42%) (23779/25728)\n",
            "Epoch: 66 | Batch_idx: 210 |  Loss: (0.2180) | Acc: (92.45%) (24969/27008)\n",
            "Epoch: 66 | Batch_idx: 220 |  Loss: (0.2179) | Acc: (92.48%) (26160/28288)\n",
            "Epoch: 66 | Batch_idx: 230 |  Loss: (0.2171) | Acc: (92.53%) (27358/29568)\n",
            "Epoch: 66 | Batch_idx: 240 |  Loss: (0.2195) | Acc: (92.47%) (28524/30848)\n",
            "Epoch: 66 | Batch_idx: 250 |  Loss: (0.2196) | Acc: (92.43%) (29697/32128)\n",
            "Epoch: 66 | Batch_idx: 260 |  Loss: (0.2218) | Acc: (92.34%) (30848/33408)\n",
            "Epoch: 66 | Batch_idx: 270 |  Loss: (0.2220) | Acc: (92.32%) (32025/34688)\n",
            "Epoch: 66 | Batch_idx: 280 |  Loss: (0.2227) | Acc: (92.32%) (33204/35968)\n",
            "Epoch: 66 | Batch_idx: 290 |  Loss: (0.2228) | Acc: (92.31%) (34383/37248)\n",
            "Epoch: 66 | Batch_idx: 300 |  Loss: (0.2221) | Acc: (92.33%) (35572/38528)\n",
            "Epoch: 66 | Batch_idx: 310 |  Loss: (0.2214) | Acc: (92.34%) (36757/39808)\n",
            "Epoch: 66 | Batch_idx: 320 |  Loss: (0.2210) | Acc: (92.35%) (37946/41088)\n",
            "Epoch: 66 | Batch_idx: 330 |  Loss: (0.2210) | Acc: (92.34%) (39124/42368)\n",
            "Epoch: 66 | Batch_idx: 340 |  Loss: (0.2208) | Acc: (92.36%) (40314/43648)\n",
            "Epoch: 66 | Batch_idx: 350 |  Loss: (0.2213) | Acc: (92.34%) (41487/44928)\n",
            "Epoch: 66 | Batch_idx: 360 |  Loss: (0.2209) | Acc: (92.36%) (42680/46208)\n",
            "Epoch: 66 | Batch_idx: 370 |  Loss: (0.2215) | Acc: (92.35%) (43853/47488)\n",
            "Epoch: 66 | Batch_idx: 380 |  Loss: (0.2215) | Acc: (92.34%) (45031/48768)\n",
            "Epoch: 66 | Batch_idx: 390 |  Loss: (0.2212) | Acc: (92.33%) (46166/50000)\n",
            "# TEST : Loss: (0.4582) | Acc: (86.58%) (8658/10000)\n",
            "Epoch: 67 | Batch_idx: 0 |  Loss: (0.1990) | Acc: (96.09%) (123/128)\n",
            "Epoch: 67 | Batch_idx: 10 |  Loss: (0.2344) | Acc: (92.40%) (1301/1408)\n",
            "Epoch: 67 | Batch_idx: 20 |  Loss: (0.2176) | Acc: (92.49%) (2486/2688)\n",
            "Epoch: 67 | Batch_idx: 30 |  Loss: (0.2185) | Acc: (92.36%) (3665/3968)\n",
            "Epoch: 67 | Batch_idx: 40 |  Loss: (0.2212) | Acc: (92.24%) (4841/5248)\n",
            "Epoch: 67 | Batch_idx: 50 |  Loss: (0.2183) | Acc: (92.22%) (6020/6528)\n",
            "Epoch: 67 | Batch_idx: 60 |  Loss: (0.2132) | Acc: (92.44%) (7218/7808)\n",
            "Epoch: 67 | Batch_idx: 70 |  Loss: (0.2146) | Acc: (92.42%) (8399/9088)\n",
            "Epoch: 67 | Batch_idx: 80 |  Loss: (0.2137) | Acc: (92.51%) (9591/10368)\n",
            "Epoch: 67 | Batch_idx: 90 |  Loss: (0.2099) | Acc: (92.60%) (10786/11648)\n",
            "Epoch: 67 | Batch_idx: 100 |  Loss: (0.2087) | Acc: (92.67%) (11981/12928)\n",
            "Epoch: 67 | Batch_idx: 110 |  Loss: (0.2100) | Acc: (92.67%) (13167/14208)\n",
            "Epoch: 67 | Batch_idx: 120 |  Loss: (0.2122) | Acc: (92.57%) (14338/15488)\n",
            "Epoch: 67 | Batch_idx: 130 |  Loss: (0.2122) | Acc: (92.56%) (15520/16768)\n",
            "Epoch: 67 | Batch_idx: 140 |  Loss: (0.2150) | Acc: (92.44%) (16683/18048)\n",
            "Epoch: 67 | Batch_idx: 150 |  Loss: (0.2131) | Acc: (92.50%) (17878/19328)\n",
            "Epoch: 67 | Batch_idx: 160 |  Loss: (0.2155) | Acc: (92.35%) (19032/20608)\n",
            "Epoch: 67 | Batch_idx: 170 |  Loss: (0.2164) | Acc: (92.30%) (20203/21888)\n",
            "Epoch: 67 | Batch_idx: 180 |  Loss: (0.2156) | Acc: (92.33%) (21390/23168)\n",
            "Epoch: 67 | Batch_idx: 190 |  Loss: (0.2150) | Acc: (92.36%) (22580/24448)\n",
            "Epoch: 67 | Batch_idx: 200 |  Loss: (0.2151) | Acc: (92.32%) (23752/25728)\n",
            "Epoch: 67 | Batch_idx: 210 |  Loss: (0.2156) | Acc: (92.32%) (24934/27008)\n",
            "Epoch: 67 | Batch_idx: 220 |  Loss: (0.2168) | Acc: (92.28%) (26103/28288)\n",
            "Epoch: 67 | Batch_idx: 230 |  Loss: (0.2182) | Acc: (92.22%) (27269/29568)\n",
            "Epoch: 67 | Batch_idx: 240 |  Loss: (0.2183) | Acc: (92.21%) (28446/30848)\n",
            "Epoch: 67 | Batch_idx: 250 |  Loss: (0.2185) | Acc: (92.22%) (29627/32128)\n",
            "Epoch: 67 | Batch_idx: 260 |  Loss: (0.2184) | Acc: (92.24%) (30815/33408)\n",
            "Epoch: 67 | Batch_idx: 270 |  Loss: (0.2185) | Acc: (92.21%) (31986/34688)\n",
            "Epoch: 67 | Batch_idx: 280 |  Loss: (0.2195) | Acc: (92.20%) (33162/35968)\n",
            "Epoch: 67 | Batch_idx: 290 |  Loss: (0.2200) | Acc: (92.22%) (34349/37248)\n",
            "Epoch: 67 | Batch_idx: 300 |  Loss: (0.2201) | Acc: (92.21%) (35527/38528)\n",
            "Epoch: 67 | Batch_idx: 310 |  Loss: (0.2206) | Acc: (92.20%) (36704/39808)\n",
            "Epoch: 67 | Batch_idx: 320 |  Loss: (0.2208) | Acc: (92.19%) (37878/41088)\n",
            "Epoch: 67 | Batch_idx: 330 |  Loss: (0.2209) | Acc: (92.20%) (39063/42368)\n",
            "Epoch: 67 | Batch_idx: 340 |  Loss: (0.2215) | Acc: (92.18%) (40236/43648)\n",
            "Epoch: 67 | Batch_idx: 350 |  Loss: (0.2227) | Acc: (92.15%) (41400/44928)\n",
            "Epoch: 67 | Batch_idx: 360 |  Loss: (0.2226) | Acc: (92.15%) (42579/46208)\n",
            "Epoch: 67 | Batch_idx: 370 |  Loss: (0.2227) | Acc: (92.11%) (43742/47488)\n",
            "Epoch: 67 | Batch_idx: 380 |  Loss: (0.2217) | Acc: (92.15%) (44938/48768)\n",
            "Epoch: 67 | Batch_idx: 390 |  Loss: (0.2218) | Acc: (92.16%) (46078/50000)\n",
            "# TEST : Loss: (0.5317) | Acc: (85.31%) (8531/10000)\n",
            "Epoch: 68 | Batch_idx: 0 |  Loss: (0.2643) | Acc: (92.97%) (119/128)\n",
            "Epoch: 68 | Batch_idx: 10 |  Loss: (0.2096) | Acc: (92.76%) (1306/1408)\n",
            "Epoch: 68 | Batch_idx: 20 |  Loss: (0.2126) | Acc: (92.34%) (2482/2688)\n",
            "Epoch: 68 | Batch_idx: 30 |  Loss: (0.2101) | Acc: (92.39%) (3666/3968)\n",
            "Epoch: 68 | Batch_idx: 40 |  Loss: (0.2104) | Acc: (92.44%) (4851/5248)\n",
            "Epoch: 68 | Batch_idx: 50 |  Loss: (0.2105) | Acc: (92.40%) (6032/6528)\n",
            "Epoch: 68 | Batch_idx: 60 |  Loss: (0.2163) | Acc: (92.28%) (7205/7808)\n",
            "Epoch: 68 | Batch_idx: 70 |  Loss: (0.2178) | Acc: (92.26%) (8385/9088)\n",
            "Epoch: 68 | Batch_idx: 80 |  Loss: (0.2130) | Acc: (92.41%) (9581/10368)\n",
            "Epoch: 68 | Batch_idx: 90 |  Loss: (0.2122) | Acc: (92.41%) (10764/11648)\n",
            "Epoch: 68 | Batch_idx: 100 |  Loss: (0.2119) | Acc: (92.41%) (11947/12928)\n",
            "Epoch: 68 | Batch_idx: 110 |  Loss: (0.2110) | Acc: (92.48%) (13139/14208)\n",
            "Epoch: 68 | Batch_idx: 120 |  Loss: (0.2109) | Acc: (92.46%) (14320/15488)\n",
            "Epoch: 68 | Batch_idx: 130 |  Loss: (0.2089) | Acc: (92.62%) (15530/16768)\n",
            "Epoch: 68 | Batch_idx: 140 |  Loss: (0.2109) | Acc: (92.51%) (16696/18048)\n",
            "Epoch: 68 | Batch_idx: 150 |  Loss: (0.2110) | Acc: (92.48%) (17875/19328)\n",
            "Epoch: 68 | Batch_idx: 160 |  Loss: (0.2110) | Acc: (92.47%) (19057/20608)\n",
            "Epoch: 68 | Batch_idx: 170 |  Loss: (0.2117) | Acc: (92.45%) (20236/21888)\n",
            "Epoch: 68 | Batch_idx: 180 |  Loss: (0.2124) | Acc: (92.46%) (21422/23168)\n",
            "Epoch: 68 | Batch_idx: 190 |  Loss: (0.2138) | Acc: (92.40%) (22591/24448)\n",
            "Epoch: 68 | Batch_idx: 200 |  Loss: (0.2148) | Acc: (92.34%) (23758/25728)\n",
            "Epoch: 68 | Batch_idx: 210 |  Loss: (0.2134) | Acc: (92.43%) (24963/27008)\n",
            "Epoch: 68 | Batch_idx: 220 |  Loss: (0.2140) | Acc: (92.40%) (26139/28288)\n",
            "Epoch: 68 | Batch_idx: 230 |  Loss: (0.2148) | Acc: (92.38%) (27315/29568)\n",
            "Epoch: 68 | Batch_idx: 240 |  Loss: (0.2144) | Acc: (92.40%) (28505/30848)\n",
            "Epoch: 68 | Batch_idx: 250 |  Loss: (0.2141) | Acc: (92.41%) (29688/32128)\n",
            "Epoch: 68 | Batch_idx: 260 |  Loss: (0.2141) | Acc: (92.41%) (30872/33408)\n",
            "Epoch: 68 | Batch_idx: 270 |  Loss: (0.2144) | Acc: (92.43%) (32061/34688)\n",
            "Epoch: 68 | Batch_idx: 280 |  Loss: (0.2145) | Acc: (92.40%) (33235/35968)\n",
            "Epoch: 68 | Batch_idx: 290 |  Loss: (0.2151) | Acc: (92.39%) (34415/37248)\n",
            "Epoch: 68 | Batch_idx: 300 |  Loss: (0.2151) | Acc: (92.37%) (35587/38528)\n",
            "Epoch: 68 | Batch_idx: 310 |  Loss: (0.2150) | Acc: (92.40%) (36783/39808)\n",
            "Epoch: 68 | Batch_idx: 320 |  Loss: (0.2154) | Acc: (92.38%) (37959/41088)\n",
            "Epoch: 68 | Batch_idx: 330 |  Loss: (0.2153) | Acc: (92.35%) (39126/42368)\n",
            "Epoch: 68 | Batch_idx: 340 |  Loss: (0.2148) | Acc: (92.38%) (40321/43648)\n",
            "Epoch: 68 | Batch_idx: 350 |  Loss: (0.2149) | Acc: (92.39%) (41511/44928)\n",
            "Epoch: 68 | Batch_idx: 360 |  Loss: (0.2150) | Acc: (92.40%) (42697/46208)\n",
            "Epoch: 68 | Batch_idx: 370 |  Loss: (0.2151) | Acc: (92.41%) (43882/47488)\n",
            "Epoch: 68 | Batch_idx: 380 |  Loss: (0.2162) | Acc: (92.37%) (45048/48768)\n",
            "Epoch: 68 | Batch_idx: 390 |  Loss: (0.2179) | Acc: (92.34%) (46168/50000)\n",
            "# TEST : Loss: (0.5855) | Acc: (83.74%) (8374/10000)\n",
            "Epoch: 69 | Batch_idx: 0 |  Loss: (0.1577) | Acc: (94.53%) (121/128)\n",
            "Epoch: 69 | Batch_idx: 10 |  Loss: (0.2149) | Acc: (91.97%) (1295/1408)\n",
            "Epoch: 69 | Batch_idx: 20 |  Loss: (0.2193) | Acc: (92.08%) (2475/2688)\n",
            "Epoch: 69 | Batch_idx: 30 |  Loss: (0.2170) | Acc: (92.31%) (3663/3968)\n",
            "Epoch: 69 | Batch_idx: 40 |  Loss: (0.2118) | Acc: (92.55%) (4857/5248)\n",
            "Epoch: 69 | Batch_idx: 50 |  Loss: (0.2075) | Acc: (92.75%) (6055/6528)\n",
            "Epoch: 69 | Batch_idx: 60 |  Loss: (0.2083) | Acc: (92.83%) (7248/7808)\n",
            "Epoch: 69 | Batch_idx: 70 |  Loss: (0.2104) | Acc: (92.65%) (8420/9088)\n",
            "Epoch: 69 | Batch_idx: 80 |  Loss: (0.2119) | Acc: (92.60%) (9601/10368)\n",
            "Epoch: 69 | Batch_idx: 90 |  Loss: (0.2094) | Acc: (92.67%) (10794/11648)\n",
            "Epoch: 69 | Batch_idx: 100 |  Loss: (0.2114) | Acc: (92.60%) (11971/12928)\n",
            "Epoch: 69 | Batch_idx: 110 |  Loss: (0.2112) | Acc: (92.58%) (13154/14208)\n",
            "Epoch: 69 | Batch_idx: 120 |  Loss: (0.2112) | Acc: (92.60%) (14342/15488)\n",
            "Epoch: 69 | Batch_idx: 130 |  Loss: (0.2110) | Acc: (92.57%) (15522/16768)\n",
            "Epoch: 69 | Batch_idx: 140 |  Loss: (0.2116) | Acc: (92.56%) (16705/18048)\n",
            "Epoch: 69 | Batch_idx: 150 |  Loss: (0.2108) | Acc: (92.54%) (17886/19328)\n",
            "Epoch: 69 | Batch_idx: 160 |  Loss: (0.2123) | Acc: (92.54%) (19070/20608)\n",
            "Epoch: 69 | Batch_idx: 170 |  Loss: (0.2143) | Acc: (92.43%) (20230/21888)\n",
            "Epoch: 69 | Batch_idx: 180 |  Loss: (0.2144) | Acc: (92.42%) (21413/23168)\n",
            "Epoch: 69 | Batch_idx: 190 |  Loss: (0.2144) | Acc: (92.44%) (22599/24448)\n",
            "Epoch: 69 | Batch_idx: 200 |  Loss: (0.2159) | Acc: (92.39%) (23769/25728)\n",
            "Epoch: 69 | Batch_idx: 210 |  Loss: (0.2154) | Acc: (92.39%) (24953/27008)\n",
            "Epoch: 69 | Batch_idx: 220 |  Loss: (0.2166) | Acc: (92.34%) (26121/28288)\n",
            "Epoch: 69 | Batch_idx: 230 |  Loss: (0.2165) | Acc: (92.31%) (27295/29568)\n",
            "Epoch: 69 | Batch_idx: 240 |  Loss: (0.2167) | Acc: (92.28%) (28465/30848)\n",
            "Epoch: 69 | Batch_idx: 250 |  Loss: (0.2178) | Acc: (92.22%) (29628/32128)\n",
            "Epoch: 69 | Batch_idx: 260 |  Loss: (0.2192) | Acc: (92.20%) (30801/33408)\n",
            "Epoch: 69 | Batch_idx: 270 |  Loss: (0.2196) | Acc: (92.18%) (31977/34688)\n",
            "Epoch: 69 | Batch_idx: 280 |  Loss: (0.2207) | Acc: (92.14%) (33142/35968)\n",
            "Epoch: 69 | Batch_idx: 290 |  Loss: (0.2226) | Acc: (92.07%) (34294/37248)\n",
            "Epoch: 69 | Batch_idx: 300 |  Loss: (0.2233) | Acc: (92.03%) (35458/38528)\n",
            "Epoch: 69 | Batch_idx: 310 |  Loss: (0.2230) | Acc: (92.07%) (36650/39808)\n",
            "Epoch: 69 | Batch_idx: 320 |  Loss: (0.2233) | Acc: (92.06%) (37826/41088)\n",
            "Epoch: 69 | Batch_idx: 330 |  Loss: (0.2235) | Acc: (92.03%) (38993/42368)\n",
            "Epoch: 69 | Batch_idx: 340 |  Loss: (0.2247) | Acc: (92.02%) (40165/43648)\n",
            "Epoch: 69 | Batch_idx: 350 |  Loss: (0.2245) | Acc: (92.04%) (41352/44928)\n",
            "Epoch: 69 | Batch_idx: 360 |  Loss: (0.2241) | Acc: (92.04%) (42532/46208)\n",
            "Epoch: 69 | Batch_idx: 370 |  Loss: (0.2242) | Acc: (92.02%) (43697/47488)\n",
            "Epoch: 69 | Batch_idx: 380 |  Loss: (0.2235) | Acc: (92.05%) (44890/48768)\n",
            "Epoch: 69 | Batch_idx: 390 |  Loss: (0.2245) | Acc: (92.02%) (46009/50000)\n",
            "# TEST : Loss: (0.4339) | Acc: (86.99%) (8699/10000)\n",
            "Epoch: 70 | Batch_idx: 0 |  Loss: (0.1831) | Acc: (93.75%) (120/128)\n",
            "Epoch: 70 | Batch_idx: 10 |  Loss: (0.2059) | Acc: (92.40%) (1301/1408)\n",
            "Epoch: 70 | Batch_idx: 20 |  Loss: (0.2096) | Acc: (92.19%) (2478/2688)\n",
            "Epoch: 70 | Batch_idx: 30 |  Loss: (0.2088) | Acc: (92.46%) (3669/3968)\n",
            "Epoch: 70 | Batch_idx: 40 |  Loss: (0.2063) | Acc: (92.63%) (4861/5248)\n",
            "Epoch: 70 | Batch_idx: 50 |  Loss: (0.2052) | Acc: (92.63%) (6047/6528)\n",
            "Epoch: 70 | Batch_idx: 60 |  Loss: (0.2030) | Acc: (92.69%) (7237/7808)\n",
            "Epoch: 70 | Batch_idx: 70 |  Loss: (0.2037) | Acc: (92.80%) (8434/9088)\n",
            "Epoch: 70 | Batch_idx: 80 |  Loss: (0.2055) | Acc: (92.68%) (9609/10368)\n",
            "Epoch: 70 | Batch_idx: 90 |  Loss: (0.2047) | Acc: (92.77%) (10806/11648)\n",
            "Epoch: 70 | Batch_idx: 100 |  Loss: (0.2059) | Acc: (92.74%) (11990/12928)\n",
            "Epoch: 70 | Batch_idx: 110 |  Loss: (0.2094) | Acc: (92.65%) (13164/14208)\n",
            "Epoch: 70 | Batch_idx: 120 |  Loss: (0.2090) | Acc: (92.66%) (14351/15488)\n",
            "Epoch: 70 | Batch_idx: 130 |  Loss: (0.2093) | Acc: (92.66%) (15538/16768)\n",
            "Epoch: 70 | Batch_idx: 140 |  Loss: (0.2087) | Acc: (92.63%) (16718/18048)\n",
            "Epoch: 70 | Batch_idx: 150 |  Loss: (0.2082) | Acc: (92.65%) (17907/19328)\n",
            "Epoch: 70 | Batch_idx: 160 |  Loss: (0.2090) | Acc: (92.60%) (19082/20608)\n",
            "Epoch: 70 | Batch_idx: 170 |  Loss: (0.2107) | Acc: (92.59%) (20266/21888)\n",
            "Epoch: 70 | Batch_idx: 180 |  Loss: (0.2093) | Acc: (92.66%) (21467/23168)\n",
            "Epoch: 70 | Batch_idx: 190 |  Loss: (0.2099) | Acc: (92.66%) (22653/24448)\n",
            "Epoch: 70 | Batch_idx: 200 |  Loss: (0.2111) | Acc: (92.64%) (23834/25728)\n",
            "Epoch: 70 | Batch_idx: 210 |  Loss: (0.2135) | Acc: (92.53%) (24990/27008)\n",
            "Epoch: 70 | Batch_idx: 220 |  Loss: (0.2135) | Acc: (92.53%) (26176/28288)\n",
            "Epoch: 70 | Batch_idx: 230 |  Loss: (0.2152) | Acc: (92.45%) (27337/29568)\n",
            "Epoch: 70 | Batch_idx: 240 |  Loss: (0.2159) | Acc: (92.42%) (28510/30848)\n",
            "Epoch: 70 | Batch_idx: 250 |  Loss: (0.2158) | Acc: (92.41%) (29688/32128)\n",
            "Epoch: 70 | Batch_idx: 260 |  Loss: (0.2164) | Acc: (92.41%) (30873/33408)\n",
            "Epoch: 70 | Batch_idx: 270 |  Loss: (0.2168) | Acc: (92.38%) (32046/34688)\n",
            "Epoch: 70 | Batch_idx: 280 |  Loss: (0.2174) | Acc: (92.36%) (33220/35968)\n",
            "Epoch: 70 | Batch_idx: 290 |  Loss: (0.2185) | Acc: (92.34%) (34396/37248)\n",
            "Epoch: 70 | Batch_idx: 300 |  Loss: (0.2184) | Acc: (92.36%) (35584/38528)\n",
            "Epoch: 70 | Batch_idx: 310 |  Loss: (0.2175) | Acc: (92.38%) (36776/39808)\n",
            "Epoch: 70 | Batch_idx: 320 |  Loss: (0.2172) | Acc: (92.40%) (37965/41088)\n",
            "Epoch: 70 | Batch_idx: 330 |  Loss: (0.2176) | Acc: (92.39%) (39143/42368)\n",
            "Epoch: 70 | Batch_idx: 340 |  Loss: (0.2166) | Acc: (92.42%) (40339/43648)\n",
            "Epoch: 70 | Batch_idx: 350 |  Loss: (0.2174) | Acc: (92.40%) (41513/44928)\n",
            "Epoch: 70 | Batch_idx: 360 |  Loss: (0.2171) | Acc: (92.41%) (42700/46208)\n",
            "Epoch: 70 | Batch_idx: 370 |  Loss: (0.2171) | Acc: (92.40%) (43880/47488)\n",
            "Epoch: 70 | Batch_idx: 380 |  Loss: (0.2171) | Acc: (92.39%) (45058/48768)\n",
            "Epoch: 70 | Batch_idx: 390 |  Loss: (0.2170) | Acc: (92.38%) (46191/50000)\n",
            "# TEST : Loss: (0.4474) | Acc: (86.97%) (8697/10000)\n",
            "Epoch: 71 | Batch_idx: 0 |  Loss: (0.1642) | Acc: (96.09%) (123/128)\n",
            "Epoch: 71 | Batch_idx: 10 |  Loss: (0.2243) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 71 | Batch_idx: 20 |  Loss: (0.2060) | Acc: (92.97%) (2499/2688)\n",
            "Epoch: 71 | Batch_idx: 30 |  Loss: (0.2040) | Acc: (93.02%) (3691/3968)\n",
            "Epoch: 71 | Batch_idx: 40 |  Loss: (0.1972) | Acc: (93.22%) (4892/5248)\n",
            "Epoch: 71 | Batch_idx: 50 |  Loss: (0.1971) | Acc: (93.18%) (6083/6528)\n",
            "Epoch: 71 | Batch_idx: 60 |  Loss: (0.1969) | Acc: (93.17%) (7275/7808)\n",
            "Epoch: 71 | Batch_idx: 70 |  Loss: (0.2028) | Acc: (93.01%) (8453/9088)\n",
            "Epoch: 71 | Batch_idx: 80 |  Loss: (0.2052) | Acc: (92.85%) (9627/10368)\n",
            "Epoch: 71 | Batch_idx: 90 |  Loss: (0.2042) | Acc: (92.93%) (10824/11648)\n",
            "Epoch: 71 | Batch_idx: 100 |  Loss: (0.2060) | Acc: (92.94%) (12015/12928)\n",
            "Epoch: 71 | Batch_idx: 110 |  Loss: (0.2071) | Acc: (92.91%) (13201/14208)\n",
            "Epoch: 71 | Batch_idx: 120 |  Loss: (0.2062) | Acc: (92.83%) (14378/15488)\n",
            "Epoch: 71 | Batch_idx: 130 |  Loss: (0.2082) | Acc: (92.71%) (15546/16768)\n",
            "Epoch: 71 | Batch_idx: 140 |  Loss: (0.2076) | Acc: (92.75%) (16740/18048)\n",
            "Epoch: 71 | Batch_idx: 150 |  Loss: (0.2092) | Acc: (92.65%) (17908/19328)\n",
            "Epoch: 71 | Batch_idx: 160 |  Loss: (0.2107) | Acc: (92.61%) (19086/20608)\n",
            "Epoch: 71 | Batch_idx: 170 |  Loss: (0.2111) | Acc: (92.57%) (20261/21888)\n",
            "Epoch: 71 | Batch_idx: 180 |  Loss: (0.2106) | Acc: (92.56%) (21445/23168)\n",
            "Epoch: 71 | Batch_idx: 190 |  Loss: (0.2089) | Acc: (92.59%) (22636/24448)\n",
            "Epoch: 71 | Batch_idx: 200 |  Loss: (0.2096) | Acc: (92.58%) (23818/25728)\n",
            "Epoch: 71 | Batch_idx: 210 |  Loss: (0.2093) | Acc: (92.56%) (24998/27008)\n",
            "Epoch: 71 | Batch_idx: 220 |  Loss: (0.2094) | Acc: (92.57%) (26185/28288)\n",
            "Epoch: 71 | Batch_idx: 230 |  Loss: (0.2121) | Acc: (92.50%) (27350/29568)\n",
            "Epoch: 71 | Batch_idx: 240 |  Loss: (0.2114) | Acc: (92.55%) (28551/30848)\n",
            "Epoch: 71 | Batch_idx: 250 |  Loss: (0.2145) | Acc: (92.44%) (29700/32128)\n",
            "Epoch: 71 | Batch_idx: 260 |  Loss: (0.2138) | Acc: (92.44%) (30884/33408)\n",
            "Epoch: 71 | Batch_idx: 270 |  Loss: (0.2141) | Acc: (92.44%) (32066/34688)\n",
            "Epoch: 71 | Batch_idx: 280 |  Loss: (0.2151) | Acc: (92.41%) (33238/35968)\n",
            "Epoch: 71 | Batch_idx: 290 |  Loss: (0.2165) | Acc: (92.38%) (34408/37248)\n",
            "Epoch: 71 | Batch_idx: 300 |  Loss: (0.2172) | Acc: (92.32%) (35569/38528)\n",
            "Epoch: 71 | Batch_idx: 310 |  Loss: (0.2190) | Acc: (92.27%) (36731/39808)\n",
            "Epoch: 71 | Batch_idx: 320 |  Loss: (0.2192) | Acc: (92.25%) (37902/41088)\n",
            "Epoch: 71 | Batch_idx: 330 |  Loss: (0.2191) | Acc: (92.26%) (39087/42368)\n",
            "Epoch: 71 | Batch_idx: 340 |  Loss: (0.2195) | Acc: (92.24%) (40259/43648)\n",
            "Epoch: 71 | Batch_idx: 350 |  Loss: (0.2189) | Acc: (92.27%) (41457/44928)\n",
            "Epoch: 71 | Batch_idx: 360 |  Loss: (0.2190) | Acc: (92.27%) (42636/46208)\n",
            "Epoch: 71 | Batch_idx: 370 |  Loss: (0.2197) | Acc: (92.24%) (43801/47488)\n",
            "Epoch: 71 | Batch_idx: 380 |  Loss: (0.2207) | Acc: (92.19%) (44959/48768)\n",
            "Epoch: 71 | Batch_idx: 390 |  Loss: (0.2209) | Acc: (92.18%) (46092/50000)\n",
            "# TEST : Loss: (0.4133) | Acc: (87.41%) (8741/10000)\n",
            "Epoch: 72 | Batch_idx: 0 |  Loss: (0.2070) | Acc: (91.41%) (117/128)\n",
            "Epoch: 72 | Batch_idx: 10 |  Loss: (0.2219) | Acc: (91.62%) (1290/1408)\n",
            "Epoch: 72 | Batch_idx: 20 |  Loss: (0.2192) | Acc: (91.93%) (2471/2688)\n",
            "Epoch: 72 | Batch_idx: 30 |  Loss: (0.2188) | Acc: (92.34%) (3664/3968)\n",
            "Epoch: 72 | Batch_idx: 40 |  Loss: (0.2224) | Acc: (92.40%) (4849/5248)\n",
            "Epoch: 72 | Batch_idx: 50 |  Loss: (0.2232) | Acc: (92.31%) (6026/6528)\n",
            "Epoch: 72 | Batch_idx: 60 |  Loss: (0.2242) | Acc: (92.34%) (7210/7808)\n",
            "Epoch: 72 | Batch_idx: 70 |  Loss: (0.2224) | Acc: (92.39%) (8396/9088)\n",
            "Epoch: 72 | Batch_idx: 80 |  Loss: (0.2189) | Acc: (92.42%) (9582/10368)\n",
            "Epoch: 72 | Batch_idx: 90 |  Loss: (0.2190) | Acc: (92.50%) (10774/11648)\n",
            "Epoch: 72 | Batch_idx: 100 |  Loss: (0.2167) | Acc: (92.47%) (11955/12928)\n",
            "Epoch: 72 | Batch_idx: 110 |  Loss: (0.2152) | Acc: (92.51%) (13144/14208)\n",
            "Epoch: 72 | Batch_idx: 120 |  Loss: (0.2153) | Acc: (92.52%) (14330/15488)\n",
            "Epoch: 72 | Batch_idx: 130 |  Loss: (0.2174) | Acc: (92.44%) (15500/16768)\n",
            "Epoch: 72 | Batch_idx: 140 |  Loss: (0.2155) | Acc: (92.48%) (16691/18048)\n",
            "Epoch: 72 | Batch_idx: 150 |  Loss: (0.2164) | Acc: (92.44%) (17866/19328)\n",
            "Epoch: 72 | Batch_idx: 160 |  Loss: (0.2154) | Acc: (92.48%) (19058/20608)\n",
            "Epoch: 72 | Batch_idx: 170 |  Loss: (0.2154) | Acc: (92.45%) (20236/21888)\n",
            "Epoch: 72 | Batch_idx: 180 |  Loss: (0.2168) | Acc: (92.42%) (21413/23168)\n",
            "Epoch: 72 | Batch_idx: 190 |  Loss: (0.2167) | Acc: (92.41%) (22592/24448)\n",
            "Epoch: 72 | Batch_idx: 200 |  Loss: (0.2165) | Acc: (92.42%) (23777/25728)\n",
            "Epoch: 72 | Batch_idx: 210 |  Loss: (0.2173) | Acc: (92.39%) (24953/27008)\n",
            "Epoch: 72 | Batch_idx: 220 |  Loss: (0.2173) | Acc: (92.41%) (26142/28288)\n",
            "Epoch: 72 | Batch_idx: 230 |  Loss: (0.2173) | Acc: (92.43%) (27329/29568)\n",
            "Epoch: 72 | Batch_idx: 240 |  Loss: (0.2177) | Acc: (92.39%) (28499/30848)\n",
            "Epoch: 72 | Batch_idx: 250 |  Loss: (0.2173) | Acc: (92.40%) (29686/32128)\n",
            "Epoch: 72 | Batch_idx: 260 |  Loss: (0.2161) | Acc: (92.42%) (30875/33408)\n",
            "Epoch: 72 | Batch_idx: 270 |  Loss: (0.2161) | Acc: (92.43%) (32063/34688)\n",
            "Epoch: 72 | Batch_idx: 280 |  Loss: (0.2155) | Acc: (92.44%) (33250/35968)\n",
            "Epoch: 72 | Batch_idx: 290 |  Loss: (0.2162) | Acc: (92.45%) (34434/37248)\n",
            "Epoch: 72 | Batch_idx: 300 |  Loss: (0.2174) | Acc: (92.38%) (35592/38528)\n",
            "Epoch: 72 | Batch_idx: 310 |  Loss: (0.2174) | Acc: (92.35%) (36762/39808)\n",
            "Epoch: 72 | Batch_idx: 320 |  Loss: (0.2181) | Acc: (92.33%) (37938/41088)\n",
            "Epoch: 72 | Batch_idx: 330 |  Loss: (0.2174) | Acc: (92.36%) (39131/42368)\n",
            "Epoch: 72 | Batch_idx: 340 |  Loss: (0.2182) | Acc: (92.31%) (40290/43648)\n",
            "Epoch: 72 | Batch_idx: 350 |  Loss: (0.2178) | Acc: (92.32%) (41477/44928)\n",
            "Epoch: 72 | Batch_idx: 360 |  Loss: (0.2180) | Acc: (92.32%) (42660/46208)\n",
            "Epoch: 72 | Batch_idx: 370 |  Loss: (0.2183) | Acc: (92.31%) (43836/47488)\n",
            "Epoch: 72 | Batch_idx: 380 |  Loss: (0.2184) | Acc: (92.30%) (45014/48768)\n",
            "Epoch: 72 | Batch_idx: 390 |  Loss: (0.2191) | Acc: (92.26%) (46128/50000)\n",
            "# TEST : Loss: (0.4698) | Acc: (85.94%) (8594/10000)\n",
            "Epoch: 73 | Batch_idx: 0 |  Loss: (0.2345) | Acc: (90.62%) (116/128)\n",
            "Epoch: 73 | Batch_idx: 10 |  Loss: (0.2302) | Acc: (92.19%) (1298/1408)\n",
            "Epoch: 73 | Batch_idx: 20 |  Loss: (0.2244) | Acc: (92.26%) (2480/2688)\n",
            "Epoch: 73 | Batch_idx: 30 |  Loss: (0.2270) | Acc: (92.24%) (3660/3968)\n",
            "Epoch: 73 | Batch_idx: 40 |  Loss: (0.2288) | Acc: (92.05%) (4831/5248)\n",
            "Epoch: 73 | Batch_idx: 50 |  Loss: (0.2250) | Acc: (92.13%) (6014/6528)\n",
            "Epoch: 73 | Batch_idx: 60 |  Loss: (0.2229) | Acc: (92.24%) (7202/7808)\n",
            "Epoch: 73 | Batch_idx: 70 |  Loss: (0.2221) | Acc: (92.24%) (8383/9088)\n",
            "Epoch: 73 | Batch_idx: 80 |  Loss: (0.2209) | Acc: (92.31%) (9571/10368)\n",
            "Epoch: 73 | Batch_idx: 90 |  Loss: (0.2202) | Acc: (92.33%) (10755/11648)\n",
            "Epoch: 73 | Batch_idx: 100 |  Loss: (0.2173) | Acc: (92.45%) (11952/12928)\n",
            "Epoch: 73 | Batch_idx: 110 |  Loss: (0.2139) | Acc: (92.58%) (13154/14208)\n",
            "Epoch: 73 | Batch_idx: 120 |  Loss: (0.2128) | Acc: (92.58%) (14339/15488)\n",
            "Epoch: 73 | Batch_idx: 130 |  Loss: (0.2125) | Acc: (92.57%) (15522/16768)\n",
            "Epoch: 73 | Batch_idx: 140 |  Loss: (0.2108) | Acc: (92.64%) (16720/18048)\n",
            "Epoch: 73 | Batch_idx: 150 |  Loss: (0.2117) | Acc: (92.59%) (17896/19328)\n",
            "Epoch: 73 | Batch_idx: 160 |  Loss: (0.2130) | Acc: (92.54%) (19071/20608)\n",
            "Epoch: 73 | Batch_idx: 170 |  Loss: (0.2122) | Acc: (92.55%) (20258/21888)\n",
            "Epoch: 73 | Batch_idx: 180 |  Loss: (0.2125) | Acc: (92.49%) (21427/23168)\n",
            "Epoch: 73 | Batch_idx: 190 |  Loss: (0.2132) | Acc: (92.46%) (22605/24448)\n",
            "Epoch: 73 | Batch_idx: 200 |  Loss: (0.2139) | Acc: (92.45%) (23786/25728)\n",
            "Epoch: 73 | Batch_idx: 210 |  Loss: (0.2148) | Acc: (92.43%) (24964/27008)\n",
            "Epoch: 73 | Batch_idx: 220 |  Loss: (0.2142) | Acc: (92.46%) (26155/28288)\n",
            "Epoch: 73 | Batch_idx: 230 |  Loss: (0.2151) | Acc: (92.44%) (27333/29568)\n",
            "Epoch: 73 | Batch_idx: 240 |  Loss: (0.2155) | Acc: (92.40%) (28505/30848)\n",
            "Epoch: 73 | Batch_idx: 250 |  Loss: (0.2158) | Acc: (92.41%) (29688/32128)\n",
            "Epoch: 73 | Batch_idx: 260 |  Loss: (0.2158) | Acc: (92.42%) (30875/33408)\n",
            "Epoch: 73 | Batch_idx: 270 |  Loss: (0.2156) | Acc: (92.44%) (32065/34688)\n",
            "Epoch: 73 | Batch_idx: 280 |  Loss: (0.2161) | Acc: (92.46%) (33257/35968)\n",
            "Epoch: 73 | Batch_idx: 290 |  Loss: (0.2156) | Acc: (92.49%) (34449/37248)\n",
            "Epoch: 73 | Batch_idx: 300 |  Loss: (0.2162) | Acc: (92.48%) (35629/38528)\n",
            "Epoch: 73 | Batch_idx: 310 |  Loss: (0.2158) | Acc: (92.50%) (36824/39808)\n",
            "Epoch: 73 | Batch_idx: 320 |  Loss: (0.2172) | Acc: (92.46%) (37989/41088)\n",
            "Epoch: 73 | Batch_idx: 330 |  Loss: (0.2183) | Acc: (92.43%) (39160/42368)\n",
            "Epoch: 73 | Batch_idx: 340 |  Loss: (0.2183) | Acc: (92.43%) (40343/43648)\n",
            "Epoch: 73 | Batch_idx: 350 |  Loss: (0.2195) | Acc: (92.39%) (41508/44928)\n",
            "Epoch: 73 | Batch_idx: 360 |  Loss: (0.2202) | Acc: (92.36%) (42678/46208)\n",
            "Epoch: 73 | Batch_idx: 370 |  Loss: (0.2205) | Acc: (92.35%) (43854/47488)\n",
            "Epoch: 73 | Batch_idx: 380 |  Loss: (0.2206) | Acc: (92.33%) (45026/48768)\n",
            "Epoch: 73 | Batch_idx: 390 |  Loss: (0.2201) | Acc: (92.33%) (46165/50000)\n",
            "# TEST : Loss: (0.4180) | Acc: (87.06%) (8706/10000)\n",
            "Epoch: 74 | Batch_idx: 0 |  Loss: (0.2124) | Acc: (94.53%) (121/128)\n",
            "Epoch: 74 | Batch_idx: 10 |  Loss: (0.1750) | Acc: (93.89%) (1322/1408)\n",
            "Epoch: 74 | Batch_idx: 20 |  Loss: (0.2049) | Acc: (92.37%) (2483/2688)\n",
            "Epoch: 74 | Batch_idx: 30 |  Loss: (0.2125) | Acc: (92.29%) (3662/3968)\n",
            "Epoch: 74 | Batch_idx: 40 |  Loss: (0.2077) | Acc: (92.49%) (4854/5248)\n",
            "Epoch: 74 | Batch_idx: 50 |  Loss: (0.2092) | Acc: (92.59%) (6044/6528)\n",
            "Epoch: 74 | Batch_idx: 60 |  Loss: (0.2076) | Acc: (92.66%) (7235/7808)\n",
            "Epoch: 74 | Batch_idx: 70 |  Loss: (0.2085) | Acc: (92.58%) (8414/9088)\n",
            "Epoch: 74 | Batch_idx: 80 |  Loss: (0.2091) | Acc: (92.52%) (9592/10368)\n",
            "Epoch: 74 | Batch_idx: 90 |  Loss: (0.2095) | Acc: (92.46%) (10770/11648)\n",
            "Epoch: 74 | Batch_idx: 100 |  Loss: (0.2083) | Acc: (92.51%) (11960/12928)\n",
            "Epoch: 74 | Batch_idx: 110 |  Loss: (0.2081) | Acc: (92.51%) (13144/14208)\n",
            "Epoch: 74 | Batch_idx: 120 |  Loss: (0.2092) | Acc: (92.43%) (14315/15488)\n",
            "Epoch: 74 | Batch_idx: 130 |  Loss: (0.2088) | Acc: (92.45%) (15502/16768)\n",
            "Epoch: 74 | Batch_idx: 140 |  Loss: (0.2074) | Acc: (92.52%) (16698/18048)\n",
            "Epoch: 74 | Batch_idx: 150 |  Loss: (0.2085) | Acc: (92.50%) (17879/19328)\n",
            "Epoch: 74 | Batch_idx: 160 |  Loss: (0.2111) | Acc: (92.40%) (19042/20608)\n",
            "Epoch: 74 | Batch_idx: 170 |  Loss: (0.2124) | Acc: (92.38%) (20221/21888)\n",
            "Epoch: 74 | Batch_idx: 180 |  Loss: (0.2112) | Acc: (92.40%) (21407/23168)\n",
            "Epoch: 74 | Batch_idx: 190 |  Loss: (0.2118) | Acc: (92.41%) (22593/24448)\n",
            "Epoch: 74 | Batch_idx: 200 |  Loss: (0.2121) | Acc: (92.42%) (23779/25728)\n",
            "Epoch: 74 | Batch_idx: 210 |  Loss: (0.2127) | Acc: (92.40%) (24955/27008)\n",
            "Epoch: 74 | Batch_idx: 220 |  Loss: (0.2106) | Acc: (92.49%) (26164/28288)\n",
            "Epoch: 74 | Batch_idx: 230 |  Loss: (0.2094) | Acc: (92.51%) (27353/29568)\n",
            "Epoch: 74 | Batch_idx: 240 |  Loss: (0.2106) | Acc: (92.46%) (28522/30848)\n",
            "Epoch: 74 | Batch_idx: 250 |  Loss: (0.2101) | Acc: (92.52%) (29724/32128)\n",
            "Epoch: 74 | Batch_idx: 260 |  Loss: (0.2094) | Acc: (92.53%) (30914/33408)\n",
            "Epoch: 74 | Batch_idx: 270 |  Loss: (0.2093) | Acc: (92.55%) (32103/34688)\n",
            "Epoch: 74 | Batch_idx: 280 |  Loss: (0.2086) | Acc: (92.57%) (33296/35968)\n",
            "Epoch: 74 | Batch_idx: 290 |  Loss: (0.2095) | Acc: (92.53%) (34467/37248)\n",
            "Epoch: 74 | Batch_idx: 300 |  Loss: (0.2114) | Acc: (92.46%) (35622/38528)\n",
            "Epoch: 74 | Batch_idx: 310 |  Loss: (0.2122) | Acc: (92.40%) (36784/39808)\n",
            "Epoch: 74 | Batch_idx: 320 |  Loss: (0.2134) | Acc: (92.37%) (37951/41088)\n",
            "Epoch: 74 | Batch_idx: 330 |  Loss: (0.2145) | Acc: (92.34%) (39122/42368)\n",
            "Epoch: 74 | Batch_idx: 340 |  Loss: (0.2151) | Acc: (92.32%) (40294/43648)\n",
            "Epoch: 74 | Batch_idx: 350 |  Loss: (0.2158) | Acc: (92.29%) (41466/44928)\n",
            "Epoch: 74 | Batch_idx: 360 |  Loss: (0.2160) | Acc: (92.28%) (42642/46208)\n",
            "Epoch: 74 | Batch_idx: 370 |  Loss: (0.2170) | Acc: (92.26%) (43811/47488)\n",
            "Epoch: 74 | Batch_idx: 380 |  Loss: (0.2167) | Acc: (92.26%) (44995/48768)\n",
            "Epoch: 74 | Batch_idx: 390 |  Loss: (0.2168) | Acc: (92.27%) (46133/50000)\n",
            "# TEST : Loss: (0.4609) | Acc: (85.86%) (8586/10000)\n",
            "Epoch: 75 | Batch_idx: 0 |  Loss: (0.2863) | Acc: (89.06%) (114/128)\n",
            "Epoch: 75 | Batch_idx: 10 |  Loss: (0.2096) | Acc: (92.90%) (1308/1408)\n",
            "Epoch: 75 | Batch_idx: 20 |  Loss: (0.2126) | Acc: (92.71%) (2492/2688)\n",
            "Epoch: 75 | Batch_idx: 30 |  Loss: (0.1947) | Acc: (93.07%) (3693/3968)\n",
            "Epoch: 75 | Batch_idx: 40 |  Loss: (0.1961) | Acc: (93.01%) (4881/5248)\n",
            "Epoch: 75 | Batch_idx: 50 |  Loss: (0.1961) | Acc: (93.01%) (6072/6528)\n",
            "Epoch: 75 | Batch_idx: 60 |  Loss: (0.1996) | Acc: (92.83%) (7248/7808)\n",
            "Epoch: 75 | Batch_idx: 70 |  Loss: (0.2008) | Acc: (92.69%) (8424/9088)\n",
            "Epoch: 75 | Batch_idx: 80 |  Loss: (0.2027) | Acc: (92.67%) (9608/10368)\n",
            "Epoch: 75 | Batch_idx: 90 |  Loss: (0.2060) | Acc: (92.57%) (10783/11648)\n",
            "Epoch: 75 | Batch_idx: 100 |  Loss: (0.2082) | Acc: (92.51%) (11960/12928)\n",
            "Epoch: 75 | Batch_idx: 110 |  Loss: (0.2056) | Acc: (92.61%) (13158/14208)\n",
            "Epoch: 75 | Batch_idx: 120 |  Loss: (0.2025) | Acc: (92.76%) (14367/15488)\n",
            "Epoch: 75 | Batch_idx: 130 |  Loss: (0.2038) | Acc: (92.74%) (15551/16768)\n",
            "Epoch: 75 | Batch_idx: 140 |  Loss: (0.2036) | Acc: (92.74%) (16737/18048)\n",
            "Epoch: 75 | Batch_idx: 150 |  Loss: (0.2063) | Acc: (92.72%) (17920/19328)\n",
            "Epoch: 75 | Batch_idx: 160 |  Loss: (0.2091) | Acc: (92.61%) (19085/20608)\n",
            "Epoch: 75 | Batch_idx: 170 |  Loss: (0.2096) | Acc: (92.59%) (20267/21888)\n",
            "Epoch: 75 | Batch_idx: 180 |  Loss: (0.2100) | Acc: (92.64%) (21463/23168)\n",
            "Epoch: 75 | Batch_idx: 190 |  Loss: (0.2104) | Acc: (92.62%) (22644/24448)\n",
            "Epoch: 75 | Batch_idx: 200 |  Loss: (0.2104) | Acc: (92.65%) (23838/25728)\n",
            "Epoch: 75 | Batch_idx: 210 |  Loss: (0.2108) | Acc: (92.62%) (25014/27008)\n",
            "Epoch: 75 | Batch_idx: 220 |  Loss: (0.2120) | Acc: (92.56%) (26183/28288)\n",
            "Epoch: 75 | Batch_idx: 230 |  Loss: (0.2121) | Acc: (92.53%) (27358/29568)\n",
            "Epoch: 75 | Batch_idx: 240 |  Loss: (0.2131) | Acc: (92.53%) (28544/30848)\n",
            "Epoch: 75 | Batch_idx: 250 |  Loss: (0.2135) | Acc: (92.53%) (29729/32128)\n",
            "Epoch: 75 | Batch_idx: 260 |  Loss: (0.2138) | Acc: (92.50%) (30902/33408)\n",
            "Epoch: 75 | Batch_idx: 270 |  Loss: (0.2145) | Acc: (92.46%) (32071/34688)\n",
            "Epoch: 75 | Batch_idx: 280 |  Loss: (0.2141) | Acc: (92.49%) (33268/35968)\n",
            "Epoch: 75 | Batch_idx: 290 |  Loss: (0.2140) | Acc: (92.49%) (34452/37248)\n",
            "Epoch: 75 | Batch_idx: 300 |  Loss: (0.2158) | Acc: (92.41%) (35603/38528)\n",
            "Epoch: 75 | Batch_idx: 310 |  Loss: (0.2162) | Acc: (92.40%) (36781/39808)\n",
            "Epoch: 75 | Batch_idx: 320 |  Loss: (0.2150) | Acc: (92.44%) (37981/41088)\n",
            "Epoch: 75 | Batch_idx: 330 |  Loss: (0.2143) | Acc: (92.45%) (39171/42368)\n",
            "Epoch: 75 | Batch_idx: 340 |  Loss: (0.2151) | Acc: (92.40%) (40330/43648)\n",
            "Epoch: 75 | Batch_idx: 350 |  Loss: (0.2155) | Acc: (92.40%) (41513/44928)\n",
            "Epoch: 75 | Batch_idx: 360 |  Loss: (0.2165) | Acc: (92.38%) (42689/46208)\n",
            "Epoch: 75 | Batch_idx: 370 |  Loss: (0.2160) | Acc: (92.41%) (43882/47488)\n",
            "Epoch: 75 | Batch_idx: 380 |  Loss: (0.2152) | Acc: (92.43%) (45075/48768)\n",
            "Epoch: 75 | Batch_idx: 390 |  Loss: (0.2152) | Acc: (92.42%) (46210/50000)\n",
            "# TEST : Loss: (0.3876) | Acc: (87.95%) (8795/10000)\n",
            "Epoch: 76 | Batch_idx: 0 |  Loss: (0.1323) | Acc: (93.75%) (120/128)\n",
            "Epoch: 76 | Batch_idx: 10 |  Loss: (0.1874) | Acc: (93.61%) (1318/1408)\n",
            "Epoch: 76 | Batch_idx: 20 |  Loss: (0.2017) | Acc: (92.97%) (2499/2688)\n",
            "Epoch: 76 | Batch_idx: 30 |  Loss: (0.2083) | Acc: (92.79%) (3682/3968)\n",
            "Epoch: 76 | Batch_idx: 40 |  Loss: (0.2079) | Acc: (92.85%) (4873/5248)\n",
            "Epoch: 76 | Batch_idx: 50 |  Loss: (0.2019) | Acc: (92.91%) (6065/6528)\n",
            "Epoch: 76 | Batch_idx: 60 |  Loss: (0.1973) | Acc: (93.06%) (7266/7808)\n",
            "Epoch: 76 | Batch_idx: 70 |  Loss: (0.2002) | Acc: (93.00%) (8452/9088)\n",
            "Epoch: 76 | Batch_idx: 80 |  Loss: (0.2021) | Acc: (92.93%) (9635/10368)\n",
            "Epoch: 76 | Batch_idx: 90 |  Loss: (0.2021) | Acc: (92.91%) (10822/11648)\n",
            "Epoch: 76 | Batch_idx: 100 |  Loss: (0.2052) | Acc: (92.77%) (11993/12928)\n",
            "Epoch: 76 | Batch_idx: 110 |  Loss: (0.2031) | Acc: (92.87%) (13195/14208)\n",
            "Epoch: 76 | Batch_idx: 120 |  Loss: (0.2025) | Acc: (92.90%) (14389/15488)\n",
            "Epoch: 76 | Batch_idx: 130 |  Loss: (0.2021) | Acc: (92.93%) (15583/16768)\n",
            "Epoch: 76 | Batch_idx: 140 |  Loss: (0.2039) | Acc: (92.86%) (16759/18048)\n",
            "Epoch: 76 | Batch_idx: 150 |  Loss: (0.2034) | Acc: (92.84%) (17944/19328)\n",
            "Epoch: 76 | Batch_idx: 160 |  Loss: (0.2052) | Acc: (92.79%) (19122/20608)\n",
            "Epoch: 76 | Batch_idx: 170 |  Loss: (0.2055) | Acc: (92.76%) (20304/21888)\n",
            "Epoch: 76 | Batch_idx: 180 |  Loss: (0.2057) | Acc: (92.74%) (21486/23168)\n",
            "Epoch: 76 | Batch_idx: 190 |  Loss: (0.2063) | Acc: (92.75%) (22676/24448)\n",
            "Epoch: 76 | Batch_idx: 200 |  Loss: (0.2068) | Acc: (92.70%) (23850/25728)\n",
            "Epoch: 76 | Batch_idx: 210 |  Loss: (0.2076) | Acc: (92.65%) (25022/27008)\n",
            "Epoch: 76 | Batch_idx: 220 |  Loss: (0.2078) | Acc: (92.68%) (26216/28288)\n",
            "Epoch: 76 | Batch_idx: 230 |  Loss: (0.2086) | Acc: (92.66%) (27399/29568)\n",
            "Epoch: 76 | Batch_idx: 240 |  Loss: (0.2093) | Acc: (92.64%) (28579/30848)\n",
            "Epoch: 76 | Batch_idx: 250 |  Loss: (0.2097) | Acc: (92.61%) (29755/32128)\n",
            "Epoch: 76 | Batch_idx: 260 |  Loss: (0.2113) | Acc: (92.56%) (30923/33408)\n",
            "Epoch: 76 | Batch_idx: 270 |  Loss: (0.2115) | Acc: (92.57%) (32112/34688)\n",
            "Epoch: 76 | Batch_idx: 280 |  Loss: (0.2114) | Acc: (92.61%) (33309/35968)\n",
            "Epoch: 76 | Batch_idx: 290 |  Loss: (0.2117) | Acc: (92.59%) (34488/37248)\n",
            "Epoch: 76 | Batch_idx: 300 |  Loss: (0.2126) | Acc: (92.58%) (35671/38528)\n",
            "Epoch: 76 | Batch_idx: 310 |  Loss: (0.2134) | Acc: (92.57%) (36849/39808)\n",
            "Epoch: 76 | Batch_idx: 320 |  Loss: (0.2146) | Acc: (92.52%) (38015/41088)\n",
            "Epoch: 76 | Batch_idx: 330 |  Loss: (0.2146) | Acc: (92.54%) (39207/42368)\n",
            "Epoch: 76 | Batch_idx: 340 |  Loss: (0.2150) | Acc: (92.52%) (40383/43648)\n",
            "Epoch: 76 | Batch_idx: 350 |  Loss: (0.2150) | Acc: (92.49%) (41556/44928)\n",
            "Epoch: 76 | Batch_idx: 360 |  Loss: (0.2144) | Acc: (92.51%) (42746/46208)\n",
            "Epoch: 76 | Batch_idx: 370 |  Loss: (0.2147) | Acc: (92.50%) (43925/47488)\n",
            "Epoch: 76 | Batch_idx: 380 |  Loss: (0.2146) | Acc: (92.50%) (45112/48768)\n",
            "Epoch: 76 | Batch_idx: 390 |  Loss: (0.2150) | Acc: (92.50%) (46251/50000)\n",
            "# TEST : Loss: (0.4790) | Acc: (85.64%) (8564/10000)\n",
            "Epoch: 77 | Batch_idx: 0 |  Loss: (0.1986) | Acc: (93.75%) (120/128)\n",
            "Epoch: 77 | Batch_idx: 10 |  Loss: (0.2005) | Acc: (92.90%) (1308/1408)\n",
            "Epoch: 77 | Batch_idx: 20 |  Loss: (0.1969) | Acc: (92.93%) (2498/2688)\n",
            "Epoch: 77 | Batch_idx: 30 |  Loss: (0.2026) | Acc: (92.59%) (3674/3968)\n",
            "Epoch: 77 | Batch_idx: 40 |  Loss: (0.2018) | Acc: (92.72%) (4866/5248)\n",
            "Epoch: 77 | Batch_idx: 50 |  Loss: (0.1983) | Acc: (93.08%) (6076/6528)\n",
            "Epoch: 77 | Batch_idx: 60 |  Loss: (0.1959) | Acc: (93.07%) (7267/7808)\n",
            "Epoch: 77 | Batch_idx: 70 |  Loss: (0.1943) | Acc: (93.16%) (8466/9088)\n",
            "Epoch: 77 | Batch_idx: 80 |  Loss: (0.1955) | Acc: (93.14%) (9657/10368)\n",
            "Epoch: 77 | Batch_idx: 90 |  Loss: (0.1974) | Acc: (93.04%) (10837/11648)\n",
            "Epoch: 77 | Batch_idx: 100 |  Loss: (0.1993) | Acc: (92.96%) (12018/12928)\n",
            "Epoch: 77 | Batch_idx: 110 |  Loss: (0.2010) | Acc: (92.92%) (13202/14208)\n",
            "Epoch: 77 | Batch_idx: 120 |  Loss: (0.2048) | Acc: (92.78%) (14370/15488)\n",
            "Epoch: 77 | Batch_idx: 130 |  Loss: (0.2074) | Acc: (92.71%) (15545/16768)\n",
            "Epoch: 77 | Batch_idx: 140 |  Loss: (0.2052) | Acc: (92.74%) (16737/18048)\n",
            "Epoch: 77 | Batch_idx: 150 |  Loss: (0.2059) | Acc: (92.70%) (17917/19328)\n",
            "Epoch: 77 | Batch_idx: 160 |  Loss: (0.2062) | Acc: (92.72%) (19108/20608)\n",
            "Epoch: 77 | Batch_idx: 170 |  Loss: (0.2040) | Acc: (92.75%) (20302/21888)\n",
            "Epoch: 77 | Batch_idx: 180 |  Loss: (0.2020) | Acc: (92.86%) (21513/23168)\n",
            "Epoch: 77 | Batch_idx: 190 |  Loss: (0.2024) | Acc: (92.84%) (22697/24448)\n",
            "Epoch: 77 | Batch_idx: 200 |  Loss: (0.2034) | Acc: (92.83%) (23884/25728)\n",
            "Epoch: 77 | Batch_idx: 210 |  Loss: (0.2058) | Acc: (92.75%) (25049/27008)\n",
            "Epoch: 77 | Batch_idx: 220 |  Loss: (0.2059) | Acc: (92.76%) (26239/28288)\n",
            "Epoch: 77 | Batch_idx: 230 |  Loss: (0.2064) | Acc: (92.75%) (27424/29568)\n",
            "Epoch: 77 | Batch_idx: 240 |  Loss: (0.2068) | Acc: (92.75%) (28611/30848)\n",
            "Epoch: 77 | Batch_idx: 250 |  Loss: (0.2066) | Acc: (92.73%) (29792/32128)\n",
            "Epoch: 77 | Batch_idx: 260 |  Loss: (0.2063) | Acc: (92.73%) (30979/33408)\n",
            "Epoch: 77 | Batch_idx: 270 |  Loss: (0.2072) | Acc: (92.68%) (32150/34688)\n",
            "Epoch: 77 | Batch_idx: 280 |  Loss: (0.2089) | Acc: (92.64%) (33320/35968)\n",
            "Epoch: 77 | Batch_idx: 290 |  Loss: (0.2094) | Acc: (92.64%) (34505/37248)\n",
            "Epoch: 77 | Batch_idx: 300 |  Loss: (0.2092) | Acc: (92.66%) (35700/38528)\n",
            "Epoch: 77 | Batch_idx: 310 |  Loss: (0.2097) | Acc: (92.64%) (36879/39808)\n",
            "Epoch: 77 | Batch_idx: 320 |  Loss: (0.2105) | Acc: (92.61%) (38053/41088)\n",
            "Epoch: 77 | Batch_idx: 330 |  Loss: (0.2113) | Acc: (92.62%) (39241/42368)\n",
            "Epoch: 77 | Batch_idx: 340 |  Loss: (0.2118) | Acc: (92.62%) (40426/43648)\n",
            "Epoch: 77 | Batch_idx: 350 |  Loss: (0.2117) | Acc: (92.62%) (41613/44928)\n",
            "Epoch: 77 | Batch_idx: 360 |  Loss: (0.2130) | Acc: (92.56%) (42772/46208)\n",
            "Epoch: 77 | Batch_idx: 370 |  Loss: (0.2137) | Acc: (92.53%) (43939/47488)\n",
            "Epoch: 77 | Batch_idx: 380 |  Loss: (0.2151) | Acc: (92.50%) (45110/48768)\n",
            "Epoch: 77 | Batch_idx: 390 |  Loss: (0.2155) | Acc: (92.48%) (46240/50000)\n",
            "# TEST : Loss: (0.4057) | Acc: (87.78%) (8778/10000)\n",
            "Epoch: 78 | Batch_idx: 0 |  Loss: (0.1177) | Acc: (96.88%) (124/128)\n",
            "Epoch: 78 | Batch_idx: 10 |  Loss: (0.1988) | Acc: (92.83%) (1307/1408)\n",
            "Epoch: 78 | Batch_idx: 20 |  Loss: (0.2008) | Acc: (92.82%) (2495/2688)\n",
            "Epoch: 78 | Batch_idx: 30 |  Loss: (0.2007) | Acc: (92.94%) (3688/3968)\n",
            "Epoch: 78 | Batch_idx: 40 |  Loss: (0.2045) | Acc: (92.68%) (4864/5248)\n",
            "Epoch: 78 | Batch_idx: 50 |  Loss: (0.2002) | Acc: (92.80%) (6058/6528)\n",
            "Epoch: 78 | Batch_idx: 60 |  Loss: (0.1994) | Acc: (92.89%) (7253/7808)\n",
            "Epoch: 78 | Batch_idx: 70 |  Loss: (0.1985) | Acc: (93.00%) (8452/9088)\n",
            "Epoch: 78 | Batch_idx: 80 |  Loss: (0.1996) | Acc: (92.82%) (9624/10368)\n",
            "Epoch: 78 | Batch_idx: 90 |  Loss: (0.1982) | Acc: (92.94%) (10826/11648)\n",
            "Epoch: 78 | Batch_idx: 100 |  Loss: (0.1969) | Acc: (92.96%) (12018/12928)\n",
            "Epoch: 78 | Batch_idx: 110 |  Loss: (0.1959) | Acc: (93.03%) (13217/14208)\n",
            "Epoch: 78 | Batch_idx: 120 |  Loss: (0.1969) | Acc: (92.96%) (14398/15488)\n",
            "Epoch: 78 | Batch_idx: 130 |  Loss: (0.1980) | Acc: (92.92%) (15581/16768)\n",
            "Epoch: 78 | Batch_idx: 140 |  Loss: (0.1989) | Acc: (92.92%) (16770/18048)\n",
            "Epoch: 78 | Batch_idx: 150 |  Loss: (0.1998) | Acc: (92.90%) (17956/19328)\n",
            "Epoch: 78 | Batch_idx: 160 |  Loss: (0.2020) | Acc: (92.84%) (19133/20608)\n",
            "Epoch: 78 | Batch_idx: 170 |  Loss: (0.2004) | Acc: (92.96%) (20348/21888)\n",
            "Epoch: 78 | Batch_idx: 180 |  Loss: (0.1999) | Acc: (92.96%) (21537/23168)\n",
            "Epoch: 78 | Batch_idx: 190 |  Loss: (0.1994) | Acc: (92.98%) (22732/24448)\n",
            "Epoch: 78 | Batch_idx: 200 |  Loss: (0.2003) | Acc: (92.93%) (23909/25728)\n",
            "Epoch: 78 | Batch_idx: 210 |  Loss: (0.2020) | Acc: (92.91%) (25094/27008)\n",
            "Epoch: 78 | Batch_idx: 220 |  Loss: (0.2046) | Acc: (92.83%) (26260/28288)\n",
            "Epoch: 78 | Batch_idx: 230 |  Loss: (0.2052) | Acc: (92.81%) (27443/29568)\n",
            "Epoch: 78 | Batch_idx: 240 |  Loss: (0.2072) | Acc: (92.74%) (28607/30848)\n",
            "Epoch: 78 | Batch_idx: 250 |  Loss: (0.2072) | Acc: (92.75%) (29798/32128)\n",
            "Epoch: 78 | Batch_idx: 260 |  Loss: (0.2078) | Acc: (92.73%) (30980/33408)\n",
            "Epoch: 78 | Batch_idx: 270 |  Loss: (0.2078) | Acc: (92.73%) (32167/34688)\n",
            "Epoch: 78 | Batch_idx: 280 |  Loss: (0.2084) | Acc: (92.71%) (33347/35968)\n",
            "Epoch: 78 | Batch_idx: 290 |  Loss: (0.2100) | Acc: (92.67%) (34517/37248)\n",
            "Epoch: 78 | Batch_idx: 300 |  Loss: (0.2108) | Acc: (92.63%) (35690/38528)\n",
            "Epoch: 78 | Batch_idx: 310 |  Loss: (0.2113) | Acc: (92.63%) (36873/39808)\n",
            "Epoch: 78 | Batch_idx: 320 |  Loss: (0.2116) | Acc: (92.62%) (38057/41088)\n",
            "Epoch: 78 | Batch_idx: 330 |  Loss: (0.2131) | Acc: (92.57%) (39220/42368)\n",
            "Epoch: 78 | Batch_idx: 340 |  Loss: (0.2142) | Acc: (92.55%) (40397/43648)\n",
            "Epoch: 78 | Batch_idx: 350 |  Loss: (0.2146) | Acc: (92.55%) (41580/44928)\n",
            "Epoch: 78 | Batch_idx: 360 |  Loss: (0.2148) | Acc: (92.53%) (42756/46208)\n",
            "Epoch: 78 | Batch_idx: 370 |  Loss: (0.2158) | Acc: (92.47%) (43914/47488)\n",
            "Epoch: 78 | Batch_idx: 380 |  Loss: (0.2160) | Acc: (92.48%) (45100/48768)\n",
            "Epoch: 78 | Batch_idx: 390 |  Loss: (0.2157) | Acc: (92.49%) (46246/50000)\n",
            "# TEST : Loss: (0.4331) | Acc: (86.91%) (8691/10000)\n",
            "Epoch: 79 | Batch_idx: 0 |  Loss: (0.1940) | Acc: (95.31%) (122/128)\n",
            "Epoch: 79 | Batch_idx: 10 |  Loss: (0.1789) | Acc: (94.18%) (1326/1408)\n",
            "Epoch: 79 | Batch_idx: 20 |  Loss: (0.1901) | Acc: (93.53%) (2514/2688)\n",
            "Epoch: 79 | Batch_idx: 30 |  Loss: (0.1864) | Acc: (93.75%) (3720/3968)\n",
            "Epoch: 79 | Batch_idx: 40 |  Loss: (0.1815) | Acc: (93.88%) (4927/5248)\n",
            "Epoch: 79 | Batch_idx: 50 |  Loss: (0.1859) | Acc: (93.73%) (6119/6528)\n",
            "Epoch: 79 | Batch_idx: 60 |  Loss: (0.1842) | Acc: (93.84%) (7327/7808)\n",
            "Epoch: 79 | Batch_idx: 70 |  Loss: (0.1877) | Acc: (93.69%) (8515/9088)\n",
            "Epoch: 79 | Batch_idx: 80 |  Loss: (0.1870) | Acc: (93.55%) (9699/10368)\n",
            "Epoch: 79 | Batch_idx: 90 |  Loss: (0.1874) | Acc: (93.51%) (10892/11648)\n",
            "Epoch: 79 | Batch_idx: 100 |  Loss: (0.1891) | Acc: (93.39%) (12074/12928)\n",
            "Epoch: 79 | Batch_idx: 110 |  Loss: (0.1959) | Acc: (93.19%) (13241/14208)\n",
            "Epoch: 79 | Batch_idx: 120 |  Loss: (0.1997) | Acc: (93.07%) (14415/15488)\n",
            "Epoch: 79 | Batch_idx: 130 |  Loss: (0.2023) | Acc: (92.96%) (15588/16768)\n",
            "Epoch: 79 | Batch_idx: 140 |  Loss: (0.2016) | Acc: (92.98%) (16781/18048)\n",
            "Epoch: 79 | Batch_idx: 150 |  Loss: (0.2063) | Acc: (92.79%) (17935/19328)\n",
            "Epoch: 79 | Batch_idx: 160 |  Loss: (0.2058) | Acc: (92.85%) (19135/20608)\n",
            "Epoch: 79 | Batch_idx: 170 |  Loss: (0.2070) | Acc: (92.78%) (20307/21888)\n",
            "Epoch: 79 | Batch_idx: 180 |  Loss: (0.2063) | Acc: (92.83%) (21506/23168)\n",
            "Epoch: 79 | Batch_idx: 190 |  Loss: (0.2085) | Acc: (92.79%) (22686/24448)\n",
            "Epoch: 79 | Batch_idx: 200 |  Loss: (0.2088) | Acc: (92.78%) (23871/25728)\n",
            "Epoch: 79 | Batch_idx: 210 |  Loss: (0.2084) | Acc: (92.80%) (25064/27008)\n",
            "Epoch: 79 | Batch_idx: 220 |  Loss: (0.2083) | Acc: (92.78%) (26245/28288)\n",
            "Epoch: 79 | Batch_idx: 230 |  Loss: (0.2077) | Acc: (92.82%) (27445/29568)\n",
            "Epoch: 79 | Batch_idx: 240 |  Loss: (0.2077) | Acc: (92.82%) (28633/30848)\n",
            "Epoch: 79 | Batch_idx: 250 |  Loss: (0.2087) | Acc: (92.77%) (29806/32128)\n",
            "Epoch: 79 | Batch_idx: 260 |  Loss: (0.2091) | Acc: (92.77%) (30991/33408)\n",
            "Epoch: 79 | Batch_idx: 270 |  Loss: (0.2097) | Acc: (92.76%) (32177/34688)\n",
            "Epoch: 79 | Batch_idx: 280 |  Loss: (0.2106) | Acc: (92.71%) (33347/35968)\n",
            "Epoch: 79 | Batch_idx: 290 |  Loss: (0.2115) | Acc: (92.69%) (34526/37248)\n",
            "Epoch: 79 | Batch_idx: 300 |  Loss: (0.2123) | Acc: (92.66%) (35701/38528)\n",
            "Epoch: 79 | Batch_idx: 310 |  Loss: (0.2126) | Acc: (92.65%) (36882/39808)\n",
            "Epoch: 79 | Batch_idx: 320 |  Loss: (0.2132) | Acc: (92.63%) (38058/41088)\n",
            "Epoch: 79 | Batch_idx: 330 |  Loss: (0.2143) | Acc: (92.57%) (39222/42368)\n",
            "Epoch: 79 | Batch_idx: 340 |  Loss: (0.2142) | Acc: (92.59%) (40412/43648)\n",
            "Epoch: 79 | Batch_idx: 350 |  Loss: (0.2144) | Acc: (92.58%) (41596/44928)\n",
            "Epoch: 79 | Batch_idx: 360 |  Loss: (0.2146) | Acc: (92.55%) (42767/46208)\n",
            "Epoch: 79 | Batch_idx: 370 |  Loss: (0.2147) | Acc: (92.55%) (43952/47488)\n",
            "Epoch: 79 | Batch_idx: 380 |  Loss: (0.2146) | Acc: (92.55%) (45133/48768)\n",
            "Epoch: 79 | Batch_idx: 390 |  Loss: (0.2146) | Acc: (92.56%) (46278/50000)\n",
            "# TEST : Loss: (0.4520) | Acc: (86.07%) (8607/10000)\n",
            "Epoch: 80 | Batch_idx: 0 |  Loss: (0.3087) | Acc: (89.84%) (115/128)\n",
            "Epoch: 80 | Batch_idx: 10 |  Loss: (0.1764) | Acc: (93.89%) (1322/1408)\n",
            "Epoch: 80 | Batch_idx: 20 |  Loss: (0.1767) | Acc: (93.94%) (2525/2688)\n",
            "Epoch: 80 | Batch_idx: 30 |  Loss: (0.1723) | Acc: (94.15%) (3736/3968)\n",
            "Epoch: 80 | Batch_idx: 40 |  Loss: (0.1709) | Acc: (94.15%) (4941/5248)\n",
            "Epoch: 80 | Batch_idx: 50 |  Loss: (0.1653) | Acc: (94.30%) (6156/6528)\n",
            "Epoch: 80 | Batch_idx: 60 |  Loss: (0.1631) | Acc: (94.39%) (7370/7808)\n",
            "Epoch: 80 | Batch_idx: 70 |  Loss: (0.1601) | Acc: (94.49%) (8587/9088)\n",
            "Epoch: 80 | Batch_idx: 80 |  Loss: (0.1565) | Acc: (94.63%) (9811/10368)\n",
            "Epoch: 80 | Batch_idx: 90 |  Loss: (0.1563) | Acc: (94.68%) (11028/11648)\n",
            "Epoch: 80 | Batch_idx: 100 |  Loss: (0.1559) | Acc: (94.67%) (12239/12928)\n",
            "Epoch: 80 | Batch_idx: 110 |  Loss: (0.1549) | Acc: (94.70%) (13455/14208)\n",
            "Epoch: 80 | Batch_idx: 120 |  Loss: (0.1533) | Acc: (94.81%) (14684/15488)\n",
            "Epoch: 80 | Batch_idx: 130 |  Loss: (0.1522) | Acc: (94.81%) (15897/16768)\n",
            "Epoch: 80 | Batch_idx: 140 |  Loss: (0.1510) | Acc: (94.87%) (17123/18048)\n",
            "Epoch: 80 | Batch_idx: 150 |  Loss: (0.1505) | Acc: (94.93%) (18349/19328)\n",
            "Epoch: 80 | Batch_idx: 160 |  Loss: (0.1480) | Acc: (95.05%) (19588/20608)\n",
            "Epoch: 80 | Batch_idx: 170 |  Loss: (0.1471) | Acc: (95.06%) (20807/21888)\n",
            "Epoch: 80 | Batch_idx: 180 |  Loss: (0.1467) | Acc: (95.07%) (22026/23168)\n",
            "Epoch: 80 | Batch_idx: 190 |  Loss: (0.1451) | Acc: (95.14%) (23259/24448)\n",
            "Epoch: 80 | Batch_idx: 200 |  Loss: (0.1436) | Acc: (95.15%) (24480/25728)\n",
            "Epoch: 80 | Batch_idx: 210 |  Loss: (0.1436) | Acc: (95.15%) (25698/27008)\n",
            "Epoch: 80 | Batch_idx: 220 |  Loss: (0.1425) | Acc: (95.17%) (26922/28288)\n",
            "Epoch: 80 | Batch_idx: 230 |  Loss: (0.1413) | Acc: (95.24%) (28160/29568)\n",
            "Epoch: 80 | Batch_idx: 240 |  Loss: (0.1408) | Acc: (95.26%) (29385/30848)\n",
            "Epoch: 80 | Batch_idx: 250 |  Loss: (0.1401) | Acc: (95.26%) (30606/32128)\n",
            "Epoch: 80 | Batch_idx: 260 |  Loss: (0.1391) | Acc: (95.29%) (31835/33408)\n",
            "Epoch: 80 | Batch_idx: 270 |  Loss: (0.1385) | Acc: (95.33%) (33067/34688)\n",
            "Epoch: 80 | Batch_idx: 280 |  Loss: (0.1376) | Acc: (95.38%) (34306/35968)\n",
            "Epoch: 80 | Batch_idx: 290 |  Loss: (0.1370) | Acc: (95.41%) (35538/37248)\n",
            "Epoch: 80 | Batch_idx: 300 |  Loss: (0.1366) | Acc: (95.42%) (36764/38528)\n",
            "Epoch: 80 | Batch_idx: 310 |  Loss: (0.1358) | Acc: (95.45%) (37998/39808)\n",
            "Epoch: 80 | Batch_idx: 320 |  Loss: (0.1357) | Acc: (95.46%) (39224/41088)\n",
            "Epoch: 80 | Batch_idx: 330 |  Loss: (0.1352) | Acc: (95.48%) (40451/42368)\n",
            "Epoch: 80 | Batch_idx: 340 |  Loss: (0.1349) | Acc: (95.48%) (41674/43648)\n",
            "Epoch: 80 | Batch_idx: 350 |  Loss: (0.1346) | Acc: (95.46%) (42889/44928)\n",
            "Epoch: 80 | Batch_idx: 360 |  Loss: (0.1340) | Acc: (95.47%) (44115/46208)\n",
            "Epoch: 80 | Batch_idx: 370 |  Loss: (0.1338) | Acc: (95.46%) (45332/47488)\n",
            "Epoch: 80 | Batch_idx: 380 |  Loss: (0.1337) | Acc: (95.47%) (46560/48768)\n",
            "Epoch: 80 | Batch_idx: 390 |  Loss: (0.1335) | Acc: (95.47%) (47737/50000)\n",
            "# TEST : Loss: (0.2852) | Acc: (91.16%) (9116/10000)\n",
            "Epoch: 81 | Batch_idx: 0 |  Loss: (0.1958) | Acc: (92.19%) (118/128)\n",
            "Epoch: 81 | Batch_idx: 10 |  Loss: (0.1208) | Acc: (95.74%) (1348/1408)\n",
            "Epoch: 81 | Batch_idx: 20 |  Loss: (0.1180) | Acc: (95.57%) (2569/2688)\n",
            "Epoch: 81 | Batch_idx: 30 |  Loss: (0.1119) | Acc: (96.02%) (3810/3968)\n",
            "Epoch: 81 | Batch_idx: 40 |  Loss: (0.1065) | Acc: (96.40%) (5059/5248)\n",
            "Epoch: 81 | Batch_idx: 50 |  Loss: (0.1067) | Acc: (96.35%) (6290/6528)\n",
            "Epoch: 81 | Batch_idx: 60 |  Loss: (0.1084) | Acc: (96.40%) (7527/7808)\n",
            "Epoch: 81 | Batch_idx: 70 |  Loss: (0.1096) | Acc: (96.30%) (8752/9088)\n",
            "Epoch: 81 | Batch_idx: 80 |  Loss: (0.1096) | Acc: (96.34%) (9989/10368)\n",
            "Epoch: 81 | Batch_idx: 90 |  Loss: (0.1107) | Acc: (96.36%) (11224/11648)\n",
            "Epoch: 81 | Batch_idx: 100 |  Loss: (0.1101) | Acc: (96.31%) (12451/12928)\n",
            "Epoch: 81 | Batch_idx: 110 |  Loss: (0.1098) | Acc: (96.35%) (13689/14208)\n",
            "Epoch: 81 | Batch_idx: 120 |  Loss: (0.1085) | Acc: (96.44%) (14936/15488)\n",
            "Epoch: 81 | Batch_idx: 130 |  Loss: (0.1087) | Acc: (96.39%) (16163/16768)\n",
            "Epoch: 81 | Batch_idx: 140 |  Loss: (0.1092) | Acc: (96.35%) (17389/18048)\n",
            "Epoch: 81 | Batch_idx: 150 |  Loss: (0.1078) | Acc: (96.37%) (18627/19328)\n",
            "Epoch: 81 | Batch_idx: 160 |  Loss: (0.1071) | Acc: (96.37%) (19859/20608)\n",
            "Epoch: 81 | Batch_idx: 170 |  Loss: (0.1073) | Acc: (96.38%) (21096/21888)\n",
            "Epoch: 81 | Batch_idx: 180 |  Loss: (0.1089) | Acc: (96.32%) (22315/23168)\n",
            "Epoch: 81 | Batch_idx: 190 |  Loss: (0.1084) | Acc: (96.32%) (23549/24448)\n",
            "Epoch: 81 | Batch_idx: 200 |  Loss: (0.1079) | Acc: (96.35%) (24788/25728)\n",
            "Epoch: 81 | Batch_idx: 210 |  Loss: (0.1078) | Acc: (96.36%) (26026/27008)\n",
            "Epoch: 81 | Batch_idx: 220 |  Loss: (0.1080) | Acc: (96.36%) (27259/28288)\n",
            "Epoch: 81 | Batch_idx: 230 |  Loss: (0.1080) | Acc: (96.36%) (28493/29568)\n",
            "Epoch: 81 | Batch_idx: 240 |  Loss: (0.1086) | Acc: (96.36%) (29724/30848)\n",
            "Epoch: 81 | Batch_idx: 250 |  Loss: (0.1081) | Acc: (96.38%) (30966/32128)\n",
            "Epoch: 81 | Batch_idx: 260 |  Loss: (0.1084) | Acc: (96.36%) (32191/33408)\n",
            "Epoch: 81 | Batch_idx: 270 |  Loss: (0.1084) | Acc: (96.34%) (33420/34688)\n",
            "Epoch: 81 | Batch_idx: 280 |  Loss: (0.1074) | Acc: (96.39%) (34669/35968)\n",
            "Epoch: 81 | Batch_idx: 290 |  Loss: (0.1076) | Acc: (96.38%) (35898/37248)\n",
            "Epoch: 81 | Batch_idx: 300 |  Loss: (0.1074) | Acc: (96.37%) (37128/38528)\n",
            "Epoch: 81 | Batch_idx: 310 |  Loss: (0.1070) | Acc: (96.39%) (38370/39808)\n",
            "Epoch: 81 | Batch_idx: 320 |  Loss: (0.1069) | Acc: (96.40%) (39609/41088)\n",
            "Epoch: 81 | Batch_idx: 330 |  Loss: (0.1068) | Acc: (96.42%) (40850/42368)\n",
            "Epoch: 81 | Batch_idx: 340 |  Loss: (0.1066) | Acc: (96.42%) (42086/43648)\n",
            "Epoch: 81 | Batch_idx: 350 |  Loss: (0.1067) | Acc: (96.41%) (43317/44928)\n",
            "Epoch: 81 | Batch_idx: 360 |  Loss: (0.1068) | Acc: (96.42%) (44556/46208)\n",
            "Epoch: 81 | Batch_idx: 370 |  Loss: (0.1072) | Acc: (96.41%) (45784/47488)\n",
            "Epoch: 81 | Batch_idx: 380 |  Loss: (0.1066) | Acc: (96.43%) (47029/48768)\n",
            "Epoch: 81 | Batch_idx: 390 |  Loss: (0.1060) | Acc: (96.47%) (48235/50000)\n",
            "# TEST : Loss: (0.2828) | Acc: (91.48%) (9148/10000)\n",
            "Epoch: 82 | Batch_idx: 0 |  Loss: (0.1234) | Acc: (95.31%) (122/128)\n",
            "Epoch: 82 | Batch_idx: 10 |  Loss: (0.0975) | Acc: (97.02%) (1366/1408)\n",
            "Epoch: 82 | Batch_idx: 20 |  Loss: (0.1009) | Acc: (96.76%) (2601/2688)\n",
            "Epoch: 82 | Batch_idx: 30 |  Loss: (0.0984) | Acc: (96.72%) (3838/3968)\n",
            "Epoch: 82 | Batch_idx: 40 |  Loss: (0.0947) | Acc: (96.74%) (5077/5248)\n",
            "Epoch: 82 | Batch_idx: 50 |  Loss: (0.0944) | Acc: (96.84%) (6322/6528)\n",
            "Epoch: 82 | Batch_idx: 60 |  Loss: (0.0924) | Acc: (96.90%) (7566/7808)\n",
            "Epoch: 82 | Batch_idx: 70 |  Loss: (0.0941) | Acc: (96.81%) (8798/9088)\n",
            "Epoch: 82 | Batch_idx: 80 |  Loss: (0.0938) | Acc: (96.85%) (10041/10368)\n",
            "Epoch: 82 | Batch_idx: 90 |  Loss: (0.0924) | Acc: (96.88%) (11285/11648)\n",
            "Epoch: 82 | Batch_idx: 100 |  Loss: (0.0924) | Acc: (96.85%) (12521/12928)\n",
            "Epoch: 82 | Batch_idx: 110 |  Loss: (0.0929) | Acc: (96.85%) (13761/14208)\n",
            "Epoch: 82 | Batch_idx: 120 |  Loss: (0.0932) | Acc: (96.83%) (14997/15488)\n",
            "Epoch: 82 | Batch_idx: 130 |  Loss: (0.0936) | Acc: (96.83%) (16236/16768)\n",
            "Epoch: 82 | Batch_idx: 140 |  Loss: (0.0942) | Acc: (96.78%) (17467/18048)\n",
            "Epoch: 82 | Batch_idx: 150 |  Loss: (0.0951) | Acc: (96.74%) (18698/19328)\n",
            "Epoch: 82 | Batch_idx: 160 |  Loss: (0.0947) | Acc: (96.75%) (19939/20608)\n",
            "Epoch: 82 | Batch_idx: 170 |  Loss: (0.0955) | Acc: (96.72%) (21170/21888)\n",
            "Epoch: 82 | Batch_idx: 180 |  Loss: (0.0957) | Acc: (96.72%) (22408/23168)\n",
            "Epoch: 82 | Batch_idx: 190 |  Loss: (0.0953) | Acc: (96.76%) (23656/24448)\n",
            "Epoch: 82 | Batch_idx: 200 |  Loss: (0.0952) | Acc: (96.77%) (24897/25728)\n",
            "Epoch: 82 | Batch_idx: 210 |  Loss: (0.0955) | Acc: (96.77%) (26136/27008)\n",
            "Epoch: 82 | Batch_idx: 220 |  Loss: (0.0948) | Acc: (96.80%) (27382/28288)\n",
            "Epoch: 82 | Batch_idx: 230 |  Loss: (0.0949) | Acc: (96.81%) (28625/29568)\n",
            "Epoch: 82 | Batch_idx: 240 |  Loss: (0.0944) | Acc: (96.83%) (29869/30848)\n",
            "Epoch: 82 | Batch_idx: 250 |  Loss: (0.0945) | Acc: (96.81%) (31104/32128)\n",
            "Epoch: 82 | Batch_idx: 260 |  Loss: (0.0945) | Acc: (96.82%) (32344/33408)\n",
            "Epoch: 82 | Batch_idx: 270 |  Loss: (0.0950) | Acc: (96.80%) (33579/34688)\n",
            "Epoch: 82 | Batch_idx: 280 |  Loss: (0.0953) | Acc: (96.78%) (34810/35968)\n",
            "Epoch: 82 | Batch_idx: 290 |  Loss: (0.0950) | Acc: (96.79%) (36052/37248)\n",
            "Epoch: 82 | Batch_idx: 300 |  Loss: (0.0946) | Acc: (96.82%) (37301/38528)\n",
            "Epoch: 82 | Batch_idx: 310 |  Loss: (0.0950) | Acc: (96.79%) (38529/39808)\n",
            "Epoch: 82 | Batch_idx: 320 |  Loss: (0.0957) | Acc: (96.76%) (39757/41088)\n",
            "Epoch: 82 | Batch_idx: 330 |  Loss: (0.0957) | Acc: (96.74%) (40987/42368)\n",
            "Epoch: 82 | Batch_idx: 340 |  Loss: (0.0957) | Acc: (96.74%) (42226/43648)\n",
            "Epoch: 82 | Batch_idx: 350 |  Loss: (0.0962) | Acc: (96.74%) (43464/44928)\n",
            "Epoch: 82 | Batch_idx: 360 |  Loss: (0.0962) | Acc: (96.75%) (44704/46208)\n",
            "Epoch: 82 | Batch_idx: 370 |  Loss: (0.0959) | Acc: (96.75%) (45946/47488)\n",
            "Epoch: 82 | Batch_idx: 380 |  Loss: (0.0964) | Acc: (96.74%) (47180/48768)\n",
            "Epoch: 82 | Batch_idx: 390 |  Loss: (0.0962) | Acc: (96.74%) (48370/50000)\n",
            "# TEST : Loss: (0.2817) | Acc: (91.51%) (9151/10000)\n",
            "Epoch: 83 | Batch_idx: 0 |  Loss: (0.0885) | Acc: (96.09%) (123/128)\n",
            "Epoch: 83 | Batch_idx: 10 |  Loss: (0.1006) | Acc: (96.88%) (1364/1408)\n",
            "Epoch: 83 | Batch_idx: 20 |  Loss: (0.0985) | Acc: (96.73%) (2600/2688)\n",
            "Epoch: 83 | Batch_idx: 30 |  Loss: (0.0914) | Acc: (97.00%) (3849/3968)\n",
            "Epoch: 83 | Batch_idx: 40 |  Loss: (0.0930) | Acc: (96.82%) (5081/5248)\n",
            "Epoch: 83 | Batch_idx: 50 |  Loss: (0.0937) | Acc: (96.71%) (6313/6528)\n",
            "Epoch: 83 | Batch_idx: 60 |  Loss: (0.0914) | Acc: (96.77%) (7556/7808)\n",
            "Epoch: 83 | Batch_idx: 70 |  Loss: (0.0898) | Acc: (96.81%) (8798/9088)\n",
            "Epoch: 83 | Batch_idx: 80 |  Loss: (0.0887) | Acc: (96.85%) (10041/10368)\n",
            "Epoch: 83 | Batch_idx: 90 |  Loss: (0.0887) | Acc: (96.90%) (11287/11648)\n",
            "Epoch: 83 | Batch_idx: 100 |  Loss: (0.0901) | Acc: (96.89%) (12526/12928)\n",
            "Epoch: 83 | Batch_idx: 110 |  Loss: (0.0897) | Acc: (96.94%) (13773/14208)\n",
            "Epoch: 83 | Batch_idx: 120 |  Loss: (0.0898) | Acc: (96.95%) (15016/15488)\n",
            "Epoch: 83 | Batch_idx: 130 |  Loss: (0.0920) | Acc: (96.88%) (16245/16768)\n",
            "Epoch: 83 | Batch_idx: 140 |  Loss: (0.0915) | Acc: (96.90%) (17488/18048)\n",
            "Epoch: 83 | Batch_idx: 150 |  Loss: (0.0905) | Acc: (96.94%) (18737/19328)\n",
            "Epoch: 83 | Batch_idx: 160 |  Loss: (0.0895) | Acc: (96.97%) (19984/20608)\n",
            "Epoch: 83 | Batch_idx: 170 |  Loss: (0.0895) | Acc: (96.98%) (21226/21888)\n",
            "Epoch: 83 | Batch_idx: 180 |  Loss: (0.0898) | Acc: (96.97%) (22465/23168)\n",
            "Epoch: 83 | Batch_idx: 190 |  Loss: (0.0896) | Acc: (96.98%) (23710/24448)\n",
            "Epoch: 83 | Batch_idx: 200 |  Loss: (0.0897) | Acc: (96.99%) (24954/25728)\n",
            "Epoch: 83 | Batch_idx: 210 |  Loss: (0.0901) | Acc: (96.99%) (26195/27008)\n",
            "Epoch: 83 | Batch_idx: 220 |  Loss: (0.0897) | Acc: (97.01%) (27442/28288)\n",
            "Epoch: 83 | Batch_idx: 230 |  Loss: (0.0894) | Acc: (97.04%) (28692/29568)\n",
            "Epoch: 83 | Batch_idx: 240 |  Loss: (0.0894) | Acc: (97.04%) (29935/30848)\n",
            "Epoch: 83 | Batch_idx: 250 |  Loss: (0.0892) | Acc: (97.05%) (31181/32128)\n",
            "Epoch: 83 | Batch_idx: 260 |  Loss: (0.0895) | Acc: (97.02%) (32412/33408)\n",
            "Epoch: 83 | Batch_idx: 270 |  Loss: (0.0896) | Acc: (97.01%) (33650/34688)\n",
            "Epoch: 83 | Batch_idx: 280 |  Loss: (0.0892) | Acc: (97.01%) (34891/35968)\n",
            "Epoch: 83 | Batch_idx: 290 |  Loss: (0.0889) | Acc: (97.03%) (36140/37248)\n",
            "Epoch: 83 | Batch_idx: 300 |  Loss: (0.0885) | Acc: (97.04%) (37388/38528)\n",
            "Epoch: 83 | Batch_idx: 310 |  Loss: (0.0883) | Acc: (97.05%) (38632/39808)\n",
            "Epoch: 83 | Batch_idx: 320 |  Loss: (0.0879) | Acc: (97.05%) (39876/41088)\n",
            "Epoch: 83 | Batch_idx: 330 |  Loss: (0.0875) | Acc: (97.04%) (41116/42368)\n",
            "Epoch: 83 | Batch_idx: 340 |  Loss: (0.0881) | Acc: (97.04%) (42355/43648)\n",
            "Epoch: 83 | Batch_idx: 350 |  Loss: (0.0883) | Acc: (97.02%) (43591/44928)\n",
            "Epoch: 83 | Batch_idx: 360 |  Loss: (0.0889) | Acc: (96.98%) (44813/46208)\n",
            "Epoch: 83 | Batch_idx: 370 |  Loss: (0.0886) | Acc: (96.97%) (46051/47488)\n",
            "Epoch: 83 | Batch_idx: 380 |  Loss: (0.0885) | Acc: (96.98%) (47296/48768)\n",
            "Epoch: 83 | Batch_idx: 390 |  Loss: (0.0881) | Acc: (96.98%) (48491/50000)\n",
            "# TEST : Loss: (0.2847) | Acc: (91.49%) (9149/10000)\n",
            "Epoch: 84 | Batch_idx: 0 |  Loss: (0.0791) | Acc: (96.88%) (124/128)\n",
            "Epoch: 84 | Batch_idx: 10 |  Loss: (0.0842) | Acc: (97.16%) (1368/1408)\n",
            "Epoch: 84 | Batch_idx: 20 |  Loss: (0.0818) | Acc: (97.25%) (2614/2688)\n",
            "Epoch: 84 | Batch_idx: 30 |  Loss: (0.0801) | Acc: (97.35%) (3863/3968)\n",
            "Epoch: 84 | Batch_idx: 40 |  Loss: (0.0842) | Acc: (97.12%) (5097/5248)\n",
            "Epoch: 84 | Batch_idx: 50 |  Loss: (0.0824) | Acc: (97.26%) (6349/6528)\n",
            "Epoch: 84 | Batch_idx: 60 |  Loss: (0.0830) | Acc: (97.30%) (7597/7808)\n",
            "Epoch: 84 | Batch_idx: 70 |  Loss: (0.0835) | Acc: (97.23%) (8836/9088)\n",
            "Epoch: 84 | Batch_idx: 80 |  Loss: (0.0829) | Acc: (97.20%) (10078/10368)\n",
            "Epoch: 84 | Batch_idx: 90 |  Loss: (0.0829) | Acc: (97.15%) (11316/11648)\n",
            "Epoch: 84 | Batch_idx: 100 |  Loss: (0.0841) | Acc: (97.18%) (12564/12928)\n",
            "Epoch: 84 | Batch_idx: 110 |  Loss: (0.0844) | Acc: (97.22%) (13813/14208)\n",
            "Epoch: 84 | Batch_idx: 120 |  Loss: (0.0847) | Acc: (97.20%) (15055/15488)\n",
            "Epoch: 84 | Batch_idx: 130 |  Loss: (0.0844) | Acc: (97.19%) (16297/16768)\n",
            "Epoch: 84 | Batch_idx: 140 |  Loss: (0.0837) | Acc: (97.22%) (17546/18048)\n",
            "Epoch: 84 | Batch_idx: 150 |  Loss: (0.0833) | Acc: (97.23%) (18793/19328)\n",
            "Epoch: 84 | Batch_idx: 160 |  Loss: (0.0841) | Acc: (97.19%) (20029/20608)\n",
            "Epoch: 84 | Batch_idx: 170 |  Loss: (0.0840) | Acc: (97.21%) (21277/21888)\n",
            "Epoch: 84 | Batch_idx: 180 |  Loss: (0.0833) | Acc: (97.23%) (22526/23168)\n",
            "Epoch: 84 | Batch_idx: 190 |  Loss: (0.0835) | Acc: (97.23%) (23771/24448)\n",
            "Epoch: 84 | Batch_idx: 200 |  Loss: (0.0827) | Acc: (97.24%) (25017/25728)\n",
            "Epoch: 84 | Batch_idx: 210 |  Loss: (0.0828) | Acc: (97.23%) (26259/27008)\n",
            "Epoch: 84 | Batch_idx: 220 |  Loss: (0.0832) | Acc: (97.22%) (27501/28288)\n",
            "Epoch: 84 | Batch_idx: 230 |  Loss: (0.0836) | Acc: (97.19%) (28737/29568)\n",
            "Epoch: 84 | Batch_idx: 240 |  Loss: (0.0838) | Acc: (97.18%) (29979/30848)\n",
            "Epoch: 84 | Batch_idx: 250 |  Loss: (0.0843) | Acc: (97.17%) (31218/32128)\n",
            "Epoch: 84 | Batch_idx: 260 |  Loss: (0.0843) | Acc: (97.17%) (32463/33408)\n",
            "Epoch: 84 | Batch_idx: 270 |  Loss: (0.0844) | Acc: (97.16%) (33704/34688)\n",
            "Epoch: 84 | Batch_idx: 280 |  Loss: (0.0845) | Acc: (97.16%) (34946/35968)\n",
            "Epoch: 84 | Batch_idx: 290 |  Loss: (0.0842) | Acc: (97.17%) (36195/37248)\n",
            "Epoch: 84 | Batch_idx: 300 |  Loss: (0.0838) | Acc: (97.19%) (37447/38528)\n",
            "Epoch: 84 | Batch_idx: 310 |  Loss: (0.0835) | Acc: (97.21%) (38699/39808)\n",
            "Epoch: 84 | Batch_idx: 320 |  Loss: (0.0829) | Acc: (97.24%) (39952/41088)\n",
            "Epoch: 84 | Batch_idx: 330 |  Loss: (0.0832) | Acc: (97.22%) (41191/42368)\n",
            "Epoch: 84 | Batch_idx: 340 |  Loss: (0.0829) | Acc: (97.23%) (42437/43648)\n",
            "Epoch: 84 | Batch_idx: 350 |  Loss: (0.0837) | Acc: (97.18%) (43661/44928)\n",
            "Epoch: 84 | Batch_idx: 360 |  Loss: (0.0836) | Acc: (97.18%) (44905/46208)\n",
            "Epoch: 84 | Batch_idx: 370 |  Loss: (0.0834) | Acc: (97.20%) (46156/47488)\n",
            "Epoch: 84 | Batch_idx: 380 |  Loss: (0.0836) | Acc: (97.20%) (47402/48768)\n",
            "Epoch: 84 | Batch_idx: 390 |  Loss: (0.0835) | Acc: (97.19%) (48596/50000)\n",
            "# TEST : Loss: (0.2891) | Acc: (91.70%) (9170/10000)\n",
            "Epoch: 85 | Batch_idx: 0 |  Loss: (0.0809) | Acc: (97.66%) (125/128)\n",
            "Epoch: 85 | Batch_idx: 10 |  Loss: (0.0690) | Acc: (97.87%) (1378/1408)\n",
            "Epoch: 85 | Batch_idx: 20 |  Loss: (0.0742) | Acc: (97.54%) (2622/2688)\n",
            "Epoch: 85 | Batch_idx: 30 |  Loss: (0.0782) | Acc: (97.30%) (3861/3968)\n",
            "Epoch: 85 | Batch_idx: 40 |  Loss: (0.0781) | Acc: (97.26%) (5104/5248)\n",
            "Epoch: 85 | Batch_idx: 50 |  Loss: (0.0801) | Acc: (97.09%) (6338/6528)\n",
            "Epoch: 85 | Batch_idx: 60 |  Loss: (0.0772) | Acc: (97.30%) (7597/7808)\n",
            "Epoch: 85 | Batch_idx: 70 |  Loss: (0.0776) | Acc: (97.32%) (8844/9088)\n",
            "Epoch: 85 | Batch_idx: 80 |  Loss: (0.0784) | Acc: (97.24%) (10082/10368)\n",
            "Epoch: 85 | Batch_idx: 90 |  Loss: (0.0784) | Acc: (97.20%) (11322/11648)\n",
            "Epoch: 85 | Batch_idx: 100 |  Loss: (0.0784) | Acc: (97.23%) (12570/12928)\n",
            "Epoch: 85 | Batch_idx: 110 |  Loss: (0.0787) | Acc: (97.22%) (13813/14208)\n",
            "Epoch: 85 | Batch_idx: 120 |  Loss: (0.0780) | Acc: (97.26%) (15064/15488)\n",
            "Epoch: 85 | Batch_idx: 130 |  Loss: (0.0772) | Acc: (97.32%) (16319/16768)\n",
            "Epoch: 85 | Batch_idx: 140 |  Loss: (0.0766) | Acc: (97.33%) (17566/18048)\n",
            "Epoch: 85 | Batch_idx: 150 |  Loss: (0.0757) | Acc: (97.38%) (18822/19328)\n",
            "Epoch: 85 | Batch_idx: 160 |  Loss: (0.0762) | Acc: (97.37%) (20065/20608)\n",
            "Epoch: 85 | Batch_idx: 170 |  Loss: (0.0759) | Acc: (97.36%) (21311/21888)\n",
            "Epoch: 85 | Batch_idx: 180 |  Loss: (0.0766) | Acc: (97.34%) (22552/23168)\n",
            "Epoch: 85 | Batch_idx: 190 |  Loss: (0.0769) | Acc: (97.32%) (23793/24448)\n",
            "Epoch: 85 | Batch_idx: 200 |  Loss: (0.0771) | Acc: (97.32%) (25038/25728)\n",
            "Epoch: 85 | Batch_idx: 210 |  Loss: (0.0773) | Acc: (97.33%) (26286/27008)\n",
            "Epoch: 85 | Batch_idx: 220 |  Loss: (0.0779) | Acc: (97.32%) (27529/28288)\n",
            "Epoch: 85 | Batch_idx: 230 |  Loss: (0.0785) | Acc: (97.29%) (28766/29568)\n",
            "Epoch: 85 | Batch_idx: 240 |  Loss: (0.0787) | Acc: (97.30%) (30014/30848)\n",
            "Epoch: 85 | Batch_idx: 250 |  Loss: (0.0791) | Acc: (97.26%) (31249/32128)\n",
            "Epoch: 85 | Batch_idx: 260 |  Loss: (0.0793) | Acc: (97.29%) (32503/33408)\n",
            "Epoch: 85 | Batch_idx: 270 |  Loss: (0.0796) | Acc: (97.28%) (33746/34688)\n",
            "Epoch: 85 | Batch_idx: 280 |  Loss: (0.0797) | Acc: (97.27%) (34987/35968)\n",
            "Epoch: 85 | Batch_idx: 290 |  Loss: (0.0798) | Acc: (97.28%) (36234/37248)\n",
            "Epoch: 85 | Batch_idx: 300 |  Loss: (0.0802) | Acc: (97.27%) (37475/38528)\n",
            "Epoch: 85 | Batch_idx: 310 |  Loss: (0.0801) | Acc: (97.28%) (38725/39808)\n",
            "Epoch: 85 | Batch_idx: 320 |  Loss: (0.0798) | Acc: (97.29%) (39973/41088)\n",
            "Epoch: 85 | Batch_idx: 330 |  Loss: (0.0797) | Acc: (97.28%) (41217/42368)\n",
            "Epoch: 85 | Batch_idx: 340 |  Loss: (0.0800) | Acc: (97.28%) (42462/43648)\n",
            "Epoch: 85 | Batch_idx: 350 |  Loss: (0.0795) | Acc: (97.30%) (43717/44928)\n",
            "Epoch: 85 | Batch_idx: 360 |  Loss: (0.0797) | Acc: (97.30%) (44961/46208)\n",
            "Epoch: 85 | Batch_idx: 370 |  Loss: (0.0801) | Acc: (97.28%) (46198/47488)\n",
            "Epoch: 85 | Batch_idx: 380 |  Loss: (0.0799) | Acc: (97.29%) (47444/48768)\n",
            "Epoch: 85 | Batch_idx: 390 |  Loss: (0.0800) | Acc: (97.30%) (48648/50000)\n",
            "# TEST : Loss: (0.2908) | Acc: (91.70%) (9170/10000)\n",
            "Epoch: 86 | Batch_idx: 0 |  Loss: (0.0790) | Acc: (98.44%) (126/128)\n",
            "Epoch: 86 | Batch_idx: 10 |  Loss: (0.0720) | Acc: (97.59%) (1374/1408)\n",
            "Epoch: 86 | Batch_idx: 20 |  Loss: (0.0728) | Acc: (97.66%) (2625/2688)\n",
            "Epoch: 86 | Batch_idx: 30 |  Loss: (0.0708) | Acc: (97.76%) (3879/3968)\n",
            "Epoch: 86 | Batch_idx: 40 |  Loss: (0.0686) | Acc: (97.79%) (5132/5248)\n",
            "Epoch: 86 | Batch_idx: 50 |  Loss: (0.0666) | Acc: (97.79%) (6384/6528)\n",
            "Epoch: 86 | Batch_idx: 60 |  Loss: (0.0689) | Acc: (97.69%) (7628/7808)\n",
            "Epoch: 86 | Batch_idx: 70 |  Loss: (0.0708) | Acc: (97.63%) (8873/9088)\n",
            "Epoch: 86 | Batch_idx: 80 |  Loss: (0.0711) | Acc: (97.63%) (10122/10368)\n",
            "Epoch: 86 | Batch_idx: 90 |  Loss: (0.0712) | Acc: (97.60%) (11368/11648)\n",
            "Epoch: 86 | Batch_idx: 100 |  Loss: (0.0706) | Acc: (97.62%) (12620/12928)\n",
            "Epoch: 86 | Batch_idx: 110 |  Loss: (0.0694) | Acc: (97.69%) (13880/14208)\n",
            "Epoch: 86 | Batch_idx: 120 |  Loss: (0.0707) | Acc: (97.63%) (15121/15488)\n",
            "Epoch: 86 | Batch_idx: 130 |  Loss: (0.0709) | Acc: (97.62%) (16369/16768)\n",
            "Epoch: 86 | Batch_idx: 140 |  Loss: (0.0708) | Acc: (97.65%) (17623/18048)\n",
            "Epoch: 86 | Batch_idx: 150 |  Loss: (0.0704) | Acc: (97.67%) (18877/19328)\n",
            "Epoch: 86 | Batch_idx: 160 |  Loss: (0.0710) | Acc: (97.63%) (20120/20608)\n",
            "Epoch: 86 | Batch_idx: 170 |  Loss: (0.0714) | Acc: (97.64%) (21372/21888)\n",
            "Epoch: 86 | Batch_idx: 180 |  Loss: (0.0714) | Acc: (97.66%) (22627/23168)\n",
            "Epoch: 86 | Batch_idx: 190 |  Loss: (0.0715) | Acc: (97.66%) (23875/24448)\n",
            "Epoch: 86 | Batch_idx: 200 |  Loss: (0.0725) | Acc: (97.62%) (25115/25728)\n",
            "Epoch: 86 | Batch_idx: 210 |  Loss: (0.0732) | Acc: (97.57%) (26353/27008)\n",
            "Epoch: 86 | Batch_idx: 220 |  Loss: (0.0730) | Acc: (97.58%) (27603/28288)\n",
            "Epoch: 86 | Batch_idx: 230 |  Loss: (0.0735) | Acc: (97.56%) (28848/29568)\n",
            "Epoch: 86 | Batch_idx: 240 |  Loss: (0.0731) | Acc: (97.57%) (30097/30848)\n",
            "Epoch: 86 | Batch_idx: 250 |  Loss: (0.0729) | Acc: (97.56%) (31343/32128)\n",
            "Epoch: 86 | Batch_idx: 260 |  Loss: (0.0729) | Acc: (97.56%) (32593/33408)\n",
            "Epoch: 86 | Batch_idx: 270 |  Loss: (0.0730) | Acc: (97.56%) (33840/34688)\n",
            "Epoch: 86 | Batch_idx: 280 |  Loss: (0.0734) | Acc: (97.53%) (35078/35968)\n",
            "Epoch: 86 | Batch_idx: 290 |  Loss: (0.0734) | Acc: (97.53%) (36328/37248)\n",
            "Epoch: 86 | Batch_idx: 300 |  Loss: (0.0731) | Acc: (97.54%) (37580/38528)\n",
            "Epoch: 86 | Batch_idx: 310 |  Loss: (0.0735) | Acc: (97.51%) (38818/39808)\n",
            "Epoch: 86 | Batch_idx: 320 |  Loss: (0.0740) | Acc: (97.50%) (40061/41088)\n",
            "Epoch: 86 | Batch_idx: 330 |  Loss: (0.0742) | Acc: (97.49%) (41304/42368)\n",
            "Epoch: 86 | Batch_idx: 340 |  Loss: (0.0739) | Acc: (97.52%) (42564/43648)\n",
            "Epoch: 86 | Batch_idx: 350 |  Loss: (0.0743) | Acc: (97.50%) (43806/44928)\n",
            "Epoch: 86 | Batch_idx: 360 |  Loss: (0.0744) | Acc: (97.50%) (45053/46208)\n",
            "Epoch: 86 | Batch_idx: 370 |  Loss: (0.0738) | Acc: (97.52%) (46310/47488)\n",
            "Epoch: 86 | Batch_idx: 380 |  Loss: (0.0741) | Acc: (97.50%) (47549/48768)\n",
            "Epoch: 86 | Batch_idx: 390 |  Loss: (0.0737) | Acc: (97.51%) (48754/50000)\n",
            "# TEST : Loss: (0.2906) | Acc: (91.99%) (9199/10000)\n",
            "Epoch: 87 | Batch_idx: 0 |  Loss: (0.0730) | Acc: (97.66%) (125/128)\n",
            "Epoch: 87 | Batch_idx: 10 |  Loss: (0.0748) | Acc: (97.59%) (1374/1408)\n",
            "Epoch: 87 | Batch_idx: 20 |  Loss: (0.0704) | Acc: (97.73%) (2627/2688)\n",
            "Epoch: 87 | Batch_idx: 30 |  Loss: (0.0711) | Acc: (97.53%) (3870/3968)\n",
            "Epoch: 87 | Batch_idx: 40 |  Loss: (0.0702) | Acc: (97.47%) (5115/5248)\n",
            "Epoch: 87 | Batch_idx: 50 |  Loss: (0.0714) | Acc: (97.38%) (6357/6528)\n",
            "Epoch: 87 | Batch_idx: 60 |  Loss: (0.0724) | Acc: (97.41%) (7606/7808)\n",
            "Epoch: 87 | Batch_idx: 70 |  Loss: (0.0724) | Acc: (97.45%) (8856/9088)\n",
            "Epoch: 87 | Batch_idx: 80 |  Loss: (0.0726) | Acc: (97.47%) (10106/10368)\n",
            "Epoch: 87 | Batch_idx: 90 |  Loss: (0.0721) | Acc: (97.48%) (11354/11648)\n",
            "Epoch: 87 | Batch_idx: 100 |  Loss: (0.0722) | Acc: (97.47%) (12601/12928)\n",
            "Epoch: 87 | Batch_idx: 110 |  Loss: (0.0716) | Acc: (97.50%) (13853/14208)\n",
            "Epoch: 87 | Batch_idx: 120 |  Loss: (0.0716) | Acc: (97.55%) (15108/15488)\n",
            "Epoch: 87 | Batch_idx: 130 |  Loss: (0.0715) | Acc: (97.54%) (16356/16768)\n",
            "Epoch: 87 | Batch_idx: 140 |  Loss: (0.0721) | Acc: (97.51%) (17598/18048)\n",
            "Epoch: 87 | Batch_idx: 150 |  Loss: (0.0729) | Acc: (97.48%) (18841/19328)\n",
            "Epoch: 87 | Batch_idx: 160 |  Loss: (0.0733) | Acc: (97.48%) (20089/20608)\n",
            "Epoch: 87 | Batch_idx: 170 |  Loss: (0.0726) | Acc: (97.52%) (21346/21888)\n",
            "Epoch: 87 | Batch_idx: 180 |  Loss: (0.0730) | Acc: (97.49%) (22587/23168)\n",
            "Epoch: 87 | Batch_idx: 190 |  Loss: (0.0729) | Acc: (97.50%) (23838/24448)\n",
            "Epoch: 87 | Batch_idx: 200 |  Loss: (0.0721) | Acc: (97.54%) (25095/25728)\n",
            "Epoch: 87 | Batch_idx: 210 |  Loss: (0.0721) | Acc: (97.54%) (26343/27008)\n",
            "Epoch: 87 | Batch_idx: 220 |  Loss: (0.0727) | Acc: (97.53%) (27588/28288)\n",
            "Epoch: 87 | Batch_idx: 230 |  Loss: (0.0729) | Acc: (97.52%) (28835/29568)\n",
            "Epoch: 87 | Batch_idx: 240 |  Loss: (0.0724) | Acc: (97.55%) (30092/30848)\n",
            "Epoch: 87 | Batch_idx: 250 |  Loss: (0.0725) | Acc: (97.55%) (31340/32128)\n",
            "Epoch: 87 | Batch_idx: 260 |  Loss: (0.0726) | Acc: (97.54%) (32586/33408)\n",
            "Epoch: 87 | Batch_idx: 270 |  Loss: (0.0724) | Acc: (97.56%) (33840/34688)\n",
            "Epoch: 87 | Batch_idx: 280 |  Loss: (0.0724) | Acc: (97.56%) (35089/35968)\n",
            "Epoch: 87 | Batch_idx: 290 |  Loss: (0.0723) | Acc: (97.56%) (36338/37248)\n",
            "Epoch: 87 | Batch_idx: 300 |  Loss: (0.0724) | Acc: (97.56%) (37587/38528)\n",
            "Epoch: 87 | Batch_idx: 310 |  Loss: (0.0728) | Acc: (97.54%) (38830/39808)\n",
            "Epoch: 87 | Batch_idx: 320 |  Loss: (0.0730) | Acc: (97.53%) (40073/41088)\n",
            "Epoch: 87 | Batch_idx: 330 |  Loss: (0.0730) | Acc: (97.53%) (41321/42368)\n",
            "Epoch: 87 | Batch_idx: 340 |  Loss: (0.0729) | Acc: (97.54%) (42575/43648)\n",
            "Epoch: 87 | Batch_idx: 350 |  Loss: (0.0725) | Acc: (97.56%) (43830/44928)\n",
            "Epoch: 87 | Batch_idx: 360 |  Loss: (0.0725) | Acc: (97.56%) (45081/46208)\n",
            "Epoch: 87 | Batch_idx: 370 |  Loss: (0.0719) | Acc: (97.58%) (46339/47488)\n",
            "Epoch: 87 | Batch_idx: 380 |  Loss: (0.0715) | Acc: (97.59%) (47591/48768)\n",
            "Epoch: 87 | Batch_idx: 390 |  Loss: (0.0717) | Acc: (97.58%) (48788/50000)\n",
            "# TEST : Loss: (0.2948) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 88 | Batch_idx: 0 |  Loss: (0.0488) | Acc: (98.44%) (126/128)\n",
            "Epoch: 88 | Batch_idx: 10 |  Loss: (0.0649) | Acc: (97.87%) (1378/1408)\n",
            "Epoch: 88 | Batch_idx: 20 |  Loss: (0.0739) | Acc: (97.69%) (2626/2688)\n",
            "Epoch: 88 | Batch_idx: 30 |  Loss: (0.0697) | Acc: (97.86%) (3883/3968)\n",
            "Epoch: 88 | Batch_idx: 40 |  Loss: (0.0695) | Acc: (97.75%) (5130/5248)\n",
            "Epoch: 88 | Batch_idx: 50 |  Loss: (0.0689) | Acc: (97.87%) (6389/6528)\n",
            "Epoch: 88 | Batch_idx: 60 |  Loss: (0.0684) | Acc: (97.82%) (7638/7808)\n",
            "Epoch: 88 | Batch_idx: 70 |  Loss: (0.0688) | Acc: (97.76%) (8884/9088)\n",
            "Epoch: 88 | Batch_idx: 80 |  Loss: (0.0702) | Acc: (97.65%) (10124/10368)\n",
            "Epoch: 88 | Batch_idx: 90 |  Loss: (0.0703) | Acc: (97.62%) (11371/11648)\n",
            "Epoch: 88 | Batch_idx: 100 |  Loss: (0.0712) | Acc: (97.63%) (12621/12928)\n",
            "Epoch: 88 | Batch_idx: 110 |  Loss: (0.0718) | Acc: (97.57%) (13863/14208)\n",
            "Epoch: 88 | Batch_idx: 120 |  Loss: (0.0719) | Acc: (97.58%) (15113/15488)\n",
            "Epoch: 88 | Batch_idx: 130 |  Loss: (0.0728) | Acc: (97.51%) (16351/16768)\n",
            "Epoch: 88 | Batch_idx: 140 |  Loss: (0.0722) | Acc: (97.53%) (17602/18048)\n",
            "Epoch: 88 | Batch_idx: 150 |  Loss: (0.0715) | Acc: (97.57%) (18859/19328)\n",
            "Epoch: 88 | Batch_idx: 160 |  Loss: (0.0709) | Acc: (97.60%) (20114/20608)\n",
            "Epoch: 88 | Batch_idx: 170 |  Loss: (0.0706) | Acc: (97.61%) (21365/21888)\n",
            "Epoch: 88 | Batch_idx: 180 |  Loss: (0.0716) | Acc: (97.57%) (22606/23168)\n",
            "Epoch: 88 | Batch_idx: 190 |  Loss: (0.0711) | Acc: (97.60%) (23862/24448)\n",
            "Epoch: 88 | Batch_idx: 200 |  Loss: (0.0705) | Acc: (97.62%) (25116/25728)\n",
            "Epoch: 88 | Batch_idx: 210 |  Loss: (0.0709) | Acc: (97.59%) (26356/27008)\n",
            "Epoch: 88 | Batch_idx: 220 |  Loss: (0.0713) | Acc: (97.58%) (27603/28288)\n",
            "Epoch: 88 | Batch_idx: 230 |  Loss: (0.0715) | Acc: (97.55%) (28844/29568)\n",
            "Epoch: 88 | Batch_idx: 240 |  Loss: (0.0714) | Acc: (97.56%) (30096/30848)\n",
            "Epoch: 88 | Batch_idx: 250 |  Loss: (0.0713) | Acc: (97.57%) (31346/32128)\n",
            "Epoch: 88 | Batch_idx: 260 |  Loss: (0.0712) | Acc: (97.57%) (32595/33408)\n",
            "Epoch: 88 | Batch_idx: 270 |  Loss: (0.0709) | Acc: (97.59%) (33853/34688)\n",
            "Epoch: 88 | Batch_idx: 280 |  Loss: (0.0709) | Acc: (97.59%) (35102/35968)\n",
            "Epoch: 88 | Batch_idx: 290 |  Loss: (0.0706) | Acc: (97.61%) (36359/37248)\n",
            "Epoch: 88 | Batch_idx: 300 |  Loss: (0.0706) | Acc: (97.61%) (37607/38528)\n",
            "Epoch: 88 | Batch_idx: 310 |  Loss: (0.0707) | Acc: (97.60%) (38853/39808)\n",
            "Epoch: 88 | Batch_idx: 320 |  Loss: (0.0703) | Acc: (97.61%) (40108/41088)\n",
            "Epoch: 88 | Batch_idx: 330 |  Loss: (0.0701) | Acc: (97.63%) (41362/42368)\n",
            "Epoch: 88 | Batch_idx: 340 |  Loss: (0.0697) | Acc: (97.64%) (42618/43648)\n",
            "Epoch: 88 | Batch_idx: 350 |  Loss: (0.0694) | Acc: (97.66%) (43877/44928)\n",
            "Epoch: 88 | Batch_idx: 360 |  Loss: (0.0689) | Acc: (97.69%) (45139/46208)\n",
            "Epoch: 88 | Batch_idx: 370 |  Loss: (0.0692) | Acc: (97.68%) (46386/47488)\n",
            "Epoch: 88 | Batch_idx: 380 |  Loss: (0.0686) | Acc: (97.71%) (47650/48768)\n",
            "Epoch: 88 | Batch_idx: 390 |  Loss: (0.0683) | Acc: (97.72%) (48860/50000)\n",
            "# TEST : Loss: (0.3061) | Acc: (91.52%) (9152/10000)\n",
            "Epoch: 89 | Batch_idx: 0 |  Loss: (0.0525) | Acc: (98.44%) (126/128)\n",
            "Epoch: 89 | Batch_idx: 10 |  Loss: (0.0627) | Acc: (97.87%) (1378/1408)\n",
            "Epoch: 89 | Batch_idx: 20 |  Loss: (0.0603) | Acc: (97.99%) (2634/2688)\n",
            "Epoch: 89 | Batch_idx: 30 |  Loss: (0.0583) | Acc: (98.08%) (3892/3968)\n",
            "Epoch: 89 | Batch_idx: 40 |  Loss: (0.0565) | Acc: (98.15%) (5151/5248)\n",
            "Epoch: 89 | Batch_idx: 50 |  Loss: (0.0572) | Acc: (98.12%) (6405/6528)\n",
            "Epoch: 89 | Batch_idx: 60 |  Loss: (0.0597) | Acc: (97.99%) (7651/7808)\n",
            "Epoch: 89 | Batch_idx: 70 |  Loss: (0.0618) | Acc: (97.93%) (8900/9088)\n",
            "Epoch: 89 | Batch_idx: 80 |  Loss: (0.0628) | Acc: (97.90%) (10150/10368)\n",
            "Epoch: 89 | Batch_idx: 90 |  Loss: (0.0627) | Acc: (97.85%) (11397/11648)\n",
            "Epoch: 89 | Batch_idx: 100 |  Loss: (0.0649) | Acc: (97.80%) (12643/12928)\n",
            "Epoch: 89 | Batch_idx: 110 |  Loss: (0.0653) | Acc: (97.78%) (13892/14208)\n",
            "Epoch: 89 | Batch_idx: 120 |  Loss: (0.0651) | Acc: (97.77%) (15143/15488)\n",
            "Epoch: 89 | Batch_idx: 130 |  Loss: (0.0657) | Acc: (97.75%) (16391/16768)\n",
            "Epoch: 89 | Batch_idx: 140 |  Loss: (0.0675) | Acc: (97.68%) (17630/18048)\n",
            "Epoch: 89 | Batch_idx: 150 |  Loss: (0.0671) | Acc: (97.73%) (18889/19328)\n",
            "Epoch: 89 | Batch_idx: 160 |  Loss: (0.0681) | Acc: (97.70%) (20135/20608)\n",
            "Epoch: 89 | Batch_idx: 170 |  Loss: (0.0677) | Acc: (97.71%) (21386/21888)\n",
            "Epoch: 89 | Batch_idx: 180 |  Loss: (0.0675) | Acc: (97.71%) (22637/23168)\n",
            "Epoch: 89 | Batch_idx: 190 |  Loss: (0.0668) | Acc: (97.73%) (23892/24448)\n",
            "Epoch: 89 | Batch_idx: 200 |  Loss: (0.0675) | Acc: (97.70%) (25135/25728)\n",
            "Epoch: 89 | Batch_idx: 210 |  Loss: (0.0669) | Acc: (97.72%) (26393/27008)\n",
            "Epoch: 89 | Batch_idx: 220 |  Loss: (0.0671) | Acc: (97.73%) (27646/28288)\n",
            "Epoch: 89 | Batch_idx: 230 |  Loss: (0.0668) | Acc: (97.75%) (28902/29568)\n",
            "Epoch: 89 | Batch_idx: 240 |  Loss: (0.0664) | Acc: (97.76%) (30158/30848)\n",
            "Epoch: 89 | Batch_idx: 250 |  Loss: (0.0669) | Acc: (97.74%) (31401/32128)\n",
            "Epoch: 89 | Batch_idx: 260 |  Loss: (0.0670) | Acc: (97.73%) (32650/33408)\n",
            "Epoch: 89 | Batch_idx: 270 |  Loss: (0.0666) | Acc: (97.75%) (33907/34688)\n",
            "Epoch: 89 | Batch_idx: 280 |  Loss: (0.0666) | Acc: (97.74%) (35156/35968)\n",
            "Epoch: 89 | Batch_idx: 290 |  Loss: (0.0670) | Acc: (97.71%) (36394/37248)\n",
            "Epoch: 89 | Batch_idx: 300 |  Loss: (0.0676) | Acc: (97.69%) (37637/38528)\n",
            "Epoch: 89 | Batch_idx: 310 |  Loss: (0.0676) | Acc: (97.70%) (38891/39808)\n",
            "Epoch: 89 | Batch_idx: 320 |  Loss: (0.0677) | Acc: (97.68%) (40135/41088)\n",
            "Epoch: 89 | Batch_idx: 330 |  Loss: (0.0677) | Acc: (97.69%) (41388/42368)\n",
            "Epoch: 89 | Batch_idx: 340 |  Loss: (0.0676) | Acc: (97.68%) (42637/43648)\n",
            "Epoch: 89 | Batch_idx: 350 |  Loss: (0.0672) | Acc: (97.71%) (43897/44928)\n",
            "Epoch: 89 | Batch_idx: 360 |  Loss: (0.0673) | Acc: (97.71%) (45150/46208)\n",
            "Epoch: 89 | Batch_idx: 370 |  Loss: (0.0674) | Acc: (97.71%) (46399/47488)\n",
            "Epoch: 89 | Batch_idx: 380 |  Loss: (0.0674) | Acc: (97.71%) (47653/48768)\n",
            "Epoch: 89 | Batch_idx: 390 |  Loss: (0.0673) | Acc: (97.72%) (48860/50000)\n",
            "# TEST : Loss: (0.3036) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 90 | Batch_idx: 0 |  Loss: (0.0679) | Acc: (97.66%) (125/128)\n",
            "Epoch: 90 | Batch_idx: 10 |  Loss: (0.0559) | Acc: (98.22%) (1383/1408)\n",
            "Epoch: 90 | Batch_idx: 20 |  Loss: (0.0530) | Acc: (98.29%) (2642/2688)\n",
            "Epoch: 90 | Batch_idx: 30 |  Loss: (0.0577) | Acc: (98.06%) (3891/3968)\n",
            "Epoch: 90 | Batch_idx: 40 |  Loss: (0.0581) | Acc: (98.02%) (5144/5248)\n",
            "Epoch: 90 | Batch_idx: 50 |  Loss: (0.0585) | Acc: (97.96%) (6395/6528)\n",
            "Epoch: 90 | Batch_idx: 60 |  Loss: (0.0590) | Acc: (97.94%) (7647/7808)\n",
            "Epoch: 90 | Batch_idx: 70 |  Loss: (0.0598) | Acc: (97.92%) (8899/9088)\n",
            "Epoch: 90 | Batch_idx: 80 |  Loss: (0.0607) | Acc: (97.93%) (10153/10368)\n",
            "Epoch: 90 | Batch_idx: 90 |  Loss: (0.0606) | Acc: (97.94%) (11408/11648)\n",
            "Epoch: 90 | Batch_idx: 100 |  Loss: (0.0609) | Acc: (97.94%) (12662/12928)\n",
            "Epoch: 90 | Batch_idx: 110 |  Loss: (0.0607) | Acc: (97.96%) (13918/14208)\n",
            "Epoch: 90 | Batch_idx: 120 |  Loss: (0.0618) | Acc: (97.93%) (15168/15488)\n",
            "Epoch: 90 | Batch_idx: 130 |  Loss: (0.0607) | Acc: (97.99%) (16431/16768)\n",
            "Epoch: 90 | Batch_idx: 140 |  Loss: (0.0616) | Acc: (97.97%) (17681/18048)\n",
            "Epoch: 90 | Batch_idx: 150 |  Loss: (0.0619) | Acc: (97.97%) (18935/19328)\n",
            "Epoch: 90 | Batch_idx: 160 |  Loss: (0.0625) | Acc: (97.95%) (20185/20608)\n",
            "Epoch: 90 | Batch_idx: 170 |  Loss: (0.0625) | Acc: (97.93%) (21435/21888)\n",
            "Epoch: 90 | Batch_idx: 180 |  Loss: (0.0625) | Acc: (97.94%) (22691/23168)\n",
            "Epoch: 90 | Batch_idx: 190 |  Loss: (0.0628) | Acc: (97.94%) (23945/24448)\n",
            "Epoch: 90 | Batch_idx: 200 |  Loss: (0.0631) | Acc: (97.92%) (25194/25728)\n",
            "Epoch: 90 | Batch_idx: 210 |  Loss: (0.0638) | Acc: (97.88%) (26435/27008)\n",
            "Epoch: 90 | Batch_idx: 220 |  Loss: (0.0639) | Acc: (97.87%) (27685/28288)\n",
            "Epoch: 90 | Batch_idx: 230 |  Loss: (0.0645) | Acc: (97.82%) (28924/29568)\n",
            "Epoch: 90 | Batch_idx: 240 |  Loss: (0.0645) | Acc: (97.82%) (30176/30848)\n",
            "Epoch: 90 | Batch_idx: 250 |  Loss: (0.0646) | Acc: (97.82%) (31429/32128)\n",
            "Epoch: 90 | Batch_idx: 260 |  Loss: (0.0642) | Acc: (97.84%) (32687/33408)\n",
            "Epoch: 90 | Batch_idx: 270 |  Loss: (0.0645) | Acc: (97.81%) (33930/34688)\n",
            "Epoch: 90 | Batch_idx: 280 |  Loss: (0.0642) | Acc: (97.82%) (35185/35968)\n",
            "Epoch: 90 | Batch_idx: 290 |  Loss: (0.0644) | Acc: (97.82%) (36435/37248)\n",
            "Epoch: 90 | Batch_idx: 300 |  Loss: (0.0643) | Acc: (97.82%) (37688/38528)\n",
            "Epoch: 90 | Batch_idx: 310 |  Loss: (0.0640) | Acc: (97.83%) (38945/39808)\n",
            "Epoch: 90 | Batch_idx: 320 |  Loss: (0.0642) | Acc: (97.82%) (40193/41088)\n",
            "Epoch: 90 | Batch_idx: 330 |  Loss: (0.0643) | Acc: (97.81%) (41442/42368)\n",
            "Epoch: 90 | Batch_idx: 340 |  Loss: (0.0641) | Acc: (97.82%) (42696/43648)\n",
            "Epoch: 90 | Batch_idx: 350 |  Loss: (0.0641) | Acc: (97.83%) (43952/44928)\n",
            "Epoch: 90 | Batch_idx: 360 |  Loss: (0.0640) | Acc: (97.83%) (45203/46208)\n",
            "Epoch: 90 | Batch_idx: 370 |  Loss: (0.0638) | Acc: (97.83%) (46457/47488)\n",
            "Epoch: 90 | Batch_idx: 380 |  Loss: (0.0639) | Acc: (97.81%) (47702/48768)\n",
            "Epoch: 90 | Batch_idx: 390 |  Loss: (0.0643) | Acc: (97.81%) (48903/50000)\n",
            "# TEST : Loss: (0.3046) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 91 | Batch_idx: 0 |  Loss: (0.0358) | Acc: (99.22%) (127/128)\n",
            "Epoch: 91 | Batch_idx: 10 |  Loss: (0.0554) | Acc: (98.22%) (1383/1408)\n",
            "Epoch: 91 | Batch_idx: 20 |  Loss: (0.0573) | Acc: (98.25%) (2641/2688)\n",
            "Epoch: 91 | Batch_idx: 30 |  Loss: (0.0566) | Acc: (98.29%) (3900/3968)\n",
            "Epoch: 91 | Batch_idx: 40 |  Loss: (0.0572) | Acc: (98.17%) (5152/5248)\n",
            "Epoch: 91 | Batch_idx: 50 |  Loss: (0.0580) | Acc: (98.16%) (6408/6528)\n",
            "Epoch: 91 | Batch_idx: 60 |  Loss: (0.0599) | Acc: (98.10%) (7660/7808)\n",
            "Epoch: 91 | Batch_idx: 70 |  Loss: (0.0596) | Acc: (98.12%) (8917/9088)\n",
            "Epoch: 91 | Batch_idx: 80 |  Loss: (0.0604) | Acc: (98.12%) (10173/10368)\n",
            "Epoch: 91 | Batch_idx: 90 |  Loss: (0.0611) | Acc: (98.05%) (11421/11648)\n",
            "Epoch: 91 | Batch_idx: 100 |  Loss: (0.0624) | Acc: (98.01%) (12671/12928)\n",
            "Epoch: 91 | Batch_idx: 110 |  Loss: (0.0628) | Acc: (98.01%) (13925/14208)\n",
            "Epoch: 91 | Batch_idx: 120 |  Loss: (0.0630) | Acc: (97.98%) (15175/15488)\n",
            "Epoch: 91 | Batch_idx: 130 |  Loss: (0.0624) | Acc: (97.98%) (16430/16768)\n",
            "Epoch: 91 | Batch_idx: 140 |  Loss: (0.0619) | Acc: (98.00%) (17687/18048)\n",
            "Epoch: 91 | Batch_idx: 150 |  Loss: (0.0612) | Acc: (98.04%) (18949/19328)\n",
            "Epoch: 91 | Batch_idx: 160 |  Loss: (0.0613) | Acc: (98.03%) (20201/20608)\n",
            "Epoch: 91 | Batch_idx: 170 |  Loss: (0.0614) | Acc: (97.99%) (21448/21888)\n",
            "Epoch: 91 | Batch_idx: 180 |  Loss: (0.0611) | Acc: (98.01%) (22707/23168)\n",
            "Epoch: 91 | Batch_idx: 190 |  Loss: (0.0619) | Acc: (97.98%) (23954/24448)\n",
            "Epoch: 91 | Batch_idx: 200 |  Loss: (0.0622) | Acc: (97.96%) (25202/25728)\n",
            "Epoch: 91 | Batch_idx: 210 |  Loss: (0.0618) | Acc: (97.96%) (26457/27008)\n",
            "Epoch: 91 | Batch_idx: 220 |  Loss: (0.0615) | Acc: (97.95%) (27708/28288)\n",
            "Epoch: 91 | Batch_idx: 230 |  Loss: (0.0618) | Acc: (97.95%) (28963/29568)\n",
            "Epoch: 91 | Batch_idx: 240 |  Loss: (0.0617) | Acc: (97.95%) (30216/30848)\n",
            "Epoch: 91 | Batch_idx: 250 |  Loss: (0.0615) | Acc: (97.95%) (31470/32128)\n",
            "Epoch: 91 | Batch_idx: 260 |  Loss: (0.0615) | Acc: (97.96%) (32726/33408)\n",
            "Epoch: 91 | Batch_idx: 270 |  Loss: (0.0611) | Acc: (97.98%) (33986/34688)\n",
            "Epoch: 91 | Batch_idx: 280 |  Loss: (0.0615) | Acc: (97.96%) (35234/35968)\n",
            "Epoch: 91 | Batch_idx: 290 |  Loss: (0.0616) | Acc: (97.95%) (36485/37248)\n",
            "Epoch: 91 | Batch_idx: 300 |  Loss: (0.0617) | Acc: (97.94%) (37734/38528)\n",
            "Epoch: 91 | Batch_idx: 310 |  Loss: (0.0613) | Acc: (97.95%) (38991/39808)\n",
            "Epoch: 91 | Batch_idx: 320 |  Loss: (0.0610) | Acc: (97.96%) (40248/41088)\n",
            "Epoch: 91 | Batch_idx: 330 |  Loss: (0.0610) | Acc: (97.95%) (41498/42368)\n",
            "Epoch: 91 | Batch_idx: 340 |  Loss: (0.0612) | Acc: (97.94%) (42751/43648)\n",
            "Epoch: 91 | Batch_idx: 350 |  Loss: (0.0609) | Acc: (97.95%) (44007/44928)\n",
            "Epoch: 91 | Batch_idx: 360 |  Loss: (0.0612) | Acc: (97.94%) (45255/46208)\n",
            "Epoch: 91 | Batch_idx: 370 |  Loss: (0.0611) | Acc: (97.94%) (46510/47488)\n",
            "Epoch: 91 | Batch_idx: 380 |  Loss: (0.0611) | Acc: (97.95%) (47766/48768)\n",
            "Epoch: 91 | Batch_idx: 390 |  Loss: (0.0612) | Acc: (97.94%) (48968/50000)\n",
            "# TEST : Loss: (0.3099) | Acc: (91.75%) (9175/10000)\n",
            "Epoch: 92 | Batch_idx: 0 |  Loss: (0.0601) | Acc: (98.44%) (126/128)\n",
            "Epoch: 92 | Batch_idx: 10 |  Loss: (0.0589) | Acc: (98.37%) (1385/1408)\n",
            "Epoch: 92 | Batch_idx: 20 |  Loss: (0.0580) | Acc: (98.33%) (2643/2688)\n",
            "Epoch: 92 | Batch_idx: 30 |  Loss: (0.0533) | Acc: (98.46%) (3907/3968)\n",
            "Epoch: 92 | Batch_idx: 40 |  Loss: (0.0576) | Acc: (98.25%) (5156/5248)\n",
            "Epoch: 92 | Batch_idx: 50 |  Loss: (0.0562) | Acc: (98.27%) (6415/6528)\n",
            "Epoch: 92 | Batch_idx: 60 |  Loss: (0.0571) | Acc: (98.22%) (7669/7808)\n",
            "Epoch: 92 | Batch_idx: 70 |  Loss: (0.0573) | Acc: (98.15%) (8920/9088)\n",
            "Epoch: 92 | Batch_idx: 80 |  Loss: (0.0576) | Acc: (98.16%) (10177/10368)\n",
            "Epoch: 92 | Batch_idx: 90 |  Loss: (0.0578) | Acc: (98.17%) (11435/11648)\n",
            "Epoch: 92 | Batch_idx: 100 |  Loss: (0.0599) | Acc: (98.11%) (12684/12928)\n",
            "Epoch: 92 | Batch_idx: 110 |  Loss: (0.0600) | Acc: (98.11%) (13939/14208)\n",
            "Epoch: 92 | Batch_idx: 120 |  Loss: (0.0600) | Acc: (98.08%) (15190/15488)\n",
            "Epoch: 92 | Batch_idx: 130 |  Loss: (0.0593) | Acc: (98.10%) (16449/16768)\n",
            "Epoch: 92 | Batch_idx: 140 |  Loss: (0.0595) | Acc: (98.09%) (17703/18048)\n",
            "Epoch: 92 | Batch_idx: 150 |  Loss: (0.0600) | Acc: (98.08%) (18957/19328)\n",
            "Epoch: 92 | Batch_idx: 160 |  Loss: (0.0593) | Acc: (98.11%) (20218/20608)\n",
            "Epoch: 92 | Batch_idx: 170 |  Loss: (0.0595) | Acc: (98.10%) (21472/21888)\n",
            "Epoch: 92 | Batch_idx: 180 |  Loss: (0.0595) | Acc: (98.09%) (22725/23168)\n",
            "Epoch: 92 | Batch_idx: 190 |  Loss: (0.0589) | Acc: (98.12%) (23988/24448)\n",
            "Epoch: 92 | Batch_idx: 200 |  Loss: (0.0585) | Acc: (98.14%) (25250/25728)\n",
            "Epoch: 92 | Batch_idx: 210 |  Loss: (0.0591) | Acc: (98.12%) (26499/27008)\n",
            "Epoch: 92 | Batch_idx: 220 |  Loss: (0.0587) | Acc: (98.13%) (27760/28288)\n",
            "Epoch: 92 | Batch_idx: 230 |  Loss: (0.0589) | Acc: (98.13%) (29016/29568)\n",
            "Epoch: 92 | Batch_idx: 240 |  Loss: (0.0584) | Acc: (98.13%) (30270/30848)\n",
            "Epoch: 92 | Batch_idx: 250 |  Loss: (0.0579) | Acc: (98.13%) (31528/32128)\n",
            "Epoch: 92 | Batch_idx: 260 |  Loss: (0.0576) | Acc: (98.14%) (32787/33408)\n",
            "Epoch: 92 | Batch_idx: 270 |  Loss: (0.0579) | Acc: (98.12%) (34036/34688)\n",
            "Epoch: 92 | Batch_idx: 280 |  Loss: (0.0573) | Acc: (98.14%) (35300/35968)\n",
            "Epoch: 92 | Batch_idx: 290 |  Loss: (0.0572) | Acc: (98.15%) (36558/37248)\n",
            "Epoch: 92 | Batch_idx: 300 |  Loss: (0.0573) | Acc: (98.14%) (37811/38528)\n",
            "Epoch: 92 | Batch_idx: 310 |  Loss: (0.0575) | Acc: (98.12%) (39058/39808)\n",
            "Epoch: 92 | Batch_idx: 320 |  Loss: (0.0575) | Acc: (98.11%) (40313/41088)\n",
            "Epoch: 92 | Batch_idx: 330 |  Loss: (0.0577) | Acc: (98.09%) (41559/42368)\n",
            "Epoch: 92 | Batch_idx: 340 |  Loss: (0.0580) | Acc: (98.08%) (42812/43648)\n",
            "Epoch: 92 | Batch_idx: 350 |  Loss: (0.0583) | Acc: (98.07%) (44060/44928)\n",
            "Epoch: 92 | Batch_idx: 360 |  Loss: (0.0583) | Acc: (98.07%) (45314/46208)\n",
            "Epoch: 92 | Batch_idx: 370 |  Loss: (0.0580) | Acc: (98.08%) (46576/47488)\n",
            "Epoch: 92 | Batch_idx: 380 |  Loss: (0.0580) | Acc: (98.07%) (47827/48768)\n",
            "Epoch: 92 | Batch_idx: 390 |  Loss: (0.0586) | Acc: (98.05%) (49024/50000)\n",
            "# TEST : Loss: (0.3119) | Acc: (91.76%) (9176/10000)\n",
            "Epoch: 93 | Batch_idx: 0 |  Loss: (0.0662) | Acc: (96.88%) (124/128)\n",
            "Epoch: 93 | Batch_idx: 10 |  Loss: (0.0643) | Acc: (97.66%) (1375/1408)\n",
            "Epoch: 93 | Batch_idx: 20 |  Loss: (0.0640) | Acc: (97.84%) (2630/2688)\n",
            "Epoch: 93 | Batch_idx: 30 |  Loss: (0.0622) | Acc: (97.98%) (3888/3968)\n",
            "Epoch: 93 | Batch_idx: 40 |  Loss: (0.0580) | Acc: (98.19%) (5153/5248)\n",
            "Epoch: 93 | Batch_idx: 50 |  Loss: (0.0570) | Acc: (98.18%) (6409/6528)\n",
            "Epoch: 93 | Batch_idx: 60 |  Loss: (0.0554) | Acc: (98.26%) (7672/7808)\n",
            "Epoch: 93 | Batch_idx: 70 |  Loss: (0.0545) | Acc: (98.29%) (8933/9088)\n",
            "Epoch: 93 | Batch_idx: 80 |  Loss: (0.0546) | Acc: (98.26%) (10188/10368)\n",
            "Epoch: 93 | Batch_idx: 90 |  Loss: (0.0549) | Acc: (98.24%) (11443/11648)\n",
            "Epoch: 93 | Batch_idx: 100 |  Loss: (0.0547) | Acc: (98.25%) (12702/12928)\n",
            "Epoch: 93 | Batch_idx: 110 |  Loss: (0.0554) | Acc: (98.19%) (13951/14208)\n",
            "Epoch: 93 | Batch_idx: 120 |  Loss: (0.0551) | Acc: (98.21%) (15211/15488)\n",
            "Epoch: 93 | Batch_idx: 130 |  Loss: (0.0544) | Acc: (98.24%) (16473/16768)\n",
            "Epoch: 93 | Batch_idx: 140 |  Loss: (0.0546) | Acc: (98.24%) (17731/18048)\n",
            "Epoch: 93 | Batch_idx: 150 |  Loss: (0.0544) | Acc: (98.28%) (18995/19328)\n",
            "Epoch: 93 | Batch_idx: 160 |  Loss: (0.0551) | Acc: (98.25%) (20247/20608)\n",
            "Epoch: 93 | Batch_idx: 170 |  Loss: (0.0550) | Acc: (98.25%) (21506/21888)\n",
            "Epoch: 93 | Batch_idx: 180 |  Loss: (0.0555) | Acc: (98.23%) (22757/23168)\n",
            "Epoch: 93 | Batch_idx: 190 |  Loss: (0.0559) | Acc: (98.21%) (24010/24448)\n",
            "Epoch: 93 | Batch_idx: 200 |  Loss: (0.0562) | Acc: (98.20%) (25264/25728)\n",
            "Epoch: 93 | Batch_idx: 210 |  Loss: (0.0559) | Acc: (98.21%) (26524/27008)\n",
            "Epoch: 93 | Batch_idx: 220 |  Loss: (0.0563) | Acc: (98.19%) (27775/28288)\n",
            "Epoch: 93 | Batch_idx: 230 |  Loss: (0.0568) | Acc: (98.16%) (29025/29568)\n",
            "Epoch: 93 | Batch_idx: 240 |  Loss: (0.0572) | Acc: (98.13%) (30272/30848)\n",
            "Epoch: 93 | Batch_idx: 250 |  Loss: (0.0565) | Acc: (98.16%) (31537/32128)\n",
            "Epoch: 93 | Batch_idx: 260 |  Loss: (0.0568) | Acc: (98.14%) (32785/33408)\n",
            "Epoch: 93 | Batch_idx: 270 |  Loss: (0.0568) | Acc: (98.13%) (34038/34688)\n",
            "Epoch: 93 | Batch_idx: 280 |  Loss: (0.0570) | Acc: (98.10%) (35284/35968)\n",
            "Epoch: 93 | Batch_idx: 290 |  Loss: (0.0569) | Acc: (98.10%) (36540/37248)\n",
            "Epoch: 93 | Batch_idx: 300 |  Loss: (0.0569) | Acc: (98.10%) (37797/38528)\n",
            "Epoch: 93 | Batch_idx: 310 |  Loss: (0.0568) | Acc: (98.11%) (39057/39808)\n",
            "Epoch: 93 | Batch_idx: 320 |  Loss: (0.0567) | Acc: (98.11%) (40311/41088)\n",
            "Epoch: 93 | Batch_idx: 330 |  Loss: (0.0576) | Acc: (98.06%) (41547/42368)\n",
            "Epoch: 93 | Batch_idx: 340 |  Loss: (0.0574) | Acc: (98.07%) (42806/43648)\n",
            "Epoch: 93 | Batch_idx: 350 |  Loss: (0.0577) | Acc: (98.04%) (44048/44928)\n",
            "Epoch: 93 | Batch_idx: 360 |  Loss: (0.0579) | Acc: (98.04%) (45301/46208)\n",
            "Epoch: 93 | Batch_idx: 370 |  Loss: (0.0579) | Acc: (98.04%) (46555/47488)\n",
            "Epoch: 93 | Batch_idx: 380 |  Loss: (0.0580) | Acc: (98.04%) (47813/48768)\n",
            "Epoch: 93 | Batch_idx: 390 |  Loss: (0.0581) | Acc: (98.04%) (49018/50000)\n",
            "# TEST : Loss: (0.3041) | Acc: (92.18%) (9218/10000)\n",
            "Epoch: 94 | Batch_idx: 0 |  Loss: (0.0340) | Acc: (99.22%) (127/128)\n",
            "Epoch: 94 | Batch_idx: 10 |  Loss: (0.0564) | Acc: (97.73%) (1376/1408)\n",
            "Epoch: 94 | Batch_idx: 20 |  Loss: (0.0565) | Acc: (97.95%) (2633/2688)\n",
            "Epoch: 94 | Batch_idx: 30 |  Loss: (0.0550) | Acc: (98.06%) (3891/3968)\n",
            "Epoch: 94 | Batch_idx: 40 |  Loss: (0.0550) | Acc: (98.04%) (5145/5248)\n",
            "Epoch: 94 | Batch_idx: 50 |  Loss: (0.0564) | Acc: (98.07%) (6402/6528)\n",
            "Epoch: 94 | Batch_idx: 60 |  Loss: (0.0567) | Acc: (98.08%) (7658/7808)\n",
            "Epoch: 94 | Batch_idx: 70 |  Loss: (0.0564) | Acc: (98.03%) (8909/9088)\n",
            "Epoch: 94 | Batch_idx: 80 |  Loss: (0.0564) | Acc: (98.01%) (10162/10368)\n",
            "Epoch: 94 | Batch_idx: 90 |  Loss: (0.0587) | Acc: (97.88%) (11401/11648)\n",
            "Epoch: 94 | Batch_idx: 100 |  Loss: (0.0587) | Acc: (97.88%) (12654/12928)\n",
            "Epoch: 94 | Batch_idx: 110 |  Loss: (0.0581) | Acc: (97.89%) (13908/14208)\n",
            "Epoch: 94 | Batch_idx: 120 |  Loss: (0.0581) | Acc: (97.91%) (15165/15488)\n",
            "Epoch: 94 | Batch_idx: 130 |  Loss: (0.0577) | Acc: (97.94%) (16422/16768)\n",
            "Epoch: 94 | Batch_idx: 140 |  Loss: (0.0574) | Acc: (97.95%) (17678/18048)\n",
            "Epoch: 94 | Batch_idx: 150 |  Loss: (0.0564) | Acc: (97.99%) (18939/19328)\n",
            "Epoch: 94 | Batch_idx: 160 |  Loss: (0.0564) | Acc: (97.97%) (20189/20608)\n",
            "Epoch: 94 | Batch_idx: 170 |  Loss: (0.0565) | Acc: (97.97%) (21444/21888)\n",
            "Epoch: 94 | Batch_idx: 180 |  Loss: (0.0562) | Acc: (98.02%) (22710/23168)\n",
            "Epoch: 94 | Batch_idx: 190 |  Loss: (0.0561) | Acc: (98.03%) (23967/24448)\n",
            "Epoch: 94 | Batch_idx: 200 |  Loss: (0.0564) | Acc: (98.01%) (25217/25728)\n",
            "Epoch: 94 | Batch_idx: 210 |  Loss: (0.0562) | Acc: (98.02%) (26473/27008)\n",
            "Epoch: 94 | Batch_idx: 220 |  Loss: (0.0563) | Acc: (98.02%) (27728/28288)\n",
            "Epoch: 94 | Batch_idx: 230 |  Loss: (0.0555) | Acc: (98.06%) (28995/29568)\n",
            "Epoch: 94 | Batch_idx: 240 |  Loss: (0.0553) | Acc: (98.06%) (30250/30848)\n",
            "Epoch: 94 | Batch_idx: 250 |  Loss: (0.0550) | Acc: (98.09%) (31513/32128)\n",
            "Epoch: 94 | Batch_idx: 260 |  Loss: (0.0561) | Acc: (98.05%) (32756/33408)\n",
            "Epoch: 94 | Batch_idx: 270 |  Loss: (0.0562) | Acc: (98.05%) (34010/34688)\n",
            "Epoch: 94 | Batch_idx: 280 |  Loss: (0.0562) | Acc: (98.04%) (35264/35968)\n",
            "Epoch: 94 | Batch_idx: 290 |  Loss: (0.0563) | Acc: (98.04%) (36517/37248)\n",
            "Epoch: 94 | Batch_idx: 300 |  Loss: (0.0564) | Acc: (98.03%) (37768/38528)\n",
            "Epoch: 94 | Batch_idx: 310 |  Loss: (0.0563) | Acc: (98.03%) (39024/39808)\n",
            "Epoch: 94 | Batch_idx: 320 |  Loss: (0.0568) | Acc: (98.02%) (40273/41088)\n",
            "Epoch: 94 | Batch_idx: 330 |  Loss: (0.0565) | Acc: (98.03%) (41534/42368)\n",
            "Epoch: 94 | Batch_idx: 340 |  Loss: (0.0563) | Acc: (98.04%) (42792/43648)\n",
            "Epoch: 94 | Batch_idx: 350 |  Loss: (0.0559) | Acc: (98.06%) (44057/44928)\n",
            "Epoch: 94 | Batch_idx: 360 |  Loss: (0.0560) | Acc: (98.06%) (45310/46208)\n",
            "Epoch: 94 | Batch_idx: 370 |  Loss: (0.0559) | Acc: (98.07%) (46571/47488)\n",
            "Epoch: 94 | Batch_idx: 380 |  Loss: (0.0558) | Acc: (98.08%) (47831/48768)\n",
            "Epoch: 94 | Batch_idx: 390 |  Loss: (0.0558) | Acc: (98.08%) (49038/50000)\n",
            "# TEST : Loss: (0.3075) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 95 | Batch_idx: 0 |  Loss: (0.0873) | Acc: (96.88%) (124/128)\n",
            "Epoch: 95 | Batch_idx: 10 |  Loss: (0.0430) | Acc: (98.58%) (1388/1408)\n",
            "Epoch: 95 | Batch_idx: 20 |  Loss: (0.0547) | Acc: (98.10%) (2637/2688)\n",
            "Epoch: 95 | Batch_idx: 30 |  Loss: (0.0527) | Acc: (98.29%) (3900/3968)\n",
            "Epoch: 95 | Batch_idx: 40 |  Loss: (0.0547) | Acc: (98.25%) (5156/5248)\n",
            "Epoch: 95 | Batch_idx: 50 |  Loss: (0.0521) | Acc: (98.31%) (6418/6528)\n",
            "Epoch: 95 | Batch_idx: 60 |  Loss: (0.0527) | Acc: (98.23%) (7670/7808)\n",
            "Epoch: 95 | Batch_idx: 70 |  Loss: (0.0536) | Acc: (98.17%) (8922/9088)\n",
            "Epoch: 95 | Batch_idx: 80 |  Loss: (0.0532) | Acc: (98.23%) (10184/10368)\n",
            "Epoch: 95 | Batch_idx: 90 |  Loss: (0.0524) | Acc: (98.25%) (11444/11648)\n",
            "Epoch: 95 | Batch_idx: 100 |  Loss: (0.0528) | Acc: (98.17%) (12692/12928)\n",
            "Epoch: 95 | Batch_idx: 110 |  Loss: (0.0526) | Acc: (98.18%) (13950/14208)\n",
            "Epoch: 95 | Batch_idx: 120 |  Loss: (0.0527) | Acc: (98.23%) (15214/15488)\n",
            "Epoch: 95 | Batch_idx: 130 |  Loss: (0.0534) | Acc: (98.19%) (16465/16768)\n",
            "Epoch: 95 | Batch_idx: 140 |  Loss: (0.0532) | Acc: (98.22%) (17726/18048)\n",
            "Epoch: 95 | Batch_idx: 150 |  Loss: (0.0524) | Acc: (98.27%) (18994/19328)\n",
            "Epoch: 95 | Batch_idx: 160 |  Loss: (0.0524) | Acc: (98.27%) (20252/20608)\n",
            "Epoch: 95 | Batch_idx: 170 |  Loss: (0.0520) | Acc: (98.30%) (21515/21888)\n",
            "Epoch: 95 | Batch_idx: 180 |  Loss: (0.0521) | Acc: (98.30%) (22774/23168)\n",
            "Epoch: 95 | Batch_idx: 190 |  Loss: (0.0520) | Acc: (98.29%) (24030/24448)\n",
            "Epoch: 95 | Batch_idx: 200 |  Loss: (0.0523) | Acc: (98.27%) (25284/25728)\n",
            "Epoch: 95 | Batch_idx: 210 |  Loss: (0.0521) | Acc: (98.26%) (26539/27008)\n",
            "Epoch: 95 | Batch_idx: 220 |  Loss: (0.0519) | Acc: (98.28%) (27801/28288)\n",
            "Epoch: 95 | Batch_idx: 230 |  Loss: (0.0517) | Acc: (98.28%) (29059/29568)\n",
            "Epoch: 95 | Batch_idx: 240 |  Loss: (0.0518) | Acc: (98.29%) (30319/30848)\n",
            "Epoch: 95 | Batch_idx: 250 |  Loss: (0.0524) | Acc: (98.25%) (31566/32128)\n",
            "Epoch: 95 | Batch_idx: 260 |  Loss: (0.0524) | Acc: (98.23%) (32818/33408)\n",
            "Epoch: 95 | Batch_idx: 270 |  Loss: (0.0523) | Acc: (98.24%) (34079/34688)\n",
            "Epoch: 95 | Batch_idx: 280 |  Loss: (0.0526) | Acc: (98.22%) (35329/35968)\n",
            "Epoch: 95 | Batch_idx: 290 |  Loss: (0.0530) | Acc: (98.20%) (36578/37248)\n",
            "Epoch: 95 | Batch_idx: 300 |  Loss: (0.0532) | Acc: (98.18%) (37826/38528)\n",
            "Epoch: 95 | Batch_idx: 310 |  Loss: (0.0531) | Acc: (98.19%) (39087/39808)\n",
            "Epoch: 95 | Batch_idx: 320 |  Loss: (0.0538) | Acc: (98.17%) (40336/41088)\n",
            "Epoch: 95 | Batch_idx: 330 |  Loss: (0.0543) | Acc: (98.15%) (41586/42368)\n",
            "Epoch: 95 | Batch_idx: 340 |  Loss: (0.0544) | Acc: (98.15%) (42839/43648)\n",
            "Epoch: 95 | Batch_idx: 350 |  Loss: (0.0545) | Acc: (98.15%) (44095/44928)\n",
            "Epoch: 95 | Batch_idx: 360 |  Loss: (0.0545) | Acc: (98.14%) (45350/46208)\n",
            "Epoch: 95 | Batch_idx: 370 |  Loss: (0.0544) | Acc: (98.15%) (46609/47488)\n",
            "Epoch: 95 | Batch_idx: 380 |  Loss: (0.0543) | Acc: (98.15%) (47865/48768)\n",
            "Epoch: 95 | Batch_idx: 390 |  Loss: (0.0545) | Acc: (98.13%) (49065/50000)\n",
            "# TEST : Loss: (0.3092) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 96 | Batch_idx: 0 |  Loss: (0.0695) | Acc: (97.66%) (125/128)\n",
            "Epoch: 96 | Batch_idx: 10 |  Loss: (0.0554) | Acc: (98.08%) (1381/1408)\n",
            "Epoch: 96 | Batch_idx: 20 |  Loss: (0.0473) | Acc: (98.44%) (2646/2688)\n",
            "Epoch: 96 | Batch_idx: 30 |  Loss: (0.0523) | Acc: (98.24%) (3898/3968)\n",
            "Epoch: 96 | Batch_idx: 40 |  Loss: (0.0523) | Acc: (98.19%) (5153/5248)\n",
            "Epoch: 96 | Batch_idx: 50 |  Loss: (0.0520) | Acc: (98.25%) (6414/6528)\n",
            "Epoch: 96 | Batch_idx: 60 |  Loss: (0.0542) | Acc: (98.14%) (7663/7808)\n",
            "Epoch: 96 | Batch_idx: 70 |  Loss: (0.0537) | Acc: (98.22%) (8926/9088)\n",
            "Epoch: 96 | Batch_idx: 80 |  Loss: (0.0551) | Acc: (98.13%) (10174/10368)\n",
            "Epoch: 96 | Batch_idx: 90 |  Loss: (0.0541) | Acc: (98.17%) (11435/11648)\n",
            "Epoch: 96 | Batch_idx: 100 |  Loss: (0.0542) | Acc: (98.15%) (12689/12928)\n",
            "Epoch: 96 | Batch_idx: 110 |  Loss: (0.0544) | Acc: (98.15%) (13945/14208)\n",
            "Epoch: 96 | Batch_idx: 120 |  Loss: (0.0548) | Acc: (98.13%) (15199/15488)\n",
            "Epoch: 96 | Batch_idx: 130 |  Loss: (0.0544) | Acc: (98.14%) (16456/16768)\n",
            "Epoch: 96 | Batch_idx: 140 |  Loss: (0.0550) | Acc: (98.09%) (17703/18048)\n",
            "Epoch: 96 | Batch_idx: 150 |  Loss: (0.0554) | Acc: (98.07%) (18955/19328)\n",
            "Epoch: 96 | Batch_idx: 160 |  Loss: (0.0559) | Acc: (98.04%) (20205/20608)\n",
            "Epoch: 96 | Batch_idx: 170 |  Loss: (0.0559) | Acc: (98.02%) (21455/21888)\n",
            "Epoch: 96 | Batch_idx: 180 |  Loss: (0.0556) | Acc: (98.02%) (22709/23168)\n",
            "Epoch: 96 | Batch_idx: 190 |  Loss: (0.0558) | Acc: (98.00%) (23958/24448)\n",
            "Epoch: 96 | Batch_idx: 200 |  Loss: (0.0560) | Acc: (97.99%) (25211/25728)\n",
            "Epoch: 96 | Batch_idx: 210 |  Loss: (0.0567) | Acc: (97.99%) (26464/27008)\n",
            "Epoch: 96 | Batch_idx: 220 |  Loss: (0.0560) | Acc: (98.03%) (27730/28288)\n",
            "Epoch: 96 | Batch_idx: 230 |  Loss: (0.0561) | Acc: (98.02%) (28984/29568)\n",
            "Epoch: 96 | Batch_idx: 240 |  Loss: (0.0561) | Acc: (98.03%) (30239/30848)\n",
            "Epoch: 96 | Batch_idx: 250 |  Loss: (0.0554) | Acc: (98.06%) (31506/32128)\n",
            "Epoch: 96 | Batch_idx: 260 |  Loss: (0.0551) | Acc: (98.07%) (32764/33408)\n",
            "Epoch: 96 | Batch_idx: 270 |  Loss: (0.0551) | Acc: (98.07%) (34018/34688)\n",
            "Epoch: 96 | Batch_idx: 280 |  Loss: (0.0548) | Acc: (98.09%) (35280/35968)\n",
            "Epoch: 96 | Batch_idx: 290 |  Loss: (0.0548) | Acc: (98.10%) (36539/37248)\n",
            "Epoch: 96 | Batch_idx: 300 |  Loss: (0.0545) | Acc: (98.11%) (37800/38528)\n",
            "Epoch: 96 | Batch_idx: 310 |  Loss: (0.0543) | Acc: (98.11%) (39057/39808)\n",
            "Epoch: 96 | Batch_idx: 320 |  Loss: (0.0542) | Acc: (98.11%) (40313/41088)\n",
            "Epoch: 96 | Batch_idx: 330 |  Loss: (0.0542) | Acc: (98.12%) (41572/42368)\n",
            "Epoch: 96 | Batch_idx: 340 |  Loss: (0.0541) | Acc: (98.13%) (42832/43648)\n",
            "Epoch: 96 | Batch_idx: 350 |  Loss: (0.0542) | Acc: (98.13%) (44089/44928)\n",
            "Epoch: 96 | Batch_idx: 360 |  Loss: (0.0540) | Acc: (98.13%) (45346/46208)\n",
            "Epoch: 96 | Batch_idx: 370 |  Loss: (0.0540) | Acc: (98.13%) (46599/47488)\n",
            "Epoch: 96 | Batch_idx: 380 |  Loss: (0.0542) | Acc: (98.13%) (47854/48768)\n",
            "Epoch: 96 | Batch_idx: 390 |  Loss: (0.0541) | Acc: (98.13%) (49065/50000)\n",
            "# TEST : Loss: (0.3147) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 97 | Batch_idx: 0 |  Loss: (0.0899) | Acc: (96.09%) (123/128)\n",
            "Epoch: 97 | Batch_idx: 10 |  Loss: (0.0500) | Acc: (98.30%) (1384/1408)\n",
            "Epoch: 97 | Batch_idx: 20 |  Loss: (0.0491) | Acc: (98.29%) (2642/2688)\n",
            "Epoch: 97 | Batch_idx: 30 |  Loss: (0.0487) | Acc: (98.39%) (3904/3968)\n",
            "Epoch: 97 | Batch_idx: 40 |  Loss: (0.0474) | Acc: (98.44%) (5166/5248)\n",
            "Epoch: 97 | Batch_idx: 50 |  Loss: (0.0470) | Acc: (98.42%) (6425/6528)\n",
            "Epoch: 97 | Batch_idx: 60 |  Loss: (0.0450) | Acc: (98.54%) (7694/7808)\n",
            "Epoch: 97 | Batch_idx: 70 |  Loss: (0.0448) | Acc: (98.55%) (8956/9088)\n",
            "Epoch: 97 | Batch_idx: 80 |  Loss: (0.0457) | Acc: (98.52%) (10215/10368)\n",
            "Epoch: 97 | Batch_idx: 90 |  Loss: (0.0456) | Acc: (98.50%) (11473/11648)\n",
            "Epoch: 97 | Batch_idx: 100 |  Loss: (0.0464) | Acc: (98.47%) (12730/12928)\n",
            "Epoch: 97 | Batch_idx: 110 |  Loss: (0.0472) | Acc: (98.38%) (13978/14208)\n",
            "Epoch: 97 | Batch_idx: 120 |  Loss: (0.0478) | Acc: (98.35%) (15233/15488)\n",
            "Epoch: 97 | Batch_idx: 130 |  Loss: (0.0481) | Acc: (98.32%) (16487/16768)\n",
            "Epoch: 97 | Batch_idx: 140 |  Loss: (0.0486) | Acc: (98.30%) (17741/18048)\n",
            "Epoch: 97 | Batch_idx: 150 |  Loss: (0.0477) | Acc: (98.35%) (19010/19328)\n",
            "Epoch: 97 | Batch_idx: 160 |  Loss: (0.0480) | Acc: (98.34%) (20265/20608)\n",
            "Epoch: 97 | Batch_idx: 170 |  Loss: (0.0479) | Acc: (98.35%) (21527/21888)\n",
            "Epoch: 97 | Batch_idx: 180 |  Loss: (0.0479) | Acc: (98.35%) (22786/23168)\n",
            "Epoch: 97 | Batch_idx: 190 |  Loss: (0.0481) | Acc: (98.36%) (24046/24448)\n",
            "Epoch: 97 | Batch_idx: 200 |  Loss: (0.0481) | Acc: (98.35%) (25304/25728)\n",
            "Epoch: 97 | Batch_idx: 210 |  Loss: (0.0487) | Acc: (98.33%) (26557/27008)\n",
            "Epoch: 97 | Batch_idx: 220 |  Loss: (0.0493) | Acc: (98.32%) (27812/28288)\n",
            "Epoch: 97 | Batch_idx: 230 |  Loss: (0.0492) | Acc: (98.33%) (29073/29568)\n",
            "Epoch: 97 | Batch_idx: 240 |  Loss: (0.0494) | Acc: (98.31%) (30328/30848)\n",
            "Epoch: 97 | Batch_idx: 250 |  Loss: (0.0492) | Acc: (98.32%) (31589/32128)\n",
            "Epoch: 97 | Batch_idx: 260 |  Loss: (0.0491) | Acc: (98.33%) (32850/33408)\n",
            "Epoch: 97 | Batch_idx: 270 |  Loss: (0.0492) | Acc: (98.34%) (34112/34688)\n",
            "Epoch: 97 | Batch_idx: 280 |  Loss: (0.0492) | Acc: (98.35%) (35376/35968)\n",
            "Epoch: 97 | Batch_idx: 290 |  Loss: (0.0490) | Acc: (98.37%) (36640/37248)\n",
            "Epoch: 97 | Batch_idx: 300 |  Loss: (0.0489) | Acc: (98.38%) (37905/38528)\n",
            "Epoch: 97 | Batch_idx: 310 |  Loss: (0.0490) | Acc: (98.38%) (39165/39808)\n",
            "Epoch: 97 | Batch_idx: 320 |  Loss: (0.0490) | Acc: (98.37%) (40419/41088)\n",
            "Epoch: 97 | Batch_idx: 330 |  Loss: (0.0493) | Acc: (98.37%) (41679/42368)\n",
            "Epoch: 97 | Batch_idx: 340 |  Loss: (0.0497) | Acc: (98.36%) (42931/43648)\n",
            "Epoch: 97 | Batch_idx: 350 |  Loss: (0.0496) | Acc: (98.36%) (44191/44928)\n",
            "Epoch: 97 | Batch_idx: 360 |  Loss: (0.0494) | Acc: (98.37%) (45455/46208)\n",
            "Epoch: 97 | Batch_idx: 370 |  Loss: (0.0495) | Acc: (98.36%) (46711/47488)\n",
            "Epoch: 97 | Batch_idx: 380 |  Loss: (0.0499) | Acc: (98.34%) (47957/48768)\n",
            "Epoch: 97 | Batch_idx: 390 |  Loss: (0.0500) | Acc: (98.33%) (49166/50000)\n",
            "# TEST : Loss: (0.3244) | Acc: (91.69%) (9169/10000)\n",
            "Epoch: 98 | Batch_idx: 0 |  Loss: (0.0622) | Acc: (96.88%) (124/128)\n",
            "Epoch: 98 | Batch_idx: 10 |  Loss: (0.0526) | Acc: (97.87%) (1378/1408)\n",
            "Epoch: 98 | Batch_idx: 20 |  Loss: (0.0504) | Acc: (98.18%) (2639/2688)\n",
            "Epoch: 98 | Batch_idx: 30 |  Loss: (0.0428) | Acc: (98.54%) (3910/3968)\n",
            "Epoch: 98 | Batch_idx: 40 |  Loss: (0.0460) | Acc: (98.46%) (5167/5248)\n",
            "Epoch: 98 | Batch_idx: 50 |  Loss: (0.0457) | Acc: (98.48%) (6429/6528)\n",
            "Epoch: 98 | Batch_idx: 60 |  Loss: (0.0457) | Acc: (98.51%) (7692/7808)\n",
            "Epoch: 98 | Batch_idx: 70 |  Loss: (0.0466) | Acc: (98.46%) (8948/9088)\n",
            "Epoch: 98 | Batch_idx: 80 |  Loss: (0.0471) | Acc: (98.42%) (10204/10368)\n",
            "Epoch: 98 | Batch_idx: 90 |  Loss: (0.0472) | Acc: (98.42%) (11464/11648)\n",
            "Epoch: 98 | Batch_idx: 100 |  Loss: (0.0475) | Acc: (98.41%) (12723/12928)\n",
            "Epoch: 98 | Batch_idx: 110 |  Loss: (0.0472) | Acc: (98.43%) (13985/14208)\n",
            "Epoch: 98 | Batch_idx: 120 |  Loss: (0.0476) | Acc: (98.41%) (15242/15488)\n",
            "Epoch: 98 | Batch_idx: 130 |  Loss: (0.0472) | Acc: (98.43%) (16504/16768)\n",
            "Epoch: 98 | Batch_idx: 140 |  Loss: (0.0477) | Acc: (98.41%) (17761/18048)\n",
            "Epoch: 98 | Batch_idx: 150 |  Loss: (0.0479) | Acc: (98.42%) (19022/19328)\n",
            "Epoch: 98 | Batch_idx: 160 |  Loss: (0.0488) | Acc: (98.39%) (20277/20608)\n",
            "Epoch: 98 | Batch_idx: 170 |  Loss: (0.0491) | Acc: (98.40%) (21538/21888)\n",
            "Epoch: 98 | Batch_idx: 180 |  Loss: (0.0491) | Acc: (98.38%) (22793/23168)\n",
            "Epoch: 98 | Batch_idx: 190 |  Loss: (0.0489) | Acc: (98.37%) (24049/24448)\n",
            "Epoch: 98 | Batch_idx: 200 |  Loss: (0.0487) | Acc: (98.38%) (25312/25728)\n",
            "Epoch: 98 | Batch_idx: 210 |  Loss: (0.0487) | Acc: (98.40%) (26576/27008)\n",
            "Epoch: 98 | Batch_idx: 220 |  Loss: (0.0491) | Acc: (98.40%) (27835/28288)\n",
            "Epoch: 98 | Batch_idx: 230 |  Loss: (0.0484) | Acc: (98.42%) (29102/29568)\n",
            "Epoch: 98 | Batch_idx: 240 |  Loss: (0.0481) | Acc: (98.44%) (30368/30848)\n",
            "Epoch: 98 | Batch_idx: 250 |  Loss: (0.0476) | Acc: (98.46%) (31633/32128)\n",
            "Epoch: 98 | Batch_idx: 260 |  Loss: (0.0476) | Acc: (98.45%) (32889/33408)\n",
            "Epoch: 98 | Batch_idx: 270 |  Loss: (0.0475) | Acc: (98.45%) (34150/34688)\n",
            "Epoch: 98 | Batch_idx: 280 |  Loss: (0.0472) | Acc: (98.46%) (35414/35968)\n",
            "Epoch: 98 | Batch_idx: 290 |  Loss: (0.0471) | Acc: (98.46%) (36673/37248)\n",
            "Epoch: 98 | Batch_idx: 300 |  Loss: (0.0472) | Acc: (98.46%) (37933/38528)\n",
            "Epoch: 98 | Batch_idx: 310 |  Loss: (0.0475) | Acc: (98.45%) (39191/39808)\n",
            "Epoch: 98 | Batch_idx: 320 |  Loss: (0.0474) | Acc: (98.45%) (40451/41088)\n",
            "Epoch: 98 | Batch_idx: 330 |  Loss: (0.0477) | Acc: (98.44%) (41708/42368)\n",
            "Epoch: 98 | Batch_idx: 340 |  Loss: (0.0476) | Acc: (98.44%) (42965/43648)\n",
            "Epoch: 98 | Batch_idx: 350 |  Loss: (0.0478) | Acc: (98.42%) (44216/44928)\n",
            "Epoch: 98 | Batch_idx: 360 |  Loss: (0.0476) | Acc: (98.43%) (45481/46208)\n",
            "Epoch: 98 | Batch_idx: 370 |  Loss: (0.0477) | Acc: (98.43%) (46743/47488)\n",
            "Epoch: 98 | Batch_idx: 380 |  Loss: (0.0479) | Acc: (98.41%) (47995/48768)\n",
            "Epoch: 98 | Batch_idx: 390 |  Loss: (0.0483) | Acc: (98.39%) (49194/50000)\n",
            "# TEST : Loss: (0.3248) | Acc: (91.42%) (9142/10000)\n",
            "Epoch: 99 | Batch_idx: 0 |  Loss: (0.0306) | Acc: (98.44%) (126/128)\n",
            "Epoch: 99 | Batch_idx: 10 |  Loss: (0.0416) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 99 | Batch_idx: 20 |  Loss: (0.0426) | Acc: (98.92%) (2659/2688)\n",
            "Epoch: 99 | Batch_idx: 30 |  Loss: (0.0438) | Acc: (98.66%) (3915/3968)\n",
            "Epoch: 99 | Batch_idx: 40 |  Loss: (0.0428) | Acc: (98.72%) (5181/5248)\n",
            "Epoch: 99 | Batch_idx: 50 |  Loss: (0.0443) | Acc: (98.68%) (6442/6528)\n",
            "Epoch: 99 | Batch_idx: 60 |  Loss: (0.0456) | Acc: (98.59%) (7698/7808)\n",
            "Epoch: 99 | Batch_idx: 70 |  Loss: (0.0460) | Acc: (98.55%) (8956/9088)\n",
            "Epoch: 99 | Batch_idx: 80 |  Loss: (0.0460) | Acc: (98.53%) (10216/10368)\n",
            "Epoch: 99 | Batch_idx: 90 |  Loss: (0.0467) | Acc: (98.49%) (11472/11648)\n",
            "Epoch: 99 | Batch_idx: 100 |  Loss: (0.0466) | Acc: (98.48%) (12732/12928)\n",
            "Epoch: 99 | Batch_idx: 110 |  Loss: (0.0475) | Acc: (98.45%) (13988/14208)\n",
            "Epoch: 99 | Batch_idx: 120 |  Loss: (0.0474) | Acc: (98.47%) (15251/15488)\n",
            "Epoch: 99 | Batch_idx: 130 |  Loss: (0.0476) | Acc: (98.45%) (16508/16768)\n",
            "Epoch: 99 | Batch_idx: 140 |  Loss: (0.0474) | Acc: (98.46%) (17770/18048)\n",
            "Epoch: 99 | Batch_idx: 150 |  Loss: (0.0469) | Acc: (98.50%) (19038/19328)\n",
            "Epoch: 99 | Batch_idx: 160 |  Loss: (0.0480) | Acc: (98.44%) (20287/20608)\n",
            "Epoch: 99 | Batch_idx: 170 |  Loss: (0.0483) | Acc: (98.41%) (21540/21888)\n",
            "Epoch: 99 | Batch_idx: 180 |  Loss: (0.0477) | Acc: (98.44%) (22807/23168)\n",
            "Epoch: 99 | Batch_idx: 190 |  Loss: (0.0478) | Acc: (98.43%) (24065/24448)\n",
            "Epoch: 99 | Batch_idx: 200 |  Loss: (0.0484) | Acc: (98.41%) (25320/25728)\n",
            "Epoch: 99 | Batch_idx: 210 |  Loss: (0.0488) | Acc: (98.40%) (26575/27008)\n",
            "Epoch: 99 | Batch_idx: 220 |  Loss: (0.0493) | Acc: (98.37%) (27828/28288)\n",
            "Epoch: 99 | Batch_idx: 230 |  Loss: (0.0501) | Acc: (98.37%) (29085/29568)\n",
            "Epoch: 99 | Batch_idx: 240 |  Loss: (0.0500) | Acc: (98.38%) (30347/30848)\n",
            "Epoch: 99 | Batch_idx: 250 |  Loss: (0.0497) | Acc: (98.37%) (31604/32128)\n",
            "Epoch: 99 | Batch_idx: 260 |  Loss: (0.0496) | Acc: (98.37%) (32864/33408)\n",
            "Epoch: 99 | Batch_idx: 270 |  Loss: (0.0498) | Acc: (98.36%) (34119/34688)\n",
            "Epoch: 99 | Batch_idx: 280 |  Loss: (0.0498) | Acc: (98.38%) (35384/35968)\n",
            "Epoch: 99 | Batch_idx: 290 |  Loss: (0.0496) | Acc: (98.38%) (36646/37248)\n",
            "Epoch: 99 | Batch_idx: 300 |  Loss: (0.0495) | Acc: (98.40%) (37910/38528)\n",
            "Epoch: 99 | Batch_idx: 310 |  Loss: (0.0492) | Acc: (98.41%) (39174/39808)\n",
            "Epoch: 99 | Batch_idx: 320 |  Loss: (0.0491) | Acc: (98.41%) (40434/41088)\n",
            "Epoch: 99 | Batch_idx: 330 |  Loss: (0.0493) | Acc: (98.38%) (41683/42368)\n",
            "Epoch: 99 | Batch_idx: 340 |  Loss: (0.0491) | Acc: (98.38%) (42942/43648)\n",
            "Epoch: 99 | Batch_idx: 350 |  Loss: (0.0495) | Acc: (98.36%) (44190/44928)\n",
            "Epoch: 99 | Batch_idx: 360 |  Loss: (0.0497) | Acc: (98.34%) (45442/46208)\n",
            "Epoch: 99 | Batch_idx: 370 |  Loss: (0.0498) | Acc: (98.34%) (46701/47488)\n",
            "Epoch: 99 | Batch_idx: 380 |  Loss: (0.0499) | Acc: (98.33%) (47952/48768)\n",
            "Epoch: 99 | Batch_idx: 390 |  Loss: (0.0498) | Acc: (98.33%) (49165/50000)\n",
            "# TEST : Loss: (0.3208) | Acc: (91.68%) (9168/10000)\n",
            "Epoch: 100 | Batch_idx: 0 |  Loss: (0.0278) | Acc: (100.00%) (128/128)\n",
            "Epoch: 100 | Batch_idx: 10 |  Loss: (0.0465) | Acc: (98.51%) (1387/1408)\n",
            "Epoch: 100 | Batch_idx: 20 |  Loss: (0.0506) | Acc: (98.18%) (2639/2688)\n",
            "Epoch: 100 | Batch_idx: 30 |  Loss: (0.0489) | Acc: (98.31%) (3901/3968)\n",
            "Epoch: 100 | Batch_idx: 40 |  Loss: (0.0514) | Acc: (98.17%) (5152/5248)\n",
            "Epoch: 100 | Batch_idx: 50 |  Loss: (0.0507) | Acc: (98.22%) (6412/6528)\n",
            "Epoch: 100 | Batch_idx: 60 |  Loss: (0.0488) | Acc: (98.35%) (7679/7808)\n",
            "Epoch: 100 | Batch_idx: 70 |  Loss: (0.0484) | Acc: (98.34%) (8937/9088)\n",
            "Epoch: 100 | Batch_idx: 80 |  Loss: (0.0480) | Acc: (98.40%) (10202/10368)\n",
            "Epoch: 100 | Batch_idx: 90 |  Loss: (0.0484) | Acc: (98.37%) (11458/11648)\n",
            "Epoch: 100 | Batch_idx: 100 |  Loss: (0.0476) | Acc: (98.38%) (12719/12928)\n",
            "Epoch: 100 | Batch_idx: 110 |  Loss: (0.0478) | Acc: (98.37%) (13977/14208)\n",
            "Epoch: 100 | Batch_idx: 120 |  Loss: (0.0487) | Acc: (98.34%) (15231/15488)\n",
            "Epoch: 100 | Batch_idx: 130 |  Loss: (0.0487) | Acc: (98.34%) (16490/16768)\n",
            "Epoch: 100 | Batch_idx: 140 |  Loss: (0.0488) | Acc: (98.33%) (17746/18048)\n",
            "Epoch: 100 | Batch_idx: 150 |  Loss: (0.0487) | Acc: (98.33%) (19005/19328)\n",
            "Epoch: 100 | Batch_idx: 160 |  Loss: (0.0480) | Acc: (98.37%) (20272/20608)\n",
            "Epoch: 100 | Batch_idx: 170 |  Loss: (0.0482) | Acc: (98.36%) (21529/21888)\n",
            "Epoch: 100 | Batch_idx: 180 |  Loss: (0.0490) | Acc: (98.31%) (22777/23168)\n",
            "Epoch: 100 | Batch_idx: 190 |  Loss: (0.0490) | Acc: (98.32%) (24037/24448)\n",
            "Epoch: 100 | Batch_idx: 200 |  Loss: (0.0485) | Acc: (98.35%) (25303/25728)\n",
            "Epoch: 100 | Batch_idx: 210 |  Loss: (0.0483) | Acc: (98.34%) (26559/27008)\n",
            "Epoch: 100 | Batch_idx: 220 |  Loss: (0.0481) | Acc: (98.35%) (27822/28288)\n",
            "Epoch: 100 | Batch_idx: 230 |  Loss: (0.0482) | Acc: (98.36%) (29084/29568)\n",
            "Epoch: 100 | Batch_idx: 240 |  Loss: (0.0487) | Acc: (98.35%) (30340/30848)\n",
            "Epoch: 100 | Batch_idx: 250 |  Loss: (0.0485) | Acc: (98.38%) (31608/32128)\n",
            "Epoch: 100 | Batch_idx: 260 |  Loss: (0.0486) | Acc: (98.37%) (32863/33408)\n",
            "Epoch: 100 | Batch_idx: 270 |  Loss: (0.0485) | Acc: (98.36%) (34120/34688)\n",
            "Epoch: 100 | Batch_idx: 280 |  Loss: (0.0486) | Acc: (98.37%) (35380/35968)\n",
            "Epoch: 100 | Batch_idx: 290 |  Loss: (0.0485) | Acc: (98.36%) (36638/37248)\n",
            "Epoch: 100 | Batch_idx: 300 |  Loss: (0.0489) | Acc: (98.34%) (37887/38528)\n",
            "Epoch: 100 | Batch_idx: 310 |  Loss: (0.0487) | Acc: (98.34%) (39147/39808)\n",
            "Epoch: 100 | Batch_idx: 320 |  Loss: (0.0488) | Acc: (98.34%) (40404/41088)\n",
            "Epoch: 100 | Batch_idx: 330 |  Loss: (0.0487) | Acc: (98.34%) (41664/42368)\n",
            "Epoch: 100 | Batch_idx: 340 |  Loss: (0.0487) | Acc: (98.33%) (42920/43648)\n",
            "Epoch: 100 | Batch_idx: 350 |  Loss: (0.0486) | Acc: (98.34%) (44182/44928)\n",
            "Epoch: 100 | Batch_idx: 360 |  Loss: (0.0488) | Acc: (98.33%) (45435/46208)\n",
            "Epoch: 100 | Batch_idx: 370 |  Loss: (0.0487) | Acc: (98.33%) (46696/47488)\n",
            "Epoch: 100 | Batch_idx: 380 |  Loss: (0.0488) | Acc: (98.32%) (47949/48768)\n",
            "Epoch: 100 | Batch_idx: 390 |  Loss: (0.0489) | Acc: (98.31%) (49154/50000)\n",
            "# TEST : Loss: (0.3222) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 101 | Batch_idx: 0 |  Loss: (0.0726) | Acc: (97.66%) (125/128)\n",
            "Epoch: 101 | Batch_idx: 10 |  Loss: (0.0424) | Acc: (98.65%) (1389/1408)\n",
            "Epoch: 101 | Batch_idx: 20 |  Loss: (0.0506) | Acc: (98.47%) (2647/2688)\n",
            "Epoch: 101 | Batch_idx: 30 |  Loss: (0.0484) | Acc: (98.56%) (3911/3968)\n",
            "Epoch: 101 | Batch_idx: 40 |  Loss: (0.0485) | Acc: (98.51%) (5170/5248)\n",
            "Epoch: 101 | Batch_idx: 50 |  Loss: (0.0501) | Acc: (98.41%) (6424/6528)\n",
            "Epoch: 101 | Batch_idx: 60 |  Loss: (0.0497) | Acc: (98.41%) (7684/7808)\n",
            "Epoch: 101 | Batch_idx: 70 |  Loss: (0.0478) | Acc: (98.50%) (8952/9088)\n",
            "Epoch: 101 | Batch_idx: 80 |  Loss: (0.0469) | Acc: (98.52%) (10215/10368)\n",
            "Epoch: 101 | Batch_idx: 90 |  Loss: (0.0451) | Acc: (98.57%) (11482/11648)\n",
            "Epoch: 101 | Batch_idx: 100 |  Loss: (0.0461) | Acc: (98.54%) (12739/12928)\n",
            "Epoch: 101 | Batch_idx: 110 |  Loss: (0.0456) | Acc: (98.56%) (14003/14208)\n",
            "Epoch: 101 | Batch_idx: 120 |  Loss: (0.0454) | Acc: (98.57%) (15267/15488)\n",
            "Epoch: 101 | Batch_idx: 130 |  Loss: (0.0458) | Acc: (98.53%) (16521/16768)\n",
            "Epoch: 101 | Batch_idx: 140 |  Loss: (0.0474) | Acc: (98.45%) (17769/18048)\n",
            "Epoch: 101 | Batch_idx: 150 |  Loss: (0.0469) | Acc: (98.46%) (19031/19328)\n",
            "Epoch: 101 | Batch_idx: 160 |  Loss: (0.0472) | Acc: (98.44%) (20287/20608)\n",
            "Epoch: 101 | Batch_idx: 170 |  Loss: (0.0469) | Acc: (98.45%) (21549/21888)\n",
            "Epoch: 101 | Batch_idx: 180 |  Loss: (0.0476) | Acc: (98.42%) (22802/23168)\n",
            "Epoch: 101 | Batch_idx: 190 |  Loss: (0.0480) | Acc: (98.42%) (24061/24448)\n",
            "Epoch: 101 | Batch_idx: 200 |  Loss: (0.0472) | Acc: (98.45%) (25330/25728)\n",
            "Epoch: 101 | Batch_idx: 210 |  Loss: (0.0470) | Acc: (98.47%) (26595/27008)\n",
            "Epoch: 101 | Batch_idx: 220 |  Loss: (0.0470) | Acc: (98.47%) (27854/28288)\n",
            "Epoch: 101 | Batch_idx: 230 |  Loss: (0.0472) | Acc: (98.46%) (29114/29568)\n",
            "Epoch: 101 | Batch_idx: 240 |  Loss: (0.0476) | Acc: (98.45%) (30369/30848)\n",
            "Epoch: 101 | Batch_idx: 250 |  Loss: (0.0475) | Acc: (98.44%) (31626/32128)\n",
            "Epoch: 101 | Batch_idx: 260 |  Loss: (0.0479) | Acc: (98.43%) (32884/33408)\n",
            "Epoch: 101 | Batch_idx: 270 |  Loss: (0.0481) | Acc: (98.41%) (34135/34688)\n",
            "Epoch: 101 | Batch_idx: 280 |  Loss: (0.0481) | Acc: (98.40%) (35394/35968)\n",
            "Epoch: 101 | Batch_idx: 290 |  Loss: (0.0477) | Acc: (98.42%) (36660/37248)\n",
            "Epoch: 101 | Batch_idx: 300 |  Loss: (0.0478) | Acc: (98.42%) (37919/38528)\n",
            "Epoch: 101 | Batch_idx: 310 |  Loss: (0.0479) | Acc: (98.41%) (39176/39808)\n",
            "Epoch: 101 | Batch_idx: 320 |  Loss: (0.0475) | Acc: (98.43%) (40442/41088)\n",
            "Epoch: 101 | Batch_idx: 330 |  Loss: (0.0475) | Acc: (98.43%) (41701/42368)\n",
            "Epoch: 101 | Batch_idx: 340 |  Loss: (0.0474) | Acc: (98.44%) (42965/43648)\n",
            "Epoch: 101 | Batch_idx: 350 |  Loss: (0.0472) | Acc: (98.44%) (44227/44928)\n",
            "Epoch: 101 | Batch_idx: 360 |  Loss: (0.0472) | Acc: (98.44%) (45489/46208)\n",
            "Epoch: 101 | Batch_idx: 370 |  Loss: (0.0470) | Acc: (98.46%) (46757/47488)\n",
            "Epoch: 101 | Batch_idx: 380 |  Loss: (0.0472) | Acc: (98.45%) (48012/48768)\n",
            "Epoch: 101 | Batch_idx: 390 |  Loss: (0.0472) | Acc: (98.45%) (49225/50000)\n",
            "# TEST : Loss: (0.3262) | Acc: (91.64%) (9164/10000)\n",
            "Epoch: 102 | Batch_idx: 0 |  Loss: (0.0455) | Acc: (98.44%) (126/128)\n",
            "Epoch: 102 | Batch_idx: 10 |  Loss: (0.0451) | Acc: (98.44%) (1386/1408)\n",
            "Epoch: 102 | Batch_idx: 20 |  Loss: (0.0386) | Acc: (98.77%) (2655/2688)\n",
            "Epoch: 102 | Batch_idx: 30 |  Loss: (0.0396) | Acc: (98.74%) (3918/3968)\n",
            "Epoch: 102 | Batch_idx: 40 |  Loss: (0.0418) | Acc: (98.72%) (5181/5248)\n",
            "Epoch: 102 | Batch_idx: 50 |  Loss: (0.0421) | Acc: (98.68%) (6442/6528)\n",
            "Epoch: 102 | Batch_idx: 60 |  Loss: (0.0423) | Acc: (98.67%) (7704/7808)\n",
            "Epoch: 102 | Batch_idx: 70 |  Loss: (0.0421) | Acc: (98.67%) (8967/9088)\n",
            "Epoch: 102 | Batch_idx: 80 |  Loss: (0.0422) | Acc: (98.63%) (10226/10368)\n",
            "Epoch: 102 | Batch_idx: 90 |  Loss: (0.0431) | Acc: (98.63%) (11488/11648)\n",
            "Epoch: 102 | Batch_idx: 100 |  Loss: (0.0441) | Acc: (98.58%) (12744/12928)\n",
            "Epoch: 102 | Batch_idx: 110 |  Loss: (0.0432) | Acc: (98.61%) (14011/14208)\n",
            "Epoch: 102 | Batch_idx: 120 |  Loss: (0.0440) | Acc: (98.57%) (15266/15488)\n",
            "Epoch: 102 | Batch_idx: 130 |  Loss: (0.0441) | Acc: (98.54%) (16524/16768)\n",
            "Epoch: 102 | Batch_idx: 140 |  Loss: (0.0436) | Acc: (98.59%) (17793/18048)\n",
            "Epoch: 102 | Batch_idx: 150 |  Loss: (0.0439) | Acc: (98.57%) (19051/19328)\n",
            "Epoch: 102 | Batch_idx: 160 |  Loss: (0.0437) | Acc: (98.57%) (20313/20608)\n",
            "Epoch: 102 | Batch_idx: 170 |  Loss: (0.0439) | Acc: (98.56%) (21573/21888)\n",
            "Epoch: 102 | Batch_idx: 180 |  Loss: (0.0442) | Acc: (98.53%) (22827/23168)\n",
            "Epoch: 102 | Batch_idx: 190 |  Loss: (0.0438) | Acc: (98.54%) (24090/24448)\n",
            "Epoch: 102 | Batch_idx: 200 |  Loss: (0.0442) | Acc: (98.51%) (25344/25728)\n",
            "Epoch: 102 | Batch_idx: 210 |  Loss: (0.0443) | Acc: (98.51%) (26606/27008)\n",
            "Epoch: 102 | Batch_idx: 220 |  Loss: (0.0443) | Acc: (98.51%) (27867/28288)\n",
            "Epoch: 102 | Batch_idx: 230 |  Loss: (0.0446) | Acc: (98.50%) (29124/29568)\n",
            "Epoch: 102 | Batch_idx: 240 |  Loss: (0.0445) | Acc: (98.50%) (30386/30848)\n",
            "Epoch: 102 | Batch_idx: 250 |  Loss: (0.0448) | Acc: (98.50%) (31647/32128)\n",
            "Epoch: 102 | Batch_idx: 260 |  Loss: (0.0449) | Acc: (98.50%) (32907/33408)\n",
            "Epoch: 102 | Batch_idx: 270 |  Loss: (0.0451) | Acc: (98.50%) (34166/34688)\n",
            "Epoch: 102 | Batch_idx: 280 |  Loss: (0.0454) | Acc: (98.49%) (35425/35968)\n",
            "Epoch: 102 | Batch_idx: 290 |  Loss: (0.0452) | Acc: (98.49%) (36684/37248)\n",
            "Epoch: 102 | Batch_idx: 300 |  Loss: (0.0452) | Acc: (98.48%) (37943/38528)\n",
            "Epoch: 102 | Batch_idx: 310 |  Loss: (0.0454) | Acc: (98.47%) (39198/39808)\n",
            "Epoch: 102 | Batch_idx: 320 |  Loss: (0.0452) | Acc: (98.48%) (40465/41088)\n",
            "Epoch: 102 | Batch_idx: 330 |  Loss: (0.0459) | Acc: (98.45%) (41712/42368)\n",
            "Epoch: 102 | Batch_idx: 340 |  Loss: (0.0456) | Acc: (98.47%) (42981/43648)\n",
            "Epoch: 102 | Batch_idx: 350 |  Loss: (0.0455) | Acc: (98.47%) (44241/44928)\n",
            "Epoch: 102 | Batch_idx: 360 |  Loss: (0.0454) | Acc: (98.47%) (45501/46208)\n",
            "Epoch: 102 | Batch_idx: 370 |  Loss: (0.0455) | Acc: (98.46%) (46759/47488)\n",
            "Epoch: 102 | Batch_idx: 380 |  Loss: (0.0456) | Acc: (98.46%) (48017/48768)\n",
            "Epoch: 102 | Batch_idx: 390 |  Loss: (0.0457) | Acc: (98.46%) (49232/50000)\n",
            "# TEST : Loss: (0.3365) | Acc: (91.42%) (9142/10000)\n",
            "Epoch: 103 | Batch_idx: 0 |  Loss: (0.0333) | Acc: (98.44%) (126/128)\n",
            "Epoch: 103 | Batch_idx: 10 |  Loss: (0.0424) | Acc: (98.30%) (1384/1408)\n",
            "Epoch: 103 | Batch_idx: 20 |  Loss: (0.0382) | Acc: (98.66%) (2652/2688)\n",
            "Epoch: 103 | Batch_idx: 30 |  Loss: (0.0439) | Acc: (98.49%) (3908/3968)\n",
            "Epoch: 103 | Batch_idx: 40 |  Loss: (0.0447) | Acc: (98.48%) (5168/5248)\n",
            "Epoch: 103 | Batch_idx: 50 |  Loss: (0.0446) | Acc: (98.51%) (6431/6528)\n",
            "Epoch: 103 | Batch_idx: 60 |  Loss: (0.0464) | Acc: (98.44%) (7686/7808)\n",
            "Epoch: 103 | Batch_idx: 70 |  Loss: (0.0466) | Acc: (98.45%) (8947/9088)\n",
            "Epoch: 103 | Batch_idx: 80 |  Loss: (0.0472) | Acc: (98.44%) (10206/10368)\n",
            "Epoch: 103 | Batch_idx: 90 |  Loss: (0.0464) | Acc: (98.45%) (11467/11648)\n",
            "Epoch: 103 | Batch_idx: 100 |  Loss: (0.0476) | Acc: (98.39%) (12720/12928)\n",
            "Epoch: 103 | Batch_idx: 110 |  Loss: (0.0470) | Acc: (98.40%) (13980/14208)\n",
            "Epoch: 103 | Batch_idx: 120 |  Loss: (0.0477) | Acc: (98.37%) (15236/15488)\n",
            "Epoch: 103 | Batch_idx: 130 |  Loss: (0.0476) | Acc: (98.37%) (16495/16768)\n",
            "Epoch: 103 | Batch_idx: 140 |  Loss: (0.0478) | Acc: (98.36%) (17752/18048)\n",
            "Epoch: 103 | Batch_idx: 150 |  Loss: (0.0477) | Acc: (98.36%) (19011/19328)\n",
            "Epoch: 103 | Batch_idx: 160 |  Loss: (0.0472) | Acc: (98.39%) (20276/20608)\n",
            "Epoch: 103 | Batch_idx: 170 |  Loss: (0.0472) | Acc: (98.39%) (21535/21888)\n",
            "Epoch: 103 | Batch_idx: 180 |  Loss: (0.0472) | Acc: (98.40%) (22798/23168)\n",
            "Epoch: 103 | Batch_idx: 190 |  Loss: (0.0470) | Acc: (98.40%) (24058/24448)\n",
            "Epoch: 103 | Batch_idx: 200 |  Loss: (0.0468) | Acc: (98.43%) (25323/25728)\n",
            "Epoch: 103 | Batch_idx: 210 |  Loss: (0.0467) | Acc: (98.43%) (26585/27008)\n",
            "Epoch: 103 | Batch_idx: 220 |  Loss: (0.0465) | Acc: (98.46%) (27851/28288)\n",
            "Epoch: 103 | Batch_idx: 230 |  Loss: (0.0464) | Acc: (98.45%) (29109/29568)\n",
            "Epoch: 103 | Batch_idx: 240 |  Loss: (0.0462) | Acc: (98.44%) (30368/30848)\n",
            "Epoch: 103 | Batch_idx: 250 |  Loss: (0.0462) | Acc: (98.45%) (31631/32128)\n",
            "Epoch: 103 | Batch_idx: 260 |  Loss: (0.0462) | Acc: (98.46%) (32892/33408)\n",
            "Epoch: 103 | Batch_idx: 270 |  Loss: (0.0459) | Acc: (98.47%) (34157/34688)\n",
            "Epoch: 103 | Batch_idx: 280 |  Loss: (0.0456) | Acc: (98.48%) (35422/35968)\n",
            "Epoch: 103 | Batch_idx: 290 |  Loss: (0.0453) | Acc: (98.49%) (36687/37248)\n",
            "Epoch: 103 | Batch_idx: 300 |  Loss: (0.0459) | Acc: (98.48%) (37944/38528)\n",
            "Epoch: 103 | Batch_idx: 310 |  Loss: (0.0460) | Acc: (98.47%) (39199/39808)\n",
            "Epoch: 103 | Batch_idx: 320 |  Loss: (0.0461) | Acc: (98.47%) (40458/41088)\n",
            "Epoch: 103 | Batch_idx: 330 |  Loss: (0.0458) | Acc: (98.48%) (41724/42368)\n",
            "Epoch: 103 | Batch_idx: 340 |  Loss: (0.0463) | Acc: (98.44%) (42966/43648)\n",
            "Epoch: 103 | Batch_idx: 350 |  Loss: (0.0467) | Acc: (98.42%) (44220/44928)\n",
            "Epoch: 103 | Batch_idx: 360 |  Loss: (0.0465) | Acc: (98.44%) (45486/46208)\n",
            "Epoch: 103 | Batch_idx: 370 |  Loss: (0.0464) | Acc: (98.43%) (46744/47488)\n",
            "Epoch: 103 | Batch_idx: 380 |  Loss: (0.0463) | Acc: (98.44%) (48008/48768)\n",
            "Epoch: 103 | Batch_idx: 390 |  Loss: (0.0462) | Acc: (98.45%) (49226/50000)\n",
            "# TEST : Loss: (0.3350) | Acc: (91.63%) (9163/10000)\n",
            "Epoch: 104 | Batch_idx: 0 |  Loss: (0.0529) | Acc: (97.66%) (125/128)\n",
            "Epoch: 104 | Batch_idx: 10 |  Loss: (0.0450) | Acc: (98.51%) (1387/1408)\n",
            "Epoch: 104 | Batch_idx: 20 |  Loss: (0.0391) | Acc: (98.85%) (2657/2688)\n",
            "Epoch: 104 | Batch_idx: 30 |  Loss: (0.0398) | Acc: (98.74%) (3918/3968)\n",
            "Epoch: 104 | Batch_idx: 40 |  Loss: (0.0413) | Acc: (98.65%) (5177/5248)\n",
            "Epoch: 104 | Batch_idx: 50 |  Loss: (0.0413) | Acc: (98.68%) (6442/6528)\n",
            "Epoch: 104 | Batch_idx: 60 |  Loss: (0.0404) | Acc: (98.71%) (7707/7808)\n",
            "Epoch: 104 | Batch_idx: 70 |  Loss: (0.0404) | Acc: (98.70%) (8970/9088)\n",
            "Epoch: 104 | Batch_idx: 80 |  Loss: (0.0416) | Acc: (98.66%) (10229/10368)\n",
            "Epoch: 104 | Batch_idx: 90 |  Loss: (0.0429) | Acc: (98.63%) (11489/11648)\n",
            "Epoch: 104 | Batch_idx: 100 |  Loss: (0.0427) | Acc: (98.63%) (12751/12928)\n",
            "Epoch: 104 | Batch_idx: 110 |  Loss: (0.0432) | Acc: (98.63%) (14014/14208)\n",
            "Epoch: 104 | Batch_idx: 120 |  Loss: (0.0426) | Acc: (98.65%) (15279/15488)\n",
            "Epoch: 104 | Batch_idx: 130 |  Loss: (0.0426) | Acc: (98.63%) (16539/16768)\n",
            "Epoch: 104 | Batch_idx: 140 |  Loss: (0.0423) | Acc: (98.66%) (17806/18048)\n",
            "Epoch: 104 | Batch_idx: 150 |  Loss: (0.0421) | Acc: (98.64%) (19066/19328)\n",
            "Epoch: 104 | Batch_idx: 160 |  Loss: (0.0417) | Acc: (98.69%) (20338/20608)\n",
            "Epoch: 104 | Batch_idx: 170 |  Loss: (0.0411) | Acc: (98.73%) (21609/21888)\n",
            "Epoch: 104 | Batch_idx: 180 |  Loss: (0.0423) | Acc: (98.68%) (22862/23168)\n",
            "Epoch: 104 | Batch_idx: 190 |  Loss: (0.0425) | Acc: (98.67%) (24122/24448)\n",
            "Epoch: 104 | Batch_idx: 200 |  Loss: (0.0423) | Acc: (98.67%) (25386/25728)\n",
            "Epoch: 104 | Batch_idx: 210 |  Loss: (0.0421) | Acc: (98.66%) (26645/27008)\n",
            "Epoch: 104 | Batch_idx: 220 |  Loss: (0.0424) | Acc: (98.65%) (27906/28288)\n",
            "Epoch: 104 | Batch_idx: 230 |  Loss: (0.0425) | Acc: (98.64%) (29167/29568)\n",
            "Epoch: 104 | Batch_idx: 240 |  Loss: (0.0425) | Acc: (98.64%) (30428/30848)\n",
            "Epoch: 104 | Batch_idx: 250 |  Loss: (0.0424) | Acc: (98.64%) (31690/32128)\n",
            "Epoch: 104 | Batch_idx: 260 |  Loss: (0.0427) | Acc: (98.63%) (32950/33408)\n",
            "Epoch: 104 | Batch_idx: 270 |  Loss: (0.0422) | Acc: (98.64%) (34215/34688)\n",
            "Epoch: 104 | Batch_idx: 280 |  Loss: (0.0424) | Acc: (98.62%) (35471/35968)\n",
            "Epoch: 104 | Batch_idx: 290 |  Loss: (0.0426) | Acc: (98.60%) (36727/37248)\n",
            "Epoch: 104 | Batch_idx: 300 |  Loss: (0.0426) | Acc: (98.61%) (37992/38528)\n",
            "Epoch: 104 | Batch_idx: 310 |  Loss: (0.0428) | Acc: (98.60%) (39252/39808)\n",
            "Epoch: 104 | Batch_idx: 320 |  Loss: (0.0428) | Acc: (98.60%) (40514/41088)\n",
            "Epoch: 104 | Batch_idx: 330 |  Loss: (0.0428) | Acc: (98.60%) (41775/42368)\n",
            "Epoch: 104 | Batch_idx: 340 |  Loss: (0.0430) | Acc: (98.59%) (43033/43648)\n",
            "Epoch: 104 | Batch_idx: 350 |  Loss: (0.0431) | Acc: (98.60%) (44298/44928)\n",
            "Epoch: 104 | Batch_idx: 360 |  Loss: (0.0434) | Acc: (98.59%) (45557/46208)\n",
            "Epoch: 104 | Batch_idx: 370 |  Loss: (0.0432) | Acc: (98.59%) (46819/47488)\n",
            "Epoch: 104 | Batch_idx: 380 |  Loss: (0.0432) | Acc: (98.60%) (48083/48768)\n",
            "Epoch: 104 | Batch_idx: 390 |  Loss: (0.0430) | Acc: (98.61%) (49305/50000)\n",
            "# TEST : Loss: (0.3408) | Acc: (91.64%) (9164/10000)\n",
            "Epoch: 105 | Batch_idx: 0 |  Loss: (0.0283) | Acc: (99.22%) (127/128)\n",
            "Epoch: 105 | Batch_idx: 10 |  Loss: (0.0362) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 105 | Batch_idx: 20 |  Loss: (0.0347) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 105 | Batch_idx: 30 |  Loss: (0.0354) | Acc: (98.97%) (3927/3968)\n",
            "Epoch: 105 | Batch_idx: 40 |  Loss: (0.0341) | Acc: (98.93%) (5192/5248)\n",
            "Epoch: 105 | Batch_idx: 50 |  Loss: (0.0338) | Acc: (98.90%) (6456/6528)\n",
            "Epoch: 105 | Batch_idx: 60 |  Loss: (0.0355) | Acc: (98.83%) (7717/7808)\n",
            "Epoch: 105 | Batch_idx: 70 |  Loss: (0.0356) | Acc: (98.82%) (8981/9088)\n",
            "Epoch: 105 | Batch_idx: 80 |  Loss: (0.0358) | Acc: (98.81%) (10245/10368)\n",
            "Epoch: 105 | Batch_idx: 90 |  Loss: (0.0356) | Acc: (98.84%) (11513/11648)\n",
            "Epoch: 105 | Batch_idx: 100 |  Loss: (0.0367) | Acc: (98.79%) (12772/12928)\n",
            "Epoch: 105 | Batch_idx: 110 |  Loss: (0.0369) | Acc: (98.81%) (14039/14208)\n",
            "Epoch: 105 | Batch_idx: 120 |  Loss: (0.0369) | Acc: (98.82%) (15305/15488)\n",
            "Epoch: 105 | Batch_idx: 130 |  Loss: (0.0375) | Acc: (98.80%) (16567/16768)\n",
            "Epoch: 105 | Batch_idx: 140 |  Loss: (0.0378) | Acc: (98.81%) (17834/18048)\n",
            "Epoch: 105 | Batch_idx: 150 |  Loss: (0.0386) | Acc: (98.79%) (19094/19328)\n",
            "Epoch: 105 | Batch_idx: 160 |  Loss: (0.0389) | Acc: (98.80%) (20360/20608)\n",
            "Epoch: 105 | Batch_idx: 170 |  Loss: (0.0383) | Acc: (98.83%) (21631/21888)\n",
            "Epoch: 105 | Batch_idx: 180 |  Loss: (0.0385) | Acc: (98.81%) (22893/23168)\n",
            "Epoch: 105 | Batch_idx: 190 |  Loss: (0.0390) | Acc: (98.81%) (24157/24448)\n",
            "Epoch: 105 | Batch_idx: 200 |  Loss: (0.0394) | Acc: (98.79%) (25417/25728)\n",
            "Epoch: 105 | Batch_idx: 210 |  Loss: (0.0399) | Acc: (98.77%) (26675/27008)\n",
            "Epoch: 105 | Batch_idx: 220 |  Loss: (0.0403) | Acc: (98.76%) (27936/28288)\n",
            "Epoch: 105 | Batch_idx: 230 |  Loss: (0.0404) | Acc: (98.74%) (29195/29568)\n",
            "Epoch: 105 | Batch_idx: 240 |  Loss: (0.0404) | Acc: (98.72%) (30454/30848)\n",
            "Epoch: 105 | Batch_idx: 250 |  Loss: (0.0405) | Acc: (98.70%) (31709/32128)\n",
            "Epoch: 105 | Batch_idx: 260 |  Loss: (0.0407) | Acc: (98.68%) (32968/33408)\n",
            "Epoch: 105 | Batch_idx: 270 |  Loss: (0.0410) | Acc: (98.68%) (34229/34688)\n",
            "Epoch: 105 | Batch_idx: 280 |  Loss: (0.0411) | Acc: (98.67%) (35489/35968)\n",
            "Epoch: 105 | Batch_idx: 290 |  Loss: (0.0409) | Acc: (98.67%) (36753/37248)\n",
            "Epoch: 105 | Batch_idx: 300 |  Loss: (0.0407) | Acc: (98.68%) (38021/38528)\n",
            "Epoch: 105 | Batch_idx: 310 |  Loss: (0.0407) | Acc: (98.68%) (39284/39808)\n",
            "Epoch: 105 | Batch_idx: 320 |  Loss: (0.0405) | Acc: (98.70%) (40553/41088)\n",
            "Epoch: 105 | Batch_idx: 330 |  Loss: (0.0406) | Acc: (98.69%) (41811/42368)\n",
            "Epoch: 105 | Batch_idx: 340 |  Loss: (0.0408) | Acc: (98.68%) (43074/43648)\n",
            "Epoch: 105 | Batch_idx: 350 |  Loss: (0.0409) | Acc: (98.68%) (44335/44928)\n",
            "Epoch: 105 | Batch_idx: 360 |  Loss: (0.0408) | Acc: (98.68%) (45599/46208)\n",
            "Epoch: 105 | Batch_idx: 370 |  Loss: (0.0410) | Acc: (98.67%) (46858/47488)\n",
            "Epoch: 105 | Batch_idx: 380 |  Loss: (0.0413) | Acc: (98.66%) (48113/48768)\n",
            "Epoch: 105 | Batch_idx: 390 |  Loss: (0.0412) | Acc: (98.67%) (49333/50000)\n",
            "# TEST : Loss: (0.3482) | Acc: (91.56%) (9156/10000)\n",
            "Epoch: 106 | Batch_idx: 0 |  Loss: (0.0091) | Acc: (100.00%) (128/128)\n",
            "Epoch: 106 | Batch_idx: 10 |  Loss: (0.0423) | Acc: (98.72%) (1390/1408)\n",
            "Epoch: 106 | Batch_idx: 20 |  Loss: (0.0390) | Acc: (98.81%) (2656/2688)\n",
            "Epoch: 106 | Batch_idx: 30 |  Loss: (0.0385) | Acc: (98.84%) (3922/3968)\n",
            "Epoch: 106 | Batch_idx: 40 |  Loss: (0.0372) | Acc: (98.89%) (5190/5248)\n",
            "Epoch: 106 | Batch_idx: 50 |  Loss: (0.0350) | Acc: (98.93%) (6458/6528)\n",
            "Epoch: 106 | Batch_idx: 60 |  Loss: (0.0357) | Acc: (98.91%) (7723/7808)\n",
            "Epoch: 106 | Batch_idx: 70 |  Loss: (0.0367) | Acc: (98.92%) (8990/9088)\n",
            "Epoch: 106 | Batch_idx: 80 |  Loss: (0.0371) | Acc: (98.92%) (10256/10368)\n",
            "Epoch: 106 | Batch_idx: 90 |  Loss: (0.0367) | Acc: (98.94%) (11525/11648)\n",
            "Epoch: 106 | Batch_idx: 100 |  Loss: (0.0364) | Acc: (98.93%) (12790/12928)\n",
            "Epoch: 106 | Batch_idx: 110 |  Loss: (0.0370) | Acc: (98.89%) (14051/14208)\n",
            "Epoch: 106 | Batch_idx: 120 |  Loss: (0.0377) | Acc: (98.88%) (15315/15488)\n",
            "Epoch: 106 | Batch_idx: 130 |  Loss: (0.0386) | Acc: (98.84%) (16573/16768)\n",
            "Epoch: 106 | Batch_idx: 140 |  Loss: (0.0389) | Acc: (98.82%) (17835/18048)\n",
            "Epoch: 106 | Batch_idx: 150 |  Loss: (0.0387) | Acc: (98.83%) (19102/19328)\n",
            "Epoch: 106 | Batch_idx: 160 |  Loss: (0.0389) | Acc: (98.83%) (20366/20608)\n",
            "Epoch: 106 | Batch_idx: 170 |  Loss: (0.0384) | Acc: (98.84%) (21634/21888)\n",
            "Epoch: 106 | Batch_idx: 180 |  Loss: (0.0388) | Acc: (98.81%) (22893/23168)\n",
            "Epoch: 106 | Batch_idx: 190 |  Loss: (0.0390) | Acc: (98.80%) (24154/24448)\n",
            "Epoch: 106 | Batch_idx: 200 |  Loss: (0.0391) | Acc: (98.79%) (25417/25728)\n",
            "Epoch: 106 | Batch_idx: 210 |  Loss: (0.0389) | Acc: (98.80%) (26684/27008)\n",
            "Epoch: 106 | Batch_idx: 220 |  Loss: (0.0387) | Acc: (98.82%) (27953/28288)\n",
            "Epoch: 106 | Batch_idx: 230 |  Loss: (0.0386) | Acc: (98.82%) (29219/29568)\n",
            "Epoch: 106 | Batch_idx: 240 |  Loss: (0.0386) | Acc: (98.80%) (30478/30848)\n",
            "Epoch: 106 | Batch_idx: 250 |  Loss: (0.0386) | Acc: (98.80%) (31742/32128)\n",
            "Epoch: 106 | Batch_idx: 260 |  Loss: (0.0386) | Acc: (98.78%) (33000/33408)\n",
            "Epoch: 106 | Batch_idx: 270 |  Loss: (0.0390) | Acc: (98.76%) (34257/34688)\n",
            "Epoch: 106 | Batch_idx: 280 |  Loss: (0.0391) | Acc: (98.75%) (35520/35968)\n",
            "Epoch: 106 | Batch_idx: 290 |  Loss: (0.0391) | Acc: (98.75%) (36783/37248)\n",
            "Epoch: 106 | Batch_idx: 300 |  Loss: (0.0394) | Acc: (98.73%) (38040/38528)\n",
            "Epoch: 106 | Batch_idx: 310 |  Loss: (0.0394) | Acc: (98.73%) (39303/39808)\n",
            "Epoch: 106 | Batch_idx: 320 |  Loss: (0.0390) | Acc: (98.75%) (40574/41088)\n",
            "Epoch: 106 | Batch_idx: 330 |  Loss: (0.0390) | Acc: (98.74%) (41835/42368)\n",
            "Epoch: 106 | Batch_idx: 340 |  Loss: (0.0389) | Acc: (98.75%) (43101/43648)\n",
            "Epoch: 106 | Batch_idx: 350 |  Loss: (0.0389) | Acc: (98.75%) (44365/44928)\n",
            "Epoch: 106 | Batch_idx: 360 |  Loss: (0.0393) | Acc: (98.75%) (45630/46208)\n",
            "Epoch: 106 | Batch_idx: 370 |  Loss: (0.0391) | Acc: (98.75%) (46896/47488)\n",
            "Epoch: 106 | Batch_idx: 380 |  Loss: (0.0394) | Acc: (98.74%) (48152/48768)\n",
            "Epoch: 106 | Batch_idx: 390 |  Loss: (0.0394) | Acc: (98.74%) (49371/50000)\n",
            "# TEST : Loss: (0.3456) | Acc: (91.69%) (9169/10000)\n",
            "Epoch: 107 | Batch_idx: 0 |  Loss: (0.0442) | Acc: (99.22%) (127/128)\n",
            "Epoch: 107 | Batch_idx: 10 |  Loss: (0.0362) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 107 | Batch_idx: 20 |  Loss: (0.0363) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 107 | Batch_idx: 30 |  Loss: (0.0383) | Acc: (98.94%) (3926/3968)\n",
            "Epoch: 107 | Batch_idx: 40 |  Loss: (0.0374) | Acc: (98.89%) (5190/5248)\n",
            "Epoch: 107 | Batch_idx: 50 |  Loss: (0.0369) | Acc: (98.84%) (6452/6528)\n",
            "Epoch: 107 | Batch_idx: 60 |  Loss: (0.0362) | Acc: (98.86%) (7719/7808)\n",
            "Epoch: 107 | Batch_idx: 70 |  Loss: (0.0365) | Acc: (98.87%) (8985/9088)\n",
            "Epoch: 107 | Batch_idx: 80 |  Loss: (0.0365) | Acc: (98.81%) (10245/10368)\n",
            "Epoch: 107 | Batch_idx: 90 |  Loss: (0.0379) | Acc: (98.76%) (11503/11648)\n",
            "Epoch: 107 | Batch_idx: 100 |  Loss: (0.0383) | Acc: (98.72%) (12763/12928)\n",
            "Epoch: 107 | Batch_idx: 110 |  Loss: (0.0385) | Acc: (98.72%) (14026/14208)\n",
            "Epoch: 107 | Batch_idx: 120 |  Loss: (0.0391) | Acc: (98.69%) (15285/15488)\n",
            "Epoch: 107 | Batch_idx: 130 |  Loss: (0.0386) | Acc: (98.69%) (16549/16768)\n",
            "Epoch: 107 | Batch_idx: 140 |  Loss: (0.0392) | Acc: (98.68%) (17809/18048)\n",
            "Epoch: 107 | Batch_idx: 150 |  Loss: (0.0394) | Acc: (98.67%) (19070/19328)\n",
            "Epoch: 107 | Batch_idx: 160 |  Loss: (0.0391) | Acc: (98.68%) (20335/20608)\n",
            "Epoch: 107 | Batch_idx: 170 |  Loss: (0.0388) | Acc: (98.69%) (21602/21888)\n",
            "Epoch: 107 | Batch_idx: 180 |  Loss: (0.0396) | Acc: (98.66%) (22858/23168)\n",
            "Epoch: 107 | Batch_idx: 190 |  Loss: (0.0402) | Acc: (98.65%) (24117/24448)\n",
            "Epoch: 107 | Batch_idx: 200 |  Loss: (0.0407) | Acc: (98.64%) (25378/25728)\n",
            "Epoch: 107 | Batch_idx: 210 |  Loss: (0.0406) | Acc: (98.64%) (26641/27008)\n",
            "Epoch: 107 | Batch_idx: 220 |  Loss: (0.0408) | Acc: (98.64%) (27902/28288)\n",
            "Epoch: 107 | Batch_idx: 230 |  Loss: (0.0405) | Acc: (98.65%) (29169/29568)\n",
            "Epoch: 107 | Batch_idx: 240 |  Loss: (0.0406) | Acc: (98.65%) (30431/30848)\n",
            "Epoch: 107 | Batch_idx: 250 |  Loss: (0.0411) | Acc: (98.62%) (31684/32128)\n",
            "Epoch: 107 | Batch_idx: 260 |  Loss: (0.0414) | Acc: (98.62%) (32947/33408)\n",
            "Epoch: 107 | Batch_idx: 270 |  Loss: (0.0413) | Acc: (98.61%) (34207/34688)\n",
            "Epoch: 107 | Batch_idx: 280 |  Loss: (0.0414) | Acc: (98.60%) (35465/35968)\n",
            "Epoch: 107 | Batch_idx: 290 |  Loss: (0.0414) | Acc: (98.59%) (36724/37248)\n",
            "Epoch: 107 | Batch_idx: 300 |  Loss: (0.0413) | Acc: (98.59%) (37985/38528)\n",
            "Epoch: 107 | Batch_idx: 310 |  Loss: (0.0414) | Acc: (98.60%) (39249/39808)\n",
            "Epoch: 107 | Batch_idx: 320 |  Loss: (0.0416) | Acc: (98.59%) (40509/41088)\n",
            "Epoch: 107 | Batch_idx: 330 |  Loss: (0.0419) | Acc: (98.58%) (41766/42368)\n",
            "Epoch: 107 | Batch_idx: 340 |  Loss: (0.0424) | Acc: (98.56%) (43018/43648)\n",
            "Epoch: 107 | Batch_idx: 350 |  Loss: (0.0424) | Acc: (98.55%) (44276/44928)\n",
            "Epoch: 107 | Batch_idx: 360 |  Loss: (0.0425) | Acc: (98.54%) (45535/46208)\n",
            "Epoch: 107 | Batch_idx: 370 |  Loss: (0.0423) | Acc: (98.56%) (46802/47488)\n",
            "Epoch: 107 | Batch_idx: 380 |  Loss: (0.0420) | Acc: (98.56%) (48068/48768)\n",
            "Epoch: 107 | Batch_idx: 390 |  Loss: (0.0420) | Acc: (98.57%) (49287/50000)\n",
            "# TEST : Loss: (0.3424) | Acc: (91.66%) (9166/10000)\n",
            "Epoch: 108 | Batch_idx: 0 |  Loss: (0.0494) | Acc: (96.88%) (124/128)\n",
            "Epoch: 108 | Batch_idx: 10 |  Loss: (0.0441) | Acc: (98.15%) (1382/1408)\n",
            "Epoch: 108 | Batch_idx: 20 |  Loss: (0.0418) | Acc: (98.29%) (2642/2688)\n",
            "Epoch: 108 | Batch_idx: 30 |  Loss: (0.0390) | Acc: (98.54%) (3910/3968)\n",
            "Epoch: 108 | Batch_idx: 40 |  Loss: (0.0371) | Acc: (98.67%) (5178/5248)\n",
            "Epoch: 108 | Batch_idx: 50 |  Loss: (0.0358) | Acc: (98.73%) (6445/6528)\n",
            "Epoch: 108 | Batch_idx: 60 |  Loss: (0.0357) | Acc: (98.71%) (7707/7808)\n",
            "Epoch: 108 | Batch_idx: 70 |  Loss: (0.0392) | Acc: (98.59%) (8960/9088)\n",
            "Epoch: 108 | Batch_idx: 80 |  Loss: (0.0386) | Acc: (98.62%) (10225/10368)\n",
            "Epoch: 108 | Batch_idx: 90 |  Loss: (0.0391) | Acc: (98.63%) (11488/11648)\n",
            "Epoch: 108 | Batch_idx: 100 |  Loss: (0.0395) | Acc: (98.63%) (12751/12928)\n",
            "Epoch: 108 | Batch_idx: 110 |  Loss: (0.0389) | Acc: (98.66%) (14017/14208)\n",
            "Epoch: 108 | Batch_idx: 120 |  Loss: (0.0395) | Acc: (98.68%) (15283/15488)\n",
            "Epoch: 108 | Batch_idx: 130 |  Loss: (0.0404) | Acc: (98.63%) (16539/16768)\n",
            "Epoch: 108 | Batch_idx: 140 |  Loss: (0.0401) | Acc: (98.65%) (17804/18048)\n",
            "Epoch: 108 | Batch_idx: 150 |  Loss: (0.0395) | Acc: (98.67%) (19071/19328)\n",
            "Epoch: 108 | Batch_idx: 160 |  Loss: (0.0391) | Acc: (98.68%) (20336/20608)\n",
            "Epoch: 108 | Batch_idx: 170 |  Loss: (0.0395) | Acc: (98.65%) (21593/21888)\n",
            "Epoch: 108 | Batch_idx: 180 |  Loss: (0.0394) | Acc: (98.65%) (22855/23168)\n",
            "Epoch: 108 | Batch_idx: 190 |  Loss: (0.0393) | Acc: (98.66%) (24120/24448)\n",
            "Epoch: 108 | Batch_idx: 200 |  Loss: (0.0400) | Acc: (98.64%) (25378/25728)\n",
            "Epoch: 108 | Batch_idx: 210 |  Loss: (0.0400) | Acc: (98.64%) (26641/27008)\n",
            "Epoch: 108 | Batch_idx: 220 |  Loss: (0.0401) | Acc: (98.62%) (27899/28288)\n",
            "Epoch: 108 | Batch_idx: 230 |  Loss: (0.0402) | Acc: (98.62%) (29160/29568)\n",
            "Epoch: 108 | Batch_idx: 240 |  Loss: (0.0401) | Acc: (98.64%) (30427/30848)\n",
            "Epoch: 108 | Batch_idx: 250 |  Loss: (0.0401) | Acc: (98.65%) (31693/32128)\n",
            "Epoch: 108 | Batch_idx: 260 |  Loss: (0.0401) | Acc: (98.66%) (32961/33408)\n",
            "Epoch: 108 | Batch_idx: 270 |  Loss: (0.0401) | Acc: (98.66%) (34223/34688)\n",
            "Epoch: 108 | Batch_idx: 280 |  Loss: (0.0401) | Acc: (98.65%) (35484/35968)\n",
            "Epoch: 108 | Batch_idx: 290 |  Loss: (0.0398) | Acc: (98.66%) (36749/37248)\n",
            "Epoch: 108 | Batch_idx: 300 |  Loss: (0.0397) | Acc: (98.67%) (38014/38528)\n",
            "Epoch: 108 | Batch_idx: 310 |  Loss: (0.0394) | Acc: (98.68%) (39281/39808)\n",
            "Epoch: 108 | Batch_idx: 320 |  Loss: (0.0396) | Acc: (98.68%) (40547/41088)\n",
            "Epoch: 108 | Batch_idx: 330 |  Loss: (0.0398) | Acc: (98.68%) (41807/42368)\n",
            "Epoch: 108 | Batch_idx: 340 |  Loss: (0.0402) | Acc: (98.66%) (43062/43648)\n",
            "Epoch: 108 | Batch_idx: 350 |  Loss: (0.0399) | Acc: (98.67%) (44331/44928)\n",
            "Epoch: 108 | Batch_idx: 360 |  Loss: (0.0398) | Acc: (98.67%) (45594/46208)\n",
            "Epoch: 108 | Batch_idx: 370 |  Loss: (0.0402) | Acc: (98.66%) (46850/47488)\n",
            "Epoch: 108 | Batch_idx: 380 |  Loss: (0.0403) | Acc: (98.65%) (48112/48768)\n",
            "Epoch: 108 | Batch_idx: 390 |  Loss: (0.0402) | Acc: (98.66%) (49329/50000)\n",
            "# TEST : Loss: (0.3497) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 109 | Batch_idx: 0 |  Loss: (0.0344) | Acc: (98.44%) (126/128)\n",
            "Epoch: 109 | Batch_idx: 10 |  Loss: (0.0389) | Acc: (98.72%) (1390/1408)\n",
            "Epoch: 109 | Batch_idx: 20 |  Loss: (0.0411) | Acc: (98.70%) (2653/2688)\n",
            "Epoch: 109 | Batch_idx: 30 |  Loss: (0.0391) | Acc: (98.77%) (3919/3968)\n",
            "Epoch: 109 | Batch_idx: 40 |  Loss: (0.0410) | Acc: (98.74%) (5182/5248)\n",
            "Epoch: 109 | Batch_idx: 50 |  Loss: (0.0381) | Acc: (98.85%) (6453/6528)\n",
            "Epoch: 109 | Batch_idx: 60 |  Loss: (0.0379) | Acc: (98.81%) (7715/7808)\n",
            "Epoch: 109 | Batch_idx: 70 |  Loss: (0.0383) | Acc: (98.80%) (8979/9088)\n",
            "Epoch: 109 | Batch_idx: 80 |  Loss: (0.0389) | Acc: (98.75%) (10238/10368)\n",
            "Epoch: 109 | Batch_idx: 90 |  Loss: (0.0386) | Acc: (98.74%) (11501/11648)\n",
            "Epoch: 109 | Batch_idx: 100 |  Loss: (0.0384) | Acc: (98.78%) (12770/12928)\n",
            "Epoch: 109 | Batch_idx: 110 |  Loss: (0.0378) | Acc: (98.80%) (14038/14208)\n",
            "Epoch: 109 | Batch_idx: 120 |  Loss: (0.0383) | Acc: (98.78%) (15299/15488)\n",
            "Epoch: 109 | Batch_idx: 130 |  Loss: (0.0377) | Acc: (98.81%) (16568/16768)\n",
            "Epoch: 109 | Batch_idx: 140 |  Loss: (0.0382) | Acc: (98.76%) (17825/18048)\n",
            "Epoch: 109 | Batch_idx: 150 |  Loss: (0.0381) | Acc: (98.75%) (19087/19328)\n",
            "Epoch: 109 | Batch_idx: 160 |  Loss: (0.0381) | Acc: (98.77%) (20355/20608)\n",
            "Epoch: 109 | Batch_idx: 170 |  Loss: (0.0384) | Acc: (98.77%) (21619/21888)\n",
            "Epoch: 109 | Batch_idx: 180 |  Loss: (0.0387) | Acc: (98.76%) (22880/23168)\n",
            "Epoch: 109 | Batch_idx: 190 |  Loss: (0.0388) | Acc: (98.75%) (24143/24448)\n",
            "Epoch: 109 | Batch_idx: 200 |  Loss: (0.0390) | Acc: (98.76%) (25409/25728)\n",
            "Epoch: 109 | Batch_idx: 210 |  Loss: (0.0386) | Acc: (98.79%) (26680/27008)\n",
            "Epoch: 109 | Batch_idx: 220 |  Loss: (0.0385) | Acc: (98.79%) (27946/28288)\n",
            "Epoch: 109 | Batch_idx: 230 |  Loss: (0.0384) | Acc: (98.78%) (29207/29568)\n",
            "Epoch: 109 | Batch_idx: 240 |  Loss: (0.0389) | Acc: (98.76%) (30466/30848)\n",
            "Epoch: 109 | Batch_idx: 250 |  Loss: (0.0388) | Acc: (98.76%) (31730/32128)\n",
            "Epoch: 109 | Batch_idx: 260 |  Loss: (0.0386) | Acc: (98.76%) (32995/33408)\n",
            "Epoch: 109 | Batch_idx: 270 |  Loss: (0.0389) | Acc: (98.76%) (34257/34688)\n",
            "Epoch: 109 | Batch_idx: 280 |  Loss: (0.0391) | Acc: (98.75%) (35520/35968)\n",
            "Epoch: 109 | Batch_idx: 290 |  Loss: (0.0396) | Acc: (98.73%) (36774/37248)\n",
            "Epoch: 109 | Batch_idx: 300 |  Loss: (0.0392) | Acc: (98.74%) (38041/38528)\n",
            "Epoch: 109 | Batch_idx: 310 |  Loss: (0.0394) | Acc: (98.72%) (39299/39808)\n",
            "Epoch: 109 | Batch_idx: 320 |  Loss: (0.0394) | Acc: (98.72%) (40563/41088)\n",
            "Epoch: 109 | Batch_idx: 330 |  Loss: (0.0393) | Acc: (98.73%) (41829/42368)\n",
            "Epoch: 109 | Batch_idx: 340 |  Loss: (0.0391) | Acc: (98.74%) (43096/43648)\n",
            "Epoch: 109 | Batch_idx: 350 |  Loss: (0.0393) | Acc: (98.72%) (44355/44928)\n",
            "Epoch: 109 | Batch_idx: 360 |  Loss: (0.0393) | Acc: (98.72%) (45618/46208)\n",
            "Epoch: 109 | Batch_idx: 370 |  Loss: (0.0391) | Acc: (98.73%) (46883/47488)\n",
            "Epoch: 109 | Batch_idx: 380 |  Loss: (0.0394) | Acc: (98.72%) (48144/48768)\n",
            "Epoch: 109 | Batch_idx: 390 |  Loss: (0.0398) | Acc: (98.70%) (49351/50000)\n",
            "# TEST : Loss: (0.3475) | Acc: (91.53%) (9153/10000)\n",
            "Epoch: 110 | Batch_idx: 0 |  Loss: (0.0320) | Acc: (99.22%) (127/128)\n",
            "Epoch: 110 | Batch_idx: 10 |  Loss: (0.0406) | Acc: (98.72%) (1390/1408)\n",
            "Epoch: 110 | Batch_idx: 20 |  Loss: (0.0410) | Acc: (98.62%) (2651/2688)\n",
            "Epoch: 110 | Batch_idx: 30 |  Loss: (0.0385) | Acc: (98.77%) (3919/3968)\n",
            "Epoch: 110 | Batch_idx: 40 |  Loss: (0.0397) | Acc: (98.65%) (5177/5248)\n",
            "Epoch: 110 | Batch_idx: 50 |  Loss: (0.0397) | Acc: (98.67%) (6441/6528)\n",
            "Epoch: 110 | Batch_idx: 60 |  Loss: (0.0403) | Acc: (98.68%) (7705/7808)\n",
            "Epoch: 110 | Batch_idx: 70 |  Loss: (0.0399) | Acc: (98.68%) (8968/9088)\n",
            "Epoch: 110 | Batch_idx: 80 |  Loss: (0.0413) | Acc: (98.64%) (10227/10368)\n",
            "Epoch: 110 | Batch_idx: 90 |  Loss: (0.0405) | Acc: (98.68%) (11494/11648)\n",
            "Epoch: 110 | Batch_idx: 100 |  Loss: (0.0409) | Acc: (98.65%) (12753/12928)\n",
            "Epoch: 110 | Batch_idx: 110 |  Loss: (0.0420) | Acc: (98.61%) (14010/14208)\n",
            "Epoch: 110 | Batch_idx: 120 |  Loss: (0.0409) | Acc: (98.64%) (15278/15488)\n",
            "Epoch: 110 | Batch_idx: 130 |  Loss: (0.0404) | Acc: (98.66%) (16544/16768)\n",
            "Epoch: 110 | Batch_idx: 140 |  Loss: (0.0397) | Acc: (98.69%) (17812/18048)\n",
            "Epoch: 110 | Batch_idx: 150 |  Loss: (0.0395) | Acc: (98.70%) (19076/19328)\n",
            "Epoch: 110 | Batch_idx: 160 |  Loss: (0.0394) | Acc: (98.71%) (20342/20608)\n",
            "Epoch: 110 | Batch_idx: 170 |  Loss: (0.0390) | Acc: (98.72%) (21608/21888)\n",
            "Epoch: 110 | Batch_idx: 180 |  Loss: (0.0389) | Acc: (98.71%) (22869/23168)\n",
            "Epoch: 110 | Batch_idx: 190 |  Loss: (0.0389) | Acc: (98.71%) (24133/24448)\n",
            "Epoch: 110 | Batch_idx: 200 |  Loss: (0.0389) | Acc: (98.70%) (25393/25728)\n",
            "Epoch: 110 | Batch_idx: 210 |  Loss: (0.0385) | Acc: (98.71%) (26660/27008)\n",
            "Epoch: 110 | Batch_idx: 220 |  Loss: (0.0391) | Acc: (98.68%) (27914/28288)\n",
            "Epoch: 110 | Batch_idx: 230 |  Loss: (0.0392) | Acc: (98.66%) (29173/29568)\n",
            "Epoch: 110 | Batch_idx: 240 |  Loss: (0.0394) | Acc: (98.65%) (30432/30848)\n",
            "Epoch: 110 | Batch_idx: 250 |  Loss: (0.0394) | Acc: (98.66%) (31696/32128)\n",
            "Epoch: 110 | Batch_idx: 260 |  Loss: (0.0395) | Acc: (98.66%) (32959/33408)\n",
            "Epoch: 110 | Batch_idx: 270 |  Loss: (0.0400) | Acc: (98.65%) (34219/34688)\n",
            "Epoch: 110 | Batch_idx: 280 |  Loss: (0.0398) | Acc: (98.66%) (35485/35968)\n",
            "Epoch: 110 | Batch_idx: 290 |  Loss: (0.0399) | Acc: (98.65%) (36747/37248)\n",
            "Epoch: 110 | Batch_idx: 300 |  Loss: (0.0396) | Acc: (98.67%) (38017/38528)\n",
            "Epoch: 110 | Batch_idx: 310 |  Loss: (0.0397) | Acc: (98.68%) (39281/39808)\n",
            "Epoch: 110 | Batch_idx: 320 |  Loss: (0.0395) | Acc: (98.68%) (40546/41088)\n",
            "Epoch: 110 | Batch_idx: 330 |  Loss: (0.0392) | Acc: (98.69%) (41814/42368)\n",
            "Epoch: 110 | Batch_idx: 340 |  Loss: (0.0395) | Acc: (98.68%) (43072/43648)\n",
            "Epoch: 110 | Batch_idx: 350 |  Loss: (0.0394) | Acc: (98.68%) (44333/44928)\n",
            "Epoch: 110 | Batch_idx: 360 |  Loss: (0.0393) | Acc: (98.67%) (45595/46208)\n",
            "Epoch: 110 | Batch_idx: 370 |  Loss: (0.0392) | Acc: (98.67%) (46858/47488)\n",
            "Epoch: 110 | Batch_idx: 380 |  Loss: (0.0394) | Acc: (98.67%) (48118/48768)\n",
            "Epoch: 110 | Batch_idx: 390 |  Loss: (0.0391) | Acc: (98.68%) (49339/50000)\n",
            "# TEST : Loss: (0.3466) | Acc: (91.57%) (9157/10000)\n",
            "Epoch: 111 | Batch_idx: 0 |  Loss: (0.0480) | Acc: (97.66%) (125/128)\n",
            "Epoch: 111 | Batch_idx: 10 |  Loss: (0.0435) | Acc: (98.37%) (1385/1408)\n",
            "Epoch: 111 | Batch_idx: 20 |  Loss: (0.0368) | Acc: (98.62%) (2651/2688)\n",
            "Epoch: 111 | Batch_idx: 30 |  Loss: (0.0367) | Acc: (98.59%) (3912/3968)\n",
            "Epoch: 111 | Batch_idx: 40 |  Loss: (0.0388) | Acc: (98.59%) (5174/5248)\n",
            "Epoch: 111 | Batch_idx: 50 |  Loss: (0.0374) | Acc: (98.65%) (6440/6528)\n",
            "Epoch: 111 | Batch_idx: 60 |  Loss: (0.0348) | Acc: (98.80%) (7714/7808)\n",
            "Epoch: 111 | Batch_idx: 70 |  Loss: (0.0367) | Acc: (98.79%) (8978/9088)\n",
            "Epoch: 111 | Batch_idx: 80 |  Loss: (0.0372) | Acc: (98.78%) (10241/10368)\n",
            "Epoch: 111 | Batch_idx: 90 |  Loss: (0.0366) | Acc: (98.76%) (11503/11648)\n",
            "Epoch: 111 | Batch_idx: 100 |  Loss: (0.0377) | Acc: (98.75%) (12766/12928)\n",
            "Epoch: 111 | Batch_idx: 110 |  Loss: (0.0378) | Acc: (98.73%) (14028/14208)\n",
            "Epoch: 111 | Batch_idx: 120 |  Loss: (0.0376) | Acc: (98.74%) (15293/15488)\n",
            "Epoch: 111 | Batch_idx: 130 |  Loss: (0.0383) | Acc: (98.74%) (16557/16768)\n",
            "Epoch: 111 | Batch_idx: 140 |  Loss: (0.0376) | Acc: (98.76%) (17824/18048)\n",
            "Epoch: 111 | Batch_idx: 150 |  Loss: (0.0377) | Acc: (98.74%) (19084/19328)\n",
            "Epoch: 111 | Batch_idx: 160 |  Loss: (0.0376) | Acc: (98.76%) (20352/20608)\n",
            "Epoch: 111 | Batch_idx: 170 |  Loss: (0.0371) | Acc: (98.78%) (21621/21888)\n",
            "Epoch: 111 | Batch_idx: 180 |  Loss: (0.0374) | Acc: (98.78%) (22885/23168)\n",
            "Epoch: 111 | Batch_idx: 190 |  Loss: (0.0374) | Acc: (98.77%) (24147/24448)\n",
            "Epoch: 111 | Batch_idx: 200 |  Loss: (0.0374) | Acc: (98.77%) (25411/25728)\n",
            "Epoch: 111 | Batch_idx: 210 |  Loss: (0.0374) | Acc: (98.76%) (26674/27008)\n",
            "Epoch: 111 | Batch_idx: 220 |  Loss: (0.0374) | Acc: (98.76%) (27938/28288)\n",
            "Epoch: 111 | Batch_idx: 230 |  Loss: (0.0375) | Acc: (98.75%) (29199/29568)\n",
            "Epoch: 111 | Batch_idx: 240 |  Loss: (0.0374) | Acc: (98.76%) (30466/30848)\n",
            "Epoch: 111 | Batch_idx: 250 |  Loss: (0.0373) | Acc: (98.77%) (31732/32128)\n",
            "Epoch: 111 | Batch_idx: 260 |  Loss: (0.0374) | Acc: (98.76%) (32995/33408)\n",
            "Epoch: 111 | Batch_idx: 270 |  Loss: (0.0375) | Acc: (98.76%) (34258/34688)\n",
            "Epoch: 111 | Batch_idx: 280 |  Loss: (0.0375) | Acc: (98.76%) (35523/35968)\n",
            "Epoch: 111 | Batch_idx: 290 |  Loss: (0.0379) | Acc: (98.75%) (36783/37248)\n",
            "Epoch: 111 | Batch_idx: 300 |  Loss: (0.0377) | Acc: (98.76%) (38049/38528)\n",
            "Epoch: 111 | Batch_idx: 310 |  Loss: (0.0374) | Acc: (98.77%) (39319/39808)\n",
            "Epoch: 111 | Batch_idx: 320 |  Loss: (0.0375) | Acc: (98.76%) (40579/41088)\n",
            "Epoch: 111 | Batch_idx: 330 |  Loss: (0.0378) | Acc: (98.74%) (41836/42368)\n",
            "Epoch: 111 | Batch_idx: 340 |  Loss: (0.0380) | Acc: (98.74%) (43097/43648)\n",
            "Epoch: 111 | Batch_idx: 350 |  Loss: (0.0381) | Acc: (98.74%) (44363/44928)\n",
            "Epoch: 111 | Batch_idx: 360 |  Loss: (0.0381) | Acc: (98.74%) (45628/46208)\n",
            "Epoch: 111 | Batch_idx: 370 |  Loss: (0.0381) | Acc: (98.74%) (46890/47488)\n",
            "Epoch: 111 | Batch_idx: 380 |  Loss: (0.0383) | Acc: (98.73%) (48150/48768)\n",
            "Epoch: 111 | Batch_idx: 390 |  Loss: (0.0386) | Acc: (98.73%) (49365/50000)\n",
            "# TEST : Loss: (0.3486) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 112 | Batch_idx: 0 |  Loss: (0.0327) | Acc: (99.22%) (127/128)\n",
            "Epoch: 112 | Batch_idx: 10 |  Loss: (0.0323) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 112 | Batch_idx: 20 |  Loss: (0.0344) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 112 | Batch_idx: 30 |  Loss: (0.0357) | Acc: (98.92%) (3925/3968)\n",
            "Epoch: 112 | Batch_idx: 40 |  Loss: (0.0349) | Acc: (98.91%) (5191/5248)\n",
            "Epoch: 112 | Batch_idx: 50 |  Loss: (0.0379) | Acc: (98.76%) (6447/6528)\n",
            "Epoch: 112 | Batch_idx: 60 |  Loss: (0.0368) | Acc: (98.85%) (7718/7808)\n",
            "Epoch: 112 | Batch_idx: 70 |  Loss: (0.0369) | Acc: (98.82%) (8981/9088)\n",
            "Epoch: 112 | Batch_idx: 80 |  Loss: (0.0365) | Acc: (98.85%) (10249/10368)\n",
            "Epoch: 112 | Batch_idx: 90 |  Loss: (0.0366) | Acc: (98.85%) (11514/11648)\n",
            "Epoch: 112 | Batch_idx: 100 |  Loss: (0.0363) | Acc: (98.86%) (12780/12928)\n",
            "Epoch: 112 | Batch_idx: 110 |  Loss: (0.0363) | Acc: (98.86%) (14046/14208)\n",
            "Epoch: 112 | Batch_idx: 120 |  Loss: (0.0357) | Acc: (98.90%) (15317/15488)\n",
            "Epoch: 112 | Batch_idx: 130 |  Loss: (0.0362) | Acc: (98.87%) (16578/16768)\n",
            "Epoch: 112 | Batch_idx: 140 |  Loss: (0.0367) | Acc: (98.84%) (17838/18048)\n",
            "Epoch: 112 | Batch_idx: 150 |  Loss: (0.0369) | Acc: (98.82%) (19099/19328)\n",
            "Epoch: 112 | Batch_idx: 160 |  Loss: (0.0372) | Acc: (98.81%) (20363/20608)\n",
            "Epoch: 112 | Batch_idx: 170 |  Loss: (0.0374) | Acc: (98.80%) (21626/21888)\n",
            "Epoch: 112 | Batch_idx: 180 |  Loss: (0.0372) | Acc: (98.82%) (22895/23168)\n",
            "Epoch: 112 | Batch_idx: 190 |  Loss: (0.0373) | Acc: (98.81%) (24157/24448)\n",
            "Epoch: 112 | Batch_idx: 200 |  Loss: (0.0372) | Acc: (98.82%) (25424/25728)\n",
            "Epoch: 112 | Batch_idx: 210 |  Loss: (0.0373) | Acc: (98.80%) (26685/27008)\n",
            "Epoch: 112 | Batch_idx: 220 |  Loss: (0.0383) | Acc: (98.77%) (27940/28288)\n",
            "Epoch: 112 | Batch_idx: 230 |  Loss: (0.0378) | Acc: (98.79%) (29211/29568)\n",
            "Epoch: 112 | Batch_idx: 240 |  Loss: (0.0379) | Acc: (98.79%) (30476/30848)\n",
            "Epoch: 112 | Batch_idx: 250 |  Loss: (0.0378) | Acc: (98.79%) (31738/32128)\n",
            "Epoch: 112 | Batch_idx: 260 |  Loss: (0.0377) | Acc: (98.79%) (33004/33408)\n",
            "Epoch: 112 | Batch_idx: 270 |  Loss: (0.0377) | Acc: (98.79%) (34268/34688)\n",
            "Epoch: 112 | Batch_idx: 280 |  Loss: (0.0378) | Acc: (98.79%) (35531/35968)\n",
            "Epoch: 112 | Batch_idx: 290 |  Loss: (0.0376) | Acc: (98.79%) (36797/37248)\n",
            "Epoch: 112 | Batch_idx: 300 |  Loss: (0.0376) | Acc: (98.78%) (38059/38528)\n",
            "Epoch: 112 | Batch_idx: 310 |  Loss: (0.0377) | Acc: (98.78%) (39321/39808)\n",
            "Epoch: 112 | Batch_idx: 320 |  Loss: (0.0377) | Acc: (98.78%) (40586/41088)\n",
            "Epoch: 112 | Batch_idx: 330 |  Loss: (0.0377) | Acc: (98.77%) (41847/42368)\n",
            "Epoch: 112 | Batch_idx: 340 |  Loss: (0.0375) | Acc: (98.78%) (43116/43648)\n",
            "Epoch: 112 | Batch_idx: 350 |  Loss: (0.0376) | Acc: (98.78%) (44381/44928)\n",
            "Epoch: 112 | Batch_idx: 360 |  Loss: (0.0379) | Acc: (98.76%) (45637/46208)\n",
            "Epoch: 112 | Batch_idx: 370 |  Loss: (0.0383) | Acc: (98.75%) (46896/47488)\n",
            "Epoch: 112 | Batch_idx: 380 |  Loss: (0.0381) | Acc: (98.76%) (48162/48768)\n",
            "Epoch: 112 | Batch_idx: 390 |  Loss: (0.0381) | Acc: (98.76%) (49379/50000)\n",
            "# TEST : Loss: (0.3556) | Acc: (91.32%) (9132/10000)\n",
            "Epoch: 113 | Batch_idx: 0 |  Loss: (0.0399) | Acc: (98.44%) (126/128)\n",
            "Epoch: 113 | Batch_idx: 10 |  Loss: (0.0354) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 113 | Batch_idx: 20 |  Loss: (0.0341) | Acc: (98.85%) (2657/2688)\n",
            "Epoch: 113 | Batch_idx: 30 |  Loss: (0.0367) | Acc: (98.79%) (3920/3968)\n",
            "Epoch: 113 | Batch_idx: 40 |  Loss: (0.0337) | Acc: (98.93%) (5192/5248)\n",
            "Epoch: 113 | Batch_idx: 50 |  Loss: (0.0343) | Acc: (98.91%) (6457/6528)\n",
            "Epoch: 113 | Batch_idx: 60 |  Loss: (0.0352) | Acc: (98.89%) (7721/7808)\n",
            "Epoch: 113 | Batch_idx: 70 |  Loss: (0.0356) | Acc: (98.83%) (8982/9088)\n",
            "Epoch: 113 | Batch_idx: 80 |  Loss: (0.0347) | Acc: (98.86%) (10250/10368)\n",
            "Epoch: 113 | Batch_idx: 90 |  Loss: (0.0341) | Acc: (98.86%) (11515/11648)\n",
            "Epoch: 113 | Batch_idx: 100 |  Loss: (0.0339) | Acc: (98.89%) (12784/12928)\n",
            "Epoch: 113 | Batch_idx: 110 |  Loss: (0.0350) | Acc: (98.82%) (14041/14208)\n",
            "Epoch: 113 | Batch_idx: 120 |  Loss: (0.0355) | Acc: (98.81%) (15303/15488)\n",
            "Epoch: 113 | Batch_idx: 130 |  Loss: (0.0354) | Acc: (98.80%) (16567/16768)\n",
            "Epoch: 113 | Batch_idx: 140 |  Loss: (0.0354) | Acc: (98.83%) (17837/18048)\n",
            "Epoch: 113 | Batch_idx: 150 |  Loss: (0.0350) | Acc: (98.85%) (19105/19328)\n",
            "Epoch: 113 | Batch_idx: 160 |  Loss: (0.0356) | Acc: (98.81%) (20362/20608)\n",
            "Epoch: 113 | Batch_idx: 170 |  Loss: (0.0360) | Acc: (98.80%) (21626/21888)\n",
            "Epoch: 113 | Batch_idx: 180 |  Loss: (0.0360) | Acc: (98.79%) (22888/23168)\n",
            "Epoch: 113 | Batch_idx: 190 |  Loss: (0.0356) | Acc: (98.80%) (24155/24448)\n",
            "Epoch: 113 | Batch_idx: 200 |  Loss: (0.0352) | Acc: (98.81%) (25423/25728)\n",
            "Epoch: 113 | Batch_idx: 210 |  Loss: (0.0352) | Acc: (98.82%) (26688/27008)\n",
            "Epoch: 113 | Batch_idx: 220 |  Loss: (0.0351) | Acc: (98.83%) (27957/28288)\n",
            "Epoch: 113 | Batch_idx: 230 |  Loss: (0.0354) | Acc: (98.83%) (29223/29568)\n",
            "Epoch: 113 | Batch_idx: 240 |  Loss: (0.0357) | Acc: (98.82%) (30484/30848)\n",
            "Epoch: 113 | Batch_idx: 250 |  Loss: (0.0361) | Acc: (98.80%) (31741/32128)\n",
            "Epoch: 113 | Batch_idx: 260 |  Loss: (0.0361) | Acc: (98.81%) (33009/33408)\n",
            "Epoch: 113 | Batch_idx: 270 |  Loss: (0.0359) | Acc: (98.81%) (34276/34688)\n",
            "Epoch: 113 | Batch_idx: 280 |  Loss: (0.0357) | Acc: (98.82%) (35542/35968)\n",
            "Epoch: 113 | Batch_idx: 290 |  Loss: (0.0358) | Acc: (98.80%) (36802/37248)\n",
            "Epoch: 113 | Batch_idx: 300 |  Loss: (0.0359) | Acc: (98.80%) (38064/38528)\n",
            "Epoch: 113 | Batch_idx: 310 |  Loss: (0.0361) | Acc: (98.77%) (39317/39808)\n",
            "Epoch: 113 | Batch_idx: 320 |  Loss: (0.0363) | Acc: (98.75%) (40576/41088)\n",
            "Epoch: 113 | Batch_idx: 330 |  Loss: (0.0363) | Acc: (98.76%) (41841/42368)\n",
            "Epoch: 113 | Batch_idx: 340 |  Loss: (0.0360) | Acc: (98.77%) (43111/43648)\n",
            "Epoch: 113 | Batch_idx: 350 |  Loss: (0.0367) | Acc: (98.74%) (44360/44928)\n",
            "Epoch: 113 | Batch_idx: 360 |  Loss: (0.0368) | Acc: (98.73%) (45619/46208)\n",
            "Epoch: 113 | Batch_idx: 370 |  Loss: (0.0367) | Acc: (98.74%) (46888/47488)\n",
            "Epoch: 113 | Batch_idx: 380 |  Loss: (0.0368) | Acc: (98.73%) (48151/48768)\n",
            "Epoch: 113 | Batch_idx: 390 |  Loss: (0.0368) | Acc: (98.75%) (49374/50000)\n",
            "# TEST : Loss: (0.3573) | Acc: (91.59%) (9159/10000)\n",
            "Epoch: 114 | Batch_idx: 0 |  Loss: (0.0286) | Acc: (100.00%) (128/128)\n",
            "Epoch: 114 | Batch_idx: 10 |  Loss: (0.0338) | Acc: (98.79%) (1391/1408)\n",
            "Epoch: 114 | Batch_idx: 20 |  Loss: (0.0328) | Acc: (98.92%) (2659/2688)\n",
            "Epoch: 114 | Batch_idx: 30 |  Loss: (0.0343) | Acc: (98.97%) (3927/3968)\n",
            "Epoch: 114 | Batch_idx: 40 |  Loss: (0.0335) | Acc: (99.03%) (5197/5248)\n",
            "Epoch: 114 | Batch_idx: 50 |  Loss: (0.0339) | Acc: (98.90%) (6456/6528)\n",
            "Epoch: 114 | Batch_idx: 60 |  Loss: (0.0348) | Acc: (98.85%) (7718/7808)\n",
            "Epoch: 114 | Batch_idx: 70 |  Loss: (0.0347) | Acc: (98.87%) (8985/9088)\n",
            "Epoch: 114 | Batch_idx: 80 |  Loss: (0.0352) | Acc: (98.85%) (10249/10368)\n",
            "Epoch: 114 | Batch_idx: 90 |  Loss: (0.0356) | Acc: (98.82%) (11511/11648)\n",
            "Epoch: 114 | Batch_idx: 100 |  Loss: (0.0350) | Acc: (98.85%) (12779/12928)\n",
            "Epoch: 114 | Batch_idx: 110 |  Loss: (0.0345) | Acc: (98.86%) (14046/14208)\n",
            "Epoch: 114 | Batch_idx: 120 |  Loss: (0.0347) | Acc: (98.84%) (15309/15488)\n",
            "Epoch: 114 | Batch_idx: 130 |  Loss: (0.0347) | Acc: (98.85%) (16576/16768)\n",
            "Epoch: 114 | Batch_idx: 140 |  Loss: (0.0350) | Acc: (98.85%) (17840/18048)\n",
            "Epoch: 114 | Batch_idx: 150 |  Loss: (0.0353) | Acc: (98.84%) (19103/19328)\n",
            "Epoch: 114 | Batch_idx: 160 |  Loss: (0.0350) | Acc: (98.85%) (20370/20608)\n",
            "Epoch: 114 | Batch_idx: 170 |  Loss: (0.0348) | Acc: (98.84%) (21634/21888)\n",
            "Epoch: 114 | Batch_idx: 180 |  Loss: (0.0353) | Acc: (98.82%) (22895/23168)\n",
            "Epoch: 114 | Batch_idx: 190 |  Loss: (0.0352) | Acc: (98.82%) (24159/24448)\n",
            "Epoch: 114 | Batch_idx: 200 |  Loss: (0.0354) | Acc: (98.81%) (25421/25728)\n",
            "Epoch: 114 | Batch_idx: 210 |  Loss: (0.0354) | Acc: (98.79%) (26682/27008)\n",
            "Epoch: 114 | Batch_idx: 220 |  Loss: (0.0358) | Acc: (98.77%) (27939/28288)\n",
            "Epoch: 114 | Batch_idx: 230 |  Loss: (0.0360) | Acc: (98.77%) (29203/29568)\n",
            "Epoch: 114 | Batch_idx: 240 |  Loss: (0.0360) | Acc: (98.76%) (30467/30848)\n",
            "Epoch: 114 | Batch_idx: 250 |  Loss: (0.0363) | Acc: (98.75%) (31728/32128)\n",
            "Epoch: 114 | Batch_idx: 260 |  Loss: (0.0363) | Acc: (98.75%) (32991/33408)\n",
            "Epoch: 114 | Batch_idx: 270 |  Loss: (0.0363) | Acc: (98.75%) (34256/34688)\n",
            "Epoch: 114 | Batch_idx: 280 |  Loss: (0.0361) | Acc: (98.76%) (35521/35968)\n",
            "Epoch: 114 | Batch_idx: 290 |  Loss: (0.0362) | Acc: (98.76%) (36785/37248)\n",
            "Epoch: 114 | Batch_idx: 300 |  Loss: (0.0364) | Acc: (98.75%) (38045/38528)\n",
            "Epoch: 114 | Batch_idx: 310 |  Loss: (0.0363) | Acc: (98.75%) (39311/39808)\n",
            "Epoch: 114 | Batch_idx: 320 |  Loss: (0.0367) | Acc: (98.73%) (40566/41088)\n",
            "Epoch: 114 | Batch_idx: 330 |  Loss: (0.0365) | Acc: (98.74%) (41834/42368)\n",
            "Epoch: 114 | Batch_idx: 340 |  Loss: (0.0366) | Acc: (98.74%) (43096/43648)\n",
            "Epoch: 114 | Batch_idx: 350 |  Loss: (0.0366) | Acc: (98.73%) (44356/44928)\n",
            "Epoch: 114 | Batch_idx: 360 |  Loss: (0.0366) | Acc: (98.73%) (45621/46208)\n",
            "Epoch: 114 | Batch_idx: 370 |  Loss: (0.0367) | Acc: (98.72%) (46882/47488)\n",
            "Epoch: 114 | Batch_idx: 380 |  Loss: (0.0365) | Acc: (98.74%) (48154/48768)\n",
            "Epoch: 114 | Batch_idx: 390 |  Loss: (0.0365) | Acc: (98.74%) (49370/50000)\n",
            "# TEST : Loss: (0.3551) | Acc: (91.57%) (9157/10000)\n",
            "Epoch: 115 | Batch_idx: 0 |  Loss: (0.0587) | Acc: (97.66%) (125/128)\n",
            "Epoch: 115 | Batch_idx: 10 |  Loss: (0.0245) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 115 | Batch_idx: 20 |  Loss: (0.0285) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 115 | Batch_idx: 30 |  Loss: (0.0291) | Acc: (99.04%) (3930/3968)\n",
            "Epoch: 115 | Batch_idx: 40 |  Loss: (0.0303) | Acc: (98.97%) (5194/5248)\n",
            "Epoch: 115 | Batch_idx: 50 |  Loss: (0.0322) | Acc: (98.91%) (6457/6528)\n",
            "Epoch: 115 | Batch_idx: 60 |  Loss: (0.0325) | Acc: (98.91%) (7723/7808)\n",
            "Epoch: 115 | Batch_idx: 70 |  Loss: (0.0313) | Acc: (98.93%) (8991/9088)\n",
            "Epoch: 115 | Batch_idx: 80 |  Loss: (0.0321) | Acc: (98.87%) (10251/10368)\n",
            "Epoch: 115 | Batch_idx: 90 |  Loss: (0.0337) | Acc: (98.83%) (11512/11648)\n",
            "Epoch: 115 | Batch_idx: 100 |  Loss: (0.0340) | Acc: (98.81%) (12774/12928)\n",
            "Epoch: 115 | Batch_idx: 110 |  Loss: (0.0338) | Acc: (98.82%) (14041/14208)\n",
            "Epoch: 115 | Batch_idx: 120 |  Loss: (0.0348) | Acc: (98.79%) (15301/15488)\n",
            "Epoch: 115 | Batch_idx: 130 |  Loss: (0.0349) | Acc: (98.80%) (16567/16768)\n",
            "Epoch: 115 | Batch_idx: 140 |  Loss: (0.0348) | Acc: (98.84%) (17838/18048)\n",
            "Epoch: 115 | Batch_idx: 150 |  Loss: (0.0356) | Acc: (98.81%) (19098/19328)\n",
            "Epoch: 115 | Batch_idx: 160 |  Loss: (0.0366) | Acc: (98.77%) (20354/20608)\n",
            "Epoch: 115 | Batch_idx: 170 |  Loss: (0.0373) | Acc: (98.75%) (21615/21888)\n",
            "Epoch: 115 | Batch_idx: 180 |  Loss: (0.0373) | Acc: (98.76%) (22880/23168)\n",
            "Epoch: 115 | Batch_idx: 190 |  Loss: (0.0372) | Acc: (98.76%) (24145/24448)\n",
            "Epoch: 115 | Batch_idx: 200 |  Loss: (0.0369) | Acc: (98.77%) (25411/25728)\n",
            "Epoch: 115 | Batch_idx: 210 |  Loss: (0.0368) | Acc: (98.78%) (26678/27008)\n",
            "Epoch: 115 | Batch_idx: 220 |  Loss: (0.0372) | Acc: (98.76%) (27937/28288)\n",
            "Epoch: 115 | Batch_idx: 230 |  Loss: (0.0373) | Acc: (98.76%) (29200/29568)\n",
            "Epoch: 115 | Batch_idx: 240 |  Loss: (0.0375) | Acc: (98.76%) (30466/30848)\n",
            "Epoch: 115 | Batch_idx: 250 |  Loss: (0.0373) | Acc: (98.76%) (31731/32128)\n",
            "Epoch: 115 | Batch_idx: 260 |  Loss: (0.0371) | Acc: (98.77%) (32998/33408)\n",
            "Epoch: 115 | Batch_idx: 270 |  Loss: (0.0373) | Acc: (98.76%) (34258/34688)\n",
            "Epoch: 115 | Batch_idx: 280 |  Loss: (0.0375) | Acc: (98.75%) (35520/35968)\n",
            "Epoch: 115 | Batch_idx: 290 |  Loss: (0.0373) | Acc: (98.76%) (36787/37248)\n",
            "Epoch: 115 | Batch_idx: 300 |  Loss: (0.0371) | Acc: (98.77%) (38056/38528)\n",
            "Epoch: 115 | Batch_idx: 310 |  Loss: (0.0371) | Acc: (98.77%) (39318/39808)\n",
            "Epoch: 115 | Batch_idx: 320 |  Loss: (0.0372) | Acc: (98.77%) (40581/41088)\n",
            "Epoch: 115 | Batch_idx: 330 |  Loss: (0.0372) | Acc: (98.77%) (41847/42368)\n",
            "Epoch: 115 | Batch_idx: 340 |  Loss: (0.0373) | Acc: (98.78%) (43115/43648)\n",
            "Epoch: 115 | Batch_idx: 350 |  Loss: (0.0372) | Acc: (98.77%) (44376/44928)\n",
            "Epoch: 115 | Batch_idx: 360 |  Loss: (0.0371) | Acc: (98.77%) (45640/46208)\n",
            "Epoch: 115 | Batch_idx: 370 |  Loss: (0.0372) | Acc: (98.77%) (46905/47488)\n",
            "Epoch: 115 | Batch_idx: 380 |  Loss: (0.0371) | Acc: (98.78%) (48174/48768)\n",
            "Epoch: 115 | Batch_idx: 390 |  Loss: (0.0372) | Acc: (98.78%) (49389/50000)\n",
            "# TEST : Loss: (0.3622) | Acc: (91.59%) (9159/10000)\n",
            "Epoch: 116 | Batch_idx: 0 |  Loss: (0.0472) | Acc: (98.44%) (126/128)\n",
            "Epoch: 116 | Batch_idx: 10 |  Loss: (0.0324) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 116 | Batch_idx: 20 |  Loss: (0.0328) | Acc: (98.85%) (2657/2688)\n",
            "Epoch: 116 | Batch_idx: 30 |  Loss: (0.0331) | Acc: (98.89%) (3924/3968)\n",
            "Epoch: 116 | Batch_idx: 40 |  Loss: (0.0338) | Acc: (98.93%) (5192/5248)\n",
            "Epoch: 116 | Batch_idx: 50 |  Loss: (0.0344) | Acc: (98.91%) (6457/6528)\n",
            "Epoch: 116 | Batch_idx: 60 |  Loss: (0.0346) | Acc: (98.91%) (7723/7808)\n",
            "Epoch: 116 | Batch_idx: 70 |  Loss: (0.0363) | Acc: (98.80%) (8979/9088)\n",
            "Epoch: 116 | Batch_idx: 80 |  Loss: (0.0356) | Acc: (98.81%) (10245/10368)\n",
            "Epoch: 116 | Batch_idx: 90 |  Loss: (0.0361) | Acc: (98.78%) (11506/11648)\n",
            "Epoch: 116 | Batch_idx: 100 |  Loss: (0.0360) | Acc: (98.79%) (12771/12928)\n",
            "Epoch: 116 | Batch_idx: 110 |  Loss: (0.0354) | Acc: (98.82%) (14040/14208)\n",
            "Epoch: 116 | Batch_idx: 120 |  Loss: (0.0351) | Acc: (98.80%) (15302/15488)\n",
            "Epoch: 116 | Batch_idx: 130 |  Loss: (0.0351) | Acc: (98.80%) (16567/16768)\n",
            "Epoch: 116 | Batch_idx: 140 |  Loss: (0.0356) | Acc: (98.78%) (17827/18048)\n",
            "Epoch: 116 | Batch_idx: 150 |  Loss: (0.0351) | Acc: (98.80%) (19097/19328)\n",
            "Epoch: 116 | Batch_idx: 160 |  Loss: (0.0355) | Acc: (98.81%) (20363/20608)\n",
            "Epoch: 116 | Batch_idx: 170 |  Loss: (0.0355) | Acc: (98.79%) (21624/21888)\n",
            "Epoch: 116 | Batch_idx: 180 |  Loss: (0.0360) | Acc: (98.77%) (22883/23168)\n",
            "Epoch: 116 | Batch_idx: 190 |  Loss: (0.0361) | Acc: (98.76%) (24146/24448)\n",
            "Epoch: 116 | Batch_idx: 200 |  Loss: (0.0360) | Acc: (98.77%) (25411/25728)\n",
            "Epoch: 116 | Batch_idx: 210 |  Loss: (0.0363) | Acc: (98.77%) (26676/27008)\n",
            "Epoch: 116 | Batch_idx: 220 |  Loss: (0.0366) | Acc: (98.76%) (27936/28288)\n",
            "Epoch: 116 | Batch_idx: 230 |  Loss: (0.0364) | Acc: (98.78%) (29208/29568)\n",
            "Epoch: 116 | Batch_idx: 240 |  Loss: (0.0365) | Acc: (98.78%) (30472/30848)\n",
            "Epoch: 116 | Batch_idx: 250 |  Loss: (0.0362) | Acc: (98.79%) (31739/32128)\n",
            "Epoch: 116 | Batch_idx: 260 |  Loss: (0.0358) | Acc: (98.81%) (33011/33408)\n",
            "Epoch: 116 | Batch_idx: 270 |  Loss: (0.0359) | Acc: (98.81%) (34275/34688)\n",
            "Epoch: 116 | Batch_idx: 280 |  Loss: (0.0358) | Acc: (98.81%) (35539/35968)\n",
            "Epoch: 116 | Batch_idx: 290 |  Loss: (0.0357) | Acc: (98.81%) (36805/37248)\n",
            "Epoch: 116 | Batch_idx: 300 |  Loss: (0.0352) | Acc: (98.83%) (38077/38528)\n",
            "Epoch: 116 | Batch_idx: 310 |  Loss: (0.0355) | Acc: (98.82%) (39339/39808)\n",
            "Epoch: 116 | Batch_idx: 320 |  Loss: (0.0356) | Acc: (98.82%) (40605/41088)\n",
            "Epoch: 116 | Batch_idx: 330 |  Loss: (0.0356) | Acc: (98.82%) (41868/42368)\n",
            "Epoch: 116 | Batch_idx: 340 |  Loss: (0.0355) | Acc: (98.83%) (43136/43648)\n",
            "Epoch: 116 | Batch_idx: 350 |  Loss: (0.0356) | Acc: (98.82%) (44397/44928)\n",
            "Epoch: 116 | Batch_idx: 360 |  Loss: (0.0359) | Acc: (98.82%) (45663/46208)\n",
            "Epoch: 116 | Batch_idx: 370 |  Loss: (0.0356) | Acc: (98.83%) (46932/47488)\n",
            "Epoch: 116 | Batch_idx: 380 |  Loss: (0.0358) | Acc: (98.83%) (48195/48768)\n",
            "Epoch: 116 | Batch_idx: 390 |  Loss: (0.0357) | Acc: (98.83%) (49413/50000)\n",
            "# TEST : Loss: (0.3748) | Acc: (91.36%) (9136/10000)\n",
            "Epoch: 117 | Batch_idx: 0 |  Loss: (0.0398) | Acc: (97.66%) (125/128)\n",
            "Epoch: 117 | Batch_idx: 10 |  Loss: (0.0346) | Acc: (98.65%) (1389/1408)\n",
            "Epoch: 117 | Batch_idx: 20 |  Loss: (0.0368) | Acc: (98.77%) (2655/2688)\n",
            "Epoch: 117 | Batch_idx: 30 |  Loss: (0.0438) | Acc: (98.46%) (3907/3968)\n",
            "Epoch: 117 | Batch_idx: 40 |  Loss: (0.0420) | Acc: (98.55%) (5172/5248)\n",
            "Epoch: 117 | Batch_idx: 50 |  Loss: (0.0400) | Acc: (98.65%) (6440/6528)\n",
            "Epoch: 117 | Batch_idx: 60 |  Loss: (0.0391) | Acc: (98.66%) (7703/7808)\n",
            "Epoch: 117 | Batch_idx: 70 |  Loss: (0.0383) | Acc: (98.69%) (8969/9088)\n",
            "Epoch: 117 | Batch_idx: 80 |  Loss: (0.0388) | Acc: (98.69%) (10232/10368)\n",
            "Epoch: 117 | Batch_idx: 90 |  Loss: (0.0383) | Acc: (98.70%) (11496/11648)\n",
            "Epoch: 117 | Batch_idx: 100 |  Loss: (0.0379) | Acc: (98.71%) (12761/12928)\n",
            "Epoch: 117 | Batch_idx: 110 |  Loss: (0.0377) | Acc: (98.73%) (14028/14208)\n",
            "Epoch: 117 | Batch_idx: 120 |  Loss: (0.0382) | Acc: (98.71%) (15288/15488)\n",
            "Epoch: 117 | Batch_idx: 130 |  Loss: (0.0379) | Acc: (98.72%) (16553/16768)\n",
            "Epoch: 117 | Batch_idx: 140 |  Loss: (0.0376) | Acc: (98.71%) (17816/18048)\n",
            "Epoch: 117 | Batch_idx: 150 |  Loss: (0.0372) | Acc: (98.73%) (19083/19328)\n",
            "Epoch: 117 | Batch_idx: 160 |  Loss: (0.0368) | Acc: (98.76%) (20353/20608)\n",
            "Epoch: 117 | Batch_idx: 170 |  Loss: (0.0364) | Acc: (98.79%) (21623/21888)\n",
            "Epoch: 117 | Batch_idx: 180 |  Loss: (0.0361) | Acc: (98.80%) (22890/23168)\n",
            "Epoch: 117 | Batch_idx: 190 |  Loss: (0.0361) | Acc: (98.81%) (24156/24448)\n",
            "Epoch: 117 | Batch_idx: 200 |  Loss: (0.0362) | Acc: (98.82%) (25425/25728)\n",
            "Epoch: 117 | Batch_idx: 210 |  Loss: (0.0356) | Acc: (98.85%) (26698/27008)\n",
            "Epoch: 117 | Batch_idx: 220 |  Loss: (0.0355) | Acc: (98.86%) (27965/28288)\n",
            "Epoch: 117 | Batch_idx: 230 |  Loss: (0.0355) | Acc: (98.85%) (29229/29568)\n",
            "Epoch: 117 | Batch_idx: 240 |  Loss: (0.0353) | Acc: (98.85%) (30494/30848)\n",
            "Epoch: 117 | Batch_idx: 250 |  Loss: (0.0352) | Acc: (98.85%) (31759/32128)\n",
            "Epoch: 117 | Batch_idx: 260 |  Loss: (0.0355) | Acc: (98.84%) (33021/33408)\n",
            "Epoch: 117 | Batch_idx: 270 |  Loss: (0.0356) | Acc: (98.83%) (34281/34688)\n",
            "Epoch: 117 | Batch_idx: 280 |  Loss: (0.0355) | Acc: (98.83%) (35546/35968)\n",
            "Epoch: 117 | Batch_idx: 290 |  Loss: (0.0352) | Acc: (98.84%) (36815/37248)\n",
            "Epoch: 117 | Batch_idx: 300 |  Loss: (0.0352) | Acc: (98.85%) (38084/38528)\n",
            "Epoch: 117 | Batch_idx: 310 |  Loss: (0.0353) | Acc: (98.84%) (39348/39808)\n",
            "Epoch: 117 | Batch_idx: 320 |  Loss: (0.0350) | Acc: (98.85%) (40617/41088)\n",
            "Epoch: 117 | Batch_idx: 330 |  Loss: (0.0349) | Acc: (98.86%) (41886/42368)\n",
            "Epoch: 117 | Batch_idx: 340 |  Loss: (0.0350) | Acc: (98.85%) (43148/43648)\n",
            "Epoch: 117 | Batch_idx: 350 |  Loss: (0.0353) | Acc: (98.84%) (44408/44928)\n",
            "Epoch: 117 | Batch_idx: 360 |  Loss: (0.0357) | Acc: (98.83%) (45669/46208)\n",
            "Epoch: 117 | Batch_idx: 370 |  Loss: (0.0356) | Acc: (98.84%) (46938/47488)\n",
            "Epoch: 117 | Batch_idx: 380 |  Loss: (0.0356) | Acc: (98.85%) (48205/48768)\n",
            "Epoch: 117 | Batch_idx: 390 |  Loss: (0.0360) | Acc: (98.83%) (49413/50000)\n",
            "# TEST : Loss: (0.3706) | Acc: (91.47%) (9147/10000)\n",
            "Epoch: 118 | Batch_idx: 0 |  Loss: (0.0494) | Acc: (96.88%) (124/128)\n",
            "Epoch: 118 | Batch_idx: 10 |  Loss: (0.0319) | Acc: (98.86%) (1392/1408)\n",
            "Epoch: 118 | Batch_idx: 20 |  Loss: (0.0359) | Acc: (98.81%) (2656/2688)\n",
            "Epoch: 118 | Batch_idx: 30 |  Loss: (0.0371) | Acc: (98.79%) (3920/3968)\n",
            "Epoch: 118 | Batch_idx: 40 |  Loss: (0.0378) | Acc: (98.78%) (5184/5248)\n",
            "Epoch: 118 | Batch_idx: 50 |  Loss: (0.0355) | Acc: (98.87%) (6454/6528)\n",
            "Epoch: 118 | Batch_idx: 60 |  Loss: (0.0359) | Acc: (98.80%) (7714/7808)\n",
            "Epoch: 118 | Batch_idx: 70 |  Loss: (0.0357) | Acc: (98.75%) (8974/9088)\n",
            "Epoch: 118 | Batch_idx: 80 |  Loss: (0.0363) | Acc: (98.74%) (10237/10368)\n",
            "Epoch: 118 | Batch_idx: 90 |  Loss: (0.0350) | Acc: (98.78%) (11506/11648)\n",
            "Epoch: 118 | Batch_idx: 100 |  Loss: (0.0348) | Acc: (98.74%) (12765/12928)\n",
            "Epoch: 118 | Batch_idx: 110 |  Loss: (0.0344) | Acc: (98.79%) (14036/14208)\n",
            "Epoch: 118 | Batch_idx: 120 |  Loss: (0.0346) | Acc: (98.77%) (15298/15488)\n",
            "Epoch: 118 | Batch_idx: 130 |  Loss: (0.0340) | Acc: (98.81%) (16568/16768)\n",
            "Epoch: 118 | Batch_idx: 140 |  Loss: (0.0345) | Acc: (98.78%) (17827/18048)\n",
            "Epoch: 118 | Batch_idx: 150 |  Loss: (0.0346) | Acc: (98.78%) (19093/19328)\n",
            "Epoch: 118 | Batch_idx: 160 |  Loss: (0.0343) | Acc: (98.82%) (20364/20608)\n",
            "Epoch: 118 | Batch_idx: 170 |  Loss: (0.0343) | Acc: (98.81%) (21628/21888)\n",
            "Epoch: 118 | Batch_idx: 180 |  Loss: (0.0342) | Acc: (98.83%) (22896/23168)\n",
            "Epoch: 118 | Batch_idx: 190 |  Loss: (0.0342) | Acc: (98.83%) (24163/24448)\n",
            "Epoch: 118 | Batch_idx: 200 |  Loss: (0.0348) | Acc: (98.79%) (25417/25728)\n",
            "Epoch: 118 | Batch_idx: 210 |  Loss: (0.0347) | Acc: (98.81%) (26686/27008)\n",
            "Epoch: 118 | Batch_idx: 220 |  Loss: (0.0342) | Acc: (98.84%) (27961/28288)\n",
            "Epoch: 118 | Batch_idx: 230 |  Loss: (0.0339) | Acc: (98.87%) (29233/29568)\n",
            "Epoch: 118 | Batch_idx: 240 |  Loss: (0.0341) | Acc: (98.86%) (30496/30848)\n",
            "Epoch: 118 | Batch_idx: 250 |  Loss: (0.0343) | Acc: (98.85%) (31759/32128)\n",
            "Epoch: 118 | Batch_idx: 260 |  Loss: (0.0340) | Acc: (98.87%) (33030/33408)\n",
            "Epoch: 118 | Batch_idx: 270 |  Loss: (0.0338) | Acc: (98.89%) (34304/34688)\n",
            "Epoch: 118 | Batch_idx: 280 |  Loss: (0.0342) | Acc: (98.87%) (35562/35968)\n",
            "Epoch: 118 | Batch_idx: 290 |  Loss: (0.0342) | Acc: (98.88%) (36830/37248)\n",
            "Epoch: 118 | Batch_idx: 300 |  Loss: (0.0342) | Acc: (98.89%) (38100/38528)\n",
            "Epoch: 118 | Batch_idx: 310 |  Loss: (0.0342) | Acc: (98.89%) (39366/39808)\n",
            "Epoch: 118 | Batch_idx: 320 |  Loss: (0.0342) | Acc: (98.89%) (40632/41088)\n",
            "Epoch: 118 | Batch_idx: 330 |  Loss: (0.0339) | Acc: (98.90%) (41902/42368)\n",
            "Epoch: 118 | Batch_idx: 340 |  Loss: (0.0340) | Acc: (98.90%) (43166/43648)\n",
            "Epoch: 118 | Batch_idx: 350 |  Loss: (0.0340) | Acc: (98.90%) (44433/44928)\n",
            "Epoch: 118 | Batch_idx: 360 |  Loss: (0.0338) | Acc: (98.92%) (45707/46208)\n",
            "Epoch: 118 | Batch_idx: 370 |  Loss: (0.0338) | Acc: (98.92%) (46973/47488)\n",
            "Epoch: 118 | Batch_idx: 380 |  Loss: (0.0339) | Acc: (98.91%) (48236/48768)\n",
            "Epoch: 118 | Batch_idx: 390 |  Loss: (0.0337) | Acc: (98.92%) (49458/50000)\n",
            "# TEST : Loss: (0.3556) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 119 | Batch_idx: 0 |  Loss: (0.0125) | Acc: (99.22%) (127/128)\n",
            "Epoch: 119 | Batch_idx: 10 |  Loss: (0.0244) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 119 | Batch_idx: 20 |  Loss: (0.0268) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 119 | Batch_idx: 30 |  Loss: (0.0272) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 119 | Batch_idx: 40 |  Loss: (0.0298) | Acc: (99.10%) (5201/5248)\n",
            "Epoch: 119 | Batch_idx: 50 |  Loss: (0.0314) | Acc: (99.02%) (6464/6528)\n",
            "Epoch: 119 | Batch_idx: 60 |  Loss: (0.0309) | Acc: (99.03%) (7732/7808)\n",
            "Epoch: 119 | Batch_idx: 70 |  Loss: (0.0314) | Acc: (98.97%) (8994/9088)\n",
            "Epoch: 119 | Batch_idx: 80 |  Loss: (0.0305) | Acc: (98.98%) (10262/10368)\n",
            "Epoch: 119 | Batch_idx: 90 |  Loss: (0.0314) | Acc: (98.94%) (11524/11648)\n",
            "Epoch: 119 | Batch_idx: 100 |  Loss: (0.0310) | Acc: (98.94%) (12791/12928)\n",
            "Epoch: 119 | Batch_idx: 110 |  Loss: (0.0315) | Acc: (98.97%) (14061/14208)\n",
            "Epoch: 119 | Batch_idx: 120 |  Loss: (0.0315) | Acc: (98.95%) (15326/15488)\n",
            "Epoch: 119 | Batch_idx: 130 |  Loss: (0.0312) | Acc: (98.98%) (16597/16768)\n",
            "Epoch: 119 | Batch_idx: 140 |  Loss: (0.0312) | Acc: (98.99%) (17865/18048)\n",
            "Epoch: 119 | Batch_idx: 150 |  Loss: (0.0313) | Acc: (98.98%) (19130/19328)\n",
            "Epoch: 119 | Batch_idx: 160 |  Loss: (0.0312) | Acc: (99.00%) (20401/20608)\n",
            "Epoch: 119 | Batch_idx: 170 |  Loss: (0.0312) | Acc: (99.01%) (21671/21888)\n",
            "Epoch: 119 | Batch_idx: 180 |  Loss: (0.0315) | Acc: (99.00%) (22936/23168)\n",
            "Epoch: 119 | Batch_idx: 190 |  Loss: (0.0313) | Acc: (99.01%) (24206/24448)\n",
            "Epoch: 119 | Batch_idx: 200 |  Loss: (0.0313) | Acc: (99.00%) (25472/25728)\n",
            "Epoch: 119 | Batch_idx: 210 |  Loss: (0.0319) | Acc: (98.99%) (26734/27008)\n",
            "Epoch: 119 | Batch_idx: 220 |  Loss: (0.0322) | Acc: (98.96%) (27994/28288)\n",
            "Epoch: 119 | Batch_idx: 230 |  Loss: (0.0328) | Acc: (98.94%) (29254/29568)\n",
            "Epoch: 119 | Batch_idx: 240 |  Loss: (0.0329) | Acc: (98.94%) (30521/30848)\n",
            "Epoch: 119 | Batch_idx: 250 |  Loss: (0.0329) | Acc: (98.94%) (31789/32128)\n",
            "Epoch: 119 | Batch_idx: 260 |  Loss: (0.0331) | Acc: (98.94%) (33053/33408)\n",
            "Epoch: 119 | Batch_idx: 270 |  Loss: (0.0332) | Acc: (98.93%) (34317/34688)\n",
            "Epoch: 119 | Batch_idx: 280 |  Loss: (0.0332) | Acc: (98.92%) (35581/35968)\n",
            "Epoch: 119 | Batch_idx: 290 |  Loss: (0.0332) | Acc: (98.92%) (36845/37248)\n",
            "Epoch: 119 | Batch_idx: 300 |  Loss: (0.0335) | Acc: (98.91%) (38109/38528)\n",
            "Epoch: 119 | Batch_idx: 310 |  Loss: (0.0333) | Acc: (98.91%) (39376/39808)\n",
            "Epoch: 119 | Batch_idx: 320 |  Loss: (0.0337) | Acc: (98.90%) (40638/41088)\n",
            "Epoch: 119 | Batch_idx: 330 |  Loss: (0.0343) | Acc: (98.88%) (41894/42368)\n",
            "Epoch: 119 | Batch_idx: 340 |  Loss: (0.0346) | Acc: (98.86%) (43149/43648)\n",
            "Epoch: 119 | Batch_idx: 350 |  Loss: (0.0345) | Acc: (98.86%) (44417/44928)\n",
            "Epoch: 119 | Batch_idx: 360 |  Loss: (0.0348) | Acc: (98.86%) (45679/46208)\n",
            "Epoch: 119 | Batch_idx: 370 |  Loss: (0.0350) | Acc: (98.85%) (46940/47488)\n",
            "Epoch: 119 | Batch_idx: 380 |  Loss: (0.0348) | Acc: (98.85%) (48209/48768)\n",
            "Epoch: 119 | Batch_idx: 390 |  Loss: (0.0348) | Acc: (98.84%) (49422/50000)\n",
            "# TEST : Loss: (0.3619) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 120 | Batch_idx: 0 |  Loss: (0.0204) | Acc: (99.22%) (127/128)\n",
            "Epoch: 120 | Batch_idx: 10 |  Loss: (0.0333) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 120 | Batch_idx: 20 |  Loss: (0.0343) | Acc: (98.96%) (2660/2688)\n",
            "Epoch: 120 | Batch_idx: 30 |  Loss: (0.0344) | Acc: (98.87%) (3923/3968)\n",
            "Epoch: 120 | Batch_idx: 40 |  Loss: (0.0321) | Acc: (98.95%) (5193/5248)\n",
            "Epoch: 120 | Batch_idx: 50 |  Loss: (0.0308) | Acc: (99.02%) (6464/6528)\n",
            "Epoch: 120 | Batch_idx: 60 |  Loss: (0.0304) | Acc: (99.05%) (7734/7808)\n",
            "Epoch: 120 | Batch_idx: 70 |  Loss: (0.0309) | Acc: (98.99%) (8996/9088)\n",
            "Epoch: 120 | Batch_idx: 80 |  Loss: (0.0306) | Acc: (98.98%) (10262/10368)\n",
            "Epoch: 120 | Batch_idx: 90 |  Loss: (0.0303) | Acc: (99.00%) (11532/11648)\n",
            "Epoch: 120 | Batch_idx: 100 |  Loss: (0.0303) | Acc: (99.02%) (12801/12928)\n",
            "Epoch: 120 | Batch_idx: 110 |  Loss: (0.0304) | Acc: (99.04%) (14071/14208)\n",
            "Epoch: 120 | Batch_idx: 120 |  Loss: (0.0309) | Acc: (99.03%) (15337/15488)\n",
            "Epoch: 120 | Batch_idx: 130 |  Loss: (0.0303) | Acc: (99.03%) (16605/16768)\n",
            "Epoch: 120 | Batch_idx: 140 |  Loss: (0.0310) | Acc: (99.00%) (17868/18048)\n",
            "Epoch: 120 | Batch_idx: 150 |  Loss: (0.0318) | Acc: (98.97%) (19128/19328)\n",
            "Epoch: 120 | Batch_idx: 160 |  Loss: (0.0322) | Acc: (98.96%) (20393/20608)\n",
            "Epoch: 120 | Batch_idx: 170 |  Loss: (0.0328) | Acc: (98.93%) (21653/21888)\n",
            "Epoch: 120 | Batch_idx: 180 |  Loss: (0.0326) | Acc: (98.93%) (22921/23168)\n",
            "Epoch: 120 | Batch_idx: 190 |  Loss: (0.0324) | Acc: (98.95%) (24191/24448)\n",
            "Epoch: 120 | Batch_idx: 200 |  Loss: (0.0321) | Acc: (98.97%) (25462/25728)\n",
            "Epoch: 120 | Batch_idx: 210 |  Loss: (0.0318) | Acc: (98.98%) (26732/27008)\n",
            "Epoch: 120 | Batch_idx: 220 |  Loss: (0.0314) | Acc: (98.98%) (27999/28288)\n",
            "Epoch: 120 | Batch_idx: 230 |  Loss: (0.0313) | Acc: (98.97%) (29264/29568)\n",
            "Epoch: 120 | Batch_idx: 240 |  Loss: (0.0313) | Acc: (98.98%) (30534/30848)\n",
            "Epoch: 120 | Batch_idx: 250 |  Loss: (0.0311) | Acc: (98.98%) (31801/32128)\n",
            "Epoch: 120 | Batch_idx: 260 |  Loss: (0.0310) | Acc: (98.99%) (33070/33408)\n",
            "Epoch: 120 | Batch_idx: 270 |  Loss: (0.0312) | Acc: (98.97%) (34332/34688)\n",
            "Epoch: 120 | Batch_idx: 280 |  Loss: (0.0310) | Acc: (98.99%) (35605/35968)\n",
            "Epoch: 120 | Batch_idx: 290 |  Loss: (0.0306) | Acc: (99.01%) (36880/37248)\n",
            "Epoch: 120 | Batch_idx: 300 |  Loss: (0.0304) | Acc: (99.03%) (38153/38528)\n",
            "Epoch: 120 | Batch_idx: 310 |  Loss: (0.0301) | Acc: (99.04%) (39425/39808)\n",
            "Epoch: 120 | Batch_idx: 320 |  Loss: (0.0300) | Acc: (99.04%) (40694/41088)\n",
            "Epoch: 120 | Batch_idx: 330 |  Loss: (0.0300) | Acc: (99.04%) (41961/42368)\n",
            "Epoch: 120 | Batch_idx: 340 |  Loss: (0.0300) | Acc: (99.05%) (43232/43648)\n",
            "Epoch: 120 | Batch_idx: 350 |  Loss: (0.0298) | Acc: (99.05%) (44501/44928)\n",
            "Epoch: 120 | Batch_idx: 360 |  Loss: (0.0300) | Acc: (99.05%) (45771/46208)\n",
            "Epoch: 120 | Batch_idx: 370 |  Loss: (0.0298) | Acc: (99.07%) (47045/47488)\n",
            "Epoch: 120 | Batch_idx: 380 |  Loss: (0.0298) | Acc: (99.07%) (48313/48768)\n",
            "Epoch: 120 | Batch_idx: 390 |  Loss: (0.0296) | Acc: (99.07%) (49536/50000)\n",
            "# TEST : Loss: (0.3537) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 121 | Batch_idx: 0 |  Loss: (0.0481) | Acc: (99.22%) (127/128)\n",
            "Epoch: 121 | Batch_idx: 10 |  Loss: (0.0244) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 121 | Batch_idx: 20 |  Loss: (0.0296) | Acc: (99.33%) (2670/2688)\n",
            "Epoch: 121 | Batch_idx: 30 |  Loss: (0.0292) | Acc: (99.32%) (3941/3968)\n",
            "Epoch: 121 | Batch_idx: 40 |  Loss: (0.0270) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 121 | Batch_idx: 50 |  Loss: (0.0272) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 121 | Batch_idx: 60 |  Loss: (0.0259) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 121 | Batch_idx: 70 |  Loss: (0.0275) | Acc: (99.26%) (9021/9088)\n",
            "Epoch: 121 | Batch_idx: 80 |  Loss: (0.0268) | Acc: (99.28%) (10293/10368)\n",
            "Epoch: 121 | Batch_idx: 90 |  Loss: (0.0271) | Acc: (99.24%) (11559/11648)\n",
            "Epoch: 121 | Batch_idx: 100 |  Loss: (0.0267) | Acc: (99.24%) (12830/12928)\n",
            "Epoch: 121 | Batch_idx: 110 |  Loss: (0.0262) | Acc: (99.24%) (14100/14208)\n",
            "Epoch: 121 | Batch_idx: 120 |  Loss: (0.0258) | Acc: (99.26%) (15373/15488)\n",
            "Epoch: 121 | Batch_idx: 130 |  Loss: (0.0257) | Acc: (99.27%) (16645/16768)\n",
            "Epoch: 121 | Batch_idx: 140 |  Loss: (0.0261) | Acc: (99.26%) (17914/18048)\n",
            "Epoch: 121 | Batch_idx: 150 |  Loss: (0.0261) | Acc: (99.26%) (19185/19328)\n",
            "Epoch: 121 | Batch_idx: 160 |  Loss: (0.0268) | Acc: (99.22%) (20447/20608)\n",
            "Epoch: 121 | Batch_idx: 170 |  Loss: (0.0268) | Acc: (99.21%) (21715/21888)\n",
            "Epoch: 121 | Batch_idx: 180 |  Loss: (0.0271) | Acc: (99.19%) (22981/23168)\n",
            "Epoch: 121 | Batch_idx: 190 |  Loss: (0.0275) | Acc: (99.19%) (24249/24448)\n",
            "Epoch: 121 | Batch_idx: 200 |  Loss: (0.0277) | Acc: (99.18%) (25517/25728)\n",
            "Epoch: 121 | Batch_idx: 210 |  Loss: (0.0276) | Acc: (99.18%) (26787/27008)\n",
            "Epoch: 121 | Batch_idx: 220 |  Loss: (0.0277) | Acc: (99.17%) (28053/28288)\n",
            "Epoch: 121 | Batch_idx: 230 |  Loss: (0.0278) | Acc: (99.16%) (29320/29568)\n",
            "Epoch: 121 | Batch_idx: 240 |  Loss: (0.0275) | Acc: (99.17%) (30592/30848)\n",
            "Epoch: 121 | Batch_idx: 250 |  Loss: (0.0276) | Acc: (99.17%) (31862/32128)\n",
            "Epoch: 121 | Batch_idx: 260 |  Loss: (0.0276) | Acc: (99.16%) (33128/33408)\n",
            "Epoch: 121 | Batch_idx: 270 |  Loss: (0.0276) | Acc: (99.17%) (34399/34688)\n",
            "Epoch: 121 | Batch_idx: 280 |  Loss: (0.0276) | Acc: (99.17%) (35671/35968)\n",
            "Epoch: 121 | Batch_idx: 290 |  Loss: (0.0273) | Acc: (99.19%) (36945/37248)\n",
            "Epoch: 121 | Batch_idx: 300 |  Loss: (0.0275) | Acc: (99.19%) (38214/38528)\n",
            "Epoch: 121 | Batch_idx: 310 |  Loss: (0.0275) | Acc: (99.19%) (39487/39808)\n",
            "Epoch: 121 | Batch_idx: 320 |  Loss: (0.0277) | Acc: (99.18%) (40752/41088)\n",
            "Epoch: 121 | Batch_idx: 330 |  Loss: (0.0277) | Acc: (99.18%) (42022/42368)\n",
            "Epoch: 121 | Batch_idx: 340 |  Loss: (0.0277) | Acc: (99.18%) (43291/43648)\n",
            "Epoch: 121 | Batch_idx: 350 |  Loss: (0.0275) | Acc: (99.19%) (44565/44928)\n",
            "Epoch: 121 | Batch_idx: 360 |  Loss: (0.0277) | Acc: (99.19%) (45833/46208)\n",
            "Epoch: 121 | Batch_idx: 370 |  Loss: (0.0276) | Acc: (99.19%) (47102/47488)\n",
            "Epoch: 121 | Batch_idx: 380 |  Loss: (0.0274) | Acc: (99.19%) (48372/48768)\n",
            "Epoch: 121 | Batch_idx: 390 |  Loss: (0.0273) | Acc: (99.19%) (49596/50000)\n",
            "# TEST : Loss: (0.3523) | Acc: (91.97%) (9197/10000)\n",
            "Epoch: 122 | Batch_idx: 0 |  Loss: (0.0291) | Acc: (98.44%) (126/128)\n",
            "Epoch: 122 | Batch_idx: 10 |  Loss: (0.0314) | Acc: (98.93%) (1393/1408)\n",
            "Epoch: 122 | Batch_idx: 20 |  Loss: (0.0367) | Acc: (98.70%) (2653/2688)\n",
            "Epoch: 122 | Batch_idx: 30 |  Loss: (0.0338) | Acc: (98.92%) (3925/3968)\n",
            "Epoch: 122 | Batch_idx: 40 |  Loss: (0.0314) | Acc: (99.01%) (5196/5248)\n",
            "Epoch: 122 | Batch_idx: 50 |  Loss: (0.0311) | Acc: (99.05%) (6466/6528)\n",
            "Epoch: 122 | Batch_idx: 60 |  Loss: (0.0307) | Acc: (99.04%) (7733/7808)\n",
            "Epoch: 122 | Batch_idx: 70 |  Loss: (0.0305) | Acc: (99.08%) (9004/9088)\n",
            "Epoch: 122 | Batch_idx: 80 |  Loss: (0.0310) | Acc: (99.02%) (10266/10368)\n",
            "Epoch: 122 | Batch_idx: 90 |  Loss: (0.0307) | Acc: (99.05%) (11537/11648)\n",
            "Epoch: 122 | Batch_idx: 100 |  Loss: (0.0301) | Acc: (99.08%) (12809/12928)\n",
            "Epoch: 122 | Batch_idx: 110 |  Loss: (0.0295) | Acc: (99.11%) (14081/14208)\n",
            "Epoch: 122 | Batch_idx: 120 |  Loss: (0.0291) | Acc: (99.12%) (15351/15488)\n",
            "Epoch: 122 | Batch_idx: 130 |  Loss: (0.0289) | Acc: (99.12%) (16620/16768)\n",
            "Epoch: 122 | Batch_idx: 140 |  Loss: (0.0285) | Acc: (99.14%) (17893/18048)\n",
            "Epoch: 122 | Batch_idx: 150 |  Loss: (0.0284) | Acc: (99.15%) (19164/19328)\n",
            "Epoch: 122 | Batch_idx: 160 |  Loss: (0.0277) | Acc: (99.18%) (20439/20608)\n",
            "Epoch: 122 | Batch_idx: 170 |  Loss: (0.0272) | Acc: (99.21%) (21716/21888)\n",
            "Epoch: 122 | Batch_idx: 180 |  Loss: (0.0268) | Acc: (99.24%) (22991/23168)\n",
            "Epoch: 122 | Batch_idx: 190 |  Loss: (0.0265) | Acc: (99.25%) (24264/24448)\n",
            "Epoch: 122 | Batch_idx: 200 |  Loss: (0.0262) | Acc: (99.26%) (25538/25728)\n",
            "Epoch: 122 | Batch_idx: 210 |  Loss: (0.0265) | Acc: (99.26%) (26807/27008)\n",
            "Epoch: 122 | Batch_idx: 220 |  Loss: (0.0266) | Acc: (99.23%) (28071/28288)\n",
            "Epoch: 122 | Batch_idx: 230 |  Loss: (0.0268) | Acc: (99.22%) (29337/29568)\n",
            "Epoch: 122 | Batch_idx: 240 |  Loss: (0.0267) | Acc: (99.22%) (30606/30848)\n",
            "Epoch: 122 | Batch_idx: 250 |  Loss: (0.0268) | Acc: (99.22%) (31876/32128)\n",
            "Epoch: 122 | Batch_idx: 260 |  Loss: (0.0268) | Acc: (99.22%) (33148/33408)\n",
            "Epoch: 122 | Batch_idx: 270 |  Loss: (0.0265) | Acc: (99.23%) (34421/34688)\n",
            "Epoch: 122 | Batch_idx: 280 |  Loss: (0.0263) | Acc: (99.24%) (35693/35968)\n",
            "Epoch: 122 | Batch_idx: 290 |  Loss: (0.0262) | Acc: (99.24%) (36966/37248)\n",
            "Epoch: 122 | Batch_idx: 300 |  Loss: (0.0264) | Acc: (99.23%) (38231/38528)\n",
            "Epoch: 122 | Batch_idx: 310 |  Loss: (0.0265) | Acc: (99.22%) (39499/39808)\n",
            "Epoch: 122 | Batch_idx: 320 |  Loss: (0.0263) | Acc: (99.22%) (40768/41088)\n",
            "Epoch: 122 | Batch_idx: 330 |  Loss: (0.0266) | Acc: (99.21%) (42034/42368)\n",
            "Epoch: 122 | Batch_idx: 340 |  Loss: (0.0266) | Acc: (99.21%) (43304/43648)\n",
            "Epoch: 122 | Batch_idx: 350 |  Loss: (0.0267) | Acc: (99.21%) (44575/44928)\n",
            "Epoch: 122 | Batch_idx: 360 |  Loss: (0.0268) | Acc: (99.21%) (45845/46208)\n",
            "Epoch: 122 | Batch_idx: 370 |  Loss: (0.0268) | Acc: (99.21%) (47115/47488)\n",
            "Epoch: 122 | Batch_idx: 380 |  Loss: (0.0268) | Acc: (99.22%) (48386/48768)\n",
            "Epoch: 122 | Batch_idx: 390 |  Loss: (0.0268) | Acc: (99.22%) (49609/50000)\n",
            "# TEST : Loss: (0.3547) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 123 | Batch_idx: 0 |  Loss: (0.0183) | Acc: (100.00%) (128/128)\n",
            "Epoch: 123 | Batch_idx: 10 |  Loss: (0.0261) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 123 | Batch_idx: 20 |  Loss: (0.0281) | Acc: (99.00%) (2661/2688)\n",
            "Epoch: 123 | Batch_idx: 30 |  Loss: (0.0264) | Acc: (99.14%) (3934/3968)\n",
            "Epoch: 123 | Batch_idx: 40 |  Loss: (0.0267) | Acc: (99.14%) (5203/5248)\n",
            "Epoch: 123 | Batch_idx: 50 |  Loss: (0.0265) | Acc: (99.13%) (6471/6528)\n",
            "Epoch: 123 | Batch_idx: 60 |  Loss: (0.0258) | Acc: (99.14%) (7741/7808)\n",
            "Epoch: 123 | Batch_idx: 70 |  Loss: (0.0264) | Acc: (99.15%) (9011/9088)\n",
            "Epoch: 123 | Batch_idx: 80 |  Loss: (0.0265) | Acc: (99.16%) (10281/10368)\n",
            "Epoch: 123 | Batch_idx: 90 |  Loss: (0.0269) | Acc: (99.14%) (11548/11648)\n",
            "Epoch: 123 | Batch_idx: 100 |  Loss: (0.0270) | Acc: (99.13%) (12816/12928)\n",
            "Epoch: 123 | Batch_idx: 110 |  Loss: (0.0274) | Acc: (99.11%) (14082/14208)\n",
            "Epoch: 123 | Batch_idx: 120 |  Loss: (0.0266) | Acc: (99.16%) (15358/15488)\n",
            "Epoch: 123 | Batch_idx: 130 |  Loss: (0.0263) | Acc: (99.19%) (16633/16768)\n",
            "Epoch: 123 | Batch_idx: 140 |  Loss: (0.0265) | Acc: (99.19%) (17901/18048)\n",
            "Epoch: 123 | Batch_idx: 150 |  Loss: (0.0263) | Acc: (99.18%) (19170/19328)\n",
            "Epoch: 123 | Batch_idx: 160 |  Loss: (0.0261) | Acc: (99.19%) (20441/20608)\n",
            "Epoch: 123 | Batch_idx: 170 |  Loss: (0.0264) | Acc: (99.18%) (21708/21888)\n",
            "Epoch: 123 | Batch_idx: 180 |  Loss: (0.0268) | Acc: (99.17%) (22975/23168)\n",
            "Epoch: 123 | Batch_idx: 190 |  Loss: (0.0270) | Acc: (99.15%) (24240/24448)\n",
            "Epoch: 123 | Batch_idx: 200 |  Loss: (0.0272) | Acc: (99.14%) (25507/25728)\n",
            "Epoch: 123 | Batch_idx: 210 |  Loss: (0.0272) | Acc: (99.13%) (26772/27008)\n",
            "Epoch: 123 | Batch_idx: 220 |  Loss: (0.0270) | Acc: (99.14%) (28045/28288)\n",
            "Epoch: 123 | Batch_idx: 230 |  Loss: (0.0267) | Acc: (99.15%) (29317/29568)\n",
            "Epoch: 123 | Batch_idx: 240 |  Loss: (0.0265) | Acc: (99.16%) (30589/30848)\n",
            "Epoch: 123 | Batch_idx: 250 |  Loss: (0.0265) | Acc: (99.16%) (31859/32128)\n",
            "Epoch: 123 | Batch_idx: 260 |  Loss: (0.0263) | Acc: (99.16%) (33128/33408)\n",
            "Epoch: 123 | Batch_idx: 270 |  Loss: (0.0264) | Acc: (99.16%) (34396/34688)\n",
            "Epoch: 123 | Batch_idx: 280 |  Loss: (0.0263) | Acc: (99.16%) (35665/35968)\n",
            "Epoch: 123 | Batch_idx: 290 |  Loss: (0.0262) | Acc: (99.16%) (36936/37248)\n",
            "Epoch: 123 | Batch_idx: 300 |  Loss: (0.0262) | Acc: (99.17%) (38208/38528)\n",
            "Epoch: 123 | Batch_idx: 310 |  Loss: (0.0259) | Acc: (99.18%) (39482/39808)\n",
            "Epoch: 123 | Batch_idx: 320 |  Loss: (0.0259) | Acc: (99.19%) (40755/41088)\n",
            "Epoch: 123 | Batch_idx: 330 |  Loss: (0.0259) | Acc: (99.20%) (42027/42368)\n",
            "Epoch: 123 | Batch_idx: 340 |  Loss: (0.0257) | Acc: (99.20%) (43299/43648)\n",
            "Epoch: 123 | Batch_idx: 350 |  Loss: (0.0257) | Acc: (99.21%) (44571/44928)\n",
            "Epoch: 123 | Batch_idx: 360 |  Loss: (0.0257) | Acc: (99.21%) (45844/46208)\n",
            "Epoch: 123 | Batch_idx: 370 |  Loss: (0.0260) | Acc: (99.20%) (47110/47488)\n",
            "Epoch: 123 | Batch_idx: 380 |  Loss: (0.0259) | Acc: (99.21%) (48382/48768)\n",
            "Epoch: 123 | Batch_idx: 390 |  Loss: (0.0259) | Acc: (99.21%) (49605/50000)\n",
            "# TEST : Loss: (0.3550) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 124 | Batch_idx: 0 |  Loss: (0.0217) | Acc: (99.22%) (127/128)\n",
            "Epoch: 124 | Batch_idx: 10 |  Loss: (0.0225) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 124 | Batch_idx: 20 |  Loss: (0.0232) | Acc: (99.22%) (2667/2688)\n",
            "Epoch: 124 | Batch_idx: 30 |  Loss: (0.0213) | Acc: (99.32%) (3941/3968)\n",
            "Epoch: 124 | Batch_idx: 40 |  Loss: (0.0233) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 124 | Batch_idx: 50 |  Loss: (0.0223) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 124 | Batch_idx: 60 |  Loss: (0.0224) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 124 | Batch_idx: 70 |  Loss: (0.0234) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 124 | Batch_idx: 80 |  Loss: (0.0230) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 124 | Batch_idx: 90 |  Loss: (0.0238) | Acc: (99.30%) (11567/11648)\n",
            "Epoch: 124 | Batch_idx: 100 |  Loss: (0.0235) | Acc: (99.33%) (12842/12928)\n",
            "Epoch: 124 | Batch_idx: 110 |  Loss: (0.0237) | Acc: (99.34%) (14114/14208)\n",
            "Epoch: 124 | Batch_idx: 120 |  Loss: (0.0237) | Acc: (99.34%) (15386/15488)\n",
            "Epoch: 124 | Batch_idx: 130 |  Loss: (0.0244) | Acc: (99.33%) (16655/16768)\n",
            "Epoch: 124 | Batch_idx: 140 |  Loss: (0.0242) | Acc: (99.31%) (17923/18048)\n",
            "Epoch: 124 | Batch_idx: 150 |  Loss: (0.0245) | Acc: (99.31%) (19195/19328)\n",
            "Epoch: 124 | Batch_idx: 160 |  Loss: (0.0246) | Acc: (99.31%) (20465/20608)\n",
            "Epoch: 124 | Batch_idx: 170 |  Loss: (0.0251) | Acc: (99.29%) (21732/21888)\n",
            "Epoch: 124 | Batch_idx: 180 |  Loss: (0.0248) | Acc: (99.31%) (23007/23168)\n",
            "Epoch: 124 | Batch_idx: 190 |  Loss: (0.0247) | Acc: (99.31%) (24279/24448)\n",
            "Epoch: 124 | Batch_idx: 200 |  Loss: (0.0250) | Acc: (99.30%) (25547/25728)\n",
            "Epoch: 124 | Batch_idx: 210 |  Loss: (0.0252) | Acc: (99.29%) (26815/27008)\n",
            "Epoch: 124 | Batch_idx: 220 |  Loss: (0.0251) | Acc: (99.30%) (28089/28288)\n",
            "Epoch: 124 | Batch_idx: 230 |  Loss: (0.0252) | Acc: (99.30%) (29360/29568)\n",
            "Epoch: 124 | Batch_idx: 240 |  Loss: (0.0251) | Acc: (99.30%) (30633/30848)\n",
            "Epoch: 124 | Batch_idx: 250 |  Loss: (0.0251) | Acc: (99.29%) (31901/32128)\n",
            "Epoch: 124 | Batch_idx: 260 |  Loss: (0.0252) | Acc: (99.29%) (33171/33408)\n",
            "Epoch: 124 | Batch_idx: 270 |  Loss: (0.0253) | Acc: (99.29%) (34441/34688)\n",
            "Epoch: 124 | Batch_idx: 280 |  Loss: (0.0252) | Acc: (99.29%) (35712/35968)\n",
            "Epoch: 124 | Batch_idx: 290 |  Loss: (0.0250) | Acc: (99.30%) (36987/37248)\n",
            "Epoch: 124 | Batch_idx: 300 |  Loss: (0.0251) | Acc: (99.29%) (38254/38528)\n",
            "Epoch: 124 | Batch_idx: 310 |  Loss: (0.0250) | Acc: (99.29%) (39526/39808)\n",
            "Epoch: 124 | Batch_idx: 320 |  Loss: (0.0251) | Acc: (99.29%) (40795/41088)\n",
            "Epoch: 124 | Batch_idx: 330 |  Loss: (0.0251) | Acc: (99.29%) (42067/42368)\n",
            "Epoch: 124 | Batch_idx: 340 |  Loss: (0.0253) | Acc: (99.28%) (43333/43648)\n",
            "Epoch: 124 | Batch_idx: 350 |  Loss: (0.0255) | Acc: (99.27%) (44601/44928)\n",
            "Epoch: 124 | Batch_idx: 360 |  Loss: (0.0255) | Acc: (99.28%) (45873/46208)\n",
            "Epoch: 124 | Batch_idx: 370 |  Loss: (0.0256) | Acc: (99.27%) (47143/47488)\n",
            "Epoch: 124 | Batch_idx: 380 |  Loss: (0.0255) | Acc: (99.28%) (48416/48768)\n",
            "Epoch: 124 | Batch_idx: 390 |  Loss: (0.0254) | Acc: (99.28%) (49641/50000)\n",
            "# TEST : Loss: (0.3561) | Acc: (91.96%) (9196/10000)\n",
            "Epoch: 125 | Batch_idx: 0 |  Loss: (0.0368) | Acc: (99.22%) (127/128)\n",
            "Epoch: 125 | Batch_idx: 10 |  Loss: (0.0304) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 125 | Batch_idx: 20 |  Loss: (0.0275) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 125 | Batch_idx: 30 |  Loss: (0.0268) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 125 | Batch_idx: 40 |  Loss: (0.0248) | Acc: (99.20%) (5206/5248)\n",
            "Epoch: 125 | Batch_idx: 50 |  Loss: (0.0263) | Acc: (99.16%) (6473/6528)\n",
            "Epoch: 125 | Batch_idx: 60 |  Loss: (0.0264) | Acc: (99.18%) (7744/7808)\n",
            "Epoch: 125 | Batch_idx: 70 |  Loss: (0.0260) | Acc: (99.22%) (9017/9088)\n",
            "Epoch: 125 | Batch_idx: 80 |  Loss: (0.0251) | Acc: (99.26%) (10291/10368)\n",
            "Epoch: 125 | Batch_idx: 90 |  Loss: (0.0248) | Acc: (99.28%) (11564/11648)\n",
            "Epoch: 125 | Batch_idx: 100 |  Loss: (0.0248) | Acc: (99.30%) (12837/12928)\n",
            "Epoch: 125 | Batch_idx: 110 |  Loss: (0.0248) | Acc: (99.30%) (14108/14208)\n",
            "Epoch: 125 | Batch_idx: 120 |  Loss: (0.0248) | Acc: (99.30%) (15379/15488)\n",
            "Epoch: 125 | Batch_idx: 130 |  Loss: (0.0244) | Acc: (99.30%) (16650/16768)\n",
            "Epoch: 125 | Batch_idx: 140 |  Loss: (0.0240) | Acc: (99.32%) (17925/18048)\n",
            "Epoch: 125 | Batch_idx: 150 |  Loss: (0.0241) | Acc: (99.33%) (19199/19328)\n",
            "Epoch: 125 | Batch_idx: 160 |  Loss: (0.0242) | Acc: (99.33%) (20469/20608)\n",
            "Epoch: 125 | Batch_idx: 170 |  Loss: (0.0246) | Acc: (99.30%) (21734/21888)\n",
            "Epoch: 125 | Batch_idx: 180 |  Loss: (0.0242) | Acc: (99.31%) (23008/23168)\n",
            "Epoch: 125 | Batch_idx: 190 |  Loss: (0.0243) | Acc: (99.31%) (24279/24448)\n",
            "Epoch: 125 | Batch_idx: 200 |  Loss: (0.0244) | Acc: (99.29%) (25546/25728)\n",
            "Epoch: 125 | Batch_idx: 210 |  Loss: (0.0243) | Acc: (99.29%) (26815/27008)\n",
            "Epoch: 125 | Batch_idx: 220 |  Loss: (0.0241) | Acc: (99.30%) (28089/28288)\n",
            "Epoch: 125 | Batch_idx: 230 |  Loss: (0.0241) | Acc: (99.30%) (29362/29568)\n",
            "Epoch: 125 | Batch_idx: 240 |  Loss: (0.0244) | Acc: (99.28%) (30626/30848)\n",
            "Epoch: 125 | Batch_idx: 250 |  Loss: (0.0244) | Acc: (99.28%) (31896/32128)\n",
            "Epoch: 125 | Batch_idx: 260 |  Loss: (0.0244) | Acc: (99.29%) (33170/33408)\n",
            "Epoch: 125 | Batch_idx: 270 |  Loss: (0.0242) | Acc: (99.29%) (34443/34688)\n",
            "Epoch: 125 | Batch_idx: 280 |  Loss: (0.0243) | Acc: (99.29%) (35711/35968)\n",
            "Epoch: 125 | Batch_idx: 290 |  Loss: (0.0243) | Acc: (99.29%) (36985/37248)\n",
            "Epoch: 125 | Batch_idx: 300 |  Loss: (0.0243) | Acc: (99.29%) (38253/38528)\n",
            "Epoch: 125 | Batch_idx: 310 |  Loss: (0.0244) | Acc: (99.29%) (39526/39808)\n",
            "Epoch: 125 | Batch_idx: 320 |  Loss: (0.0243) | Acc: (99.30%) (40800/41088)\n",
            "Epoch: 125 | Batch_idx: 330 |  Loss: (0.0242) | Acc: (99.30%) (42071/42368)\n",
            "Epoch: 125 | Batch_idx: 340 |  Loss: (0.0243) | Acc: (99.29%) (43339/43648)\n",
            "Epoch: 125 | Batch_idx: 350 |  Loss: (0.0243) | Acc: (99.29%) (44607/44928)\n",
            "Epoch: 125 | Batch_idx: 360 |  Loss: (0.0244) | Acc: (99.29%) (45878/46208)\n",
            "Epoch: 125 | Batch_idx: 370 |  Loss: (0.0245) | Acc: (99.28%) (47147/47488)\n",
            "Epoch: 125 | Batch_idx: 380 |  Loss: (0.0246) | Acc: (99.27%) (48414/48768)\n",
            "Epoch: 125 | Batch_idx: 390 |  Loss: (0.0245) | Acc: (99.28%) (49639/50000)\n",
            "# TEST : Loss: (0.3585) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 126 | Batch_idx: 0 |  Loss: (0.0441) | Acc: (98.44%) (126/128)\n",
            "Epoch: 126 | Batch_idx: 10 |  Loss: (0.0271) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 126 | Batch_idx: 20 |  Loss: (0.0275) | Acc: (99.22%) (2667/2688)\n",
            "Epoch: 126 | Batch_idx: 30 |  Loss: (0.0275) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 126 | Batch_idx: 40 |  Loss: (0.0268) | Acc: (99.18%) (5205/5248)\n",
            "Epoch: 126 | Batch_idx: 50 |  Loss: (0.0260) | Acc: (99.26%) (6480/6528)\n",
            "Epoch: 126 | Batch_idx: 60 |  Loss: (0.0248) | Acc: (99.32%) (7755/7808)\n",
            "Epoch: 126 | Batch_idx: 70 |  Loss: (0.0243) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 126 | Batch_idx: 80 |  Loss: (0.0240) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 126 | Batch_idx: 90 |  Loss: (0.0242) | Acc: (99.31%) (11568/11648)\n",
            "Epoch: 126 | Batch_idx: 100 |  Loss: (0.0244) | Acc: (99.30%) (12838/12928)\n",
            "Epoch: 126 | Batch_idx: 110 |  Loss: (0.0250) | Acc: (99.27%) (14104/14208)\n",
            "Epoch: 126 | Batch_idx: 120 |  Loss: (0.0242) | Acc: (99.31%) (15381/15488)\n",
            "Epoch: 126 | Batch_idx: 130 |  Loss: (0.0248) | Acc: (99.29%) (16649/16768)\n",
            "Epoch: 126 | Batch_idx: 140 |  Loss: (0.0245) | Acc: (99.30%) (17922/18048)\n",
            "Epoch: 126 | Batch_idx: 150 |  Loss: (0.0246) | Acc: (99.30%) (19193/19328)\n",
            "Epoch: 126 | Batch_idx: 160 |  Loss: (0.0249) | Acc: (99.30%) (20464/20608)\n",
            "Epoch: 126 | Batch_idx: 170 |  Loss: (0.0249) | Acc: (99.31%) (21737/21888)\n",
            "Epoch: 126 | Batch_idx: 180 |  Loss: (0.0251) | Acc: (99.31%) (23007/23168)\n",
            "Epoch: 126 | Batch_idx: 190 |  Loss: (0.0248) | Acc: (99.32%) (24282/24448)\n",
            "Epoch: 126 | Batch_idx: 200 |  Loss: (0.0246) | Acc: (99.32%) (25554/25728)\n",
            "Epoch: 126 | Batch_idx: 210 |  Loss: (0.0245) | Acc: (99.32%) (26823/27008)\n",
            "Epoch: 126 | Batch_idx: 220 |  Loss: (0.0248) | Acc: (99.32%) (28095/28288)\n",
            "Epoch: 126 | Batch_idx: 230 |  Loss: (0.0248) | Acc: (99.31%) (29363/29568)\n",
            "Epoch: 126 | Batch_idx: 240 |  Loss: (0.0244) | Acc: (99.32%) (30639/30848)\n",
            "Epoch: 126 | Batch_idx: 250 |  Loss: (0.0245) | Acc: (99.33%) (31913/32128)\n",
            "Epoch: 126 | Batch_idx: 260 |  Loss: (0.0243) | Acc: (99.34%) (33186/33408)\n",
            "Epoch: 126 | Batch_idx: 270 |  Loss: (0.0243) | Acc: (99.33%) (34456/34688)\n",
            "Epoch: 126 | Batch_idx: 280 |  Loss: (0.0244) | Acc: (99.32%) (35725/35968)\n",
            "Epoch: 126 | Batch_idx: 290 |  Loss: (0.0244) | Acc: (99.32%) (36994/37248)\n",
            "Epoch: 126 | Batch_idx: 300 |  Loss: (0.0243) | Acc: (99.32%) (38266/38528)\n",
            "Epoch: 126 | Batch_idx: 310 |  Loss: (0.0243) | Acc: (99.32%) (39538/39808)\n",
            "Epoch: 126 | Batch_idx: 320 |  Loss: (0.0243) | Acc: (99.32%) (40807/41088)\n",
            "Epoch: 126 | Batch_idx: 330 |  Loss: (0.0244) | Acc: (99.30%) (42071/42368)\n",
            "Epoch: 126 | Batch_idx: 340 |  Loss: (0.0243) | Acc: (99.30%) (43344/43648)\n",
            "Epoch: 126 | Batch_idx: 350 |  Loss: (0.0242) | Acc: (99.30%) (44615/44928)\n",
            "Epoch: 126 | Batch_idx: 360 |  Loss: (0.0241) | Acc: (99.31%) (45888/46208)\n",
            "Epoch: 126 | Batch_idx: 370 |  Loss: (0.0244) | Acc: (99.30%) (47155/47488)\n",
            "Epoch: 126 | Batch_idx: 380 |  Loss: (0.0245) | Acc: (99.30%) (48429/48768)\n",
            "Epoch: 126 | Batch_idx: 390 |  Loss: (0.0246) | Acc: (99.30%) (49650/50000)\n",
            "# TEST : Loss: (0.3570) | Acc: (91.91%) (9191/10000)\n",
            "Epoch: 127 | Batch_idx: 0 |  Loss: (0.0168) | Acc: (100.00%) (128/128)\n",
            "Epoch: 127 | Batch_idx: 10 |  Loss: (0.0209) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 127 | Batch_idx: 20 |  Loss: (0.0235) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 127 | Batch_idx: 30 |  Loss: (0.0237) | Acc: (99.24%) (3938/3968)\n",
            "Epoch: 127 | Batch_idx: 40 |  Loss: (0.0235) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 127 | Batch_idx: 50 |  Loss: (0.0256) | Acc: (99.13%) (6471/6528)\n",
            "Epoch: 127 | Batch_idx: 60 |  Loss: (0.0264) | Acc: (99.12%) (7739/7808)\n",
            "Epoch: 127 | Batch_idx: 70 |  Loss: (0.0258) | Acc: (99.16%) (9012/9088)\n",
            "Epoch: 127 | Batch_idx: 80 |  Loss: (0.0256) | Acc: (99.21%) (10286/10368)\n",
            "Epoch: 127 | Batch_idx: 90 |  Loss: (0.0257) | Acc: (99.19%) (11554/11648)\n",
            "Epoch: 127 | Batch_idx: 100 |  Loss: (0.0252) | Acc: (99.23%) (12829/12928)\n",
            "Epoch: 127 | Batch_idx: 110 |  Loss: (0.0256) | Acc: (99.24%) (14100/14208)\n",
            "Epoch: 127 | Batch_idx: 120 |  Loss: (0.0261) | Acc: (99.22%) (15367/15488)\n",
            "Epoch: 127 | Batch_idx: 130 |  Loss: (0.0259) | Acc: (99.24%) (16640/16768)\n",
            "Epoch: 127 | Batch_idx: 140 |  Loss: (0.0256) | Acc: (99.25%) (17913/18048)\n",
            "Epoch: 127 | Batch_idx: 150 |  Loss: (0.0258) | Acc: (99.24%) (19182/19328)\n",
            "Epoch: 127 | Batch_idx: 160 |  Loss: (0.0258) | Acc: (99.24%) (20452/20608)\n",
            "Epoch: 127 | Batch_idx: 170 |  Loss: (0.0255) | Acc: (99.26%) (21726/21888)\n",
            "Epoch: 127 | Batch_idx: 180 |  Loss: (0.0255) | Acc: (99.26%) (22997/23168)\n",
            "Epoch: 127 | Batch_idx: 190 |  Loss: (0.0254) | Acc: (99.27%) (24269/24448)\n",
            "Epoch: 127 | Batch_idx: 200 |  Loss: (0.0253) | Acc: (99.28%) (25542/25728)\n",
            "Epoch: 127 | Batch_idx: 210 |  Loss: (0.0249) | Acc: (99.29%) (26817/27008)\n",
            "Epoch: 127 | Batch_idx: 220 |  Loss: (0.0248) | Acc: (99.30%) (28089/28288)\n",
            "Epoch: 127 | Batch_idx: 230 |  Loss: (0.0249) | Acc: (99.30%) (29361/29568)\n",
            "Epoch: 127 | Batch_idx: 240 |  Loss: (0.0251) | Acc: (99.30%) (30633/30848)\n",
            "Epoch: 127 | Batch_idx: 250 |  Loss: (0.0248) | Acc: (99.31%) (31905/32128)\n",
            "Epoch: 127 | Batch_idx: 260 |  Loss: (0.0245) | Acc: (99.32%) (33181/33408)\n",
            "Epoch: 127 | Batch_idx: 270 |  Loss: (0.0247) | Acc: (99.31%) (34448/34688)\n",
            "Epoch: 127 | Batch_idx: 280 |  Loss: (0.0246) | Acc: (99.31%) (35721/35968)\n",
            "Epoch: 127 | Batch_idx: 290 |  Loss: (0.0246) | Acc: (99.32%) (36993/37248)\n",
            "Epoch: 127 | Batch_idx: 300 |  Loss: (0.0246) | Acc: (99.31%) (38264/38528)\n",
            "Epoch: 127 | Batch_idx: 310 |  Loss: (0.0245) | Acc: (99.32%) (39536/39808)\n",
            "Epoch: 127 | Batch_idx: 320 |  Loss: (0.0244) | Acc: (99.33%) (40811/41088)\n",
            "Epoch: 127 | Batch_idx: 330 |  Loss: (0.0243) | Acc: (99.32%) (42081/42368)\n",
            "Epoch: 127 | Batch_idx: 340 |  Loss: (0.0243) | Acc: (99.32%) (43351/43648)\n",
            "Epoch: 127 | Batch_idx: 350 |  Loss: (0.0242) | Acc: (99.33%) (44625/44928)\n",
            "Epoch: 127 | Batch_idx: 360 |  Loss: (0.0244) | Acc: (99.32%) (45895/46208)\n",
            "Epoch: 127 | Batch_idx: 370 |  Loss: (0.0242) | Acc: (99.33%) (47169/47488)\n",
            "Epoch: 127 | Batch_idx: 380 |  Loss: (0.0244) | Acc: (99.32%) (48436/48768)\n",
            "Epoch: 127 | Batch_idx: 390 |  Loss: (0.0243) | Acc: (99.31%) (49657/50000)\n",
            "# TEST : Loss: (0.3554) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 128 | Batch_idx: 0 |  Loss: (0.0138) | Acc: (100.00%) (128/128)\n",
            "Epoch: 128 | Batch_idx: 10 |  Loss: (0.0234) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 128 | Batch_idx: 20 |  Loss: (0.0246) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 128 | Batch_idx: 30 |  Loss: (0.0264) | Acc: (99.27%) (3939/3968)\n",
            "Epoch: 128 | Batch_idx: 40 |  Loss: (0.0269) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 128 | Batch_idx: 50 |  Loss: (0.0266) | Acc: (99.22%) (6477/6528)\n",
            "Epoch: 128 | Batch_idx: 60 |  Loss: (0.0264) | Acc: (99.23%) (7748/7808)\n",
            "Epoch: 128 | Batch_idx: 70 |  Loss: (0.0255) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 128 | Batch_idx: 80 |  Loss: (0.0250) | Acc: (99.33%) (10299/10368)\n",
            "Epoch: 128 | Batch_idx: 90 |  Loss: (0.0247) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 128 | Batch_idx: 100 |  Loss: (0.0246) | Acc: (99.33%) (12842/12928)\n",
            "Epoch: 128 | Batch_idx: 110 |  Loss: (0.0245) | Acc: (99.35%) (14115/14208)\n",
            "Epoch: 128 | Batch_idx: 120 |  Loss: (0.0251) | Acc: (99.31%) (15381/15488)\n",
            "Epoch: 128 | Batch_idx: 130 |  Loss: (0.0251) | Acc: (99.29%) (16649/16768)\n",
            "Epoch: 128 | Batch_idx: 140 |  Loss: (0.0250) | Acc: (99.29%) (17920/18048)\n",
            "Epoch: 128 | Batch_idx: 150 |  Loss: (0.0251) | Acc: (99.29%) (19191/19328)\n",
            "Epoch: 128 | Batch_idx: 160 |  Loss: (0.0248) | Acc: (99.32%) (20467/20608)\n",
            "Epoch: 128 | Batch_idx: 170 |  Loss: (0.0252) | Acc: (99.29%) (21733/21888)\n",
            "Epoch: 128 | Batch_idx: 180 |  Loss: (0.0253) | Acc: (99.30%) (23005/23168)\n",
            "Epoch: 128 | Batch_idx: 190 |  Loss: (0.0253) | Acc: (99.30%) (24277/24448)\n",
            "Epoch: 128 | Batch_idx: 200 |  Loss: (0.0255) | Acc: (99.28%) (25544/25728)\n",
            "Epoch: 128 | Batch_idx: 210 |  Loss: (0.0251) | Acc: (99.30%) (26820/27008)\n",
            "Epoch: 128 | Batch_idx: 220 |  Loss: (0.0252) | Acc: (99.31%) (28093/28288)\n",
            "Epoch: 128 | Batch_idx: 230 |  Loss: (0.0249) | Acc: (99.32%) (29366/29568)\n",
            "Epoch: 128 | Batch_idx: 240 |  Loss: (0.0251) | Acc: (99.31%) (30636/30848)\n",
            "Epoch: 128 | Batch_idx: 250 |  Loss: (0.0250) | Acc: (99.32%) (31910/32128)\n",
            "Epoch: 128 | Batch_idx: 260 |  Loss: (0.0250) | Acc: (99.32%) (33180/33408)\n",
            "Epoch: 128 | Batch_idx: 270 |  Loss: (0.0250) | Acc: (99.31%) (34448/34688)\n",
            "Epoch: 128 | Batch_idx: 280 |  Loss: (0.0249) | Acc: (99.31%) (35720/35968)\n",
            "Epoch: 128 | Batch_idx: 290 |  Loss: (0.0248) | Acc: (99.32%) (36994/37248)\n",
            "Epoch: 128 | Batch_idx: 300 |  Loss: (0.0248) | Acc: (99.31%) (38261/38528)\n",
            "Epoch: 128 | Batch_idx: 310 |  Loss: (0.0250) | Acc: (99.29%) (39526/39808)\n",
            "Epoch: 128 | Batch_idx: 320 |  Loss: (0.0251) | Acc: (99.28%) (40792/41088)\n",
            "Epoch: 128 | Batch_idx: 330 |  Loss: (0.0250) | Acc: (99.28%) (42061/42368)\n",
            "Epoch: 128 | Batch_idx: 340 |  Loss: (0.0249) | Acc: (99.28%) (43333/43648)\n",
            "Epoch: 128 | Batch_idx: 350 |  Loss: (0.0248) | Acc: (99.28%) (44604/44928)\n",
            "Epoch: 128 | Batch_idx: 360 |  Loss: (0.0249) | Acc: (99.28%) (45873/46208)\n",
            "Epoch: 128 | Batch_idx: 370 |  Loss: (0.0248) | Acc: (99.28%) (47145/47488)\n",
            "Epoch: 128 | Batch_idx: 380 |  Loss: (0.0248) | Acc: (99.27%) (48413/48768)\n",
            "Epoch: 128 | Batch_idx: 390 |  Loss: (0.0249) | Acc: (99.27%) (49633/50000)\n",
            "# TEST : Loss: (0.3585) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 129 | Batch_idx: 0 |  Loss: (0.0587) | Acc: (97.66%) (125/128)\n",
            "Epoch: 129 | Batch_idx: 10 |  Loss: (0.0244) | Acc: (99.36%) (1399/1408)\n",
            "Epoch: 129 | Batch_idx: 20 |  Loss: (0.0292) | Acc: (99.07%) (2663/2688)\n",
            "Epoch: 129 | Batch_idx: 30 |  Loss: (0.0262) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 129 | Batch_idx: 40 |  Loss: (0.0263) | Acc: (99.12%) (5202/5248)\n",
            "Epoch: 129 | Batch_idx: 50 |  Loss: (0.0255) | Acc: (99.17%) (6474/6528)\n",
            "Epoch: 129 | Batch_idx: 60 |  Loss: (0.0262) | Acc: (99.15%) (7742/7808)\n",
            "Epoch: 129 | Batch_idx: 70 |  Loss: (0.0257) | Acc: (99.20%) (9015/9088)\n",
            "Epoch: 129 | Batch_idx: 80 |  Loss: (0.0256) | Acc: (99.20%) (10285/10368)\n",
            "Epoch: 129 | Batch_idx: 90 |  Loss: (0.0256) | Acc: (99.20%) (11555/11648)\n",
            "Epoch: 129 | Batch_idx: 100 |  Loss: (0.0256) | Acc: (99.20%) (12825/12928)\n",
            "Epoch: 129 | Batch_idx: 110 |  Loss: (0.0250) | Acc: (99.22%) (14097/14208)\n",
            "Epoch: 129 | Batch_idx: 120 |  Loss: (0.0254) | Acc: (99.22%) (15367/15488)\n",
            "Epoch: 129 | Batch_idx: 130 |  Loss: (0.0250) | Acc: (99.22%) (16638/16768)\n",
            "Epoch: 129 | Batch_idx: 140 |  Loss: (0.0249) | Acc: (99.25%) (17912/18048)\n",
            "Epoch: 129 | Batch_idx: 150 |  Loss: (0.0250) | Acc: (99.24%) (19181/19328)\n",
            "Epoch: 129 | Batch_idx: 160 |  Loss: (0.0250) | Acc: (99.25%) (20454/20608)\n",
            "Epoch: 129 | Batch_idx: 170 |  Loss: (0.0249) | Acc: (99.26%) (21725/21888)\n",
            "Epoch: 129 | Batch_idx: 180 |  Loss: (0.0247) | Acc: (99.27%) (22998/23168)\n",
            "Epoch: 129 | Batch_idx: 190 |  Loss: (0.0251) | Acc: (99.25%) (24264/24448)\n",
            "Epoch: 129 | Batch_idx: 200 |  Loss: (0.0250) | Acc: (99.26%) (25537/25728)\n",
            "Epoch: 129 | Batch_idx: 210 |  Loss: (0.0246) | Acc: (99.27%) (26811/27008)\n",
            "Epoch: 129 | Batch_idx: 220 |  Loss: (0.0249) | Acc: (99.27%) (28081/28288)\n",
            "Epoch: 129 | Batch_idx: 230 |  Loss: (0.0246) | Acc: (99.28%) (29356/29568)\n",
            "Epoch: 129 | Batch_idx: 240 |  Loss: (0.0248) | Acc: (99.27%) (30622/30848)\n",
            "Epoch: 129 | Batch_idx: 250 |  Loss: (0.0248) | Acc: (99.26%) (31889/32128)\n",
            "Epoch: 129 | Batch_idx: 260 |  Loss: (0.0249) | Acc: (99.26%) (33160/33408)\n",
            "Epoch: 129 | Batch_idx: 270 |  Loss: (0.0246) | Acc: (99.27%) (34435/34688)\n",
            "Epoch: 129 | Batch_idx: 280 |  Loss: (0.0243) | Acc: (99.29%) (35713/35968)\n",
            "Epoch: 129 | Batch_idx: 290 |  Loss: (0.0242) | Acc: (99.30%) (36987/37248)\n",
            "Epoch: 129 | Batch_idx: 300 |  Loss: (0.0243) | Acc: (99.30%) (38259/38528)\n",
            "Epoch: 129 | Batch_idx: 310 |  Loss: (0.0242) | Acc: (99.30%) (39530/39808)\n",
            "Epoch: 129 | Batch_idx: 320 |  Loss: (0.0242) | Acc: (99.30%) (40802/41088)\n",
            "Epoch: 129 | Batch_idx: 330 |  Loss: (0.0241) | Acc: (99.31%) (42074/42368)\n",
            "Epoch: 129 | Batch_idx: 340 |  Loss: (0.0240) | Acc: (99.31%) (43348/43648)\n",
            "Epoch: 129 | Batch_idx: 350 |  Loss: (0.0243) | Acc: (99.31%) (44618/44928)\n",
            "Epoch: 129 | Batch_idx: 360 |  Loss: (0.0242) | Acc: (99.31%) (45888/46208)\n",
            "Epoch: 129 | Batch_idx: 370 |  Loss: (0.0245) | Acc: (99.30%) (47154/47488)\n",
            "Epoch: 129 | Batch_idx: 380 |  Loss: (0.0246) | Acc: (99.28%) (48418/48768)\n",
            "Epoch: 129 | Batch_idx: 390 |  Loss: (0.0245) | Acc: (99.29%) (49643/50000)\n",
            "# TEST : Loss: (0.3581) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 130 | Batch_idx: 0 |  Loss: (0.0155) | Acc: (100.00%) (128/128)\n",
            "Epoch: 130 | Batch_idx: 10 |  Loss: (0.0203) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 130 | Batch_idx: 20 |  Loss: (0.0194) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 130 | Batch_idx: 30 |  Loss: (0.0197) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 130 | Batch_idx: 40 |  Loss: (0.0202) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 130 | Batch_idx: 50 |  Loss: (0.0219) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 130 | Batch_idx: 60 |  Loss: (0.0222) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 130 | Batch_idx: 70 |  Loss: (0.0216) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 130 | Batch_idx: 80 |  Loss: (0.0209) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 130 | Batch_idx: 90 |  Loss: (0.0208) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 130 | Batch_idx: 100 |  Loss: (0.0214) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 130 | Batch_idx: 110 |  Loss: (0.0220) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 130 | Batch_idx: 120 |  Loss: (0.0222) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 130 | Batch_idx: 130 |  Loss: (0.0224) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 130 | Batch_idx: 140 |  Loss: (0.0232) | Acc: (99.40%) (17939/18048)\n",
            "Epoch: 130 | Batch_idx: 150 |  Loss: (0.0233) | Acc: (99.38%) (19209/19328)\n",
            "Epoch: 130 | Batch_idx: 160 |  Loss: (0.0234) | Acc: (99.36%) (20477/20608)\n",
            "Epoch: 130 | Batch_idx: 170 |  Loss: (0.0232) | Acc: (99.37%) (21750/21888)\n",
            "Epoch: 130 | Batch_idx: 180 |  Loss: (0.0233) | Acc: (99.36%) (23019/23168)\n",
            "Epoch: 130 | Batch_idx: 190 |  Loss: (0.0231) | Acc: (99.37%) (24293/24448)\n",
            "Epoch: 130 | Batch_idx: 200 |  Loss: (0.0231) | Acc: (99.36%) (25564/25728)\n",
            "Epoch: 130 | Batch_idx: 210 |  Loss: (0.0234) | Acc: (99.36%) (26834/27008)\n",
            "Epoch: 130 | Batch_idx: 220 |  Loss: (0.0232) | Acc: (99.36%) (28108/28288)\n",
            "Epoch: 130 | Batch_idx: 230 |  Loss: (0.0233) | Acc: (99.36%) (29378/29568)\n",
            "Epoch: 130 | Batch_idx: 240 |  Loss: (0.0231) | Acc: (99.36%) (30651/30848)\n",
            "Epoch: 130 | Batch_idx: 250 |  Loss: (0.0230) | Acc: (99.37%) (31924/32128)\n",
            "Epoch: 130 | Batch_idx: 260 |  Loss: (0.0230) | Acc: (99.37%) (33198/33408)\n",
            "Epoch: 130 | Batch_idx: 270 |  Loss: (0.0230) | Acc: (99.37%) (34470/34688)\n",
            "Epoch: 130 | Batch_idx: 280 |  Loss: (0.0230) | Acc: (99.36%) (35738/35968)\n",
            "Epoch: 130 | Batch_idx: 290 |  Loss: (0.0232) | Acc: (99.35%) (37005/37248)\n",
            "Epoch: 130 | Batch_idx: 300 |  Loss: (0.0232) | Acc: (99.34%) (38273/38528)\n",
            "Epoch: 130 | Batch_idx: 310 |  Loss: (0.0232) | Acc: (99.34%) (39544/39808)\n",
            "Epoch: 130 | Batch_idx: 320 |  Loss: (0.0231) | Acc: (99.34%) (40817/41088)\n",
            "Epoch: 130 | Batch_idx: 330 |  Loss: (0.0229) | Acc: (99.35%) (42091/42368)\n",
            "Epoch: 130 | Batch_idx: 340 |  Loss: (0.0231) | Acc: (99.34%) (43359/43648)\n",
            "Epoch: 130 | Batch_idx: 350 |  Loss: (0.0230) | Acc: (99.35%) (44634/44928)\n",
            "Epoch: 130 | Batch_idx: 360 |  Loss: (0.0230) | Acc: (99.35%) (45906/46208)\n",
            "Epoch: 130 | Batch_idx: 370 |  Loss: (0.0230) | Acc: (99.34%) (47176/47488)\n",
            "Epoch: 130 | Batch_idx: 380 |  Loss: (0.0232) | Acc: (99.32%) (48438/48768)\n",
            "Epoch: 130 | Batch_idx: 390 |  Loss: (0.0232) | Acc: (99.33%) (49664/50000)\n",
            "# TEST : Loss: (0.3572) | Acc: (91.93%) (9193/10000)\n",
            "Epoch: 131 | Batch_idx: 0 |  Loss: (0.0081) | Acc: (100.00%) (128/128)\n",
            "Epoch: 131 | Batch_idx: 10 |  Loss: (0.0278) | Acc: (99.01%) (1394/1408)\n",
            "Epoch: 131 | Batch_idx: 20 |  Loss: (0.0258) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 131 | Batch_idx: 30 |  Loss: (0.0239) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 131 | Batch_idx: 40 |  Loss: (0.0239) | Acc: (99.16%) (5204/5248)\n",
            "Epoch: 131 | Batch_idx: 50 |  Loss: (0.0242) | Acc: (99.19%) (6475/6528)\n",
            "Epoch: 131 | Batch_idx: 60 |  Loss: (0.0233) | Acc: (99.26%) (7750/7808)\n",
            "Epoch: 131 | Batch_idx: 70 |  Loss: (0.0230) | Acc: (99.28%) (9023/9088)\n",
            "Epoch: 131 | Batch_idx: 80 |  Loss: (0.0222) | Acc: (99.32%) (10297/10368)\n",
            "Epoch: 131 | Batch_idx: 90 |  Loss: (0.0230) | Acc: (99.29%) (11565/11648)\n",
            "Epoch: 131 | Batch_idx: 100 |  Loss: (0.0227) | Acc: (99.30%) (12838/12928)\n",
            "Epoch: 131 | Batch_idx: 110 |  Loss: (0.0233) | Acc: (99.26%) (14103/14208)\n",
            "Epoch: 131 | Batch_idx: 120 |  Loss: (0.0229) | Acc: (99.29%) (15378/15488)\n",
            "Epoch: 131 | Batch_idx: 130 |  Loss: (0.0228) | Acc: (99.28%) (16647/16768)\n",
            "Epoch: 131 | Batch_idx: 140 |  Loss: (0.0232) | Acc: (99.26%) (17915/18048)\n",
            "Epoch: 131 | Batch_idx: 150 |  Loss: (0.0233) | Acc: (99.28%) (19188/19328)\n",
            "Epoch: 131 | Batch_idx: 160 |  Loss: (0.0230) | Acc: (99.30%) (20463/20608)\n",
            "Epoch: 131 | Batch_idx: 170 |  Loss: (0.0229) | Acc: (99.30%) (21734/21888)\n",
            "Epoch: 131 | Batch_idx: 180 |  Loss: (0.0226) | Acc: (99.31%) (23009/23168)\n",
            "Epoch: 131 | Batch_idx: 190 |  Loss: (0.0226) | Acc: (99.32%) (24281/24448)\n",
            "Epoch: 131 | Batch_idx: 200 |  Loss: (0.0229) | Acc: (99.28%) (25544/25728)\n",
            "Epoch: 131 | Batch_idx: 210 |  Loss: (0.0232) | Acc: (99.26%) (26809/27008)\n",
            "Epoch: 131 | Batch_idx: 220 |  Loss: (0.0233) | Acc: (99.26%) (28079/28288)\n",
            "Epoch: 131 | Batch_idx: 230 |  Loss: (0.0234) | Acc: (99.27%) (29353/29568)\n",
            "Epoch: 131 | Batch_idx: 240 |  Loss: (0.0237) | Acc: (99.26%) (30620/30848)\n",
            "Epoch: 131 | Batch_idx: 250 |  Loss: (0.0238) | Acc: (99.26%) (31890/32128)\n",
            "Epoch: 131 | Batch_idx: 260 |  Loss: (0.0235) | Acc: (99.27%) (33164/33408)\n",
            "Epoch: 131 | Batch_idx: 270 |  Loss: (0.0235) | Acc: (99.28%) (34438/34688)\n",
            "Epoch: 131 | Batch_idx: 280 |  Loss: (0.0235) | Acc: (99.28%) (35709/35968)\n",
            "Epoch: 131 | Batch_idx: 290 |  Loss: (0.0234) | Acc: (99.29%) (36984/37248)\n",
            "Epoch: 131 | Batch_idx: 300 |  Loss: (0.0231) | Acc: (99.30%) (38257/38528)\n",
            "Epoch: 131 | Batch_idx: 310 |  Loss: (0.0234) | Acc: (99.29%) (39524/39808)\n",
            "Epoch: 131 | Batch_idx: 320 |  Loss: (0.0235) | Acc: (99.28%) (40791/41088)\n",
            "Epoch: 131 | Batch_idx: 330 |  Loss: (0.0237) | Acc: (99.27%) (42059/42368)\n",
            "Epoch: 131 | Batch_idx: 340 |  Loss: (0.0237) | Acc: (99.27%) (43331/43648)\n",
            "Epoch: 131 | Batch_idx: 350 |  Loss: (0.0237) | Acc: (99.27%) (44601/44928)\n",
            "Epoch: 131 | Batch_idx: 360 |  Loss: (0.0237) | Acc: (99.27%) (45870/46208)\n",
            "Epoch: 131 | Batch_idx: 370 |  Loss: (0.0236) | Acc: (99.28%) (47145/47488)\n",
            "Epoch: 131 | Batch_idx: 380 |  Loss: (0.0236) | Acc: (99.27%) (48413/48768)\n",
            "Epoch: 131 | Batch_idx: 390 |  Loss: (0.0238) | Acc: (99.26%) (49630/50000)\n",
            "# TEST : Loss: (0.3564) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 132 | Batch_idx: 0 |  Loss: (0.0491) | Acc: (98.44%) (126/128)\n",
            "Epoch: 132 | Batch_idx: 10 |  Loss: (0.0236) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 132 | Batch_idx: 20 |  Loss: (0.0239) | Acc: (99.18%) (2666/2688)\n",
            "Epoch: 132 | Batch_idx: 30 |  Loss: (0.0273) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 132 | Batch_idx: 40 |  Loss: (0.0261) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 132 | Batch_idx: 50 |  Loss: (0.0240) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 132 | Batch_idx: 60 |  Loss: (0.0229) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 132 | Batch_idx: 70 |  Loss: (0.0240) | Acc: (99.32%) (9026/9088)\n",
            "Epoch: 132 | Batch_idx: 80 |  Loss: (0.0242) | Acc: (99.30%) (10295/10368)\n",
            "Epoch: 132 | Batch_idx: 90 |  Loss: (0.0236) | Acc: (99.31%) (11568/11648)\n",
            "Epoch: 132 | Batch_idx: 100 |  Loss: (0.0238) | Acc: (99.33%) (12841/12928)\n",
            "Epoch: 132 | Batch_idx: 110 |  Loss: (0.0233) | Acc: (99.34%) (14114/14208)\n",
            "Epoch: 132 | Batch_idx: 120 |  Loss: (0.0238) | Acc: (99.30%) (15380/15488)\n",
            "Epoch: 132 | Batch_idx: 130 |  Loss: (0.0237) | Acc: (99.30%) (16651/16768)\n",
            "Epoch: 132 | Batch_idx: 140 |  Loss: (0.0238) | Acc: (99.29%) (17919/18048)\n",
            "Epoch: 132 | Batch_idx: 150 |  Loss: (0.0243) | Acc: (99.28%) (19188/19328)\n",
            "Epoch: 132 | Batch_idx: 160 |  Loss: (0.0238) | Acc: (99.30%) (20464/20608)\n",
            "Epoch: 132 | Batch_idx: 170 |  Loss: (0.0242) | Acc: (99.28%) (21731/21888)\n",
            "Epoch: 132 | Batch_idx: 180 |  Loss: (0.0243) | Acc: (99.29%) (23003/23168)\n",
            "Epoch: 132 | Batch_idx: 190 |  Loss: (0.0241) | Acc: (99.30%) (24277/24448)\n",
            "Epoch: 132 | Batch_idx: 200 |  Loss: (0.0240) | Acc: (99.30%) (25549/25728)\n",
            "Epoch: 132 | Batch_idx: 210 |  Loss: (0.0240) | Acc: (99.32%) (26823/27008)\n",
            "Epoch: 132 | Batch_idx: 220 |  Loss: (0.0240) | Acc: (99.32%) (28095/28288)\n",
            "Epoch: 132 | Batch_idx: 230 |  Loss: (0.0239) | Acc: (99.32%) (29368/29568)\n",
            "Epoch: 132 | Batch_idx: 240 |  Loss: (0.0242) | Acc: (99.30%) (30631/30848)\n",
            "Epoch: 132 | Batch_idx: 250 |  Loss: (0.0240) | Acc: (99.31%) (31907/32128)\n",
            "Epoch: 132 | Batch_idx: 260 |  Loss: (0.0240) | Acc: (99.30%) (33175/33408)\n",
            "Epoch: 132 | Batch_idx: 270 |  Loss: (0.0243) | Acc: (99.29%) (34442/34688)\n",
            "Epoch: 132 | Batch_idx: 280 |  Loss: (0.0245) | Acc: (99.29%) (35711/35968)\n",
            "Epoch: 132 | Batch_idx: 290 |  Loss: (0.0247) | Acc: (99.29%) (36982/37248)\n",
            "Epoch: 132 | Batch_idx: 300 |  Loss: (0.0244) | Acc: (99.30%) (38259/38528)\n",
            "Epoch: 132 | Batch_idx: 310 |  Loss: (0.0243) | Acc: (99.32%) (39536/39808)\n",
            "Epoch: 132 | Batch_idx: 320 |  Loss: (0.0241) | Acc: (99.33%) (40812/41088)\n",
            "Epoch: 132 | Batch_idx: 330 |  Loss: (0.0239) | Acc: (99.33%) (42086/42368)\n",
            "Epoch: 132 | Batch_idx: 340 |  Loss: (0.0239) | Acc: (99.33%) (43357/43648)\n",
            "Epoch: 132 | Batch_idx: 350 |  Loss: (0.0239) | Acc: (99.33%) (44626/44928)\n",
            "Epoch: 132 | Batch_idx: 360 |  Loss: (0.0239) | Acc: (99.33%) (45897/46208)\n",
            "Epoch: 132 | Batch_idx: 370 |  Loss: (0.0239) | Acc: (99.33%) (47169/47488)\n",
            "Epoch: 132 | Batch_idx: 380 |  Loss: (0.0239) | Acc: (99.33%) (48439/48768)\n",
            "Epoch: 132 | Batch_idx: 390 |  Loss: (0.0239) | Acc: (99.32%) (49662/50000)\n",
            "# TEST : Loss: (0.3582) | Acc: (91.90%) (9190/10000)\n",
            "Epoch: 133 | Batch_idx: 0 |  Loss: (0.0506) | Acc: (96.09%) (123/128)\n",
            "Epoch: 133 | Batch_idx: 10 |  Loss: (0.0275) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 133 | Batch_idx: 20 |  Loss: (0.0239) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 133 | Batch_idx: 30 |  Loss: (0.0243) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 133 | Batch_idx: 40 |  Loss: (0.0258) | Acc: (99.18%) (5205/5248)\n",
            "Epoch: 133 | Batch_idx: 50 |  Loss: (0.0255) | Acc: (99.23%) (6478/6528)\n",
            "Epoch: 133 | Batch_idx: 60 |  Loss: (0.0256) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 133 | Batch_idx: 70 |  Loss: (0.0265) | Acc: (99.26%) (9021/9088)\n",
            "Epoch: 133 | Batch_idx: 80 |  Loss: (0.0257) | Acc: (99.30%) (10295/10368)\n",
            "Epoch: 133 | Batch_idx: 90 |  Loss: (0.0259) | Acc: (99.30%) (11566/11648)\n",
            "Epoch: 133 | Batch_idx: 100 |  Loss: (0.0256) | Acc: (99.28%) (12835/12928)\n",
            "Epoch: 133 | Batch_idx: 110 |  Loss: (0.0259) | Acc: (99.25%) (14101/14208)\n",
            "Epoch: 133 | Batch_idx: 120 |  Loss: (0.0257) | Acc: (99.26%) (15373/15488)\n",
            "Epoch: 133 | Batch_idx: 130 |  Loss: (0.0253) | Acc: (99.26%) (16644/16768)\n",
            "Epoch: 133 | Batch_idx: 140 |  Loss: (0.0249) | Acc: (99.27%) (17917/18048)\n",
            "Epoch: 133 | Batch_idx: 150 |  Loss: (0.0246) | Acc: (99.29%) (19191/19328)\n",
            "Epoch: 133 | Batch_idx: 160 |  Loss: (0.0244) | Acc: (99.29%) (20462/20608)\n",
            "Epoch: 133 | Batch_idx: 170 |  Loss: (0.0245) | Acc: (99.28%) (21730/21888)\n",
            "Epoch: 133 | Batch_idx: 180 |  Loss: (0.0244) | Acc: (99.27%) (22999/23168)\n",
            "Epoch: 133 | Batch_idx: 190 |  Loss: (0.0243) | Acc: (99.27%) (24270/24448)\n",
            "Epoch: 133 | Batch_idx: 200 |  Loss: (0.0243) | Acc: (99.29%) (25545/25728)\n",
            "Epoch: 133 | Batch_idx: 210 |  Loss: (0.0246) | Acc: (99.27%) (26812/27008)\n",
            "Epoch: 133 | Batch_idx: 220 |  Loss: (0.0245) | Acc: (99.28%) (28083/28288)\n",
            "Epoch: 133 | Batch_idx: 230 |  Loss: (0.0247) | Acc: (99.28%) (29354/29568)\n",
            "Epoch: 133 | Batch_idx: 240 |  Loss: (0.0246) | Acc: (99.28%) (30626/30848)\n",
            "Epoch: 133 | Batch_idx: 250 |  Loss: (0.0244) | Acc: (99.30%) (31902/32128)\n",
            "Epoch: 133 | Batch_idx: 260 |  Loss: (0.0242) | Acc: (99.30%) (33174/33408)\n",
            "Epoch: 133 | Batch_idx: 270 |  Loss: (0.0240) | Acc: (99.31%) (34448/34688)\n",
            "Epoch: 133 | Batch_idx: 280 |  Loss: (0.0239) | Acc: (99.32%) (35723/35968)\n",
            "Epoch: 133 | Batch_idx: 290 |  Loss: (0.0242) | Acc: (99.30%) (36988/37248)\n",
            "Epoch: 133 | Batch_idx: 300 |  Loss: (0.0242) | Acc: (99.30%) (38257/38528)\n",
            "Epoch: 133 | Batch_idx: 310 |  Loss: (0.0239) | Acc: (99.31%) (39532/39808)\n",
            "Epoch: 133 | Batch_idx: 320 |  Loss: (0.0238) | Acc: (99.32%) (40807/41088)\n",
            "Epoch: 133 | Batch_idx: 330 |  Loss: (0.0239) | Acc: (99.31%) (42077/42368)\n",
            "Epoch: 133 | Batch_idx: 340 |  Loss: (0.0237) | Acc: (99.32%) (43351/43648)\n",
            "Epoch: 133 | Batch_idx: 350 |  Loss: (0.0236) | Acc: (99.33%) (44626/44928)\n",
            "Epoch: 133 | Batch_idx: 360 |  Loss: (0.0236) | Acc: (99.32%) (45896/46208)\n",
            "Epoch: 133 | Batch_idx: 370 |  Loss: (0.0236) | Acc: (99.33%) (47168/47488)\n",
            "Epoch: 133 | Batch_idx: 380 |  Loss: (0.0234) | Acc: (99.33%) (48442/48768)\n",
            "Epoch: 133 | Batch_idx: 390 |  Loss: (0.0235) | Acc: (99.33%) (49663/50000)\n",
            "# TEST : Loss: (0.3570) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 134 | Batch_idx: 0 |  Loss: (0.0438) | Acc: (99.22%) (127/128)\n",
            "Epoch: 134 | Batch_idx: 10 |  Loss: (0.0224) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 134 | Batch_idx: 20 |  Loss: (0.0249) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 134 | Batch_idx: 30 |  Loss: (0.0227) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 134 | Batch_idx: 40 |  Loss: (0.0220) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 134 | Batch_idx: 50 |  Loss: (0.0214) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 134 | Batch_idx: 60 |  Loss: (0.0209) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 134 | Batch_idx: 70 |  Loss: (0.0210) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 134 | Batch_idx: 80 |  Loss: (0.0214) | Acc: (99.37%) (10303/10368)\n",
            "Epoch: 134 | Batch_idx: 90 |  Loss: (0.0216) | Acc: (99.38%) (11576/11648)\n",
            "Epoch: 134 | Batch_idx: 100 |  Loss: (0.0211) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 134 | Batch_idx: 110 |  Loss: (0.0217) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 134 | Batch_idx: 120 |  Loss: (0.0214) | Acc: (99.39%) (15394/15488)\n",
            "Epoch: 134 | Batch_idx: 130 |  Loss: (0.0214) | Acc: (99.40%) (16668/16768)\n",
            "Epoch: 134 | Batch_idx: 140 |  Loss: (0.0216) | Acc: (99.41%) (17941/18048)\n",
            "Epoch: 134 | Batch_idx: 150 |  Loss: (0.0222) | Acc: (99.39%) (19210/19328)\n",
            "Epoch: 134 | Batch_idx: 160 |  Loss: (0.0225) | Acc: (99.37%) (20479/20608)\n",
            "Epoch: 134 | Batch_idx: 170 |  Loss: (0.0223) | Acc: (99.38%) (21753/21888)\n",
            "Epoch: 134 | Batch_idx: 180 |  Loss: (0.0227) | Acc: (99.37%) (23022/23168)\n",
            "Epoch: 134 | Batch_idx: 190 |  Loss: (0.0227) | Acc: (99.37%) (24293/24448)\n",
            "Epoch: 134 | Batch_idx: 200 |  Loss: (0.0230) | Acc: (99.35%) (25562/25728)\n",
            "Epoch: 134 | Batch_idx: 210 |  Loss: (0.0232) | Acc: (99.33%) (26828/27008)\n",
            "Epoch: 134 | Batch_idx: 220 |  Loss: (0.0229) | Acc: (99.34%) (28102/28288)\n",
            "Epoch: 134 | Batch_idx: 230 |  Loss: (0.0229) | Acc: (99.35%) (29376/29568)\n",
            "Epoch: 134 | Batch_idx: 240 |  Loss: (0.0230) | Acc: (99.35%) (30649/30848)\n",
            "Epoch: 134 | Batch_idx: 250 |  Loss: (0.0227) | Acc: (99.37%) (31926/32128)\n",
            "Epoch: 134 | Batch_idx: 260 |  Loss: (0.0226) | Acc: (99.37%) (33199/33408)\n",
            "Epoch: 134 | Batch_idx: 270 |  Loss: (0.0228) | Acc: (99.37%) (34468/34688)\n",
            "Epoch: 134 | Batch_idx: 280 |  Loss: (0.0228) | Acc: (99.37%) (35742/35968)\n",
            "Epoch: 134 | Batch_idx: 290 |  Loss: (0.0227) | Acc: (99.38%) (37017/37248)\n",
            "Epoch: 134 | Batch_idx: 300 |  Loss: (0.0226) | Acc: (99.38%) (38290/38528)\n",
            "Epoch: 134 | Batch_idx: 310 |  Loss: (0.0226) | Acc: (99.38%) (39561/39808)\n",
            "Epoch: 134 | Batch_idx: 320 |  Loss: (0.0227) | Acc: (99.36%) (40826/41088)\n",
            "Epoch: 134 | Batch_idx: 330 |  Loss: (0.0227) | Acc: (99.36%) (42097/42368)\n",
            "Epoch: 134 | Batch_idx: 340 |  Loss: (0.0227) | Acc: (99.36%) (43367/43648)\n",
            "Epoch: 134 | Batch_idx: 350 |  Loss: (0.0228) | Acc: (99.35%) (44637/44928)\n",
            "Epoch: 134 | Batch_idx: 360 |  Loss: (0.0228) | Acc: (99.36%) (45910/46208)\n",
            "Epoch: 134 | Batch_idx: 370 |  Loss: (0.0228) | Acc: (99.36%) (47184/47488)\n",
            "Epoch: 134 | Batch_idx: 380 |  Loss: (0.0229) | Acc: (99.35%) (48451/48768)\n",
            "Epoch: 134 | Batch_idx: 390 |  Loss: (0.0229) | Acc: (99.35%) (49675/50000)\n",
            "# TEST : Loss: (0.3595) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 135 | Batch_idx: 0 |  Loss: (0.0295) | Acc: (99.22%) (127/128)\n",
            "Epoch: 135 | Batch_idx: 10 |  Loss: (0.0186) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 135 | Batch_idx: 20 |  Loss: (0.0233) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 135 | Batch_idx: 30 |  Loss: (0.0219) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 135 | Batch_idx: 40 |  Loss: (0.0232) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 135 | Batch_idx: 50 |  Loss: (0.0228) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 135 | Batch_idx: 60 |  Loss: (0.0224) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 135 | Batch_idx: 70 |  Loss: (0.0215) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 135 | Batch_idx: 80 |  Loss: (0.0211) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 135 | Batch_idx: 90 |  Loss: (0.0208) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 135 | Batch_idx: 100 |  Loss: (0.0212) | Acc: (99.47%) (12859/12928)\n",
            "Epoch: 135 | Batch_idx: 110 |  Loss: (0.0220) | Acc: (99.44%) (14128/14208)\n",
            "Epoch: 135 | Batch_idx: 120 |  Loss: (0.0220) | Acc: (99.43%) (15399/15488)\n",
            "Epoch: 135 | Batch_idx: 130 |  Loss: (0.0224) | Acc: (99.40%) (16668/16768)\n",
            "Epoch: 135 | Batch_idx: 140 |  Loss: (0.0225) | Acc: (99.40%) (17939/18048)\n",
            "Epoch: 135 | Batch_idx: 150 |  Loss: (0.0225) | Acc: (99.39%) (19211/19328)\n",
            "Epoch: 135 | Batch_idx: 160 |  Loss: (0.0221) | Acc: (99.41%) (20486/20608)\n",
            "Epoch: 135 | Batch_idx: 170 |  Loss: (0.0218) | Acc: (99.43%) (21763/21888)\n",
            "Epoch: 135 | Batch_idx: 180 |  Loss: (0.0219) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 135 | Batch_idx: 190 |  Loss: (0.0222) | Acc: (99.39%) (24300/24448)\n",
            "Epoch: 135 | Batch_idx: 200 |  Loss: (0.0223) | Acc: (99.37%) (25567/25728)\n",
            "Epoch: 135 | Batch_idx: 210 |  Loss: (0.0221) | Acc: (99.39%) (26842/27008)\n",
            "Epoch: 135 | Batch_idx: 220 |  Loss: (0.0220) | Acc: (99.39%) (28115/28288)\n",
            "Epoch: 135 | Batch_idx: 230 |  Loss: (0.0219) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 135 | Batch_idx: 240 |  Loss: (0.0221) | Acc: (99.39%) (30659/30848)\n",
            "Epoch: 135 | Batch_idx: 250 |  Loss: (0.0223) | Acc: (99.37%) (31927/32128)\n",
            "Epoch: 135 | Batch_idx: 260 |  Loss: (0.0226) | Acc: (99.37%) (33196/33408)\n",
            "Epoch: 135 | Batch_idx: 270 |  Loss: (0.0225) | Acc: (99.36%) (34467/34688)\n",
            "Epoch: 135 | Batch_idx: 280 |  Loss: (0.0225) | Acc: (99.36%) (35738/35968)\n",
            "Epoch: 135 | Batch_idx: 290 |  Loss: (0.0225) | Acc: (99.36%) (37009/37248)\n",
            "Epoch: 135 | Batch_idx: 300 |  Loss: (0.0225) | Acc: (99.36%) (38281/38528)\n",
            "Epoch: 135 | Batch_idx: 310 |  Loss: (0.0227) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 135 | Batch_idx: 320 |  Loss: (0.0226) | Acc: (99.36%) (40823/41088)\n",
            "Epoch: 135 | Batch_idx: 330 |  Loss: (0.0227) | Acc: (99.36%) (42095/42368)\n",
            "Epoch: 135 | Batch_idx: 340 |  Loss: (0.0228) | Acc: (99.36%) (43367/43648)\n",
            "Epoch: 135 | Batch_idx: 350 |  Loss: (0.0229) | Acc: (99.35%) (44634/44928)\n",
            "Epoch: 135 | Batch_idx: 360 |  Loss: (0.0231) | Acc: (99.34%) (45902/46208)\n",
            "Epoch: 135 | Batch_idx: 370 |  Loss: (0.0234) | Acc: (99.32%) (47166/47488)\n",
            "Epoch: 135 | Batch_idx: 380 |  Loss: (0.0232) | Acc: (99.33%) (48442/48768)\n",
            "Epoch: 135 | Batch_idx: 390 |  Loss: (0.0231) | Acc: (99.33%) (49666/50000)\n",
            "# TEST : Loss: (0.3578) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 136 | Batch_idx: 0 |  Loss: (0.0189) | Acc: (99.22%) (127/128)\n",
            "Epoch: 136 | Batch_idx: 10 |  Loss: (0.0204) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 136 | Batch_idx: 20 |  Loss: (0.0178) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 136 | Batch_idx: 30 |  Loss: (0.0207) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 136 | Batch_idx: 40 |  Loss: (0.0221) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 136 | Batch_idx: 50 |  Loss: (0.0221) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 136 | Batch_idx: 60 |  Loss: (0.0216) | Acc: (99.45%) (7765/7808)\n",
            "Epoch: 136 | Batch_idx: 70 |  Loss: (0.0213) | Acc: (99.46%) (9039/9088)\n",
            "Epoch: 136 | Batch_idx: 80 |  Loss: (0.0215) | Acc: (99.45%) (10311/10368)\n",
            "Epoch: 136 | Batch_idx: 90 |  Loss: (0.0212) | Acc: (99.47%) (11586/11648)\n",
            "Epoch: 136 | Batch_idx: 100 |  Loss: (0.0216) | Acc: (99.44%) (12855/12928)\n",
            "Epoch: 136 | Batch_idx: 110 |  Loss: (0.0211) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 136 | Batch_idx: 120 |  Loss: (0.0213) | Acc: (99.45%) (15403/15488)\n",
            "Epoch: 136 | Batch_idx: 130 |  Loss: (0.0213) | Acc: (99.45%) (16675/16768)\n",
            "Epoch: 136 | Batch_idx: 140 |  Loss: (0.0212) | Acc: (99.44%) (17947/18048)\n",
            "Epoch: 136 | Batch_idx: 150 |  Loss: (0.0213) | Acc: (99.43%) (19218/19328)\n",
            "Epoch: 136 | Batch_idx: 160 |  Loss: (0.0215) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 136 | Batch_idx: 170 |  Loss: (0.0212) | Acc: (99.42%) (21762/21888)\n",
            "Epoch: 136 | Batch_idx: 180 |  Loss: (0.0214) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 136 | Batch_idx: 190 |  Loss: (0.0214) | Acc: (99.42%) (24306/24448)\n",
            "Epoch: 136 | Batch_idx: 200 |  Loss: (0.0215) | Acc: (99.40%) (25574/25728)\n",
            "Epoch: 136 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.41%) (26848/27008)\n",
            "Epoch: 136 | Batch_idx: 220 |  Loss: (0.0215) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 136 | Batch_idx: 230 |  Loss: (0.0213) | Acc: (99.41%) (29395/29568)\n",
            "Epoch: 136 | Batch_idx: 240 |  Loss: (0.0211) | Acc: (99.42%) (30669/30848)\n",
            "Epoch: 136 | Batch_idx: 250 |  Loss: (0.0211) | Acc: (99.41%) (31939/32128)\n",
            "Epoch: 136 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.42%) (33213/33408)\n",
            "Epoch: 136 | Batch_idx: 270 |  Loss: (0.0212) | Acc: (99.42%) (34486/34688)\n",
            "Epoch: 136 | Batch_idx: 280 |  Loss: (0.0211) | Acc: (99.42%) (35761/35968)\n",
            "Epoch: 136 | Batch_idx: 290 |  Loss: (0.0211) | Acc: (99.42%) (37033/37248)\n",
            "Epoch: 136 | Batch_idx: 300 |  Loss: (0.0212) | Acc: (99.41%) (38302/38528)\n",
            "Epoch: 136 | Batch_idx: 310 |  Loss: (0.0211) | Acc: (99.42%) (39579/39808)\n",
            "Epoch: 136 | Batch_idx: 320 |  Loss: (0.0212) | Acc: (99.41%) (40847/41088)\n",
            "Epoch: 136 | Batch_idx: 330 |  Loss: (0.0215) | Acc: (99.40%) (42114/42368)\n",
            "Epoch: 136 | Batch_idx: 340 |  Loss: (0.0214) | Acc: (99.41%) (43389/43648)\n",
            "Epoch: 136 | Batch_idx: 350 |  Loss: (0.0214) | Acc: (99.41%) (44661/44928)\n",
            "Epoch: 136 | Batch_idx: 360 |  Loss: (0.0215) | Acc: (99.40%) (45933/46208)\n",
            "Epoch: 136 | Batch_idx: 370 |  Loss: (0.0214) | Acc: (99.41%) (47206/47488)\n",
            "Epoch: 136 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.41%) (48480/48768)\n",
            "Epoch: 136 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.42%) (49711/50000)\n",
            "# TEST : Loss: (0.3619) | Acc: (91.84%) (9184/10000)\n",
            "Epoch: 137 | Batch_idx: 0 |  Loss: (0.0134) | Acc: (100.00%) (128/128)\n",
            "Epoch: 137 | Batch_idx: 10 |  Loss: (0.0262) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 137 | Batch_idx: 20 |  Loss: (0.0279) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 137 | Batch_idx: 30 |  Loss: (0.0264) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 137 | Batch_idx: 40 |  Loss: (0.0244) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 137 | Batch_idx: 50 |  Loss: (0.0247) | Acc: (99.30%) (6482/6528)\n",
            "Epoch: 137 | Batch_idx: 60 |  Loss: (0.0257) | Acc: (99.24%) (7749/7808)\n",
            "Epoch: 137 | Batch_idx: 70 |  Loss: (0.0250) | Acc: (99.26%) (9021/9088)\n",
            "Epoch: 137 | Batch_idx: 80 |  Loss: (0.0252) | Acc: (99.25%) (10290/10368)\n",
            "Epoch: 137 | Batch_idx: 90 |  Loss: (0.0258) | Acc: (99.22%) (11557/11648)\n",
            "Epoch: 137 | Batch_idx: 100 |  Loss: (0.0259) | Acc: (99.21%) (12826/12928)\n",
            "Epoch: 137 | Batch_idx: 110 |  Loss: (0.0260) | Acc: (99.19%) (14093/14208)\n",
            "Epoch: 137 | Batch_idx: 120 |  Loss: (0.0251) | Acc: (99.23%) (15368/15488)\n",
            "Epoch: 137 | Batch_idx: 130 |  Loss: (0.0248) | Acc: (99.25%) (16643/16768)\n",
            "Epoch: 137 | Batch_idx: 140 |  Loss: (0.0244) | Acc: (99.27%) (17916/18048)\n",
            "Epoch: 137 | Batch_idx: 150 |  Loss: (0.0245) | Acc: (99.28%) (19188/19328)\n",
            "Epoch: 137 | Batch_idx: 160 |  Loss: (0.0243) | Acc: (99.29%) (20461/20608)\n",
            "Epoch: 137 | Batch_idx: 170 |  Loss: (0.0246) | Acc: (99.27%) (21729/21888)\n",
            "Epoch: 137 | Batch_idx: 180 |  Loss: (0.0246) | Acc: (99.29%) (23003/23168)\n",
            "Epoch: 137 | Batch_idx: 190 |  Loss: (0.0247) | Acc: (99.28%) (24273/24448)\n",
            "Epoch: 137 | Batch_idx: 200 |  Loss: (0.0247) | Acc: (99.28%) (25543/25728)\n",
            "Epoch: 137 | Batch_idx: 210 |  Loss: (0.0246) | Acc: (99.29%) (26815/27008)\n",
            "Epoch: 137 | Batch_idx: 220 |  Loss: (0.0242) | Acc: (99.30%) (28090/28288)\n",
            "Epoch: 137 | Batch_idx: 230 |  Loss: (0.0242) | Acc: (99.31%) (29363/29568)\n",
            "Epoch: 137 | Batch_idx: 240 |  Loss: (0.0240) | Acc: (99.32%) (30637/30848)\n",
            "Epoch: 137 | Batch_idx: 250 |  Loss: (0.0236) | Acc: (99.34%) (31915/32128)\n",
            "Epoch: 137 | Batch_idx: 260 |  Loss: (0.0238) | Acc: (99.33%) (33183/33408)\n",
            "Epoch: 137 | Batch_idx: 270 |  Loss: (0.0237) | Acc: (99.33%) (34456/34688)\n",
            "Epoch: 137 | Batch_idx: 280 |  Loss: (0.0234) | Acc: (99.35%) (35733/35968)\n",
            "Epoch: 137 | Batch_idx: 290 |  Loss: (0.0232) | Acc: (99.35%) (37007/37248)\n",
            "Epoch: 137 | Batch_idx: 300 |  Loss: (0.0230) | Acc: (99.36%) (38280/38528)\n",
            "Epoch: 137 | Batch_idx: 310 |  Loss: (0.0230) | Acc: (99.35%) (39551/39808)\n",
            "Epoch: 137 | Batch_idx: 320 |  Loss: (0.0229) | Acc: (99.36%) (40825/41088)\n",
            "Epoch: 137 | Batch_idx: 330 |  Loss: (0.0229) | Acc: (99.37%) (42100/42368)\n",
            "Epoch: 137 | Batch_idx: 340 |  Loss: (0.0228) | Acc: (99.37%) (43374/43648)\n",
            "Epoch: 137 | Batch_idx: 350 |  Loss: (0.0229) | Acc: (99.37%) (44646/44928)\n",
            "Epoch: 137 | Batch_idx: 360 |  Loss: (0.0229) | Acc: (99.37%) (45919/46208)\n",
            "Epoch: 137 | Batch_idx: 370 |  Loss: (0.0230) | Acc: (99.37%) (47191/47488)\n",
            "Epoch: 137 | Batch_idx: 380 |  Loss: (0.0231) | Acc: (99.37%) (48460/48768)\n",
            "Epoch: 137 | Batch_idx: 390 |  Loss: (0.0231) | Acc: (99.37%) (49686/50000)\n",
            "# TEST : Loss: (0.3571) | Acc: (91.80%) (9180/10000)\n",
            "Epoch: 138 | Batch_idx: 0 |  Loss: (0.0122) | Acc: (100.00%) (128/128)\n",
            "Epoch: 138 | Batch_idx: 10 |  Loss: (0.0177) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 138 | Batch_idx: 20 |  Loss: (0.0196) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 138 | Batch_idx: 30 |  Loss: (0.0201) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 138 | Batch_idx: 40 |  Loss: (0.0212) | Acc: (99.47%) (5220/5248)\n",
            "Epoch: 138 | Batch_idx: 50 |  Loss: (0.0213) | Acc: (99.45%) (6492/6528)\n",
            "Epoch: 138 | Batch_idx: 60 |  Loss: (0.0213) | Acc: (99.44%) (7764/7808)\n",
            "Epoch: 138 | Batch_idx: 70 |  Loss: (0.0214) | Acc: (99.42%) (9035/9088)\n",
            "Epoch: 138 | Batch_idx: 80 |  Loss: (0.0217) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 138 | Batch_idx: 90 |  Loss: (0.0214) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 138 | Batch_idx: 100 |  Loss: (0.0214) | Acc: (99.41%) (12852/12928)\n",
            "Epoch: 138 | Batch_idx: 110 |  Loss: (0.0215) | Acc: (99.40%) (14123/14208)\n",
            "Epoch: 138 | Batch_idx: 120 |  Loss: (0.0215) | Acc: (99.41%) (15397/15488)\n",
            "Epoch: 138 | Batch_idx: 130 |  Loss: (0.0218) | Acc: (99.41%) (16669/16768)\n",
            "Epoch: 138 | Batch_idx: 140 |  Loss: (0.0224) | Acc: (99.37%) (17935/18048)\n",
            "Epoch: 138 | Batch_idx: 150 |  Loss: (0.0224) | Acc: (99.37%) (19207/19328)\n",
            "Epoch: 138 | Batch_idx: 160 |  Loss: (0.0226) | Acc: (99.37%) (20479/20608)\n",
            "Epoch: 138 | Batch_idx: 170 |  Loss: (0.0224) | Acc: (99.39%) (21754/21888)\n",
            "Epoch: 138 | Batch_idx: 180 |  Loss: (0.0224) | Acc: (99.38%) (23025/23168)\n",
            "Epoch: 138 | Batch_idx: 190 |  Loss: (0.0223) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 138 | Batch_idx: 200 |  Loss: (0.0224) | Acc: (99.38%) (25569/25728)\n",
            "Epoch: 138 | Batch_idx: 210 |  Loss: (0.0222) | Acc: (99.40%) (26845/27008)\n",
            "Epoch: 138 | Batch_idx: 220 |  Loss: (0.0221) | Acc: (99.40%) (28118/28288)\n",
            "Epoch: 138 | Batch_idx: 230 |  Loss: (0.0224) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 138 | Batch_idx: 240 |  Loss: (0.0222) | Acc: (99.40%) (30663/30848)\n",
            "Epoch: 138 | Batch_idx: 250 |  Loss: (0.0223) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 138 | Batch_idx: 260 |  Loss: (0.0224) | Acc: (99.38%) (33201/33408)\n",
            "Epoch: 138 | Batch_idx: 270 |  Loss: (0.0225) | Acc: (99.38%) (34473/34688)\n",
            "Epoch: 138 | Batch_idx: 280 |  Loss: (0.0223) | Acc: (99.39%) (35747/35968)\n",
            "Epoch: 138 | Batch_idx: 290 |  Loss: (0.0224) | Acc: (99.38%) (37018/37248)\n",
            "Epoch: 138 | Batch_idx: 300 |  Loss: (0.0225) | Acc: (99.37%) (38285/38528)\n",
            "Epoch: 138 | Batch_idx: 310 |  Loss: (0.0224) | Acc: (99.37%) (39559/39808)\n",
            "Epoch: 138 | Batch_idx: 320 |  Loss: (0.0225) | Acc: (99.37%) (40831/41088)\n",
            "Epoch: 138 | Batch_idx: 330 |  Loss: (0.0224) | Acc: (99.38%) (42104/42368)\n",
            "Epoch: 138 | Batch_idx: 340 |  Loss: (0.0223) | Acc: (99.38%) (43377/43648)\n",
            "Epoch: 138 | Batch_idx: 350 |  Loss: (0.0222) | Acc: (99.38%) (44650/44928)\n",
            "Epoch: 138 | Batch_idx: 360 |  Loss: (0.0224) | Acc: (99.37%) (45918/46208)\n",
            "Epoch: 138 | Batch_idx: 370 |  Loss: (0.0224) | Acc: (99.36%) (47186/47488)\n",
            "Epoch: 138 | Batch_idx: 380 |  Loss: (0.0223) | Acc: (99.37%) (48461/48768)\n",
            "Epoch: 138 | Batch_idx: 390 |  Loss: (0.0222) | Acc: (99.38%) (49688/50000)\n",
            "# TEST : Loss: (0.3592) | Acc: (91.93%) (9193/10000)\n",
            "Epoch: 139 | Batch_idx: 0 |  Loss: (0.0254) | Acc: (99.22%) (127/128)\n",
            "Epoch: 139 | Batch_idx: 10 |  Loss: (0.0191) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 139 | Batch_idx: 20 |  Loss: (0.0213) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 139 | Batch_idx: 30 |  Loss: (0.0211) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 139 | Batch_idx: 40 |  Loss: (0.0208) | Acc: (99.62%) (5228/5248)\n",
            "Epoch: 139 | Batch_idx: 50 |  Loss: (0.0203) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 139 | Batch_idx: 60 |  Loss: (0.0209) | Acc: (99.55%) (7773/7808)\n",
            "Epoch: 139 | Batch_idx: 70 |  Loss: (0.0210) | Acc: (99.53%) (9045/9088)\n",
            "Epoch: 139 | Batch_idx: 80 |  Loss: (0.0212) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 139 | Batch_idx: 90 |  Loss: (0.0216) | Acc: (99.50%) (11590/11648)\n",
            "Epoch: 139 | Batch_idx: 100 |  Loss: (0.0217) | Acc: (99.48%) (12861/12928)\n",
            "Epoch: 139 | Batch_idx: 110 |  Loss: (0.0218) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 139 | Batch_idx: 120 |  Loss: (0.0217) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 139 | Batch_idx: 130 |  Loss: (0.0211) | Acc: (99.49%) (16682/16768)\n",
            "Epoch: 139 | Batch_idx: 140 |  Loss: (0.0211) | Acc: (99.48%) (17954/18048)\n",
            "Epoch: 139 | Batch_idx: 150 |  Loss: (0.0210) | Acc: (99.49%) (19229/19328)\n",
            "Epoch: 139 | Batch_idx: 160 |  Loss: (0.0207) | Acc: (99.50%) (20505/20608)\n",
            "Epoch: 139 | Batch_idx: 170 |  Loss: (0.0211) | Acc: (99.48%) (21775/21888)\n",
            "Epoch: 139 | Batch_idx: 180 |  Loss: (0.0212) | Acc: (99.46%) (23044/23168)\n",
            "Epoch: 139 | Batch_idx: 190 |  Loss: (0.0214) | Acc: (99.46%) (24316/24448)\n",
            "Epoch: 139 | Batch_idx: 200 |  Loss: (0.0214) | Acc: (99.46%) (25589/25728)\n",
            "Epoch: 139 | Batch_idx: 210 |  Loss: (0.0213) | Acc: (99.47%) (26864/27008)\n",
            "Epoch: 139 | Batch_idx: 220 |  Loss: (0.0213) | Acc: (99.47%) (28137/28288)\n",
            "Epoch: 139 | Batch_idx: 230 |  Loss: (0.0212) | Acc: (99.47%) (29411/29568)\n",
            "Epoch: 139 | Batch_idx: 240 |  Loss: (0.0212) | Acc: (99.47%) (30684/30848)\n",
            "Epoch: 139 | Batch_idx: 250 |  Loss: (0.0211) | Acc: (99.47%) (31959/32128)\n",
            "Epoch: 139 | Batch_idx: 260 |  Loss: (0.0212) | Acc: (99.47%) (33231/33408)\n",
            "Epoch: 139 | Batch_idx: 270 |  Loss: (0.0213) | Acc: (99.46%) (34502/34688)\n",
            "Epoch: 139 | Batch_idx: 280 |  Loss: (0.0212) | Acc: (99.46%) (35775/35968)\n",
            "Epoch: 139 | Batch_idx: 290 |  Loss: (0.0212) | Acc: (99.47%) (37049/37248)\n",
            "Epoch: 139 | Batch_idx: 300 |  Loss: (0.0213) | Acc: (99.46%) (38321/38528)\n",
            "Epoch: 139 | Batch_idx: 310 |  Loss: (0.0213) | Acc: (99.45%) (39591/39808)\n",
            "Epoch: 139 | Batch_idx: 320 |  Loss: (0.0213) | Acc: (99.45%) (40863/41088)\n",
            "Epoch: 139 | Batch_idx: 330 |  Loss: (0.0215) | Acc: (99.45%) (42133/42368)\n",
            "Epoch: 139 | Batch_idx: 340 |  Loss: (0.0215) | Acc: (99.44%) (43405/43648)\n",
            "Epoch: 139 | Batch_idx: 350 |  Loss: (0.0215) | Acc: (99.44%) (44676/44928)\n",
            "Epoch: 139 | Batch_idx: 360 |  Loss: (0.0214) | Acc: (99.44%) (45948/46208)\n",
            "Epoch: 139 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.44%) (47223/47488)\n",
            "Epoch: 139 | Batch_idx: 380 |  Loss: (0.0214) | Acc: (99.44%) (48494/48768)\n",
            "Epoch: 139 | Batch_idx: 390 |  Loss: (0.0214) | Acc: (99.44%) (49719/50000)\n",
            "# TEST : Loss: (0.3588) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 140 | Batch_idx: 0 |  Loss: (0.0033) | Acc: (100.00%) (128/128)\n",
            "Epoch: 140 | Batch_idx: 10 |  Loss: (0.0158) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 140 | Batch_idx: 20 |  Loss: (0.0177) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 140 | Batch_idx: 30 |  Loss: (0.0194) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 140 | Batch_idx: 40 |  Loss: (0.0205) | Acc: (99.35%) (5214/5248)\n",
            "Epoch: 140 | Batch_idx: 50 |  Loss: (0.0203) | Acc: (99.36%) (6486/6528)\n",
            "Epoch: 140 | Batch_idx: 60 |  Loss: (0.0196) | Acc: (99.41%) (7762/7808)\n",
            "Epoch: 140 | Batch_idx: 70 |  Loss: (0.0194) | Acc: (99.43%) (9036/9088)\n",
            "Epoch: 140 | Batch_idx: 80 |  Loss: (0.0202) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 140 | Batch_idx: 90 |  Loss: (0.0215) | Acc: (99.37%) (11575/11648)\n",
            "Epoch: 140 | Batch_idx: 100 |  Loss: (0.0213) | Acc: (99.37%) (12846/12928)\n",
            "Epoch: 140 | Batch_idx: 110 |  Loss: (0.0215) | Acc: (99.37%) (14118/14208)\n",
            "Epoch: 140 | Batch_idx: 120 |  Loss: (0.0217) | Acc: (99.35%) (15388/15488)\n",
            "Epoch: 140 | Batch_idx: 130 |  Loss: (0.0217) | Acc: (99.37%) (16662/16768)\n",
            "Epoch: 140 | Batch_idx: 140 |  Loss: (0.0216) | Acc: (99.37%) (17934/18048)\n",
            "Epoch: 140 | Batch_idx: 150 |  Loss: (0.0214) | Acc: (99.37%) (19207/19328)\n",
            "Epoch: 140 | Batch_idx: 160 |  Loss: (0.0212) | Acc: (99.39%) (20483/20608)\n",
            "Epoch: 140 | Batch_idx: 170 |  Loss: (0.0215) | Acc: (99.37%) (21751/21888)\n",
            "Epoch: 140 | Batch_idx: 180 |  Loss: (0.0217) | Acc: (99.37%) (23023/23168)\n",
            "Epoch: 140 | Batch_idx: 190 |  Loss: (0.0215) | Acc: (99.39%) (24299/24448)\n",
            "Epoch: 140 | Batch_idx: 200 |  Loss: (0.0216) | Acc: (99.39%) (25572/25728)\n",
            "Epoch: 140 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.40%) (26847/27008)\n",
            "Epoch: 140 | Batch_idx: 220 |  Loss: (0.0213) | Acc: (99.40%) (28119/28288)\n",
            "Epoch: 140 | Batch_idx: 230 |  Loss: (0.0216) | Acc: (99.40%) (29390/29568)\n",
            "Epoch: 140 | Batch_idx: 240 |  Loss: (0.0220) | Acc: (99.38%) (30657/30848)\n",
            "Epoch: 140 | Batch_idx: 250 |  Loss: (0.0218) | Acc: (99.39%) (31932/32128)\n",
            "Epoch: 140 | Batch_idx: 260 |  Loss: (0.0219) | Acc: (99.39%) (33203/33408)\n",
            "Epoch: 140 | Batch_idx: 270 |  Loss: (0.0221) | Acc: (99.39%) (34475/34688)\n",
            "Epoch: 140 | Batch_idx: 280 |  Loss: (0.0222) | Acc: (99.38%) (35744/35968)\n",
            "Epoch: 140 | Batch_idx: 290 |  Loss: (0.0221) | Acc: (99.38%) (37016/37248)\n",
            "Epoch: 140 | Batch_idx: 300 |  Loss: (0.0221) | Acc: (99.38%) (38289/38528)\n",
            "Epoch: 140 | Batch_idx: 310 |  Loss: (0.0221) | Acc: (99.38%) (39560/39808)\n",
            "Epoch: 140 | Batch_idx: 320 |  Loss: (0.0225) | Acc: (99.36%) (40826/41088)\n",
            "Epoch: 140 | Batch_idx: 330 |  Loss: (0.0223) | Acc: (99.36%) (42097/42368)\n",
            "Epoch: 140 | Batch_idx: 340 |  Loss: (0.0227) | Acc: (99.33%) (43357/43648)\n",
            "Epoch: 140 | Batch_idx: 350 |  Loss: (0.0227) | Acc: (99.33%) (44627/44928)\n",
            "Epoch: 140 | Batch_idx: 360 |  Loss: (0.0227) | Acc: (99.34%) (45901/46208)\n",
            "Epoch: 140 | Batch_idx: 370 |  Loss: (0.0226) | Acc: (99.34%) (47175/47488)\n",
            "Epoch: 140 | Batch_idx: 380 |  Loss: (0.0228) | Acc: (99.33%) (48443/48768)\n",
            "Epoch: 140 | Batch_idx: 390 |  Loss: (0.0226) | Acc: (99.35%) (49674/50000)\n",
            "# TEST : Loss: (0.3610) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 141 | Batch_idx: 0 |  Loss: (0.0331) | Acc: (100.00%) (128/128)\n",
            "Epoch: 141 | Batch_idx: 10 |  Loss: (0.0208) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 141 | Batch_idx: 20 |  Loss: (0.0246) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 141 | Batch_idx: 30 |  Loss: (0.0251) | Acc: (99.42%) (3945/3968)\n",
            "Epoch: 141 | Batch_idx: 40 |  Loss: (0.0249) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 141 | Batch_idx: 50 |  Loss: (0.0239) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 141 | Batch_idx: 60 |  Loss: (0.0241) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 141 | Batch_idx: 70 |  Loss: (0.0229) | Acc: (99.43%) (9036/9088)\n",
            "Epoch: 141 | Batch_idx: 80 |  Loss: (0.0231) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 141 | Batch_idx: 90 |  Loss: (0.0228) | Acc: (99.41%) (11579/11648)\n",
            "Epoch: 141 | Batch_idx: 100 |  Loss: (0.0228) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 141 | Batch_idx: 110 |  Loss: (0.0223) | Acc: (99.42%) (14126/14208)\n",
            "Epoch: 141 | Batch_idx: 120 |  Loss: (0.0220) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 141 | Batch_idx: 130 |  Loss: (0.0214) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 141 | Batch_idx: 140 |  Loss: (0.0213) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 141 | Batch_idx: 150 |  Loss: (0.0213) | Acc: (99.46%) (19224/19328)\n",
            "Epoch: 141 | Batch_idx: 160 |  Loss: (0.0215) | Acc: (99.45%) (20495/20608)\n",
            "Epoch: 141 | Batch_idx: 170 |  Loss: (0.0213) | Acc: (99.47%) (21771/21888)\n",
            "Epoch: 141 | Batch_idx: 180 |  Loss: (0.0215) | Acc: (99.45%) (23041/23168)\n",
            "Epoch: 141 | Batch_idx: 190 |  Loss: (0.0212) | Acc: (99.47%) (24318/24448)\n",
            "Epoch: 141 | Batch_idx: 200 |  Loss: (0.0213) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 141 | Batch_idx: 210 |  Loss: (0.0215) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 141 | Batch_idx: 220 |  Loss: (0.0216) | Acc: (99.45%) (28133/28288)\n",
            "Epoch: 141 | Batch_idx: 230 |  Loss: (0.0215) | Acc: (99.45%) (29406/29568)\n",
            "Epoch: 141 | Batch_idx: 240 |  Loss: (0.0217) | Acc: (99.45%) (30677/30848)\n",
            "Epoch: 141 | Batch_idx: 250 |  Loss: (0.0216) | Acc: (99.46%) (31954/32128)\n",
            "Epoch: 141 | Batch_idx: 260 |  Loss: (0.0216) | Acc: (99.45%) (33224/33408)\n",
            "Epoch: 141 | Batch_idx: 270 |  Loss: (0.0218) | Acc: (99.44%) (34494/34688)\n",
            "Epoch: 141 | Batch_idx: 280 |  Loss: (0.0217) | Acc: (99.43%) (35764/35968)\n",
            "Epoch: 141 | Batch_idx: 290 |  Loss: (0.0219) | Acc: (99.41%) (37029/37248)\n",
            "Epoch: 141 | Batch_idx: 300 |  Loss: (0.0219) | Acc: (99.41%) (38301/38528)\n",
            "Epoch: 141 | Batch_idx: 310 |  Loss: (0.0219) | Acc: (99.40%) (39571/39808)\n",
            "Epoch: 141 | Batch_idx: 320 |  Loss: (0.0219) | Acc: (99.41%) (40844/41088)\n",
            "Epoch: 141 | Batch_idx: 330 |  Loss: (0.0219) | Acc: (99.41%) (42117/42368)\n",
            "Epoch: 141 | Batch_idx: 340 |  Loss: (0.0217) | Acc: (99.42%) (43393/43648)\n",
            "Epoch: 141 | Batch_idx: 350 |  Loss: (0.0216) | Acc: (99.42%) (44667/44928)\n",
            "Epoch: 141 | Batch_idx: 360 |  Loss: (0.0218) | Acc: (99.41%) (45935/46208)\n",
            "Epoch: 141 | Batch_idx: 370 |  Loss: (0.0217) | Acc: (99.41%) (47207/47488)\n",
            "Epoch: 141 | Batch_idx: 380 |  Loss: (0.0216) | Acc: (99.41%) (48480/48768)\n",
            "Epoch: 141 | Batch_idx: 390 |  Loss: (0.0217) | Acc: (99.40%) (49700/50000)\n",
            "# TEST : Loss: (0.3582) | Acc: (91.82%) (9182/10000)\n",
            "Epoch: 142 | Batch_idx: 0 |  Loss: (0.0060) | Acc: (100.00%) (128/128)\n",
            "Epoch: 142 | Batch_idx: 10 |  Loss: (0.0271) | Acc: (99.08%) (1395/1408)\n",
            "Epoch: 142 | Batch_idx: 20 |  Loss: (0.0270) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 142 | Batch_idx: 30 |  Loss: (0.0245) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 142 | Batch_idx: 40 |  Loss: (0.0234) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 142 | Batch_idx: 50 |  Loss: (0.0236) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 142 | Batch_idx: 60 |  Loss: (0.0238) | Acc: (99.30%) (7753/7808)\n",
            "Epoch: 142 | Batch_idx: 70 |  Loss: (0.0241) | Acc: (99.30%) (9024/9088)\n",
            "Epoch: 142 | Batch_idx: 80 |  Loss: (0.0239) | Acc: (99.32%) (10297/10368)\n",
            "Epoch: 142 | Batch_idx: 90 |  Loss: (0.0231) | Acc: (99.36%) (11573/11648)\n",
            "Epoch: 142 | Batch_idx: 100 |  Loss: (0.0225) | Acc: (99.38%) (12848/12928)\n",
            "Epoch: 142 | Batch_idx: 110 |  Loss: (0.0224) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 142 | Batch_idx: 120 |  Loss: (0.0218) | Acc: (99.40%) (15395/15488)\n",
            "Epoch: 142 | Batch_idx: 130 |  Loss: (0.0215) | Acc: (99.42%) (16670/16768)\n",
            "Epoch: 142 | Batch_idx: 140 |  Loss: (0.0210) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 142 | Batch_idx: 150 |  Loss: (0.0213) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 142 | Batch_idx: 160 |  Loss: (0.0212) | Acc: (99.45%) (20495/20608)\n",
            "Epoch: 142 | Batch_idx: 170 |  Loss: (0.0211) | Acc: (99.46%) (21769/21888)\n",
            "Epoch: 142 | Batch_idx: 180 |  Loss: (0.0213) | Acc: (99.46%) (23042/23168)\n",
            "Epoch: 142 | Batch_idx: 190 |  Loss: (0.0213) | Acc: (99.44%) (24310/24448)\n",
            "Epoch: 142 | Batch_idx: 200 |  Loss: (0.0210) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 142 | Batch_idx: 210 |  Loss: (0.0210) | Acc: (99.46%) (26862/27008)\n",
            "Epoch: 142 | Batch_idx: 220 |  Loss: (0.0208) | Acc: (99.46%) (28135/28288)\n",
            "Epoch: 142 | Batch_idx: 230 |  Loss: (0.0208) | Acc: (99.47%) (29410/29568)\n",
            "Epoch: 142 | Batch_idx: 240 |  Loss: (0.0207) | Acc: (99.48%) (30687/30848)\n",
            "Epoch: 142 | Batch_idx: 250 |  Loss: (0.0209) | Acc: (99.47%) (31957/32128)\n",
            "Epoch: 142 | Batch_idx: 260 |  Loss: (0.0208) | Acc: (99.47%) (33230/33408)\n",
            "Epoch: 142 | Batch_idx: 270 |  Loss: (0.0207) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 142 | Batch_idx: 280 |  Loss: (0.0207) | Acc: (99.48%) (35780/35968)\n",
            "Epoch: 142 | Batch_idx: 290 |  Loss: (0.0205) | Acc: (99.48%) (37055/37248)\n",
            "Epoch: 142 | Batch_idx: 300 |  Loss: (0.0209) | Acc: (99.46%) (38320/38528)\n",
            "Epoch: 142 | Batch_idx: 310 |  Loss: (0.0209) | Acc: (99.46%) (39595/39808)\n",
            "Epoch: 142 | Batch_idx: 320 |  Loss: (0.0211) | Acc: (99.45%) (40863/41088)\n",
            "Epoch: 142 | Batch_idx: 330 |  Loss: (0.0211) | Acc: (99.45%) (42136/42368)\n",
            "Epoch: 142 | Batch_idx: 340 |  Loss: (0.0212) | Acc: (99.45%) (43407/43648)\n",
            "Epoch: 142 | Batch_idx: 350 |  Loss: (0.0211) | Acc: (99.45%) (44681/44928)\n",
            "Epoch: 142 | Batch_idx: 360 |  Loss: (0.0214) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 142 | Batch_idx: 370 |  Loss: (0.0214) | Acc: (99.44%) (47220/47488)\n",
            "Epoch: 142 | Batch_idx: 380 |  Loss: (0.0213) | Acc: (99.44%) (48495/48768)\n",
            "Epoch: 142 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.45%) (49724/50000)\n",
            "# TEST : Loss: (0.3626) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 143 | Batch_idx: 0 |  Loss: (0.0110) | Acc: (100.00%) (128/128)\n",
            "Epoch: 143 | Batch_idx: 10 |  Loss: (0.0210) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 143 | Batch_idx: 20 |  Loss: (0.0231) | Acc: (99.14%) (2665/2688)\n",
            "Epoch: 143 | Batch_idx: 30 |  Loss: (0.0217) | Acc: (99.22%) (3937/3968)\n",
            "Epoch: 143 | Batch_idx: 40 |  Loss: (0.0215) | Acc: (99.28%) (5210/5248)\n",
            "Epoch: 143 | Batch_idx: 50 |  Loss: (0.0218) | Acc: (99.30%) (6482/6528)\n",
            "Epoch: 143 | Batch_idx: 60 |  Loss: (0.0211) | Acc: (99.36%) (7758/7808)\n",
            "Epoch: 143 | Batch_idx: 70 |  Loss: (0.0217) | Acc: (99.34%) (9028/9088)\n",
            "Epoch: 143 | Batch_idx: 80 |  Loss: (0.0216) | Acc: (99.33%) (10299/10368)\n",
            "Epoch: 143 | Batch_idx: 90 |  Loss: (0.0217) | Acc: (99.30%) (11566/11648)\n",
            "Epoch: 143 | Batch_idx: 100 |  Loss: (0.0215) | Acc: (99.32%) (12840/12928)\n",
            "Epoch: 143 | Batch_idx: 110 |  Loss: (0.0213) | Acc: (99.33%) (14113/14208)\n",
            "Epoch: 143 | Batch_idx: 120 |  Loss: (0.0213) | Acc: (99.33%) (15384/15488)\n",
            "Epoch: 143 | Batch_idx: 130 |  Loss: (0.0213) | Acc: (99.32%) (16654/16768)\n",
            "Epoch: 143 | Batch_idx: 140 |  Loss: (0.0210) | Acc: (99.34%) (17929/18048)\n",
            "Epoch: 143 | Batch_idx: 150 |  Loss: (0.0210) | Acc: (99.35%) (19202/19328)\n",
            "Epoch: 143 | Batch_idx: 160 |  Loss: (0.0207) | Acc: (99.37%) (20478/20608)\n",
            "Epoch: 143 | Batch_idx: 170 |  Loss: (0.0204) | Acc: (99.39%) (21754/21888)\n",
            "Epoch: 143 | Batch_idx: 180 |  Loss: (0.0204) | Acc: (99.40%) (23029/23168)\n",
            "Epoch: 143 | Batch_idx: 190 |  Loss: (0.0206) | Acc: (99.42%) (24306/24448)\n",
            "Epoch: 143 | Batch_idx: 200 |  Loss: (0.0208) | Acc: (99.42%) (25578/25728)\n",
            "Epoch: 143 | Batch_idx: 210 |  Loss: (0.0207) | Acc: (99.42%) (26852/27008)\n",
            "Epoch: 143 | Batch_idx: 220 |  Loss: (0.0207) | Acc: (99.42%) (28124/28288)\n",
            "Epoch: 143 | Batch_idx: 230 |  Loss: (0.0207) | Acc: (99.43%) (29399/29568)\n",
            "Epoch: 143 | Batch_idx: 240 |  Loss: (0.0209) | Acc: (99.42%) (30668/30848)\n",
            "Epoch: 143 | Batch_idx: 250 |  Loss: (0.0208) | Acc: (99.42%) (31942/32128)\n",
            "Epoch: 143 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.43%) (33216/33408)\n",
            "Epoch: 143 | Batch_idx: 270 |  Loss: (0.0207) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 143 | Batch_idx: 280 |  Loss: (0.0207) | Acc: (99.42%) (35758/35968)\n",
            "Epoch: 143 | Batch_idx: 290 |  Loss: (0.0208) | Acc: (99.42%) (37031/37248)\n",
            "Epoch: 143 | Batch_idx: 300 |  Loss: (0.0206) | Acc: (99.42%) (38306/38528)\n",
            "Epoch: 143 | Batch_idx: 310 |  Loss: (0.0210) | Acc: (99.41%) (39575/39808)\n",
            "Epoch: 143 | Batch_idx: 320 |  Loss: (0.0211) | Acc: (99.41%) (40847/41088)\n",
            "Epoch: 143 | Batch_idx: 330 |  Loss: (0.0210) | Acc: (99.42%) (42123/42368)\n",
            "Epoch: 143 | Batch_idx: 340 |  Loss: (0.0212) | Acc: (99.41%) (43392/43648)\n",
            "Epoch: 143 | Batch_idx: 350 |  Loss: (0.0211) | Acc: (99.42%) (44668/44928)\n",
            "Epoch: 143 | Batch_idx: 360 |  Loss: (0.0212) | Acc: (99.42%) (45941/46208)\n",
            "Epoch: 143 | Batch_idx: 370 |  Loss: (0.0212) | Acc: (99.43%) (47215/47488)\n",
            "Epoch: 143 | Batch_idx: 380 |  Loss: (0.0212) | Acc: (99.43%) (48489/48768)\n",
            "Epoch: 143 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.42%) (49712/50000)\n",
            "# TEST : Loss: (0.3602) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 144 | Batch_idx: 0 |  Loss: (0.0322) | Acc: (99.22%) (127/128)\n",
            "Epoch: 144 | Batch_idx: 10 |  Loss: (0.0164) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 144 | Batch_idx: 20 |  Loss: (0.0178) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 144 | Batch_idx: 30 |  Loss: (0.0227) | Acc: (99.29%) (3940/3968)\n",
            "Epoch: 144 | Batch_idx: 40 |  Loss: (0.0230) | Acc: (99.29%) (5211/5248)\n",
            "Epoch: 144 | Batch_idx: 50 |  Loss: (0.0229) | Acc: (99.33%) (6484/6528)\n",
            "Epoch: 144 | Batch_idx: 60 |  Loss: (0.0228) | Acc: (99.33%) (7756/7808)\n",
            "Epoch: 144 | Batch_idx: 70 |  Loss: (0.0219) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 144 | Batch_idx: 80 |  Loss: (0.0214) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 144 | Batch_idx: 90 |  Loss: (0.0219) | Acc: (99.34%) (11571/11648)\n",
            "Epoch: 144 | Batch_idx: 100 |  Loss: (0.0214) | Acc: (99.36%) (12845/12928)\n",
            "Epoch: 144 | Batch_idx: 110 |  Loss: (0.0211) | Acc: (99.39%) (14121/14208)\n",
            "Epoch: 144 | Batch_idx: 120 |  Loss: (0.0207) | Acc: (99.42%) (15398/15488)\n",
            "Epoch: 144 | Batch_idx: 130 |  Loss: (0.0205) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 144 | Batch_idx: 140 |  Loss: (0.0206) | Acc: (99.42%) (17943/18048)\n",
            "Epoch: 144 | Batch_idx: 150 |  Loss: (0.0204) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 144 | Batch_idx: 160 |  Loss: (0.0203) | Acc: (99.43%) (20491/20608)\n",
            "Epoch: 144 | Batch_idx: 170 |  Loss: (0.0208) | Acc: (99.42%) (21760/21888)\n",
            "Epoch: 144 | Batch_idx: 180 |  Loss: (0.0210) | Acc: (99.41%) (23032/23168)\n",
            "Epoch: 144 | Batch_idx: 190 |  Loss: (0.0211) | Acc: (99.40%) (24302/24448)\n",
            "Epoch: 144 | Batch_idx: 200 |  Loss: (0.0212) | Acc: (99.41%) (25575/25728)\n",
            "Epoch: 144 | Batch_idx: 210 |  Loss: (0.0212) | Acc: (99.40%) (26847/27008)\n",
            "Epoch: 144 | Batch_idx: 220 |  Loss: (0.0212) | Acc: (99.41%) (28120/28288)\n",
            "Epoch: 144 | Batch_idx: 230 |  Loss: (0.0215) | Acc: (99.39%) (29388/29568)\n",
            "Epoch: 144 | Batch_idx: 240 |  Loss: (0.0215) | Acc: (99.38%) (30658/30848)\n",
            "Epoch: 144 | Batch_idx: 250 |  Loss: (0.0217) | Acc: (99.37%) (31926/32128)\n",
            "Epoch: 144 | Batch_idx: 260 |  Loss: (0.0218) | Acc: (99.37%) (33197/33408)\n",
            "Epoch: 144 | Batch_idx: 270 |  Loss: (0.0219) | Acc: (99.37%) (34469/34688)\n",
            "Epoch: 144 | Batch_idx: 280 |  Loss: (0.0220) | Acc: (99.35%) (35736/35968)\n",
            "Epoch: 144 | Batch_idx: 290 |  Loss: (0.0220) | Acc: (99.36%) (37009/37248)\n",
            "Epoch: 144 | Batch_idx: 300 |  Loss: (0.0220) | Acc: (99.36%) (38283/38528)\n",
            "Epoch: 144 | Batch_idx: 310 |  Loss: (0.0220) | Acc: (99.36%) (39554/39808)\n",
            "Epoch: 144 | Batch_idx: 320 |  Loss: (0.0220) | Acc: (99.36%) (40825/41088)\n",
            "Epoch: 144 | Batch_idx: 330 |  Loss: (0.0218) | Acc: (99.38%) (42104/42368)\n",
            "Epoch: 144 | Batch_idx: 340 |  Loss: (0.0219) | Acc: (99.38%) (43376/43648)\n",
            "Epoch: 144 | Batch_idx: 350 |  Loss: (0.0219) | Acc: (99.37%) (44645/44928)\n",
            "Epoch: 144 | Batch_idx: 360 |  Loss: (0.0219) | Acc: (99.37%) (45918/46208)\n",
            "Epoch: 144 | Batch_idx: 370 |  Loss: (0.0220) | Acc: (99.37%) (47189/47488)\n",
            "Epoch: 144 | Batch_idx: 380 |  Loss: (0.0220) | Acc: (99.37%) (48459/48768)\n",
            "Epoch: 144 | Batch_idx: 390 |  Loss: (0.0218) | Acc: (99.37%) (49685/50000)\n",
            "# TEST : Loss: (0.3618) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 145 | Batch_idx: 0 |  Loss: (0.0144) | Acc: (100.00%) (128/128)\n",
            "Epoch: 145 | Batch_idx: 10 |  Loss: (0.0189) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 145 | Batch_idx: 20 |  Loss: (0.0217) | Acc: (99.26%) (2668/2688)\n",
            "Epoch: 145 | Batch_idx: 30 |  Loss: (0.0213) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 145 | Batch_idx: 40 |  Loss: (0.0213) | Acc: (99.39%) (5216/5248)\n",
            "Epoch: 145 | Batch_idx: 50 |  Loss: (0.0209) | Acc: (99.43%) (6491/6528)\n",
            "Epoch: 145 | Batch_idx: 60 |  Loss: (0.0207) | Acc: (99.42%) (7763/7808)\n",
            "Epoch: 145 | Batch_idx: 70 |  Loss: (0.0200) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 145 | Batch_idx: 80 |  Loss: (0.0205) | Acc: (99.46%) (10312/10368)\n",
            "Epoch: 145 | Batch_idx: 90 |  Loss: (0.0213) | Acc: (99.42%) (11581/11648)\n",
            "Epoch: 145 | Batch_idx: 100 |  Loss: (0.0203) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 145 | Batch_idx: 110 |  Loss: (0.0201) | Acc: (99.47%) (14132/14208)\n",
            "Epoch: 145 | Batch_idx: 120 |  Loss: (0.0199) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 145 | Batch_idx: 130 |  Loss: (0.0205) | Acc: (99.43%) (16673/16768)\n",
            "Epoch: 145 | Batch_idx: 140 |  Loss: (0.0207) | Acc: (99.43%) (17945/18048)\n",
            "Epoch: 145 | Batch_idx: 150 |  Loss: (0.0208) | Acc: (99.43%) (19218/19328)\n",
            "Epoch: 145 | Batch_idx: 160 |  Loss: (0.0207) | Acc: (99.45%) (20494/20608)\n",
            "Epoch: 145 | Batch_idx: 170 |  Loss: (0.0208) | Acc: (99.44%) (21766/21888)\n",
            "Epoch: 145 | Batch_idx: 180 |  Loss: (0.0210) | Acc: (99.43%) (23036/23168)\n",
            "Epoch: 145 | Batch_idx: 190 |  Loss: (0.0211) | Acc: (99.44%) (24310/24448)\n",
            "Epoch: 145 | Batch_idx: 200 |  Loss: (0.0207) | Acc: (99.46%) (25589/25728)\n",
            "Epoch: 145 | Batch_idx: 210 |  Loss: (0.0207) | Acc: (99.46%) (26863/27008)\n",
            "Epoch: 145 | Batch_idx: 220 |  Loss: (0.0206) | Acc: (99.46%) (28135/28288)\n",
            "Epoch: 145 | Batch_idx: 230 |  Loss: (0.0207) | Acc: (99.46%) (29408/29568)\n",
            "Epoch: 145 | Batch_idx: 240 |  Loss: (0.0205) | Acc: (99.47%) (30684/30848)\n",
            "Epoch: 145 | Batch_idx: 250 |  Loss: (0.0206) | Acc: (99.47%) (31958/32128)\n",
            "Epoch: 145 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.47%) (33230/33408)\n",
            "Epoch: 145 | Batch_idx: 270 |  Loss: (0.0205) | Acc: (99.46%) (34502/34688)\n",
            "Epoch: 145 | Batch_idx: 280 |  Loss: (0.0206) | Acc: (99.47%) (35776/35968)\n",
            "Epoch: 145 | Batch_idx: 290 |  Loss: (0.0207) | Acc: (99.46%) (37046/37248)\n",
            "Epoch: 145 | Batch_idx: 300 |  Loss: (0.0206) | Acc: (99.46%) (38319/38528)\n",
            "Epoch: 145 | Batch_idx: 310 |  Loss: (0.0206) | Acc: (99.45%) (39591/39808)\n",
            "Epoch: 145 | Batch_idx: 320 |  Loss: (0.0207) | Acc: (99.45%) (40861/41088)\n",
            "Epoch: 145 | Batch_idx: 330 |  Loss: (0.0208) | Acc: (99.43%) (42127/42368)\n",
            "Epoch: 145 | Batch_idx: 340 |  Loss: (0.0208) | Acc: (99.43%) (43401/43648)\n",
            "Epoch: 145 | Batch_idx: 350 |  Loss: (0.0208) | Acc: (99.44%) (44677/44928)\n",
            "Epoch: 145 | Batch_idx: 360 |  Loss: (0.0208) | Acc: (99.44%) (45948/46208)\n",
            "Epoch: 145 | Batch_idx: 370 |  Loss: (0.0208) | Acc: (99.44%) (47221/47488)\n",
            "Epoch: 145 | Batch_idx: 380 |  Loss: (0.0209) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 145 | Batch_idx: 390 |  Loss: (0.0210) | Acc: (99.43%) (49717/50000)\n",
            "# TEST : Loss: (0.3634) | Acc: (91.95%) (9195/10000)\n",
            "Epoch: 146 | Batch_idx: 0 |  Loss: (0.0265) | Acc: (99.22%) (127/128)\n",
            "Epoch: 146 | Batch_idx: 10 |  Loss: (0.0179) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 146 | Batch_idx: 20 |  Loss: (0.0180) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 146 | Batch_idx: 30 |  Loss: (0.0173) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 146 | Batch_idx: 40 |  Loss: (0.0172) | Acc: (99.66%) (5230/5248)\n",
            "Epoch: 146 | Batch_idx: 50 |  Loss: (0.0175) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 146 | Batch_idx: 60 |  Loss: (0.0185) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 146 | Batch_idx: 70 |  Loss: (0.0200) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 146 | Batch_idx: 80 |  Loss: (0.0203) | Acc: (99.48%) (10314/10368)\n",
            "Epoch: 146 | Batch_idx: 90 |  Loss: (0.0195) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 146 | Batch_idx: 100 |  Loss: (0.0205) | Acc: (99.48%) (12861/12928)\n",
            "Epoch: 146 | Batch_idx: 110 |  Loss: (0.0206) | Acc: (99.49%) (14135/14208)\n",
            "Epoch: 146 | Batch_idx: 120 |  Loss: (0.0209) | Acc: (99.44%) (15402/15488)\n",
            "Epoch: 146 | Batch_idx: 130 |  Loss: (0.0206) | Acc: (99.46%) (16677/16768)\n",
            "Epoch: 146 | Batch_idx: 140 |  Loss: (0.0202) | Acc: (99.47%) (17952/18048)\n",
            "Epoch: 146 | Batch_idx: 150 |  Loss: (0.0205) | Acc: (99.45%) (19221/19328)\n",
            "Epoch: 146 | Batch_idx: 160 |  Loss: (0.0204) | Acc: (99.45%) (20494/20608)\n",
            "Epoch: 146 | Batch_idx: 170 |  Loss: (0.0203) | Acc: (99.45%) (21767/21888)\n",
            "Epoch: 146 | Batch_idx: 180 |  Loss: (0.0201) | Acc: (99.45%) (23040/23168)\n",
            "Epoch: 146 | Batch_idx: 190 |  Loss: (0.0198) | Acc: (99.46%) (24317/24448)\n",
            "Epoch: 146 | Batch_idx: 200 |  Loss: (0.0202) | Acc: (99.45%) (25587/25728)\n",
            "Epoch: 146 | Batch_idx: 210 |  Loss: (0.0201) | Acc: (99.45%) (26860/27008)\n",
            "Epoch: 146 | Batch_idx: 220 |  Loss: (0.0202) | Acc: (99.46%) (28134/28288)\n",
            "Epoch: 146 | Batch_idx: 230 |  Loss: (0.0205) | Acc: (99.44%) (29403/29568)\n",
            "Epoch: 146 | Batch_idx: 240 |  Loss: (0.0205) | Acc: (99.44%) (30676/30848)\n",
            "Epoch: 146 | Batch_idx: 250 |  Loss: (0.0204) | Acc: (99.45%) (31950/32128)\n",
            "Epoch: 146 | Batch_idx: 260 |  Loss: (0.0203) | Acc: (99.45%) (33223/33408)\n",
            "Epoch: 146 | Batch_idx: 270 |  Loss: (0.0205) | Acc: (99.44%) (34493/34688)\n",
            "Epoch: 146 | Batch_idx: 280 |  Loss: (0.0204) | Acc: (99.44%) (35767/35968)\n",
            "Epoch: 146 | Batch_idx: 290 |  Loss: (0.0204) | Acc: (99.44%) (37041/37248)\n",
            "Epoch: 146 | Batch_idx: 300 |  Loss: (0.0205) | Acc: (99.45%) (38316/38528)\n",
            "Epoch: 146 | Batch_idx: 310 |  Loss: (0.0205) | Acc: (99.45%) (39589/39808)\n",
            "Epoch: 146 | Batch_idx: 320 |  Loss: (0.0206) | Acc: (99.44%) (40858/41088)\n",
            "Epoch: 146 | Batch_idx: 330 |  Loss: (0.0206) | Acc: (99.44%) (42131/42368)\n",
            "Epoch: 146 | Batch_idx: 340 |  Loss: (0.0208) | Acc: (99.43%) (43400/43648)\n",
            "Epoch: 146 | Batch_idx: 350 |  Loss: (0.0207) | Acc: (99.44%) (44676/44928)\n",
            "Epoch: 146 | Batch_idx: 360 |  Loss: (0.0210) | Acc: (99.42%) (45940/46208)\n",
            "Epoch: 146 | Batch_idx: 370 |  Loss: (0.0212) | Acc: (99.41%) (47207/47488)\n",
            "Epoch: 146 | Batch_idx: 380 |  Loss: (0.0211) | Acc: (99.42%) (48483/48768)\n",
            "Epoch: 146 | Batch_idx: 390 |  Loss: (0.0211) | Acc: (99.41%) (49705/50000)\n",
            "# TEST : Loss: (0.3615) | Acc: (91.93%) (9193/10000)\n",
            "Epoch: 147 | Batch_idx: 0 |  Loss: (0.0838) | Acc: (96.09%) (123/128)\n",
            "Epoch: 147 | Batch_idx: 10 |  Loss: (0.0248) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 147 | Batch_idx: 20 |  Loss: (0.0257) | Acc: (99.11%) (2664/2688)\n",
            "Epoch: 147 | Batch_idx: 30 |  Loss: (0.0244) | Acc: (99.17%) (3935/3968)\n",
            "Epoch: 147 | Batch_idx: 40 |  Loss: (0.0240) | Acc: (99.24%) (5208/5248)\n",
            "Epoch: 147 | Batch_idx: 50 |  Loss: (0.0234) | Acc: (99.26%) (6480/6528)\n",
            "Epoch: 147 | Batch_idx: 60 |  Loss: (0.0231) | Acc: (99.27%) (7751/7808)\n",
            "Epoch: 147 | Batch_idx: 70 |  Loss: (0.0222) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 147 | Batch_idx: 80 |  Loss: (0.0229) | Acc: (99.32%) (10297/10368)\n",
            "Epoch: 147 | Batch_idx: 90 |  Loss: (0.0224) | Acc: (99.35%) (11572/11648)\n",
            "Epoch: 147 | Batch_idx: 100 |  Loss: (0.0220) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 147 | Batch_idx: 110 |  Loss: (0.0221) | Acc: (99.34%) (14114/14208)\n",
            "Epoch: 147 | Batch_idx: 120 |  Loss: (0.0220) | Acc: (99.34%) (15386/15488)\n",
            "Epoch: 147 | Batch_idx: 130 |  Loss: (0.0222) | Acc: (99.34%) (16657/16768)\n",
            "Epoch: 147 | Batch_idx: 140 |  Loss: (0.0220) | Acc: (99.34%) (17929/18048)\n",
            "Epoch: 147 | Batch_idx: 150 |  Loss: (0.0230) | Acc: (99.31%) (19195/19328)\n",
            "Epoch: 147 | Batch_idx: 160 |  Loss: (0.0229) | Acc: (99.31%) (20466/20608)\n",
            "Epoch: 147 | Batch_idx: 170 |  Loss: (0.0226) | Acc: (99.33%) (21742/21888)\n",
            "Epoch: 147 | Batch_idx: 180 |  Loss: (0.0226) | Acc: (99.34%) (23014/23168)\n",
            "Epoch: 147 | Batch_idx: 190 |  Loss: (0.0224) | Acc: (99.35%) (24289/24448)\n",
            "Epoch: 147 | Batch_idx: 200 |  Loss: (0.0222) | Acc: (99.36%) (25564/25728)\n",
            "Epoch: 147 | Batch_idx: 210 |  Loss: (0.0220) | Acc: (99.37%) (26837/27008)\n",
            "Epoch: 147 | Batch_idx: 220 |  Loss: (0.0220) | Acc: (99.37%) (28109/28288)\n",
            "Epoch: 147 | Batch_idx: 230 |  Loss: (0.0217) | Acc: (99.38%) (29385/29568)\n",
            "Epoch: 147 | Batch_idx: 240 |  Loss: (0.0216) | Acc: (99.39%) (30661/30848)\n",
            "Epoch: 147 | Batch_idx: 250 |  Loss: (0.0219) | Acc: (99.37%) (31926/32128)\n",
            "Epoch: 147 | Batch_idx: 260 |  Loss: (0.0223) | Acc: (99.34%) (33189/33408)\n",
            "Epoch: 147 | Batch_idx: 270 |  Loss: (0.0222) | Acc: (99.35%) (34463/34688)\n",
            "Epoch: 147 | Batch_idx: 280 |  Loss: (0.0223) | Acc: (99.35%) (35735/35968)\n",
            "Epoch: 147 | Batch_idx: 290 |  Loss: (0.0222) | Acc: (99.35%) (37007/37248)\n",
            "Epoch: 147 | Batch_idx: 300 |  Loss: (0.0219) | Acc: (99.36%) (38283/38528)\n",
            "Epoch: 147 | Batch_idx: 310 |  Loss: (0.0221) | Acc: (99.35%) (39549/39808)\n",
            "Epoch: 147 | Batch_idx: 320 |  Loss: (0.0220) | Acc: (99.35%) (40822/41088)\n",
            "Epoch: 147 | Batch_idx: 330 |  Loss: (0.0219) | Acc: (99.36%) (42096/42368)\n",
            "Epoch: 147 | Batch_idx: 340 |  Loss: (0.0219) | Acc: (99.36%) (43369/43648)\n",
            "Epoch: 147 | Batch_idx: 350 |  Loss: (0.0218) | Acc: (99.37%) (44643/44928)\n",
            "Epoch: 147 | Batch_idx: 360 |  Loss: (0.0219) | Acc: (99.36%) (45913/46208)\n",
            "Epoch: 147 | Batch_idx: 370 |  Loss: (0.0219) | Acc: (99.36%) (47186/47488)\n",
            "Epoch: 147 | Batch_idx: 380 |  Loss: (0.0221) | Acc: (99.36%) (48456/48768)\n",
            "Epoch: 147 | Batch_idx: 390 |  Loss: (0.0221) | Acc: (99.36%) (49679/50000)\n",
            "# TEST : Loss: (0.3590) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 148 | Batch_idx: 0 |  Loss: (0.0357) | Acc: (99.22%) (127/128)\n",
            "Epoch: 148 | Batch_idx: 10 |  Loss: (0.0203) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 148 | Batch_idx: 20 |  Loss: (0.0238) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 148 | Batch_idx: 30 |  Loss: (0.0214) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 148 | Batch_idx: 40 |  Loss: (0.0217) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 148 | Batch_idx: 50 |  Loss: (0.0226) | Acc: (99.39%) (6488/6528)\n",
            "Epoch: 148 | Batch_idx: 60 |  Loss: (0.0214) | Acc: (99.40%) (7761/7808)\n",
            "Epoch: 148 | Batch_idx: 70 |  Loss: (0.0214) | Acc: (99.38%) (9032/9088)\n",
            "Epoch: 148 | Batch_idx: 80 |  Loss: (0.0228) | Acc: (99.32%) (10298/10368)\n",
            "Epoch: 148 | Batch_idx: 90 |  Loss: (0.0225) | Acc: (99.34%) (11571/11648)\n",
            "Epoch: 148 | Batch_idx: 100 |  Loss: (0.0218) | Acc: (99.37%) (12847/12928)\n",
            "Epoch: 148 | Batch_idx: 110 |  Loss: (0.0215) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 148 | Batch_idx: 120 |  Loss: (0.0210) | Acc: (99.40%) (15395/15488)\n",
            "Epoch: 148 | Batch_idx: 130 |  Loss: (0.0216) | Acc: (99.36%) (16661/16768)\n",
            "Epoch: 148 | Batch_idx: 140 |  Loss: (0.0219) | Acc: (99.36%) (17933/18048)\n",
            "Epoch: 148 | Batch_idx: 150 |  Loss: (0.0227) | Acc: (99.34%) (19200/19328)\n",
            "Epoch: 148 | Batch_idx: 160 |  Loss: (0.0224) | Acc: (99.35%) (20474/20608)\n",
            "Epoch: 148 | Batch_idx: 170 |  Loss: (0.0223) | Acc: (99.36%) (21747/21888)\n",
            "Epoch: 148 | Batch_idx: 180 |  Loss: (0.0223) | Acc: (99.36%) (23019/23168)\n",
            "Epoch: 148 | Batch_idx: 190 |  Loss: (0.0221) | Acc: (99.36%) (24291/24448)\n",
            "Epoch: 148 | Batch_idx: 200 |  Loss: (0.0219) | Acc: (99.37%) (25567/25728)\n",
            "Epoch: 148 | Batch_idx: 210 |  Loss: (0.0221) | Acc: (99.36%) (26836/27008)\n",
            "Epoch: 148 | Batch_idx: 220 |  Loss: (0.0222) | Acc: (99.35%) (28105/28288)\n",
            "Epoch: 148 | Batch_idx: 230 |  Loss: (0.0221) | Acc: (99.36%) (29378/29568)\n",
            "Epoch: 148 | Batch_idx: 240 |  Loss: (0.0221) | Acc: (99.36%) (30650/30848)\n",
            "Epoch: 148 | Batch_idx: 250 |  Loss: (0.0222) | Acc: (99.35%) (31919/32128)\n",
            "Epoch: 148 | Batch_idx: 260 |  Loss: (0.0223) | Acc: (99.34%) (33188/33408)\n",
            "Epoch: 148 | Batch_idx: 270 |  Loss: (0.0225) | Acc: (99.34%) (34458/34688)\n",
            "Epoch: 148 | Batch_idx: 280 |  Loss: (0.0225) | Acc: (99.34%) (35729/35968)\n",
            "Epoch: 148 | Batch_idx: 290 |  Loss: (0.0225) | Acc: (99.33%) (37000/37248)\n",
            "Epoch: 148 | Batch_idx: 300 |  Loss: (0.0226) | Acc: (99.33%) (38271/38528)\n",
            "Epoch: 148 | Batch_idx: 310 |  Loss: (0.0226) | Acc: (99.33%) (39540/39808)\n",
            "Epoch: 148 | Batch_idx: 320 |  Loss: (0.0224) | Acc: (99.33%) (40814/41088)\n",
            "Epoch: 148 | Batch_idx: 330 |  Loss: (0.0224) | Acc: (99.33%) (42086/42368)\n",
            "Epoch: 148 | Batch_idx: 340 |  Loss: (0.0223) | Acc: (99.34%) (43360/43648)\n",
            "Epoch: 148 | Batch_idx: 350 |  Loss: (0.0221) | Acc: (99.35%) (44634/44928)\n",
            "Epoch: 148 | Batch_idx: 360 |  Loss: (0.0221) | Acc: (99.35%) (45907/46208)\n",
            "Epoch: 148 | Batch_idx: 370 |  Loss: (0.0222) | Acc: (99.34%) (47176/47488)\n",
            "Epoch: 148 | Batch_idx: 380 |  Loss: (0.0221) | Acc: (99.35%) (48449/48768)\n",
            "Epoch: 148 | Batch_idx: 390 |  Loss: (0.0222) | Acc: (99.35%) (49676/50000)\n",
            "# TEST : Loss: (0.3646) | Acc: (91.99%) (9199/10000)\n",
            "Epoch: 149 | Batch_idx: 0 |  Loss: (0.0235) | Acc: (100.00%) (128/128)\n",
            "Epoch: 149 | Batch_idx: 10 |  Loss: (0.0161) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 149 | Batch_idx: 20 |  Loss: (0.0237) | Acc: (99.37%) (2671/2688)\n",
            "Epoch: 149 | Batch_idx: 30 |  Loss: (0.0224) | Acc: (99.45%) (3946/3968)\n",
            "Epoch: 149 | Batch_idx: 40 |  Loss: (0.0207) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 149 | Batch_idx: 50 |  Loss: (0.0209) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 149 | Batch_idx: 60 |  Loss: (0.0212) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 149 | Batch_idx: 70 |  Loss: (0.0195) | Acc: (99.54%) (9046/9088)\n",
            "Epoch: 149 | Batch_idx: 80 |  Loss: (0.0191) | Acc: (99.57%) (10323/10368)\n",
            "Epoch: 149 | Batch_idx: 90 |  Loss: (0.0194) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 149 | Batch_idx: 100 |  Loss: (0.0194) | Acc: (99.54%) (12868/12928)\n",
            "Epoch: 149 | Batch_idx: 110 |  Loss: (0.0196) | Acc: (99.53%) (14141/14208)\n",
            "Epoch: 149 | Batch_idx: 120 |  Loss: (0.0195) | Acc: (99.54%) (15416/15488)\n",
            "Epoch: 149 | Batch_idx: 130 |  Loss: (0.0199) | Acc: (99.52%) (16687/16768)\n",
            "Epoch: 149 | Batch_idx: 140 |  Loss: (0.0197) | Acc: (99.53%) (17964/18048)\n",
            "Epoch: 149 | Batch_idx: 150 |  Loss: (0.0198) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 149 | Batch_idx: 160 |  Loss: (0.0197) | Acc: (99.53%) (20511/20608)\n",
            "Epoch: 149 | Batch_idx: 170 |  Loss: (0.0195) | Acc: (99.53%) (21786/21888)\n",
            "Epoch: 149 | Batch_idx: 180 |  Loss: (0.0197) | Acc: (99.52%) (23057/23168)\n",
            "Epoch: 149 | Batch_idx: 190 |  Loss: (0.0200) | Acc: (99.51%) (24327/24448)\n",
            "Epoch: 149 | Batch_idx: 200 |  Loss: (0.0204) | Acc: (99.48%) (25595/25728)\n",
            "Epoch: 149 | Batch_idx: 210 |  Loss: (0.0206) | Acc: (99.47%) (26864/27008)\n",
            "Epoch: 149 | Batch_idx: 220 |  Loss: (0.0208) | Acc: (99.46%) (28136/28288)\n",
            "Epoch: 149 | Batch_idx: 230 |  Loss: (0.0207) | Acc: (99.47%) (29410/29568)\n",
            "Epoch: 149 | Batch_idx: 240 |  Loss: (0.0206) | Acc: (99.48%) (30687/30848)\n",
            "Epoch: 149 | Batch_idx: 250 |  Loss: (0.0205) | Acc: (99.48%) (31962/32128)\n",
            "Epoch: 149 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.47%) (33232/33408)\n",
            "Epoch: 149 | Batch_idx: 270 |  Loss: (0.0205) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 149 | Batch_idx: 280 |  Loss: (0.0203) | Acc: (99.48%) (35781/35968)\n",
            "Epoch: 149 | Batch_idx: 290 |  Loss: (0.0204) | Acc: (99.47%) (37051/37248)\n",
            "Epoch: 149 | Batch_idx: 300 |  Loss: (0.0203) | Acc: (99.48%) (38328/38528)\n",
            "Epoch: 149 | Batch_idx: 310 |  Loss: (0.0202) | Acc: (99.49%) (39603/39808)\n",
            "Epoch: 149 | Batch_idx: 320 |  Loss: (0.0201) | Acc: (99.48%) (40875/41088)\n",
            "Epoch: 149 | Batch_idx: 330 |  Loss: (0.0201) | Acc: (99.48%) (42146/42368)\n",
            "Epoch: 149 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.48%) (43419/43648)\n",
            "Epoch: 149 | Batch_idx: 350 |  Loss: (0.0200) | Acc: (99.47%) (44692/44928)\n",
            "Epoch: 149 | Batch_idx: 360 |  Loss: (0.0198) | Acc: (99.49%) (45971/46208)\n",
            "Epoch: 149 | Batch_idx: 370 |  Loss: (0.0199) | Acc: (99.48%) (47242/47488)\n",
            "Epoch: 149 | Batch_idx: 380 |  Loss: (0.0199) | Acc: (99.48%) (48514/48768)\n",
            "Epoch: 149 | Batch_idx: 390 |  Loss: (0.0199) | Acc: (99.48%) (49740/50000)\n",
            "# TEST : Loss: (0.3628) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 150 | Batch_idx: 0 |  Loss: (0.0454) | Acc: (98.44%) (126/128)\n",
            "Epoch: 150 | Batch_idx: 10 |  Loss: (0.0314) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 150 | Batch_idx: 20 |  Loss: (0.0283) | Acc: (99.22%) (2667/2688)\n",
            "Epoch: 150 | Batch_idx: 30 |  Loss: (0.0299) | Acc: (99.19%) (3936/3968)\n",
            "Epoch: 150 | Batch_idx: 40 |  Loss: (0.0266) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 150 | Batch_idx: 50 |  Loss: (0.0272) | Acc: (99.22%) (6477/6528)\n",
            "Epoch: 150 | Batch_idx: 60 |  Loss: (0.0270) | Acc: (99.22%) (7747/7808)\n",
            "Epoch: 150 | Batch_idx: 70 |  Loss: (0.0255) | Acc: (99.27%) (9022/9088)\n",
            "Epoch: 150 | Batch_idx: 80 |  Loss: (0.0246) | Acc: (99.32%) (10297/10368)\n",
            "Epoch: 150 | Batch_idx: 90 |  Loss: (0.0243) | Acc: (99.33%) (11570/11648)\n",
            "Epoch: 150 | Batch_idx: 100 |  Loss: (0.0235) | Acc: (99.37%) (12846/12928)\n",
            "Epoch: 150 | Batch_idx: 110 |  Loss: (0.0230) | Acc: (99.37%) (14119/14208)\n",
            "Epoch: 150 | Batch_idx: 120 |  Loss: (0.0231) | Acc: (99.39%) (15393/15488)\n",
            "Epoch: 150 | Batch_idx: 130 |  Loss: (0.0229) | Acc: (99.38%) (16664/16768)\n",
            "Epoch: 150 | Batch_idx: 140 |  Loss: (0.0229) | Acc: (99.37%) (17934/18048)\n",
            "Epoch: 150 | Batch_idx: 150 |  Loss: (0.0232) | Acc: (99.36%) (19205/19328)\n",
            "Epoch: 150 | Batch_idx: 160 |  Loss: (0.0228) | Acc: (99.38%) (20480/20608)\n",
            "Epoch: 150 | Batch_idx: 170 |  Loss: (0.0225) | Acc: (99.39%) (21755/21888)\n",
            "Epoch: 150 | Batch_idx: 180 |  Loss: (0.0225) | Acc: (99.39%) (23026/23168)\n",
            "Epoch: 150 | Batch_idx: 190 |  Loss: (0.0226) | Acc: (99.37%) (24294/24448)\n",
            "Epoch: 150 | Batch_idx: 200 |  Loss: (0.0227) | Acc: (99.36%) (25564/25728)\n",
            "Epoch: 150 | Batch_idx: 210 |  Loss: (0.0230) | Acc: (99.35%) (26833/27008)\n",
            "Epoch: 150 | Batch_idx: 220 |  Loss: (0.0227) | Acc: (99.37%) (28111/28288)\n",
            "Epoch: 150 | Batch_idx: 230 |  Loss: (0.0231) | Acc: (99.36%) (29379/29568)\n",
            "Epoch: 150 | Batch_idx: 240 |  Loss: (0.0230) | Acc: (99.36%) (30651/30848)\n",
            "Epoch: 150 | Batch_idx: 250 |  Loss: (0.0227) | Acc: (99.38%) (31928/32128)\n",
            "Epoch: 150 | Batch_idx: 260 |  Loss: (0.0225) | Acc: (99.39%) (33203/33408)\n",
            "Epoch: 150 | Batch_idx: 270 |  Loss: (0.0222) | Acc: (99.40%) (34479/34688)\n",
            "Epoch: 150 | Batch_idx: 280 |  Loss: (0.0223) | Acc: (99.40%) (35753/35968)\n",
            "Epoch: 150 | Batch_idx: 290 |  Loss: (0.0219) | Acc: (99.41%) (37030/37248)\n",
            "Epoch: 150 | Batch_idx: 300 |  Loss: (0.0218) | Acc: (99.42%) (38305/38528)\n",
            "Epoch: 150 | Batch_idx: 310 |  Loss: (0.0220) | Acc: (99.41%) (39574/39808)\n",
            "Epoch: 150 | Batch_idx: 320 |  Loss: (0.0219) | Acc: (99.42%) (40848/41088)\n",
            "Epoch: 150 | Batch_idx: 330 |  Loss: (0.0219) | Acc: (99.41%) (42120/42368)\n",
            "Epoch: 150 | Batch_idx: 340 |  Loss: (0.0217) | Acc: (99.42%) (43393/43648)\n",
            "Epoch: 150 | Batch_idx: 350 |  Loss: (0.0215) | Acc: (99.42%) (44669/44928)\n",
            "Epoch: 150 | Batch_idx: 360 |  Loss: (0.0213) | Acc: (99.43%) (45944/46208)\n",
            "Epoch: 150 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.43%) (47219/47488)\n",
            "Epoch: 150 | Batch_idx: 380 |  Loss: (0.0213) | Acc: (99.43%) (48491/48768)\n",
            "Epoch: 150 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.44%) (49720/50000)\n",
            "# TEST : Loss: (0.3638) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 151 | Batch_idx: 0 |  Loss: (0.0155) | Acc: (100.00%) (128/128)\n",
            "Epoch: 151 | Batch_idx: 10 |  Loss: (0.0169) | Acc: (99.72%) (1404/1408)\n",
            "Epoch: 151 | Batch_idx: 20 |  Loss: (0.0190) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 151 | Batch_idx: 30 |  Loss: (0.0189) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 151 | Batch_idx: 40 |  Loss: (0.0184) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 151 | Batch_idx: 50 |  Loss: (0.0180) | Acc: (99.57%) (6500/6528)\n",
            "Epoch: 151 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 151 | Batch_idx: 70 |  Loss: (0.0198) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 151 | Batch_idx: 80 |  Loss: (0.0203) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 151 | Batch_idx: 90 |  Loss: (0.0201) | Acc: (99.46%) (11585/11648)\n",
            "Epoch: 151 | Batch_idx: 100 |  Loss: (0.0204) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 151 | Batch_idx: 110 |  Loss: (0.0207) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 151 | Batch_idx: 120 |  Loss: (0.0204) | Acc: (99.48%) (15407/15488)\n",
            "Epoch: 151 | Batch_idx: 130 |  Loss: (0.0202) | Acc: (99.49%) (16682/16768)\n",
            "Epoch: 151 | Batch_idx: 140 |  Loss: (0.0204) | Acc: (99.47%) (17953/18048)\n",
            "Epoch: 151 | Batch_idx: 150 |  Loss: (0.0205) | Acc: (99.47%) (19225/19328)\n",
            "Epoch: 151 | Batch_idx: 160 |  Loss: (0.0204) | Acc: (99.46%) (20497/20608)\n",
            "Epoch: 151 | Batch_idx: 170 |  Loss: (0.0203) | Acc: (99.46%) (21770/21888)\n",
            "Epoch: 151 | Batch_idx: 180 |  Loss: (0.0200) | Acc: (99.47%) (23046/23168)\n",
            "Epoch: 151 | Batch_idx: 190 |  Loss: (0.0199) | Acc: (99.49%) (24324/24448)\n",
            "Epoch: 151 | Batch_idx: 200 |  Loss: (0.0199) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 151 | Batch_idx: 210 |  Loss: (0.0203) | Acc: (99.47%) (26866/27008)\n",
            "Epoch: 151 | Batch_idx: 220 |  Loss: (0.0204) | Acc: (99.47%) (28139/28288)\n",
            "Epoch: 151 | Batch_idx: 230 |  Loss: (0.0205) | Acc: (99.47%) (29411/29568)\n",
            "Epoch: 151 | Batch_idx: 240 |  Loss: (0.0210) | Acc: (99.45%) (30678/30848)\n",
            "Epoch: 151 | Batch_idx: 250 |  Loss: (0.0210) | Acc: (99.45%) (31951/32128)\n",
            "Epoch: 151 | Batch_idx: 260 |  Loss: (0.0210) | Acc: (99.45%) (33224/33408)\n",
            "Epoch: 151 | Batch_idx: 270 |  Loss: (0.0209) | Acc: (99.46%) (34499/34688)\n",
            "Epoch: 151 | Batch_idx: 280 |  Loss: (0.0207) | Acc: (99.46%) (35774/35968)\n",
            "Epoch: 151 | Batch_idx: 290 |  Loss: (0.0209) | Acc: (99.44%) (37041/37248)\n",
            "Epoch: 151 | Batch_idx: 300 |  Loss: (0.0208) | Acc: (99.44%) (38313/38528)\n",
            "Epoch: 151 | Batch_idx: 310 |  Loss: (0.0207) | Acc: (99.45%) (39589/39808)\n",
            "Epoch: 151 | Batch_idx: 320 |  Loss: (0.0207) | Acc: (99.45%) (40862/41088)\n",
            "Epoch: 151 | Batch_idx: 330 |  Loss: (0.0209) | Acc: (99.44%) (42131/42368)\n",
            "Epoch: 151 | Batch_idx: 340 |  Loss: (0.0208) | Acc: (99.45%) (43407/43648)\n",
            "Epoch: 151 | Batch_idx: 350 |  Loss: (0.0206) | Acc: (99.46%) (44685/44928)\n",
            "Epoch: 151 | Batch_idx: 360 |  Loss: (0.0207) | Acc: (99.46%) (45958/46208)\n",
            "Epoch: 151 | Batch_idx: 370 |  Loss: (0.0206) | Acc: (99.47%) (47236/47488)\n",
            "Epoch: 151 | Batch_idx: 380 |  Loss: (0.0207) | Acc: (99.46%) (48507/48768)\n",
            "Epoch: 151 | Batch_idx: 390 |  Loss: (0.0208) | Acc: (99.45%) (49727/50000)\n",
            "# TEST : Loss: (0.3667) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 152 | Batch_idx: 0 |  Loss: (0.0265) | Acc: (99.22%) (127/128)\n",
            "Epoch: 152 | Batch_idx: 10 |  Loss: (0.0190) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 152 | Batch_idx: 20 |  Loss: (0.0190) | Acc: (99.63%) (2678/2688)\n",
            "Epoch: 152 | Batch_idx: 30 |  Loss: (0.0195) | Acc: (99.62%) (3953/3968)\n",
            "Epoch: 152 | Batch_idx: 40 |  Loss: (0.0187) | Acc: (99.60%) (5227/5248)\n",
            "Epoch: 152 | Batch_idx: 50 |  Loss: (0.0192) | Acc: (99.59%) (6501/6528)\n",
            "Epoch: 152 | Batch_idx: 60 |  Loss: (0.0181) | Acc: (99.63%) (7779/7808)\n",
            "Epoch: 152 | Batch_idx: 70 |  Loss: (0.0179) | Acc: (99.61%) (9053/9088)\n",
            "Epoch: 152 | Batch_idx: 80 |  Loss: (0.0192) | Acc: (99.54%) (10320/10368)\n",
            "Epoch: 152 | Batch_idx: 90 |  Loss: (0.0194) | Acc: (99.52%) (11592/11648)\n",
            "Epoch: 152 | Batch_idx: 100 |  Loss: (0.0200) | Acc: (99.50%) (12863/12928)\n",
            "Epoch: 152 | Batch_idx: 110 |  Loss: (0.0205) | Acc: (99.49%) (14135/14208)\n",
            "Epoch: 152 | Batch_idx: 120 |  Loss: (0.0209) | Acc: (99.48%) (15407/15488)\n",
            "Epoch: 152 | Batch_idx: 130 |  Loss: (0.0210) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 152 | Batch_idx: 140 |  Loss: (0.0206) | Acc: (99.49%) (17956/18048)\n",
            "Epoch: 152 | Batch_idx: 150 |  Loss: (0.0203) | Acc: (99.50%) (19232/19328)\n",
            "Epoch: 152 | Batch_idx: 160 |  Loss: (0.0201) | Acc: (99.52%) (20509/20608)\n",
            "Epoch: 152 | Batch_idx: 170 |  Loss: (0.0200) | Acc: (99.52%) (21782/21888)\n",
            "Epoch: 152 | Batch_idx: 180 |  Loss: (0.0197) | Acc: (99.53%) (23060/23168)\n",
            "Epoch: 152 | Batch_idx: 190 |  Loss: (0.0198) | Acc: (99.52%) (24331/24448)\n",
            "Epoch: 152 | Batch_idx: 200 |  Loss: (0.0201) | Acc: (99.50%) (25599/25728)\n",
            "Epoch: 152 | Batch_idx: 210 |  Loss: (0.0203) | Acc: (99.49%) (26870/27008)\n",
            "Epoch: 152 | Batch_idx: 220 |  Loss: (0.0202) | Acc: (99.49%) (28143/28288)\n",
            "Epoch: 152 | Batch_idx: 230 |  Loss: (0.0203) | Acc: (99.48%) (29415/29568)\n",
            "Epoch: 152 | Batch_idx: 240 |  Loss: (0.0204) | Acc: (99.48%) (30687/30848)\n",
            "Epoch: 152 | Batch_idx: 250 |  Loss: (0.0203) | Acc: (99.49%) (31963/32128)\n",
            "Epoch: 152 | Batch_idx: 260 |  Loss: (0.0205) | Acc: (99.47%) (33230/33408)\n",
            "Epoch: 152 | Batch_idx: 270 |  Loss: (0.0205) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 152 | Batch_idx: 280 |  Loss: (0.0204) | Acc: (99.47%) (35778/35968)\n",
            "Epoch: 152 | Batch_idx: 290 |  Loss: (0.0204) | Acc: (99.47%) (37051/37248)\n",
            "Epoch: 152 | Batch_idx: 300 |  Loss: (0.0203) | Acc: (99.48%) (38326/38528)\n",
            "Epoch: 152 | Batch_idx: 310 |  Loss: (0.0204) | Acc: (99.47%) (39598/39808)\n",
            "Epoch: 152 | Batch_idx: 320 |  Loss: (0.0204) | Acc: (99.48%) (40873/41088)\n",
            "Epoch: 152 | Batch_idx: 330 |  Loss: (0.0205) | Acc: (99.47%) (42143/42368)\n",
            "Epoch: 152 | Batch_idx: 340 |  Loss: (0.0205) | Acc: (99.46%) (43414/43648)\n",
            "Epoch: 152 | Batch_idx: 350 |  Loss: (0.0205) | Acc: (99.46%) (44685/44928)\n",
            "Epoch: 152 | Batch_idx: 360 |  Loss: (0.0203) | Acc: (99.47%) (45961/46208)\n",
            "Epoch: 152 | Batch_idx: 370 |  Loss: (0.0204) | Acc: (99.46%) (47232/47488)\n",
            "Epoch: 152 | Batch_idx: 380 |  Loss: (0.0204) | Acc: (99.46%) (48506/48768)\n",
            "Epoch: 152 | Batch_idx: 390 |  Loss: (0.0204) | Acc: (99.46%) (49729/50000)\n",
            "# TEST : Loss: (0.3631) | Acc: (91.89%) (9189/10000)\n",
            "Epoch: 153 | Batch_idx: 0 |  Loss: (0.0091) | Acc: (100.00%) (128/128)\n",
            "Epoch: 153 | Batch_idx: 10 |  Loss: (0.0202) | Acc: (99.50%) (1401/1408)\n",
            "Epoch: 153 | Batch_idx: 20 |  Loss: (0.0219) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 153 | Batch_idx: 30 |  Loss: (0.0212) | Acc: (99.37%) (3943/3968)\n",
            "Epoch: 153 | Batch_idx: 40 |  Loss: (0.0218) | Acc: (99.33%) (5213/5248)\n",
            "Epoch: 153 | Batch_idx: 50 |  Loss: (0.0213) | Acc: (99.37%) (6487/6528)\n",
            "Epoch: 153 | Batch_idx: 60 |  Loss: (0.0211) | Acc: (99.37%) (7759/7808)\n",
            "Epoch: 153 | Batch_idx: 70 |  Loss: (0.0213) | Acc: (99.35%) (9029/9088)\n",
            "Epoch: 153 | Batch_idx: 80 |  Loss: (0.0207) | Acc: (99.38%) (10304/10368)\n",
            "Epoch: 153 | Batch_idx: 90 |  Loss: (0.0207) | Acc: (99.36%) (11573/11648)\n",
            "Epoch: 153 | Batch_idx: 100 |  Loss: (0.0213) | Acc: (99.35%) (12844/12928)\n",
            "Epoch: 153 | Batch_idx: 110 |  Loss: (0.0211) | Acc: (99.35%) (14115/14208)\n",
            "Epoch: 153 | Batch_idx: 120 |  Loss: (0.0208) | Acc: (99.37%) (15390/15488)\n",
            "Epoch: 153 | Batch_idx: 130 |  Loss: (0.0205) | Acc: (99.39%) (16666/16768)\n",
            "Epoch: 153 | Batch_idx: 140 |  Loss: (0.0203) | Acc: (99.41%) (17941/18048)\n",
            "Epoch: 153 | Batch_idx: 150 |  Loss: (0.0202) | Acc: (99.40%) (19212/19328)\n",
            "Epoch: 153 | Batch_idx: 160 |  Loss: (0.0201) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 153 | Batch_idx: 170 |  Loss: (0.0200) | Acc: (99.42%) (21761/21888)\n",
            "Epoch: 153 | Batch_idx: 180 |  Loss: (0.0199) | Acc: (99.44%) (23038/23168)\n",
            "Epoch: 153 | Batch_idx: 190 |  Loss: (0.0201) | Acc: (99.44%) (24310/24448)\n",
            "Epoch: 153 | Batch_idx: 200 |  Loss: (0.0202) | Acc: (99.43%) (25581/25728)\n",
            "Epoch: 153 | Batch_idx: 210 |  Loss: (0.0201) | Acc: (99.44%) (26856/27008)\n",
            "Epoch: 153 | Batch_idx: 220 |  Loss: (0.0204) | Acc: (99.42%) (28124/28288)\n",
            "Epoch: 153 | Batch_idx: 230 |  Loss: (0.0208) | Acc: (99.40%) (29390/29568)\n",
            "Epoch: 153 | Batch_idx: 240 |  Loss: (0.0206) | Acc: (99.41%) (30666/30848)\n",
            "Epoch: 153 | Batch_idx: 250 |  Loss: (0.0205) | Acc: (99.42%) (31942/32128)\n",
            "Epoch: 153 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.42%) (33214/33408)\n",
            "Epoch: 153 | Batch_idx: 270 |  Loss: (0.0207) | Acc: (99.42%) (34487/34688)\n",
            "Epoch: 153 | Batch_idx: 280 |  Loss: (0.0209) | Acc: (99.41%) (35756/35968)\n",
            "Epoch: 153 | Batch_idx: 290 |  Loss: (0.0207) | Acc: (99.42%) (37032/37248)\n",
            "Epoch: 153 | Batch_idx: 300 |  Loss: (0.0209) | Acc: (99.41%) (38302/38528)\n",
            "Epoch: 153 | Batch_idx: 310 |  Loss: (0.0207) | Acc: (99.42%) (39577/39808)\n",
            "Epoch: 153 | Batch_idx: 320 |  Loss: (0.0207) | Acc: (99.43%) (40852/41088)\n",
            "Epoch: 153 | Batch_idx: 330 |  Loss: (0.0206) | Acc: (99.43%) (42127/42368)\n",
            "Epoch: 153 | Batch_idx: 340 |  Loss: (0.0207) | Acc: (99.42%) (43397/43648)\n",
            "Epoch: 153 | Batch_idx: 350 |  Loss: (0.0207) | Acc: (99.42%) (44668/44928)\n",
            "Epoch: 153 | Batch_idx: 360 |  Loss: (0.0208) | Acc: (99.41%) (45937/46208)\n",
            "Epoch: 153 | Batch_idx: 370 |  Loss: (0.0208) | Acc: (99.42%) (47211/47488)\n",
            "Epoch: 153 | Batch_idx: 380 |  Loss: (0.0207) | Acc: (99.42%) (48487/48768)\n",
            "Epoch: 153 | Batch_idx: 390 |  Loss: (0.0207) | Acc: (99.42%) (49711/50000)\n",
            "# TEST : Loss: (0.3635) | Acc: (91.72%) (9172/10000)\n",
            "Epoch: 154 | Batch_idx: 0 |  Loss: (0.0081) | Acc: (100.00%) (128/128)\n",
            "Epoch: 154 | Batch_idx: 10 |  Loss: (0.0170) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 154 | Batch_idx: 20 |  Loss: (0.0216) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 154 | Batch_idx: 30 |  Loss: (0.0219) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 154 | Batch_idx: 40 |  Loss: (0.0222) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 154 | Batch_idx: 50 |  Loss: (0.0215) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 154 | Batch_idx: 60 |  Loss: (0.0227) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 154 | Batch_idx: 70 |  Loss: (0.0223) | Acc: (99.37%) (9031/9088)\n",
            "Epoch: 154 | Batch_idx: 80 |  Loss: (0.0220) | Acc: (99.39%) (10305/10368)\n",
            "Epoch: 154 | Batch_idx: 90 |  Loss: (0.0224) | Acc: (99.32%) (11569/11648)\n",
            "Epoch: 154 | Batch_idx: 100 |  Loss: (0.0227) | Acc: (99.30%) (12838/12928)\n",
            "Epoch: 154 | Batch_idx: 110 |  Loss: (0.0230) | Acc: (99.32%) (14111/14208)\n",
            "Epoch: 154 | Batch_idx: 120 |  Loss: (0.0231) | Acc: (99.32%) (15383/15488)\n",
            "Epoch: 154 | Batch_idx: 130 |  Loss: (0.0232) | Acc: (99.32%) (16654/16768)\n",
            "Epoch: 154 | Batch_idx: 140 |  Loss: (0.0227) | Acc: (99.33%) (17927/18048)\n",
            "Epoch: 154 | Batch_idx: 150 |  Loss: (0.0224) | Acc: (99.35%) (19203/19328)\n",
            "Epoch: 154 | Batch_idx: 160 |  Loss: (0.0225) | Acc: (99.35%) (20474/20608)\n",
            "Epoch: 154 | Batch_idx: 170 |  Loss: (0.0225) | Acc: (99.34%) (21743/21888)\n",
            "Epoch: 154 | Batch_idx: 180 |  Loss: (0.0227) | Acc: (99.32%) (23010/23168)\n",
            "Epoch: 154 | Batch_idx: 190 |  Loss: (0.0226) | Acc: (99.33%) (24285/24448)\n",
            "Epoch: 154 | Batch_idx: 200 |  Loss: (0.0222) | Acc: (99.35%) (25562/25728)\n",
            "Epoch: 154 | Batch_idx: 210 |  Loss: (0.0221) | Acc: (99.36%) (26836/27008)\n",
            "Epoch: 154 | Batch_idx: 220 |  Loss: (0.0221) | Acc: (99.35%) (28105/28288)\n",
            "Epoch: 154 | Batch_idx: 230 |  Loss: (0.0220) | Acc: (99.36%) (29378/29568)\n",
            "Epoch: 154 | Batch_idx: 240 |  Loss: (0.0221) | Acc: (99.35%) (30648/30848)\n",
            "Epoch: 154 | Batch_idx: 250 |  Loss: (0.0220) | Acc: (99.35%) (31920/32128)\n",
            "Epoch: 154 | Batch_idx: 260 |  Loss: (0.0219) | Acc: (99.36%) (33194/33408)\n",
            "Epoch: 154 | Batch_idx: 270 |  Loss: (0.0219) | Acc: (99.36%) (34466/34688)\n",
            "Epoch: 154 | Batch_idx: 280 |  Loss: (0.0222) | Acc: (99.35%) (35734/35968)\n",
            "Epoch: 154 | Batch_idx: 290 |  Loss: (0.0221) | Acc: (99.35%) (37007/37248)\n",
            "Epoch: 154 | Batch_idx: 300 |  Loss: (0.0224) | Acc: (99.35%) (38277/38528)\n",
            "Epoch: 154 | Batch_idx: 310 |  Loss: (0.0223) | Acc: (99.36%) (39552/39808)\n",
            "Epoch: 154 | Batch_idx: 320 |  Loss: (0.0221) | Acc: (99.37%) (40828/41088)\n",
            "Epoch: 154 | Batch_idx: 330 |  Loss: (0.0223) | Acc: (99.37%) (42099/42368)\n",
            "Epoch: 154 | Batch_idx: 340 |  Loss: (0.0221) | Acc: (99.37%) (43371/43648)\n",
            "Epoch: 154 | Batch_idx: 350 |  Loss: (0.0221) | Acc: (99.37%) (44645/44928)\n",
            "Epoch: 154 | Batch_idx: 360 |  Loss: (0.0221) | Acc: (99.37%) (45917/46208)\n",
            "Epoch: 154 | Batch_idx: 370 |  Loss: (0.0219) | Acc: (99.38%) (47192/47488)\n",
            "Epoch: 154 | Batch_idx: 380 |  Loss: (0.0218) | Acc: (99.38%) (48467/48768)\n",
            "Epoch: 154 | Batch_idx: 390 |  Loss: (0.0218) | Acc: (99.38%) (49692/50000)\n",
            "# TEST : Loss: (0.3640) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 155 | Batch_idx: 0 |  Loss: (0.0131) | Acc: (100.00%) (128/128)\n",
            "Epoch: 155 | Batch_idx: 10 |  Loss: (0.0222) | Acc: (99.29%) (1398/1408)\n",
            "Epoch: 155 | Batch_idx: 20 |  Loss: (0.0207) | Acc: (99.29%) (2669/2688)\n",
            "Epoch: 155 | Batch_idx: 30 |  Loss: (0.0219) | Acc: (99.24%) (3938/3968)\n",
            "Epoch: 155 | Batch_idx: 40 |  Loss: (0.0204) | Acc: (99.31%) (5212/5248)\n",
            "Epoch: 155 | Batch_idx: 50 |  Loss: (0.0209) | Acc: (99.31%) (6483/6528)\n",
            "Epoch: 155 | Batch_idx: 60 |  Loss: (0.0205) | Acc: (99.39%) (7760/7808)\n",
            "Epoch: 155 | Batch_idx: 70 |  Loss: (0.0207) | Acc: (99.41%) (9034/9088)\n",
            "Epoch: 155 | Batch_idx: 80 |  Loss: (0.0207) | Acc: (99.41%) (10307/10368)\n",
            "Epoch: 155 | Batch_idx: 90 |  Loss: (0.0209) | Acc: (99.40%) (11578/11648)\n",
            "Epoch: 155 | Batch_idx: 100 |  Loss: (0.0207) | Acc: (99.42%) (12853/12928)\n",
            "Epoch: 155 | Batch_idx: 110 |  Loss: (0.0203) | Acc: (99.43%) (14127/14208)\n",
            "Epoch: 155 | Batch_idx: 120 |  Loss: (0.0204) | Acc: (99.44%) (15401/15488)\n",
            "Epoch: 155 | Batch_idx: 130 |  Loss: (0.0205) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 155 | Batch_idx: 140 |  Loss: (0.0210) | Acc: (99.42%) (17943/18048)\n",
            "Epoch: 155 | Batch_idx: 150 |  Loss: (0.0210) | Acc: (99.43%) (19217/19328)\n",
            "Epoch: 155 | Batch_idx: 160 |  Loss: (0.0209) | Acc: (99.44%) (20492/20608)\n",
            "Epoch: 155 | Batch_idx: 170 |  Loss: (0.0212) | Acc: (99.43%) (21763/21888)\n",
            "Epoch: 155 | Batch_idx: 180 |  Loss: (0.0210) | Acc: (99.43%) (23036/23168)\n",
            "Epoch: 155 | Batch_idx: 190 |  Loss: (0.0209) | Acc: (99.44%) (24310/24448)\n",
            "Epoch: 155 | Batch_idx: 200 |  Loss: (0.0211) | Acc: (99.42%) (25579/25728)\n",
            "Epoch: 155 | Batch_idx: 210 |  Loss: (0.0211) | Acc: (99.43%) (26854/27008)\n",
            "Epoch: 155 | Batch_idx: 220 |  Loss: (0.0213) | Acc: (99.41%) (28122/28288)\n",
            "Epoch: 155 | Batch_idx: 230 |  Loss: (0.0216) | Acc: (99.40%) (29390/29568)\n",
            "Epoch: 155 | Batch_idx: 240 |  Loss: (0.0214) | Acc: (99.41%) (30667/30848)\n",
            "Epoch: 155 | Batch_idx: 250 |  Loss: (0.0218) | Acc: (99.40%) (31935/32128)\n",
            "Epoch: 155 | Batch_idx: 260 |  Loss: (0.0217) | Acc: (99.40%) (33206/33408)\n",
            "Epoch: 155 | Batch_idx: 270 |  Loss: (0.0217) | Acc: (99.39%) (34478/34688)\n",
            "Epoch: 155 | Batch_idx: 280 |  Loss: (0.0216) | Acc: (99.40%) (35752/35968)\n",
            "Epoch: 155 | Batch_idx: 290 |  Loss: (0.0216) | Acc: (99.41%) (37027/37248)\n",
            "Epoch: 155 | Batch_idx: 300 |  Loss: (0.0214) | Acc: (99.42%) (38305/38528)\n",
            "Epoch: 155 | Batch_idx: 310 |  Loss: (0.0213) | Acc: (99.42%) (39578/39808)\n",
            "Epoch: 155 | Batch_idx: 320 |  Loss: (0.0213) | Acc: (99.42%) (40849/41088)\n",
            "Epoch: 155 | Batch_idx: 330 |  Loss: (0.0213) | Acc: (99.42%) (42123/42368)\n",
            "Epoch: 155 | Batch_idx: 340 |  Loss: (0.0213) | Acc: (99.42%) (43394/43648)\n",
            "Epoch: 155 | Batch_idx: 350 |  Loss: (0.0213) | Acc: (99.42%) (44667/44928)\n",
            "Epoch: 155 | Batch_idx: 360 |  Loss: (0.0212) | Acc: (99.41%) (45937/46208)\n",
            "Epoch: 155 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.41%) (47209/47488)\n",
            "Epoch: 155 | Batch_idx: 380 |  Loss: (0.0212) | Acc: (99.42%) (48484/48768)\n",
            "Epoch: 155 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.42%) (49708/50000)\n",
            "# TEST : Loss: (0.3631) | Acc: (91.85%) (9185/10000)\n",
            "Epoch: 156 | Batch_idx: 0 |  Loss: (0.0439) | Acc: (98.44%) (126/128)\n",
            "Epoch: 156 | Batch_idx: 10 |  Loss: (0.0239) | Acc: (99.15%) (1396/1408)\n",
            "Epoch: 156 | Batch_idx: 20 |  Loss: (0.0192) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 156 | Batch_idx: 30 |  Loss: (0.0213) | Acc: (99.40%) (3944/3968)\n",
            "Epoch: 156 | Batch_idx: 40 |  Loss: (0.0201) | Acc: (99.41%) (5217/5248)\n",
            "Epoch: 156 | Batch_idx: 50 |  Loss: (0.0187) | Acc: (99.51%) (6496/6528)\n",
            "Epoch: 156 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 156 | Batch_idx: 70 |  Loss: (0.0205) | Acc: (99.44%) (9037/9088)\n",
            "Epoch: 156 | Batch_idx: 80 |  Loss: (0.0209) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 156 | Batch_idx: 90 |  Loss: (0.0210) | Acc: (99.44%) (11583/11648)\n",
            "Epoch: 156 | Batch_idx: 100 |  Loss: (0.0217) | Acc: (99.38%) (12848/12928)\n",
            "Epoch: 156 | Batch_idx: 110 |  Loss: (0.0219) | Acc: (99.38%) (14120/14208)\n",
            "Epoch: 156 | Batch_idx: 120 |  Loss: (0.0216) | Acc: (99.39%) (15393/15488)\n",
            "Epoch: 156 | Batch_idx: 130 |  Loss: (0.0214) | Acc: (99.39%) (16665/16768)\n",
            "Epoch: 156 | Batch_idx: 140 |  Loss: (0.0213) | Acc: (99.41%) (17941/18048)\n",
            "Epoch: 156 | Batch_idx: 150 |  Loss: (0.0215) | Acc: (99.41%) (19214/19328)\n",
            "Epoch: 156 | Batch_idx: 160 |  Loss: (0.0216) | Acc: (99.41%) (20487/20608)\n",
            "Epoch: 156 | Batch_idx: 170 |  Loss: (0.0210) | Acc: (99.44%) (21766/21888)\n",
            "Epoch: 156 | Batch_idx: 180 |  Loss: (0.0210) | Acc: (99.45%) (23040/23168)\n",
            "Epoch: 156 | Batch_idx: 190 |  Loss: (0.0213) | Acc: (99.42%) (24305/24448)\n",
            "Epoch: 156 | Batch_idx: 200 |  Loss: (0.0210) | Acc: (99.43%) (25581/25728)\n",
            "Epoch: 156 | Batch_idx: 210 |  Loss: (0.0208) | Acc: (99.44%) (26858/27008)\n",
            "Epoch: 156 | Batch_idx: 220 |  Loss: (0.0206) | Acc: (99.46%) (28136/28288)\n",
            "Epoch: 156 | Batch_idx: 230 |  Loss: (0.0204) | Acc: (99.47%) (29412/29568)\n",
            "Epoch: 156 | Batch_idx: 240 |  Loss: (0.0203) | Acc: (99.47%) (30686/30848)\n",
            "Epoch: 156 | Batch_idx: 250 |  Loss: (0.0205) | Acc: (99.46%) (31955/32128)\n",
            "Epoch: 156 | Batch_idx: 260 |  Loss: (0.0206) | Acc: (99.44%) (33222/33408)\n",
            "Epoch: 156 | Batch_idx: 270 |  Loss: (0.0206) | Acc: (99.44%) (34493/34688)\n",
            "Epoch: 156 | Batch_idx: 280 |  Loss: (0.0207) | Acc: (99.43%) (35763/35968)\n",
            "Epoch: 156 | Batch_idx: 290 |  Loss: (0.0207) | Acc: (99.43%) (37037/37248)\n",
            "Epoch: 156 | Batch_idx: 300 |  Loss: (0.0206) | Acc: (99.43%) (38310/38528)\n",
            "Epoch: 156 | Batch_idx: 310 |  Loss: (0.0205) | Acc: (99.44%) (39584/39808)\n",
            "Epoch: 156 | Batch_idx: 320 |  Loss: (0.0206) | Acc: (99.44%) (40857/41088)\n",
            "Epoch: 156 | Batch_idx: 330 |  Loss: (0.0207) | Acc: (99.44%) (42131/42368)\n",
            "Epoch: 156 | Batch_idx: 340 |  Loss: (0.0210) | Acc: (99.44%) (43402/43648)\n",
            "Epoch: 156 | Batch_idx: 350 |  Loss: (0.0210) | Acc: (99.42%) (44669/44928)\n",
            "Epoch: 156 | Batch_idx: 360 |  Loss: (0.0211) | Acc: (99.41%) (45936/46208)\n",
            "Epoch: 156 | Batch_idx: 370 |  Loss: (0.0213) | Acc: (99.41%) (47208/47488)\n",
            "Epoch: 156 | Batch_idx: 380 |  Loss: (0.0212) | Acc: (99.41%) (48482/48768)\n",
            "Epoch: 156 | Batch_idx: 390 |  Loss: (0.0212) | Acc: (99.42%) (49708/50000)\n",
            "# TEST : Loss: (0.3634) | Acc: (91.86%) (9186/10000)\n",
            "Epoch: 157 | Batch_idx: 0 |  Loss: (0.0197) | Acc: (99.22%) (127/128)\n",
            "Epoch: 157 | Batch_idx: 10 |  Loss: (0.0166) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 157 | Batch_idx: 20 |  Loss: (0.0168) | Acc: (99.67%) (2679/2688)\n",
            "Epoch: 157 | Batch_idx: 30 |  Loss: (0.0181) | Acc: (99.57%) (3951/3968)\n",
            "Epoch: 157 | Batch_idx: 40 |  Loss: (0.0185) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 157 | Batch_idx: 50 |  Loss: (0.0191) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 157 | Batch_idx: 60 |  Loss: (0.0188) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 157 | Batch_idx: 70 |  Loss: (0.0195) | Acc: (99.48%) (9041/9088)\n",
            "Epoch: 157 | Batch_idx: 80 |  Loss: (0.0193) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 157 | Batch_idx: 90 |  Loss: (0.0195) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 157 | Batch_idx: 100 |  Loss: (0.0195) | Acc: (99.49%) (12862/12928)\n",
            "Epoch: 157 | Batch_idx: 110 |  Loss: (0.0194) | Acc: (99.51%) (14139/14208)\n",
            "Epoch: 157 | Batch_idx: 120 |  Loss: (0.0195) | Acc: (99.50%) (15411/15488)\n",
            "Epoch: 157 | Batch_idx: 130 |  Loss: (0.0199) | Acc: (99.48%) (16681/16768)\n",
            "Epoch: 157 | Batch_idx: 140 |  Loss: (0.0200) | Acc: (99.47%) (17952/18048)\n",
            "Epoch: 157 | Batch_idx: 150 |  Loss: (0.0200) | Acc: (99.47%) (19226/19328)\n",
            "Epoch: 157 | Batch_idx: 160 |  Loss: (0.0202) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 157 | Batch_idx: 170 |  Loss: (0.0200) | Acc: (99.48%) (21774/21888)\n",
            "Epoch: 157 | Batch_idx: 180 |  Loss: (0.0203) | Acc: (99.47%) (23046/23168)\n",
            "Epoch: 157 | Batch_idx: 190 |  Loss: (0.0205) | Acc: (99.46%) (24316/24448)\n",
            "Epoch: 157 | Batch_idx: 200 |  Loss: (0.0204) | Acc: (99.46%) (25590/25728)\n",
            "Epoch: 157 | Batch_idx: 210 |  Loss: (0.0202) | Acc: (99.47%) (26865/27008)\n",
            "Epoch: 157 | Batch_idx: 220 |  Loss: (0.0203) | Acc: (99.47%) (28137/28288)\n",
            "Epoch: 157 | Batch_idx: 230 |  Loss: (0.0206) | Acc: (99.46%) (29408/29568)\n",
            "Epoch: 157 | Batch_idx: 240 |  Loss: (0.0204) | Acc: (99.47%) (30684/30848)\n",
            "Epoch: 157 | Batch_idx: 250 |  Loss: (0.0205) | Acc: (99.46%) (31956/32128)\n",
            "Epoch: 157 | Batch_idx: 260 |  Loss: (0.0204) | Acc: (99.47%) (33232/33408)\n",
            "Epoch: 157 | Batch_idx: 270 |  Loss: (0.0203) | Acc: (99.49%) (34510/34688)\n",
            "Epoch: 157 | Batch_idx: 280 |  Loss: (0.0203) | Acc: (99.48%) (35782/35968)\n",
            "Epoch: 157 | Batch_idx: 290 |  Loss: (0.0200) | Acc: (99.49%) (37058/37248)\n",
            "Epoch: 157 | Batch_idx: 300 |  Loss: (0.0199) | Acc: (99.50%) (38334/38528)\n",
            "Epoch: 157 | Batch_idx: 310 |  Loss: (0.0198) | Acc: (99.50%) (39609/39808)\n",
            "Epoch: 157 | Batch_idx: 320 |  Loss: (0.0197) | Acc: (99.51%) (40886/41088)\n",
            "Epoch: 157 | Batch_idx: 330 |  Loss: (0.0196) | Acc: (99.52%) (42163/42368)\n",
            "Epoch: 157 | Batch_idx: 340 |  Loss: (0.0196) | Acc: (99.51%) (43436/43648)\n",
            "Epoch: 157 | Batch_idx: 350 |  Loss: (0.0194) | Acc: (99.52%) (44712/44928)\n",
            "Epoch: 157 | Batch_idx: 360 |  Loss: (0.0193) | Acc: (99.53%) (45990/46208)\n",
            "Epoch: 157 | Batch_idx: 370 |  Loss: (0.0194) | Acc: (99.52%) (47260/47488)\n",
            "Epoch: 157 | Batch_idx: 380 |  Loss: (0.0194) | Acc: (99.52%) (48532/48768)\n",
            "Epoch: 157 | Batch_idx: 390 |  Loss: (0.0196) | Acc: (99.51%) (49756/50000)\n",
            "# TEST : Loss: (0.3684) | Acc: (91.77%) (9177/10000)\n",
            "Epoch: 158 | Batch_idx: 0 |  Loss: (0.0375) | Acc: (97.66%) (125/128)\n",
            "Epoch: 158 | Batch_idx: 10 |  Loss: (0.0247) | Acc: (99.22%) (1397/1408)\n",
            "Epoch: 158 | Batch_idx: 20 |  Loss: (0.0222) | Acc: (99.40%) (2672/2688)\n",
            "Epoch: 158 | Batch_idx: 30 |  Loss: (0.0200) | Acc: (99.47%) (3947/3968)\n",
            "Epoch: 158 | Batch_idx: 40 |  Loss: (0.0198) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 158 | Batch_idx: 50 |  Loss: (0.0202) | Acc: (99.40%) (6489/6528)\n",
            "Epoch: 158 | Batch_idx: 60 |  Loss: (0.0198) | Acc: (99.46%) (7766/7808)\n",
            "Epoch: 158 | Batch_idx: 70 |  Loss: (0.0198) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 158 | Batch_idx: 80 |  Loss: (0.0193) | Acc: (99.51%) (10317/10368)\n",
            "Epoch: 158 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.48%) (11588/11648)\n",
            "Epoch: 158 | Batch_idx: 100 |  Loss: (0.0199) | Acc: (99.48%) (12861/12928)\n",
            "Epoch: 158 | Batch_idx: 110 |  Loss: (0.0207) | Acc: (99.46%) (14131/14208)\n",
            "Epoch: 158 | Batch_idx: 120 |  Loss: (0.0207) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 158 | Batch_idx: 130 |  Loss: (0.0204) | Acc: (99.47%) (16679/16768)\n",
            "Epoch: 158 | Batch_idx: 140 |  Loss: (0.0205) | Acc: (99.46%) (17951/18048)\n",
            "Epoch: 158 | Batch_idx: 150 |  Loss: (0.0205) | Acc: (99.46%) (19224/19328)\n",
            "Epoch: 158 | Batch_idx: 160 |  Loss: (0.0205) | Acc: (99.46%) (20496/20608)\n",
            "Epoch: 158 | Batch_idx: 170 |  Loss: (0.0204) | Acc: (99.46%) (21769/21888)\n",
            "Epoch: 158 | Batch_idx: 180 |  Loss: (0.0204) | Acc: (99.45%) (23041/23168)\n",
            "Epoch: 158 | Batch_idx: 190 |  Loss: (0.0202) | Acc: (99.45%) (24314/24448)\n",
            "Epoch: 158 | Batch_idx: 200 |  Loss: (0.0203) | Acc: (99.45%) (25586/25728)\n",
            "Epoch: 158 | Batch_idx: 210 |  Loss: (0.0199) | Acc: (99.46%) (26863/27008)\n",
            "Epoch: 158 | Batch_idx: 220 |  Loss: (0.0198) | Acc: (99.47%) (28137/28288)\n",
            "Epoch: 158 | Batch_idx: 230 |  Loss: (0.0201) | Acc: (99.46%) (29407/29568)\n",
            "Epoch: 158 | Batch_idx: 240 |  Loss: (0.0198) | Acc: (99.46%) (30681/30848)\n",
            "Epoch: 158 | Batch_idx: 250 |  Loss: (0.0199) | Acc: (99.46%) (31953/32128)\n",
            "Epoch: 158 | Batch_idx: 260 |  Loss: (0.0200) | Acc: (99.46%) (33226/33408)\n",
            "Epoch: 158 | Batch_idx: 270 |  Loss: (0.0198) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 158 | Batch_idx: 280 |  Loss: (0.0199) | Acc: (99.47%) (35778/35968)\n",
            "Epoch: 158 | Batch_idx: 290 |  Loss: (0.0198) | Acc: (99.47%) (37051/37248)\n",
            "Epoch: 158 | Batch_idx: 300 |  Loss: (0.0200) | Acc: (99.47%) (38322/38528)\n",
            "Epoch: 158 | Batch_idx: 310 |  Loss: (0.0200) | Acc: (99.46%) (39593/39808)\n",
            "Epoch: 158 | Batch_idx: 320 |  Loss: (0.0200) | Acc: (99.46%) (40866/41088)\n",
            "Epoch: 158 | Batch_idx: 330 |  Loss: (0.0200) | Acc: (99.45%) (42137/42368)\n",
            "Epoch: 158 | Batch_idx: 340 |  Loss: (0.0203) | Acc: (99.44%) (43405/43648)\n",
            "Epoch: 158 | Batch_idx: 350 |  Loss: (0.0203) | Acc: (99.44%) (44678/44928)\n",
            "Epoch: 158 | Batch_idx: 360 |  Loss: (0.0203) | Acc: (99.44%) (45950/46208)\n",
            "Epoch: 158 | Batch_idx: 370 |  Loss: (0.0203) | Acc: (99.44%) (47222/47488)\n",
            "Epoch: 158 | Batch_idx: 380 |  Loss: (0.0203) | Acc: (99.44%) (48495/48768)\n",
            "Epoch: 158 | Batch_idx: 390 |  Loss: (0.0201) | Acc: (99.44%) (49722/50000)\n",
            "# TEST : Loss: (0.3668) | Acc: (91.79%) (9179/10000)\n",
            "Epoch: 159 | Batch_idx: 0 |  Loss: (0.0166) | Acc: (100.00%) (128/128)\n",
            "Epoch: 159 | Batch_idx: 10 |  Loss: (0.0184) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 159 | Batch_idx: 20 |  Loss: (0.0201) | Acc: (99.59%) (2677/2688)\n",
            "Epoch: 159 | Batch_idx: 30 |  Loss: (0.0194) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 159 | Batch_idx: 40 |  Loss: (0.0211) | Acc: (99.50%) (5222/5248)\n",
            "Epoch: 159 | Batch_idx: 50 |  Loss: (0.0199) | Acc: (99.56%) (6499/6528)\n",
            "Epoch: 159 | Batch_idx: 60 |  Loss: (0.0197) | Acc: (99.54%) (7772/7808)\n",
            "Epoch: 159 | Batch_idx: 70 |  Loss: (0.0191) | Acc: (99.55%) (9047/9088)\n",
            "Epoch: 159 | Batch_idx: 80 |  Loss: (0.0197) | Acc: (99.52%) (10318/10368)\n",
            "Epoch: 159 | Batch_idx: 90 |  Loss: (0.0198) | Acc: (99.49%) (11589/11648)\n",
            "Epoch: 159 | Batch_idx: 100 |  Loss: (0.0198) | Acc: (99.50%) (12864/12928)\n",
            "Epoch: 159 | Batch_idx: 110 |  Loss: (0.0204) | Acc: (99.51%) (14139/14208)\n",
            "Epoch: 159 | Batch_idx: 120 |  Loss: (0.0203) | Acc: (99.52%) (15413/15488)\n",
            "Epoch: 159 | Batch_idx: 130 |  Loss: (0.0204) | Acc: (99.51%) (16686/16768)\n",
            "Epoch: 159 | Batch_idx: 140 |  Loss: (0.0198) | Acc: (99.53%) (17963/18048)\n",
            "Epoch: 159 | Batch_idx: 150 |  Loss: (0.0197) | Acc: (99.54%) (19240/19328)\n",
            "Epoch: 159 | Batch_idx: 160 |  Loss: (0.0192) | Acc: (99.57%) (20519/20608)\n",
            "Epoch: 159 | Batch_idx: 170 |  Loss: (0.0193) | Acc: (99.54%) (21788/21888)\n",
            "Epoch: 159 | Batch_idx: 180 |  Loss: (0.0195) | Acc: (99.54%) (23062/23168)\n",
            "Epoch: 159 | Batch_idx: 190 |  Loss: (0.0197) | Acc: (99.53%) (24334/24448)\n",
            "Epoch: 159 | Batch_idx: 200 |  Loss: (0.0202) | Acc: (99.50%) (25600/25728)\n",
            "Epoch: 159 | Batch_idx: 210 |  Loss: (0.0200) | Acc: (99.50%) (26873/27008)\n",
            "Epoch: 159 | Batch_idx: 220 |  Loss: (0.0199) | Acc: (99.49%) (28145/28288)\n",
            "Epoch: 159 | Batch_idx: 230 |  Loss: (0.0201) | Acc: (99.49%) (29418/29568)\n",
            "Epoch: 159 | Batch_idx: 240 |  Loss: (0.0201) | Acc: (99.49%) (30692/30848)\n",
            "Epoch: 159 | Batch_idx: 250 |  Loss: (0.0199) | Acc: (99.51%) (31969/32128)\n",
            "Epoch: 159 | Batch_idx: 260 |  Loss: (0.0198) | Acc: (99.51%) (33243/33408)\n",
            "Epoch: 159 | Batch_idx: 270 |  Loss: (0.0197) | Acc: (99.52%) (34520/34688)\n",
            "Epoch: 159 | Batch_idx: 280 |  Loss: (0.0198) | Acc: (99.51%) (35793/35968)\n",
            "Epoch: 159 | Batch_idx: 290 |  Loss: (0.0199) | Acc: (99.50%) (37061/37248)\n",
            "Epoch: 159 | Batch_idx: 300 |  Loss: (0.0199) | Acc: (99.50%) (38334/38528)\n",
            "Epoch: 159 | Batch_idx: 310 |  Loss: (0.0198) | Acc: (99.50%) (39608/39808)\n",
            "Epoch: 159 | Batch_idx: 320 |  Loss: (0.0199) | Acc: (99.48%) (40876/41088)\n",
            "Epoch: 159 | Batch_idx: 330 |  Loss: (0.0199) | Acc: (99.48%) (42148/42368)\n",
            "Epoch: 159 | Batch_idx: 340 |  Loss: (0.0200) | Acc: (99.47%) (43417/43648)\n",
            "Epoch: 159 | Batch_idx: 350 |  Loss: (0.0201) | Acc: (99.46%) (44686/44928)\n",
            "Epoch: 159 | Batch_idx: 360 |  Loss: (0.0200) | Acc: (99.47%) (45963/46208)\n",
            "Epoch: 159 | Batch_idx: 370 |  Loss: (0.0203) | Acc: (99.45%) (47227/47488)\n",
            "Epoch: 159 | Batch_idx: 380 |  Loss: (0.0203) | Acc: (99.45%) (48500/48768)\n",
            "Epoch: 159 | Batch_idx: 390 |  Loss: (0.0203) | Acc: (99.45%) (49727/50000)\n",
            "# TEST : Loss: (0.3651) | Acc: (91.87%) (9187/10000)\n",
            "Epoch: 160 | Batch_idx: 0 |  Loss: (0.0150) | Acc: (99.22%) (127/128)\n",
            "Epoch: 160 | Batch_idx: 10 |  Loss: (0.0165) | Acc: (99.57%) (1402/1408)\n",
            "Epoch: 160 | Batch_idx: 20 |  Loss: (0.0172) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 160 | Batch_idx: 30 |  Loss: (0.0169) | Acc: (99.60%) (3952/3968)\n",
            "Epoch: 160 | Batch_idx: 40 |  Loss: (0.0170) | Acc: (99.52%) (5223/5248)\n",
            "Epoch: 160 | Batch_idx: 50 |  Loss: (0.0178) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 160 | Batch_idx: 60 |  Loss: (0.0185) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 160 | Batch_idx: 70 |  Loss: (0.0186) | Acc: (99.47%) (9040/9088)\n",
            "Epoch: 160 | Batch_idx: 80 |  Loss: (0.0195) | Acc: (99.43%) (10309/10368)\n",
            "Epoch: 160 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.44%) (11583/11648)\n",
            "Epoch: 160 | Batch_idx: 100 |  Loss: (0.0194) | Acc: (99.47%) (12860/12928)\n",
            "Epoch: 160 | Batch_idx: 110 |  Loss: (0.0202) | Acc: (99.44%) (14128/14208)\n",
            "Epoch: 160 | Batch_idx: 120 |  Loss: (0.0197) | Acc: (99.46%) (15404/15488)\n",
            "Epoch: 160 | Batch_idx: 130 |  Loss: (0.0199) | Acc: (99.46%) (16677/16768)\n",
            "Epoch: 160 | Batch_idx: 140 |  Loss: (0.0198) | Acc: (99.47%) (17952/18048)\n",
            "Epoch: 160 | Batch_idx: 150 |  Loss: (0.0199) | Acc: (99.46%) (19224/19328)\n",
            "Epoch: 160 | Batch_idx: 160 |  Loss: (0.0200) | Acc: (99.46%) (20497/20608)\n",
            "Epoch: 160 | Batch_idx: 170 |  Loss: (0.0200) | Acc: (99.47%) (21771/21888)\n",
            "Epoch: 160 | Batch_idx: 180 |  Loss: (0.0199) | Acc: (99.47%) (23046/23168)\n",
            "Epoch: 160 | Batch_idx: 190 |  Loss: (0.0199) | Acc: (99.47%) (24318/24448)\n",
            "Epoch: 160 | Batch_idx: 200 |  Loss: (0.0195) | Acc: (99.48%) (25595/25728)\n",
            "Epoch: 160 | Batch_idx: 210 |  Loss: (0.0195) | Acc: (99.48%) (26868/27008)\n",
            "Epoch: 160 | Batch_idx: 220 |  Loss: (0.0196) | Acc: (99.48%) (28140/28288)\n",
            "Epoch: 160 | Batch_idx: 230 |  Loss: (0.0197) | Acc: (99.47%) (29411/29568)\n",
            "Epoch: 160 | Batch_idx: 240 |  Loss: (0.0198) | Acc: (99.47%) (30685/30848)\n",
            "Epoch: 160 | Batch_idx: 250 |  Loss: (0.0198) | Acc: (99.46%) (31956/32128)\n",
            "Epoch: 160 | Batch_idx: 260 |  Loss: (0.0198) | Acc: (99.47%) (33230/33408)\n",
            "Epoch: 160 | Batch_idx: 270 |  Loss: (0.0196) | Acc: (99.47%) (34504/34688)\n",
            "Epoch: 160 | Batch_idx: 280 |  Loss: (0.0195) | Acc: (99.47%) (35779/35968)\n",
            "Epoch: 160 | Batch_idx: 290 |  Loss: (0.0196) | Acc: (99.47%) (37052/37248)\n",
            "Epoch: 160 | Batch_idx: 300 |  Loss: (0.0195) | Acc: (99.48%) (38327/38528)\n",
            "Epoch: 160 | Batch_idx: 310 |  Loss: (0.0197) | Acc: (99.47%) (39598/39808)\n",
            "Epoch: 160 | Batch_idx: 320 |  Loss: (0.0199) | Acc: (99.47%) (40870/41088)\n",
            "Epoch: 160 | Batch_idx: 330 |  Loss: (0.0200) | Acc: (99.46%) (42141/42368)\n",
            "Epoch: 160 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.46%) (43413/43648)\n",
            "Epoch: 160 | Batch_idx: 350 |  Loss: (0.0201) | Acc: (99.46%) (44685/44928)\n",
            "Epoch: 160 | Batch_idx: 360 |  Loss: (0.0201) | Acc: (99.45%) (45955/46208)\n",
            "Epoch: 160 | Batch_idx: 370 |  Loss: (0.0201) | Acc: (99.45%) (47226/47488)\n",
            "Epoch: 160 | Batch_idx: 380 |  Loss: (0.0201) | Acc: (99.45%) (48498/48768)\n",
            "Epoch: 160 | Batch_idx: 390 |  Loss: (0.0201) | Acc: (99.45%) (49727/50000)\n",
            "# TEST : Loss: (0.3665) | Acc: (91.81%) (9181/10000)\n",
            "Epoch: 161 | Batch_idx: 0 |  Loss: (0.0146) | Acc: (99.22%) (127/128)\n",
            "Epoch: 161 | Batch_idx: 10 |  Loss: (0.0191) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 161 | Batch_idx: 20 |  Loss: (0.0163) | Acc: (99.55%) (2676/2688)\n",
            "Epoch: 161 | Batch_idx: 30 |  Loss: (0.0174) | Acc: (99.55%) (3950/3968)\n",
            "Epoch: 161 | Batch_idx: 40 |  Loss: (0.0168) | Acc: (99.58%) (5226/5248)\n",
            "Epoch: 161 | Batch_idx: 50 |  Loss: (0.0163) | Acc: (99.62%) (6503/6528)\n",
            "Epoch: 161 | Batch_idx: 60 |  Loss: (0.0167) | Acc: (99.58%) (7775/7808)\n",
            "Epoch: 161 | Batch_idx: 70 |  Loss: (0.0164) | Acc: (99.59%) (9051/9088)\n",
            "Epoch: 161 | Batch_idx: 80 |  Loss: (0.0171) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 161 | Batch_idx: 90 |  Loss: (0.0175) | Acc: (99.55%) (11596/11648)\n",
            "Epoch: 161 | Batch_idx: 100 |  Loss: (0.0181) | Acc: (99.54%) (12869/12928)\n",
            "Epoch: 161 | Batch_idx: 110 |  Loss: (0.0183) | Acc: (99.54%) (14143/14208)\n",
            "Epoch: 161 | Batch_idx: 120 |  Loss: (0.0185) | Acc: (99.54%) (15416/15488)\n",
            "Epoch: 161 | Batch_idx: 130 |  Loss: (0.0190) | Acc: (99.52%) (16687/16768)\n",
            "Epoch: 161 | Batch_idx: 140 |  Loss: (0.0193) | Acc: (99.51%) (17960/18048)\n",
            "Epoch: 161 | Batch_idx: 150 |  Loss: (0.0192) | Acc: (99.52%) (19235/19328)\n",
            "Epoch: 161 | Batch_idx: 160 |  Loss: (0.0201) | Acc: (99.48%) (20501/20608)\n",
            "Epoch: 161 | Batch_idx: 170 |  Loss: (0.0197) | Acc: (99.49%) (21777/21888)\n",
            "Epoch: 161 | Batch_idx: 180 |  Loss: (0.0196) | Acc: (99.49%) (23051/23168)\n",
            "Epoch: 161 | Batch_idx: 190 |  Loss: (0.0198) | Acc: (99.48%) (24322/24448)\n",
            "Epoch: 161 | Batch_idx: 200 |  Loss: (0.0198) | Acc: (99.48%) (25594/25728)\n",
            "Epoch: 161 | Batch_idx: 210 |  Loss: (0.0197) | Acc: (99.49%) (26869/27008)\n",
            "Epoch: 161 | Batch_idx: 220 |  Loss: (0.0203) | Acc: (99.46%) (28134/28288)\n",
            "Epoch: 161 | Batch_idx: 230 |  Loss: (0.0202) | Acc: (99.45%) (29406/29568)\n",
            "Epoch: 161 | Batch_idx: 240 |  Loss: (0.0200) | Acc: (99.47%) (30683/30848)\n",
            "Epoch: 161 | Batch_idx: 250 |  Loss: (0.0201) | Acc: (99.47%) (31957/32128)\n",
            "Epoch: 161 | Batch_idx: 260 |  Loss: (0.0198) | Acc: (99.48%) (33235/33408)\n",
            "Epoch: 161 | Batch_idx: 270 |  Loss: (0.0197) | Acc: (99.48%) (34509/34688)\n",
            "Epoch: 161 | Batch_idx: 280 |  Loss: (0.0199) | Acc: (99.47%) (35779/35968)\n",
            "Epoch: 161 | Batch_idx: 290 |  Loss: (0.0198) | Acc: (99.48%) (37053/37248)\n",
            "Epoch: 161 | Batch_idx: 300 |  Loss: (0.0200) | Acc: (99.47%) (38325/38528)\n",
            "Epoch: 161 | Batch_idx: 310 |  Loss: (0.0199) | Acc: (99.48%) (39600/39808)\n",
            "Epoch: 161 | Batch_idx: 320 |  Loss: (0.0200) | Acc: (99.47%) (40872/41088)\n",
            "Epoch: 161 | Batch_idx: 330 |  Loss: (0.0200) | Acc: (99.48%) (42146/42368)\n",
            "Epoch: 161 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.48%) (43419/43648)\n",
            "Epoch: 161 | Batch_idx: 350 |  Loss: (0.0200) | Acc: (99.48%) (44695/44928)\n",
            "Epoch: 161 | Batch_idx: 360 |  Loss: (0.0199) | Acc: (99.48%) (45969/46208)\n",
            "Epoch: 161 | Batch_idx: 370 |  Loss: (0.0201) | Acc: (99.48%) (47242/47488)\n",
            "Epoch: 161 | Batch_idx: 380 |  Loss: (0.0200) | Acc: (99.49%) (48518/48768)\n",
            "Epoch: 161 | Batch_idx: 390 |  Loss: (0.0202) | Acc: (99.48%) (49739/50000)\n",
            "# TEST : Loss: (0.3669) | Acc: (91.83%) (9183/10000)\n",
            "Epoch: 162 | Batch_idx: 0 |  Loss: (0.0148) | Acc: (100.00%) (128/128)\n",
            "Epoch: 162 | Batch_idx: 10 |  Loss: (0.0179) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 162 | Batch_idx: 20 |  Loss: (0.0203) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 162 | Batch_idx: 30 |  Loss: (0.0194) | Acc: (99.50%) (3948/3968)\n",
            "Epoch: 162 | Batch_idx: 40 |  Loss: (0.0185) | Acc: (99.49%) (5221/5248)\n",
            "Epoch: 162 | Batch_idx: 50 |  Loss: (0.0194) | Acc: (99.46%) (6493/6528)\n",
            "Epoch: 162 | Batch_idx: 60 |  Loss: (0.0198) | Acc: (99.47%) (7767/7808)\n",
            "Epoch: 162 | Batch_idx: 70 |  Loss: (0.0195) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 162 | Batch_idx: 80 |  Loss: (0.0194) | Acc: (99.53%) (10319/10368)\n",
            "Epoch: 162 | Batch_idx: 90 |  Loss: (0.0197) | Acc: (99.51%) (11591/11648)\n",
            "Epoch: 162 | Batch_idx: 100 |  Loss: (0.0202) | Acc: (99.49%) (12862/12928)\n",
            "Epoch: 162 | Batch_idx: 110 |  Loss: (0.0198) | Acc: (99.49%) (14135/14208)\n",
            "Epoch: 162 | Batch_idx: 120 |  Loss: (0.0202) | Acc: (99.46%) (15405/15488)\n",
            "Epoch: 162 | Batch_idx: 130 |  Loss: (0.0204) | Acc: (99.44%) (16674/16768)\n",
            "Epoch: 162 | Batch_idx: 140 |  Loss: (0.0203) | Acc: (99.45%) (17948/18048)\n",
            "Epoch: 162 | Batch_idx: 150 |  Loss: (0.0204) | Acc: (99.44%) (19220/19328)\n",
            "Epoch: 162 | Batch_idx: 160 |  Loss: (0.0205) | Acc: (99.43%) (20491/20608)\n",
            "Epoch: 162 | Batch_idx: 170 |  Loss: (0.0203) | Acc: (99.45%) (21767/21888)\n",
            "Epoch: 162 | Batch_idx: 180 |  Loss: (0.0202) | Acc: (99.45%) (23041/23168)\n",
            "Epoch: 162 | Batch_idx: 190 |  Loss: (0.0201) | Acc: (99.45%) (24314/24448)\n",
            "Epoch: 162 | Batch_idx: 200 |  Loss: (0.0204) | Acc: (99.44%) (25583/25728)\n",
            "Epoch: 162 | Batch_idx: 210 |  Loss: (0.0206) | Acc: (99.44%) (26856/27008)\n",
            "Epoch: 162 | Batch_idx: 220 |  Loss: (0.0206) | Acc: (99.43%) (28128/28288)\n",
            "Epoch: 162 | Batch_idx: 230 |  Loss: (0.0206) | Acc: (99.45%) (29405/29568)\n",
            "Epoch: 162 | Batch_idx: 240 |  Loss: (0.0205) | Acc: (99.44%) (30675/30848)\n",
            "Epoch: 162 | Batch_idx: 250 |  Loss: (0.0205) | Acc: (99.44%) (31948/32128)\n",
            "Epoch: 162 | Batch_idx: 260 |  Loss: (0.0204) | Acc: (99.45%) (33225/33408)\n",
            "Epoch: 162 | Batch_idx: 270 |  Loss: (0.0204) | Acc: (99.45%) (34496/34688)\n",
            "Epoch: 162 | Batch_idx: 280 |  Loss: (0.0204) | Acc: (99.45%) (35769/35968)\n",
            "Epoch: 162 | Batch_idx: 290 |  Loss: (0.0202) | Acc: (99.45%) (37044/37248)\n",
            "Epoch: 162 | Batch_idx: 300 |  Loss: (0.0202) | Acc: (99.45%) (38317/38528)\n",
            "Epoch: 162 | Batch_idx: 310 |  Loss: (0.0202) | Acc: (99.45%) (39590/39808)\n",
            "Epoch: 162 | Batch_idx: 320 |  Loss: (0.0203) | Acc: (99.45%) (40864/41088)\n",
            "Epoch: 162 | Batch_idx: 330 |  Loss: (0.0202) | Acc: (99.46%) (42139/42368)\n",
            "Epoch: 162 | Batch_idx: 340 |  Loss: (0.0201) | Acc: (99.46%) (43414/43648)\n",
            "Epoch: 162 | Batch_idx: 350 |  Loss: (0.0200) | Acc: (99.47%) (44689/44928)\n",
            "Epoch: 162 | Batch_idx: 360 |  Loss: (0.0201) | Acc: (99.47%) (45961/46208)\n",
            "Epoch: 162 | Batch_idx: 370 |  Loss: (0.0202) | Acc: (99.46%) (47232/47488)\n",
            "Epoch: 162 | Batch_idx: 380 |  Loss: (0.0202) | Acc: (99.46%) (48505/48768)\n",
            "Epoch: 162 | Batch_idx: 390 |  Loss: (0.0201) | Acc: (99.46%) (49732/50000)\n",
            "# TEST : Loss: (0.3633) | Acc: (91.92%) (9192/10000)\n",
            "Epoch: 163 | Batch_idx: 0 |  Loss: (0.0064) | Acc: (100.00%) (128/128)\n",
            "Epoch: 163 | Batch_idx: 10 |  Loss: (0.0196) | Acc: (99.64%) (1403/1408)\n",
            "Epoch: 163 | Batch_idx: 20 |  Loss: (0.0226) | Acc: (99.44%) (2673/2688)\n",
            "Epoch: 163 | Batch_idx: 30 |  Loss: (0.0211) | Acc: (99.52%) (3949/3968)\n",
            "Epoch: 163 | Batch_idx: 40 |  Loss: (0.0219) | Acc: (99.43%) (5218/5248)\n",
            "Epoch: 163 | Batch_idx: 50 |  Loss: (0.0206) | Acc: (99.48%) (6494/6528)\n",
            "Epoch: 163 | Batch_idx: 60 |  Loss: (0.0200) | Acc: (99.49%) (7768/7808)\n",
            "Epoch: 163 | Batch_idx: 70 |  Loss: (0.0197) | Acc: (99.49%) (9042/9088)\n",
            "Epoch: 163 | Batch_idx: 80 |  Loss: (0.0205) | Acc: (99.47%) (10313/10368)\n",
            "Epoch: 163 | Batch_idx: 90 |  Loss: (0.0207) | Acc: (99.45%) (11584/11648)\n",
            "Epoch: 163 | Batch_idx: 100 |  Loss: (0.0212) | Acc: (99.40%) (12851/12928)\n",
            "Epoch: 163 | Batch_idx: 110 |  Loss: (0.0209) | Acc: (99.40%) (14123/14208)\n",
            "Epoch: 163 | Batch_idx: 120 |  Loss: (0.0208) | Acc: (99.40%) (15395/15488)\n",
            "Epoch: 163 | Batch_idx: 130 |  Loss: (0.0207) | Acc: (99.41%) (16669/16768)\n",
            "Epoch: 163 | Batch_idx: 140 |  Loss: (0.0205) | Acc: (99.41%) (17942/18048)\n",
            "Epoch: 163 | Batch_idx: 150 |  Loss: (0.0206) | Acc: (99.42%) (19216/19328)\n",
            "Epoch: 163 | Batch_idx: 160 |  Loss: (0.0208) | Acc: (99.42%) (20489/20608)\n",
            "Epoch: 163 | Batch_idx: 170 |  Loss: (0.0211) | Acc: (99.41%) (21758/21888)\n",
            "Epoch: 163 | Batch_idx: 180 |  Loss: (0.0211) | Acc: (99.40%) (23030/23168)\n",
            "Epoch: 163 | Batch_idx: 190 |  Loss: (0.0214) | Acc: (99.38%) (24297/24448)\n",
            "Epoch: 163 | Batch_idx: 200 |  Loss: (0.0214) | Acc: (99.39%) (25570/25728)\n",
            "Epoch: 163 | Batch_idx: 210 |  Loss: (0.0213) | Acc: (99.39%) (26844/27008)\n",
            "Epoch: 163 | Batch_idx: 220 |  Loss: (0.0213) | Acc: (99.40%) (28118/28288)\n",
            "Epoch: 163 | Batch_idx: 230 |  Loss: (0.0213) | Acc: (99.39%) (29389/29568)\n",
            "Epoch: 163 | Batch_idx: 240 |  Loss: (0.0211) | Acc: (99.41%) (30665/30848)\n",
            "Epoch: 163 | Batch_idx: 250 |  Loss: (0.0210) | Acc: (99.41%) (31937/32128)\n",
            "Epoch: 163 | Batch_idx: 260 |  Loss: (0.0209) | Acc: (99.41%) (33211/33408)\n",
            "Epoch: 163 | Batch_idx: 270 |  Loss: (0.0210) | Acc: (99.40%) (34481/34688)\n",
            "Epoch: 163 | Batch_idx: 280 |  Loss: (0.0210) | Acc: (99.41%) (35756/35968)\n",
            "Epoch: 163 | Batch_idx: 290 |  Loss: (0.0211) | Acc: (99.41%) (37027/37248)\n",
            "Epoch: 163 | Batch_idx: 300 |  Loss: (0.0210) | Acc: (99.41%) (38300/38528)\n",
            "Epoch: 163 | Batch_idx: 310 |  Loss: (0.0210) | Acc: (99.41%) (39573/39808)\n",
            "Epoch: 163 | Batch_idx: 320 |  Loss: (0.0209) | Acc: (99.41%) (40846/41088)\n",
            "Epoch: 163 | Batch_idx: 330 |  Loss: (0.0209) | Acc: (99.41%) (42118/42368)\n",
            "Epoch: 163 | Batch_idx: 340 |  Loss: (0.0207) | Acc: (99.42%) (43394/43648)\n",
            "Epoch: 163 | Batch_idx: 350 |  Loss: (0.0207) | Acc: (99.42%) (44668/44928)\n",
            "Epoch: 163 | Batch_idx: 360 |  Loss: (0.0207) | Acc: (99.42%) (45939/46208)\n",
            "Epoch: 163 | Batch_idx: 370 |  Loss: (0.0206) | Acc: (99.43%) (47217/47488)\n",
            "Epoch: 163 | Batch_idx: 380 |  Loss: (0.0205) | Acc: (99.43%) (48492/48768)\n",
            "Epoch: 163 | Batch_idx: 390 |  Loss: (0.0206) | Acc: (99.43%) (49717/50000)\n",
            "# TEST : Loss: (0.3628) | Acc: (91.94%) (9194/10000)\n",
            "Epoch: 164 | Batch_idx: 0 |  Loss: (0.0162) | Acc: (100.00%) (128/128)\n",
            "Epoch: 164 | Batch_idx: 10 |  Loss: (0.0200) | Acc: (99.43%) (1400/1408)\n",
            "Epoch: 164 | Batch_idx: 20 |  Loss: (0.0202) | Acc: (99.48%) (2674/2688)\n",
            "Epoch: 164 | Batch_idx: 30 |  Loss: (0.0213) | Acc: (99.34%) (3942/3968)\n",
            "Epoch: 164 | Batch_idx: 40 |  Loss: (0.0200) | Acc: (99.45%) (5219/5248)\n",
            "Epoch: 164 | Batch_idx: 50 |  Loss: (0.0202) | Acc: (99.49%) (6495/6528)\n",
            "Epoch: 164 | Batch_idx: 60 |  Loss: (0.0191) | Acc: (99.53%) (7771/7808)\n",
            "Epoch: 164 | Batch_idx: 70 |  Loss: (0.0185) | Acc: (99.56%) (9048/9088)\n",
            "Epoch: 164 | Batch_idx: 80 |  Loss: (0.0190) | Acc: (99.55%) (10321/10368)\n",
            "Epoch: 164 | Batch_idx: 90 |  Loss: (0.0186) | Acc: (99.56%) (11597/11648)\n",
            "Epoch: 164 | Batch_idx: 100 |  Loss: (0.0184) | Acc: (99.58%) (12874/12928)\n",
            "Epoch: 164 | Batch_idx: 110 |  Loss: (0.0187) | Acc: (99.57%) (14147/14208)\n",
            "Epoch: 164 | Batch_idx: 120 |  Loss: (0.0187) | Acc: (99.55%) (15419/15488)\n",
            "Epoch: 164 | Batch_idx: 130 |  Loss: (0.0191) | Acc: (99.52%) (16688/16768)\n",
            "Epoch: 164 | Batch_idx: 140 |  Loss: (0.0190) | Acc: (99.53%) (17963/18048)\n",
            "Epoch: 164 | Batch_idx: 150 |  Loss: (0.0188) | Acc: (99.55%) (19241/19328)\n",
            "Epoch: 164 | Batch_idx: 160 |  Loss: (0.0189) | Acc: (99.53%) (20512/20608)\n",
            "Epoch: 164 | Batch_idx: 170 |  Loss: (0.0191) | Acc: (99.53%) (21785/21888)\n",
            "Epoch: 164 | Batch_idx: 180 |  Loss: (0.0187) | Acc: (99.54%) (23062/23168)\n",
            "Epoch: 164 | Batch_idx: 190 |  Loss: (0.0188) | Acc: (99.53%) (24333/24448)\n",
            "Epoch: 164 | Batch_idx: 200 |  Loss: (0.0191) | Acc: (99.51%) (25603/25728)\n",
            "Epoch: 164 | Batch_idx: 210 |  Loss: (0.0191) | Acc: (99.51%) (26875/27008)\n",
            "Epoch: 164 | Batch_idx: 220 |  Loss: (0.0190) | Acc: (99.51%) (28150/28288)\n",
            "Epoch: 164 | Batch_idx: 230 |  Loss: (0.0190) | Acc: (99.50%) (29420/29568)\n",
            "Epoch: 164 | Batch_idx: 240 |  Loss: (0.0189) | Acc: (99.51%) (30696/30848)\n",
            "Epoch: 164 | Batch_idx: 250 |  Loss: (0.0188) | Acc: (99.51%) (31971/32128)\n",
            "Epoch: 164 | Batch_idx: 260 |  Loss: (0.0187) | Acc: (99.51%) (33245/33408)\n",
            "Epoch: 164 | Batch_idx: 270 |  Loss: (0.0190) | Acc: (99.50%) (34514/34688)\n",
            "Epoch: 164 | Batch_idx: 280 |  Loss: (0.0189) | Acc: (99.49%) (35786/35968)\n",
            "Epoch: 164 | Batch_idx: 290 |  Loss: (0.0191) | Acc: (99.48%) (37053/37248)\n",
            "Epoch: 164 | Batch_idx: 300 |  Loss: (0.0191) | Acc: (99.49%) (38330/38528)\n",
            "Epoch: 164 | Batch_idx: 310 |  Loss: (0.0191) | Acc: (99.49%) (39603/39808)\n",
            "Epoch: 164 | Batch_idx: 320 |  Loss: (0.0193) | Acc: (99.47%) (40871/41088)\n",
            "Epoch: 164 | Batch_idx: 330 |  Loss: (0.0192) | Acc: (99.48%) (42149/42368)\n",
            "Epoch: 164 | Batch_idx: 340 |  Loss: (0.0191) | Acc: (99.48%) (43423/43648)\n",
            "Epoch: 164 | Batch_idx: 350 |  Loss: (0.0191) | Acc: (99.49%) (44697/44928)\n",
            "Epoch: 164 | Batch_idx: 360 |  Loss: (0.0193) | Acc: (99.48%) (45966/46208)\n",
            "Epoch: 164 | Batch_idx: 370 |  Loss: (0.0193) | Acc: (99.47%) (47238/47488)\n",
            "Epoch: 164 | Batch_idx: 380 |  Loss: (0.0195) | Acc: (99.47%) (48508/48768)\n",
            "Epoch: 164 | Batch_idx: 390 |  Loss: (0.0196) | Acc: (99.47%) (49734/50000)\n",
            "# TEST : Loss: (0.3644) | Acc: (91.85%) (9185/10000)\n",
            "1 hours 18 mins 15 secs for training\n"
          ]
        }
      ]
    }
  ]
}